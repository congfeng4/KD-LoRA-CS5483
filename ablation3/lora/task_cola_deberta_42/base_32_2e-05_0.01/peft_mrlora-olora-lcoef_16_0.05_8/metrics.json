{
    "eval_loss": 0.549129843711853,
    "eval_matthews_correlation": 0.6632431890370206,
    "eval_runtime": 0.5367,
    "eval_samples_per_second": 1943.306,
    "eval_steps_per_second": 16.769,
    "epoch": 86.56716417910448,
    "log_history": [
        {
            "loss": 0.6308,
            "grad_norm": 0.22324423491954803,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6187940835952759,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5981,
            "eval_samples_per_second": 1743.74,
            "eval_steps_per_second": 15.047,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.6005,
            "grad_norm": 0.6476060152053833,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.5642479062080383,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5501,
            "eval_samples_per_second": 1896.06,
            "eval_steps_per_second": 16.361,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4668,
            "grad_norm": 0.387513667345047,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4287274479866028,
            "eval_matthews_correlation": 0.5756414302422657,
            "eval_runtime": 0.561,
            "eval_samples_per_second": 1859.023,
            "eval_steps_per_second": 16.041,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3713,
            "grad_norm": 0.7926609516143799,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.38461610674858093,
            "eval_matthews_correlation": 0.6041033887691281,
            "eval_runtime": 0.6322,
            "eval_samples_per_second": 1649.902,
            "eval_steps_per_second": 14.237,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.324,
            "grad_norm": 0.4236554503440857,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3877451717853546,
            "eval_matthews_correlation": 0.5964966623441297,
            "eval_runtime": 0.598,
            "eval_samples_per_second": 1744.228,
            "eval_steps_per_second": 15.051,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2968,
            "grad_norm": 0.6181328296661377,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.38598766922950745,
            "eval_matthews_correlation": 0.6088262979015748,
            "eval_runtime": 0.5043,
            "eval_samples_per_second": 2068.133,
            "eval_steps_per_second": 17.846,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.274,
            "grad_norm": 0.49317261576652527,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.41692107915878296,
            "eval_matthews_correlation": 0.6306644810568987,
            "eval_runtime": 0.5842,
            "eval_samples_per_second": 1785.318,
            "eval_steps_per_second": 15.405,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2529,
            "grad_norm": 0.6824121475219727,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.4121432304382324,
            "eval_matthews_correlation": 0.6281597157868146,
            "eval_runtime": 0.5932,
            "eval_samples_per_second": 1758.402,
            "eval_steps_per_second": 15.173,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2319,
            "grad_norm": 0.6307359933853149,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4114665389060974,
            "eval_matthews_correlation": 0.6214080153834024,
            "eval_runtime": 0.6031,
            "eval_samples_per_second": 1729.321,
            "eval_steps_per_second": 14.922,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2182,
            "grad_norm": 0.8321710228919983,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.42851150035858154,
            "eval_matthews_correlation": 0.6357914877947441,
            "eval_runtime": 0.5828,
            "eval_samples_per_second": 1789.568,
            "eval_steps_per_second": 15.442,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2005,
            "grad_norm": 0.7289833426475525,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4324820041656494,
            "eval_matthews_correlation": 0.6365971662319485,
            "eval_runtime": 0.6442,
            "eval_samples_per_second": 1619.175,
            "eval_steps_per_second": 13.972,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1905,
            "grad_norm": 1.6171984672546387,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.4592825770378113,
            "eval_matthews_correlation": 0.6431581256935667,
            "eval_runtime": 0.6153,
            "eval_samples_per_second": 1695.075,
            "eval_steps_per_second": 14.627,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1768,
            "grad_norm": 0.5547059178352356,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.4964216947555542,
            "eval_matthews_correlation": 0.6331219341866674,
            "eval_runtime": 0.6125,
            "eval_samples_per_second": 1702.902,
            "eval_steps_per_second": 14.694,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1651,
            "grad_norm": 0.5456874370574951,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4883725047111511,
            "eval_matthews_correlation": 0.6381410668671454,
            "eval_runtime": 0.5882,
            "eval_samples_per_second": 1773.136,
            "eval_steps_per_second": 15.3,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1565,
            "grad_norm": 1.0919044017791748,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.49104124307632446,
            "eval_matthews_correlation": 0.6490535130984493,
            "eval_runtime": 0.585,
            "eval_samples_per_second": 1782.97,
            "eval_steps_per_second": 15.385,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1486,
            "grad_norm": 0.6200135350227356,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.49939650297164917,
            "eval_matthews_correlation": 0.6510271324239202,
            "eval_runtime": 0.6135,
            "eval_samples_per_second": 1700.157,
            "eval_steps_per_second": 14.671,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.145,
            "grad_norm": 0.6098083257675171,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.5164026618003845,
            "eval_matthews_correlation": 0.6511813794482872,
            "eval_runtime": 0.63,
            "eval_samples_per_second": 1655.609,
            "eval_steps_per_second": 14.286,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1369,
            "grad_norm": 1.053141474723816,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.5381473898887634,
            "eval_matthews_correlation": 0.6437317767243795,
            "eval_runtime": 0.5679,
            "eval_samples_per_second": 1836.482,
            "eval_steps_per_second": 15.847,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.1312,
            "grad_norm": 0.9075177907943726,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.5119879841804504,
            "eval_matthews_correlation": 0.656708330806228,
            "eval_runtime": 0.6805,
            "eval_samples_per_second": 1532.674,
            "eval_steps_per_second": 13.225,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.1248,
            "grad_norm": 0.7174238562583923,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.5456758141517639,
            "eval_matthews_correlation": 0.6359929134078908,
            "eval_runtime": 0.4872,
            "eval_samples_per_second": 2140.897,
            "eval_steps_per_second": 18.474,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.119,
            "grad_norm": 0.3675940930843353,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.539175808429718,
            "eval_matthews_correlation": 0.6535040856814195,
            "eval_runtime": 0.5641,
            "eval_samples_per_second": 1849.053,
            "eval_steps_per_second": 15.955,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.1149,
            "grad_norm": 0.9599641561508179,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.5423457026481628,
            "eval_matthews_correlation": 0.6561372224507469,
            "eval_runtime": 0.4887,
            "eval_samples_per_second": 2134.222,
            "eval_steps_per_second": 18.416,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.117,
            "grad_norm": 0.6690283417701721,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.5491874814033508,
            "eval_matthews_correlation": 0.6535040856814195,
            "eval_runtime": 0.5089,
            "eval_samples_per_second": 2049.642,
            "eval_steps_per_second": 17.686,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.1122,
            "grad_norm": 1.7729932069778442,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.549129843711853,
            "eval_matthews_correlation": 0.6632431890370206,
            "eval_runtime": 0.4954,
            "eval_samples_per_second": 2105.29,
            "eval_steps_per_second": 18.166,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.1073,
            "grad_norm": 0.9220065474510193,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.5964077115058899,
            "eval_matthews_correlation": 0.6406194503745494,
            "eval_runtime": 0.5372,
            "eval_samples_per_second": 1941.572,
            "eval_steps_per_second": 16.754,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.1019,
            "grad_norm": 0.8606393933296204,
            "learning_rate": 4.975124378109453e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.5946199297904968,
            "eval_matthews_correlation": 0.6358835820536083,
            "eval_runtime": 0.5318,
            "eval_samples_per_second": 1961.188,
            "eval_steps_per_second": 16.923,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.102,
            "grad_norm": 0.727703332901001,
            "learning_rate": 4.311774461028192e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 0.5633731484413147,
            "eval_matthews_correlation": 0.6558371211545774,
            "eval_runtime": 0.5063,
            "eval_samples_per_second": 2060.103,
            "eval_steps_per_second": 17.777,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "loss": 0.1017,
            "grad_norm": 0.5005966424942017,
            "learning_rate": 3.6484245439469325e-05,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 0.5737671852111816,
            "eval_matthews_correlation": 0.6533643185001198,
            "eval_runtime": 0.4937,
            "eval_samples_per_second": 2112.414,
            "eval_steps_per_second": 18.228,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "loss": 0.1036,
            "grad_norm": 0.5939432978630066,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "eval_loss": 0.5851232409477234,
            "eval_matthews_correlation": 0.6407586349852259,
            "eval_runtime": 0.5433,
            "eval_samples_per_second": 1919.724,
            "eval_steps_per_second": 16.565,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "train_runtime": 1048.1765,
            "train_samples_per_second": 815.798,
            "train_steps_per_second": 6.392,
            "total_flos": 4.900336668403302e+16,
            "train_loss": 0.2145831325136382,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "eval_loss": 0.549129843711853,
            "eval_matthews_correlation": 0.6632431890370206,
            "eval_runtime": 0.5367,
            "eval_samples_per_second": 1943.306,
            "eval_steps_per_second": 16.769,
            "epoch": 86.56716417910448,
            "step": 5800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation3",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": true,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "cola",
        "peft": "mrlora-olora-lcoef",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 1048.1765,
        "trainable_params_count": 0.296498,
        "memory_allocated": [
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336
        ],
        "memory_reserved": [
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176
        ]
    },
    "variant": "lora"
}