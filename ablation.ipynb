{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95587a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:50.112595Z",
     "start_time": "2026-02-09T04:57:50.110148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9375c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.062695Z",
     "start_time": "2026-02-09T04:57:51.046231Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-rs': 'MR-LoRA-RS',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.191694Z",
     "start_time": "2026-02-09T04:57:51.138931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./ablation3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ab95559e913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.673632Z",
     "start_time": "2026-02-09T04:57:51.667832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deberta'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a30665e40b194d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:52.765619Z",
     "start_time": "2026-02-09T04:57:52.762058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrlora-rs-olora', 'mrlora-rs-lcoef', 'mrlora', 'mrlora-rs',\n",
       "       'mrlora-rs-olora-lcoef', 'mrlora-olora-lcoef', 'mrlora-olora',\n",
       "       'mrlora-lcoef'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.peft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbe73398833aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:55.404732Z",
     "start_time": "2026-02-09T04:57:55.398687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c0212dc379992b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.090823Z",
     "start_time": "2026-02-09T04:57:56.074050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cola'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440790b4a0f827b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.706572Z",
     "start_time": "2026-02-09T04:57:56.696235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family  peft  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "task                                                                                             \n",
       "cola       8     8        8      8       8       8          8         8       8     8     8     8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('task').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a931016c9ee7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:57.885715Z",
     "start_time": "2026-02-09T04:57:57.881657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eval_matthews_correlation'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34344c47bffaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:58.600312Z",
     "start_time": "2026-02-09T04:57:58.596519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.seed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a075dbd861ae3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:59.829409Z",
     "start_time": "2026-02-09T04:57:59.826027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lora'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.variant.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1798adbfcbc94c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:00.436344Z",
     "start_time": "2026-02-09T04:58:00.430225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2964, 0.2965])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.params.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97703ef3d88747f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:01.086444Z",
     "start_time": "2026-02-09T04:58:01.068406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value  params  traintime  evaltime  gpumem  rank  seed\n",
       "count    0.0     0.0        0.0       0.0     0.0   0.0   0.0\n",
       "mean     NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "std      NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "min      NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "25%      NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "50%      NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "75%      NaN     NaN        NaN       NaN     NaN   NaN   NaN\n",
       "max      NaN     NaN        NaN       NaN     NaN   NaN   NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.metric == 'eval_accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05606017ed6c66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:02.217068Z",
     "start_time": "2026-02-09T04:58:02.187377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [family, peft, task, variant, value, metric, params, traintime, evaltime, gpumem, rank, seed, path]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.value == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c649ba972b5c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.154327Z",
     "start_time": "2026-02-09T04:58:03.150492Z"
    }
   },
   "outputs": [],
   "source": [
    "df_simple = df[(df.task != 'stsb') & (df['rank'] == 8) & (df.variant == 'lora')]\n",
    "df_simple = df_simple[df.metric != 'eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e62273245330afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.895450Z",
     "start_time": "2026-02-09T04:58:03.835295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_77072_row0_col0 {\n",
       "  background-color: #dff2b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77072_row1_col0 {\n",
       "  background-color: #f3fabf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77072_row2_col0 {\n",
       "  background-color: #8cd2ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77072_row3_col0 {\n",
       "  background-color: #39adc3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_77072_row4_col0, #T_77072_row5_col0 {\n",
       "  background-color: #e1f3b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77072_row6_col0 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_77072_row7_col0 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_77072\">\n",
       "  <caption>MrLoRA Feature Ablation Study</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_77072_level0_col0\" class=\"col_heading level0 col0\" >cola</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >rs</th>\n",
       "      <th class=\"index_name level1\" >lcoef</th>\n",
       "      <th class=\"index_name level2\" >olora</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">False</th>\n",
       "      <th id=\"T_77072_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_77072_level2_row0\" class=\"row_heading level2 row0\" >False</th>\n",
       "      <td id=\"T_77072_row0_col0\" class=\"data row0 col0\" >0.6580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level2_row1\" class=\"row_heading level2 row1\" >True</th>\n",
       "      <td id=\"T_77072_row1_col0\" class=\"data row1 col0\" >0.6567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_77072_level2_row2\" class=\"row_heading level2 row2\" >False</th>\n",
       "      <td id=\"T_77072_row2_col0\" class=\"data row2 col0\" >0.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level2_row3\" class=\"row_heading level2 row3\" >True</th>\n",
       "      <td id=\"T_77072_row3_col0\" class=\"data row3 col0\" >0.6632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">True</th>\n",
       "      <th id=\"T_77072_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_77072_level2_row4\" class=\"row_heading level2 row4\" >False</th>\n",
       "      <td id=\"T_77072_row4_col0\" class=\"data row4 col0\" >0.6579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level2_row5\" class=\"row_heading level2 row5\" >True</th>\n",
       "      <td id=\"T_77072_row5_col0\" class=\"data row5 col0\" >0.6579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_77072_level2_row6\" class=\"row_heading level2 row6\" >False</th>\n",
       "      <td id=\"T_77072_row6_col0\" class=\"data row6 col0\" >0.6555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_77072_level2_row7\" class=\"row_heading level2 row7\" >True</th>\n",
       "      <td id=\"T_77072_row7_col0\" class=\"data row7 col0\" >0.6700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff3c07f8550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Expand the 'peft' strings into feature columns\n",
    "features = [ 'rs', 'lcoef', 'olora', ]\n",
    "\n",
    "for f in features:\n",
    "    # Checks if the feature name exists as a standalone word in the string\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))\n",
    "\n",
    "# 2. Create a Pivot Table\n",
    "# We group by the feature flags and show the mean 'value' for each 'task'\n",
    "pivot_df = df_simple.pivot_table(\n",
    "    index=features,\n",
    "    columns='task',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# 3. Apply Styling (Conditional Formatting)\n",
    "styled_table = pivot_df.style.background_gradient(axis=0, cmap='YlGnBu') \\\n",
    "                             .format(\"{:.4f}\") \\\n",
    "                             .set_caption(\"MrLoRA Feature Ablation Study\")\n",
    "\n",
    "# Display in Jupyter/Colab\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a54ce04a4a75ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:04.594457Z",
     "start_time": "2026-02-09T04:58:04.537143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features to isolate\n",
    "features = ['olora', 'rs', 'lcoef']\n",
    "\n",
    "# Create boolean columns: True if feature name is in the 'peft' string\n",
    "for f in features:\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e0cfa4b46888",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb5854cd105ad44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:05.185286Z",
     "start_time": "2026-02-09T04:58:05.178940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg    Delta\n",
      "0   olora  0.658000  0.661950  0.00395\n",
      "1      rs  0.659625  0.660325  0.00070\n",
      "2   lcoef  0.657625  0.662325  0.00470\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['value'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f145e2e877ecd1",
   "metadata": {},
   "source": [
    "1. bias cause obvious drop.\n",
    "2. rs and lcoef boost perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f12b207fde3f9e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:06.505857Z",
     "start_time": "2026-02-09T04:58:05.983960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3976254/1667137800.py:13: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  g = sns.catplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7ff340255ac0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melt the data for visualization\n",
    "plot_data = []\n",
    "for f in features:\n",
    "    subset = df_simple[[f, 'value', 'task']].copy()\n",
    "    subset['Feature_Name'] = f\n",
    "    subset = subset.rename(columns={f: 'Status'})\n",
    "    subset['Status'] = subset['Status'].map({True: 'On', False: 'Off'})\n",
    "    plot_data.append(subset)\n",
    "\n",
    "df_plot = pd.concat(plot_data)\n",
    "\n",
    "# Create a FacetGrid to see On/Off for each feature across tasks\n",
    "g = sns.catplot(\n",
    "    data=df_plot, x='Status', y='value',\n",
    "    col='Feature_Name', kind='bar',\n",
    "    palette='muted', height=4, aspect=0.7\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370cc5235e224ab",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91bf48a86140a816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:10.595609Z",
     "start_time": "2026-02-09T04:58:10.582585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Off_Avg   On_Avg   Delta\n",
      "0   olora  0.29645  0.29645  0.0000\n",
      "1      rs  0.29645  0.29645  0.0000\n",
      "2   lcoef  0.29640  0.29650  0.0001\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['params'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570453e5699aa3",
   "metadata": {},
   "source": [
    "### Traintime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9c002fa7d60b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.256511Z",
     "start_time": "2026-02-09T04:58:11.231191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  300.8525  646.6800  345.8275\n",
      "1      rs  635.0550  312.4775 -322.5775\n",
      "2   lcoef  433.5100  514.0225   80.5125\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['traintime'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0571e908c87d",
   "metadata": {},
   "source": [
    "1. Olora cuts traintime.\n",
    "2. rs add traintime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357b36f540c8e5",
   "metadata": {},
   "source": [
    "### GPUMEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "155dd12a1a8cea22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.416928Z",
     "start_time": "2026-02-09T04:58:11.408028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Off_Avg   On_Avg  Delta\n",
      "0   olora  761.635  761.665   0.03\n",
      "1      rs  761.635  761.665   0.03\n",
      "2   lcoef  761.620  761.680   0.06\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['gpumem'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "301c37fed59d5101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:12.147491Z",
     "start_time": "2026-02-09T04:58:12.143853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([761.65, 761.68, 761.53])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.gpumem.unique() # Almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c736e089edac5e7",
   "metadata": {},
   "source": [
    "## Compare with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f998732af3a0030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:36.666812Z",
     "start_time": "2026-02-09T04:58:35.763401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract data from results/fft/task_mnli_bert_42/base_32_2e-05_0.01/peft_lora_16_{}_8/ckpt/checkpoint-200/config.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'log_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_base \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_experiment_results\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_base \u001b[38;5;241m=\u001b[39m df_base[df_base\u001b[38;5;241m.\u001b[39mvariant \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlora\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m df_base \u001b[38;5;241m=\u001b[39m df_base[df_base\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39misin(df\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39munique())]\n",
      "Cell \u001b[0;32mIn[3], line 83\u001b[0m, in \u001b[0;36maggregate_experiment_results\u001b[0;34m(root_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to extract data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_dfs:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid data extracted from found files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36maggregate_experiment_results\u001b[0;34m(root_dir)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     rows \u001b[38;5;241m=\u001b[39m extract_experiment_data(f, root_dir)\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mall_dfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to extract data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mextract_experiment_data\u001b[0;34m(json_file, root_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     eval_runtime_history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item:\n\u001b[1;32m     28\u001b[0m             eval_runtime_history\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_history'"
     ]
    }
   ],
   "source": [
    "df_base = aggregate_experiment_results('./results')\n",
    "df_base = df_base[df_base.variant == 'lora']\n",
    "df_base = df_base[df_base.task.isin(df.task.unique())]\n",
    "df_base = df_base[df_base.family.isin(df.family.unique())]\n",
    "df_base = df_base[df_base.seed == 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f61536854053fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:39.339410Z",
     "start_time": "2026-02-09T04:58:39.337459Z"
    }
   },
   "outputs": [],
   "source": [
    "df_our = df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f0f541cd088db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:40.957626Z",
     "start_time": "2026-02-09T04:58:40.917101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "      <th>rs</th>\n",
       "      <th>lcoef</th>\n",
       "      <th>olora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2904.21</td>\n",
       "      <td>3.05</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2335.51</td>\n",
       "      <td>3.69</td>\n",
       "      <td>763.49</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9295</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>2204.85</td>\n",
       "      <td>3.21</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2296.15</td>\n",
       "      <td>3.36</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1497.80</td>\n",
       "      <td>2.15</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1921.80</td>\n",
       "      <td>2.08</td>\n",
       "      <td>533.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1512.78</td>\n",
       "      <td>2.13</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1480.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1259.06</td>\n",
       "      <td>2.18</td>\n",
       "      <td>534.62</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>2197.91</td>\n",
       "      <td>2.20</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>839.51</td>\n",
       "      <td>2.06</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1813.79</td>\n",
       "      <td>2.41</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1656.87</td>\n",
       "      <td>2.21</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1511.81</td>\n",
       "      <td>1.79</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1895.72</td>\n",
       "      <td>2.22</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>777.28</td>\n",
       "      <td>2.06</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>775.92</td>\n",
       "      <td>1.87</td>\n",
       "      <td>533.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>801.39</td>\n",
       "      <td>2.60</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>947.99</td>\n",
       "      <td>2.10</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.36</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>504.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>763.11</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>523.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8231</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>521.92</td>\n",
       "      <td>0.33</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>510.73</td>\n",
       "      <td>0.30</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>308.40</td>\n",
       "      <td>0.19</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>325.97</td>\n",
       "      <td>0.15</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>344.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>300.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>414.78</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>415.82</td>\n",
       "      <td>0.30</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>513.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>341.81</td>\n",
       "      <td>0.16</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>414.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>296.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>462.03</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>330.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>307.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>264.39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>343.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>242.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>267.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>296.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>301.52</td>\n",
       "      <td>0.17</td>\n",
       "      <td>534.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>343.76</td>\n",
       "      <td>0.22</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>341.93</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family                   peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path     rs  lcoef  olora\n",
       "205  deberta              mrlora-rs  qnli    lora  0.9418  eval_accuracy  0.2964    2904.21      3.05  762.71     8    42          ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "204  deberta                 mrlora  qnli    lora  0.9352  eval_accuracy  0.2964    2335.51      3.69  763.49     8    42             ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "206  deberta           mrlora-lcoef  qnli    lora  0.9295  eval_accuracy  0.2965    2204.85      3.21  762.73     8    42       ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "207  deberta           mrlora-olora  qnli    lora  0.9255  eval_accuracy  0.2964    2296.15      3.36  762.71     8    42       ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "211  roberta        mrlora-olora-rs  qnli    lora  0.9171  eval_accuracy  0.8870    1497.80      2.15  533.31     8    42    ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "209  roberta     mrlora-olora-lcoef  qnli    lora  0.9165  eval_accuracy  0.8871    1921.80      2.08  533.34     8    42  ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....  False   True   True\n",
       "210  roberta        mrlora-rs-lcoef  qnli    lora  0.9162  eval_accuracy  0.8871    1512.78      2.13  534.12     8    42    ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "214  roberta           mrlora-olora  qnli    lora  0.9140  eval_accuracy  0.8870    1480.16      2.16  533.31     8    42       ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "212  roberta              mrlora-rs  qnli    lora  0.9134  eval_accuracy  0.8870    1259.06      2.18  534.62     8    42          ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "229     bert           mrlora-lcoef  qnli    lora  0.9057  eval_accuracy  0.2965    2197.91      2.20  463.10     8    42          ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "213  roberta           mrlora-lcoef  qnli    lora  0.8999  eval_accuracy  0.8871     839.51      2.06  534.12     8    42       ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "226     bert        mrlora-rs-lcoef  qnli    lora  0.8993  eval_accuracy  0.2965    1813.79      2.41  463.10     8    42       ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "228     bert              mrlora-rs  qnli    lora  0.8984  eval_accuracy  0.2964    1656.87      2.21  463.08     8    42             ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "230     bert           mrlora-olora  qnli    lora  0.8977  eval_accuracy  0.2964    1511.81      1.79  463.08     8    42          ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "225     bert     mrlora-olora-lcoef  qnli    lora  0.8960  eval_accuracy  0.2965    1895.72      2.22  463.10     8    42    ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "208  roberta                 mrlora  qnli    lora  0.8960  eval_accuracy  0.8870     777.28      2.06  533.31     8    42             ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "215  roberta  mrlora-olora-rs-lcoef  qnli    lora  0.8894  eval_accuracy  0.8871     775.92      1.87  533.34     8    42  ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...   True   True   True\n",
       "224     bert                 mrlora  qnli    lora  0.8817  eval_accuracy  0.2964     801.39      2.60  463.08     8    42                ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "231     bert  mrlora-olora-rs-lcoef  qnli    lora  0.8742  eval_accuracy  0.2965     947.99      2.10  463.10     8    42  ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics....   True   True   True\n",
       "227     bert        mrlora-olora-rs  qnli    lora  0.8739  eval_accuracy  0.2964     946.44      2.36  463.08     8    42       ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "216  deberta                 mrlora   rte    lora  0.8303  eval_accuracy  0.2964     504.58      0.27  763.11     8    42              ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "221  deberta           mrlora-lcoef   rte    lora  0.8303  eval_accuracy  0.2965     523.60      0.27  762.73     8    42        ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "218  deberta        mrlora-rs-lcoef   rte    lora  0.8231  eval_accuracy  0.2965     521.92      0.33  762.73     8    42     ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "220  deberta              mrlora-rs   rte    lora  0.8195  eval_accuracy  0.2964     510.73      0.30  762.71     8    42           ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "201  roberta           mrlora-lcoef   rte    lora  0.7581  eval_accuracy  0.8871     308.40      0.19  534.91     8    42        ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "200  roberta              mrlora-rs   rte    lora  0.7437  eval_accuracy  0.8870     325.97      0.15  534.10     8    42           ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "198  roberta        mrlora-rs-lcoef   rte    lora  0.7401  eval_accuracy  0.8871     344.14      0.16  534.12     8    42     ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "196  roberta                 mrlora   rte    lora  0.7365  eval_accuracy  0.8870     300.92      0.16  534.10     8    42              ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "217  deberta     mrlora-olora-lcoef   rte    lora  0.7112  eval_accuracy  0.2965     414.78      0.27  762.73     8    42  ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "223  deberta  mrlora-olora-rs-lcoef   rte    lora  0.7076  eval_accuracy  0.2965     415.82      0.30  762.73     8    42  ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...   True   True   True\n",
       "222  deberta           mrlora-olora   rte    lora  0.7076  eval_accuracy  0.2964     513.65      0.31  762.71     8    42        ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "234     bert        mrlora-rs-lcoef   rte    lora  0.6968  eval_accuracy  0.2965     341.81      0.16  463.89     8    42        ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "219  deberta        mrlora-olora-rs   rte    lora  0.6931  eval_accuracy  0.2964     414.05      0.27  762.71     8    42     ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "232     bert                 mrlora   rte    lora  0.6823  eval_accuracy  0.2964     296.45      0.19  462.03     8    42                 ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "236     bert              mrlora-rs   rte    lora  0.6823  eval_accuracy  0.2964     330.31      0.21  463.87     8    42              ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "237     bert           mrlora-lcoef   rte    lora  0.6679  eval_accuracy  0.2965     307.03      0.19  463.89     8    42           ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "199  roberta        mrlora-olora-rs   rte    lora  0.6570  eval_accuracy  0.8870     264.39      0.10  534.10     8    42     ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "203  roberta  mrlora-olora-rs-lcoef   rte    lora  0.6534  eval_accuracy  0.8871     343.14      0.15  534.91     8    42  ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...   True   True   True\n",
       "233     bert     mrlora-olora-lcoef   rte    lora  0.6534  eval_accuracy  0.2965     242.13      0.17  463.89     8    42     ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "235     bert        mrlora-olora-rs   rte    lora  0.6534  eval_accuracy  0.2964     267.09      0.19  463.87     8    42        ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "238     bert           mrlora-olora   rte    lora  0.6354  eval_accuracy  0.2964     296.08      0.18  463.87     8    42           ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "202  roberta           mrlora-olora   rte    lora  0.6318  eval_accuracy  0.8870     301.52      0.17  534.88     8    42        ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "239     bert  mrlora-olora-rs-lcoef   rte    lora  0.6245  eval_accuracy  0.2965     343.76      0.22  463.89     8    42  ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics.json   True   True   True\n",
       "197  roberta     mrlora-olora-lcoef   rte    lora  0.6209  eval_accuracy  0.8871     341.93      0.16  534.91     8    42  ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_our.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e08081d96b22fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:42.997489Z",
     "start_time": "2026-02-09T04:58:42.988918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1663.23</td>\n",
       "      <td>1.91</td>\n",
       "      <td>761.37</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1838.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>762.15</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>1962.25</td>\n",
       "      <td>2.87</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1606.84</td>\n",
       "      <td>4.00</td>\n",
       "      <td>761.66</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>deberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1302.84</td>\n",
       "      <td>2.27</td>\n",
       "      <td>761.37</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>deberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>346.63</td>\n",
       "      <td>15.82</td>\n",
       "      <td>762.42</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>deberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>418.94</td>\n",
       "      <td>19.24</td>\n",
       "      <td>767.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>422.37</td>\n",
       "      <td>18.90</td>\n",
       "      <td>762.70</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>344.17</td>\n",
       "      <td>17.05</td>\n",
       "      <td>763.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>roberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>293.23</td>\n",
       "      <td>11.24</td>\n",
       "      <td>538.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       family             peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                              path\n",
       "1995  deberta           rslora  qnli    lora  0.9389  eval_accuracy  0.2964    1663.23      1.91  761.37     8    42           results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "1996  deberta             lora  qnli    lora  0.9363  eval_accuracy  0.2964    1838.87      1.79  762.15     8    42             results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "2000  deberta             dora  qnli    lora  0.9337  eval_accuracy  0.3149    1962.25      2.87  761.65     8    42             results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "1997  deberta  mrlora-rs-olora  qnli    lora  0.9319  eval_accuracy  0.2964    1606.84      4.00  761.66     8    42  results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json\n",
       "1998  deberta            olora  qnli    lora  0.9317  eval_accuracy  0.2964    1302.84      2.27  761.37     8    42            results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "...       ...              ...   ...     ...     ...            ...     ...        ...       ...     ...   ...   ...                                                                                               ...\n",
       "2397  deberta            olora   qqp    lora  0.3682  eval_accuracy  0.2964     346.63     15.82  762.42     8    42             results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "2399  deberta          adalora   qqp    lora  0.3682  eval_accuracy  0.5917     418.94     19.24  767.34     8    42           results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "2401  deberta             dora   qqp    lora  0.3682  eval_accuracy  0.3149     422.37     18.90  762.70     8    42              results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "2393  deberta             lora   qqp    lora  0.3682  eval_accuracy  0.2964     344.17     17.05  763.20     8    42              results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "2135  roberta          adalora   qqp    lora  0.0000        eval_f1  1.1823     293.23     11.24  538.20     8    42           results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "\n",
       "[214 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.sort_values('value', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
