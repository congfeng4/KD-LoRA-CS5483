{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "95587a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:50.112595Z",
     "start_time": "2026-02-09T04:57:50.110148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "9375c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.062695Z",
     "start_time": "2026-02-09T04:57:51.046231Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-rs': 'MR-LoRA-RS',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.191694Z",
     "start_time": "2026-02-09T04:57:51.138931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"metrics.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./ablation3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "51ab95559e913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.673632Z",
     "start_time": "2026-02-09T04:57:51.667832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deberta'], dtype=object)"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "14a30665e40b194d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:52.765619Z",
     "start_time": "2026-02-09T04:57:52.762058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrlora-rs-olora', 'mrlora-rs-lcoef', 'mrlora', 'mrlora-rs',\n",
       "       'mrlora-rs-olora-lcoef', 'mrlora-olora-lcoef', 'mrlora-olora',\n",
       "       'mrlora-lcoef'], dtype=object)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.peft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "8fbe73398833aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:55.404732Z",
     "start_time": "2026-02-09T04:57:55.398687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "44c0212dc379992b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.090823Z",
     "start_time": "2026-02-09T04:57:56.074050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qnli', 'qqp', 'mrpc', 'cola', 'sst2', 'rte', 'mnli', 'stsb'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "440790b4a0f827b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.706572Z",
     "start_time": "2026-02-09T04:57:56.696235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stsb</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family  peft  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "task                                                                                             \n",
       "cola       8     8        8      8       8       8          8         8       8     8     8     8\n",
       "mnli       8     8        8      8       8       8          8         8       8     8     8     8\n",
       "mrpc       8     8        8      8       8       8          8         8       8     8     8     8\n",
       "qnli       8     8        8      8       8       8          8         8       8     8     8     8\n",
       "qqp        8     8        8      8       8       8          8         8       8     8     8     8\n",
       "rte       12    12       12     12      12      12         12        12      12    12    12    12\n",
       "sst2       4     4        4      4       4       4          4         4       4     4     4     4\n",
       "stsb       8     8        8      8       8       8          8         8       8     8     8     8"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('task').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "57a931016c9ee7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:57.885715Z",
     "start_time": "2026-02-09T04:57:57.881657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eval_accuracy', 'eval_f1', 'eval_matthews_correlation',\n",
       "       'matched_accuracy', 'mismatched_accuracy', 'eval_pearson',\n",
       "       'eval_spearman'], dtype=object)"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "c34344c47bffaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:58.600312Z",
     "start_time": "2026-02-09T04:57:58.596519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.seed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "8a075dbd861ae3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:59.829409Z",
     "start_time": "2026-02-09T04:57:59.826027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lora', 'kd-lora'], dtype=object)"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.variant.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "1798adbfcbc94c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:00.436344Z",
     "start_time": "2026-02-09T04:58:00.430225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2964, 0.2965, 0.2972, 0.2973, 0.2957, 0.149 ])"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.params.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "97703ef3d88747f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:01.086444Z",
     "start_time": "2026-02-09T04:58:01.068406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.758722</td>\n",
       "      <td>0.278019</td>\n",
       "      <td>704.739688</td>\n",
       "      <td>2.722812</td>\n",
       "      <td>739.965625</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.189415</td>\n",
       "      <td>0.049545</td>\n",
       "      <td>595.832787</td>\n",
       "      <td>4.548364</td>\n",
       "      <td>58.272219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>193.880000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>588.150000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.659750</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>272.617500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>761.552500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.807300</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>406.750000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>761.650000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.920525</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>1188.525000</td>\n",
       "      <td>3.235000</td>\n",
       "      <td>761.680000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>2439.520000</td>\n",
       "      <td>14.910000</td>\n",
       "      <td>761.680000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value     params    traintime   evaltime      gpumem  rank  seed\n",
       "count  32.000000  32.000000    32.000000  32.000000   32.000000  32.0  32.0\n",
       "mean    0.758722   0.278019   704.739688   2.722812  739.965625   8.0  42.0\n",
       "std     0.189415   0.049545   595.832787   4.548364   58.272219   0.0   0.0\n",
       "min     0.368200   0.149000   193.880000   0.090000  588.150000   8.0  42.0\n",
       "25%     0.659750   0.296400   272.617500   0.225000  761.552500   8.0  42.0\n",
       "50%     0.807300   0.296400   406.750000   0.300000  761.650000   8.0  42.0\n",
       "75%     0.920525   0.296500  1188.525000   3.235000  761.680000   8.0  42.0\n",
       "max     0.950700   0.296500  2439.520000  14.910000  761.680000   8.0  42.0"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.metric == 'eval_accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "c05606017ed6c66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:02.217068Z",
     "start_time": "2026-02-09T04:58:02.187377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [family, peft, task, variant, value, metric, params, traintime, evaltime, gpumem, rank, seed, path]\n",
       "Index: []"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.value == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "59c649ba972b5c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.154327Z",
     "start_time": "2026-02-09T04:58:03.150492Z"
    }
   },
   "outputs": [],
   "source": [
    "df_simple = df[(df.task != 'stsb') & (df['rank'] == 8) & (df.variant == 'kd-lora')]\n",
    "df_simple = df_simple[df_simple.metric != 'eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "6e62273245330afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.895450Z",
     "start_time": "2026-02-09T04:58:03.835295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a567a_row0_col0, #T_a567a_row2_col0 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a567a_row1_col0, #T_a567a_row3_col0 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a567a\">\n",
       "  <caption>MrLoRA Feature Ablation Study</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_a567a_level0_col0\" class=\"col_heading level0 col0\" >rte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >rs</th>\n",
       "      <th class=\"index_name level1\" >lcoef</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a567a_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_a567a_level1_row0\" class=\"row_heading level1 row0\" >False</th>\n",
       "      <td id=\"T_a567a_row0_col0\" class=\"data row0 col0\" >0.6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a567a_level1_row1\" class=\"row_heading level1 row1\" >True</th>\n",
       "      <td id=\"T_a567a_row1_col0\" class=\"data row1 col0\" >0.6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a567a_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_a567a_level1_row2\" class=\"row_heading level1 row2\" >False</th>\n",
       "      <td id=\"T_a567a_row2_col0\" class=\"data row2 col0\" >0.6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a567a_level1_row3\" class=\"row_heading level1 row3\" >True</th>\n",
       "      <td id=\"T_a567a_row3_col0\" class=\"data row3 col0\" >0.6245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f973304c4c0>"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Expand the 'peft' strings into feature columns\n",
    "features = [ 'rs', 'lcoef',]# 'olora', ]\n",
    "\n",
    "for f in features:\n",
    "    # Checks if the feature name exists as a standalone word in the string\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))\n",
    "\n",
    "# 2. Create a Pivot Table\n",
    "# We group by the feature flags and show the mean 'value' for each 'task'\n",
    "pivot_df = df_simple.pivot_table(\n",
    "    index=features,\n",
    "    columns='task',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# 3. Apply Styling (Conditional Formatting)\n",
    "styled_table = pivot_df.style.background_gradient(axis=0, cmap='YlGnBu') \\\n",
    "                             .format(\"{:.4f}\") \\\n",
    "                             .set_caption(\"MrLoRA Feature Ablation Study\")\n",
    "\n",
    "# Display in Jupyter/Colab\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "c9a54ce04a4a75ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:04.594457Z",
     "start_time": "2026-02-09T04:58:04.537143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features to isolate\n",
    "features = ['olora', 'rs', 'lcoef']\n",
    "\n",
    "# Create boolean columns: True if feature name is in the 'peft' string\n",
    "for f in features:\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e0cfa4b46888",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "bcb5854cd105ad44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:05.185286Z",
     "start_time": "2026-02-09T04:58:05.178940Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5846\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt8HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5870\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt8HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[810], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Calculate Mean for 'On' vs 'Off' across all tasks\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     summary \u001b[38;5;241m=\u001b[39m df_simple\u001b[38;5;241m.\u001b[39mgroupby(f)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      6\u001b[0m     impact_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: f,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOff_Avg\u001b[39m\u001b[38;5;124m'\u001b[39m: summary[\u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOn_Avg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelta\u001b[39m\u001b[38;5;124m'\u001b[39m: summary[\u001b[38;5;28;01mTrue\u001b[39;00m] \u001b[38;5;241m-\u001b[39m summary[\u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     11\u001b[0m     })\n\u001b[1;32m     13\u001b[0m df_impact \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(impact_results)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_impact)\n",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/lora/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['value'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f145e2e877ecd1",
   "metadata": {},
   "source": [
    "1. bias cause obvious drop.\n",
    "2. rs and lcoef boost perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b207fde3f9e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:06.505857Z",
     "start_time": "2026-02-09T04:58:05.983960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_564228/1667137800.py:13: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  g = sns.catplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9731e92d30>"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAGGCAYAAABR+u/qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxRUlEQVR4nO3df1xUdb7H8feAMogoSigYklx/lVwVEoSwWm0vLj7qWu7tGv1EqfCxGTdz+mGkQmmKay5SG0V1Za1tTW6btd2rSz/mRm3KXkuzH66aWoq5gKAGie1gcO4fPZx2FiwHgcOceT0fj/N4eL7ne2Y+xzN+Hr45Zw42wzAMAQAAAIBFBZhdAAAAAAB0JUIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPfEpFRYVsNpu++uors0sBAADdaMqUKbr77ru77f02b96scePGqXfv3poxY0a3vS+6Ri+zCwAAAAB6GofDoYSEBP3xj39UaGio2eXgHHGlB36nubnZ7BIAdDH+nQM4V/v379dPf/pTDR06VAMGDDC7HJwjQg96HJfLpbvuukuDBw9WcHCwLrvsMr3//vtnnP/yyy/rn//5n2W32xUbG6tf/epXHttjY2O1dOlSZWZmqn///pozZ44kacGCBRo9erRCQkI0fPhwLV68WKdOnerSYwPQNaZMmaKcnBzdfffdioiIUHp6uh566CFdcMEFstvtOv/883XXXXeZXSaATuJyubRgwQLFxMTIbrdr5MiRWrNmjXv7O++8o+TkZNntdg0ZMkQPPPCAvv32W/f21tZWFRQU6J/+6Z/Up08fxcfH6/e//70k6cCBA7LZbDp69KhuvfVW2Ww2rV27trsPEZ2M0IMe5/7779fLL7+s5557Ttu3b9fIkSOVnp6uY8eOtZm7bds2XXfddbr++uv1ySef6KGHHtLixYvbNKdVq1YpPj5eH374oRYvXixJ6tevn9auXau//OUveuyxx/Tss89q9erV3XGIALrAc889p6CgIG3evFnTpk3T6tWr9fTTT2vv3r169dVXNW7cOLNLBNBJMjMz9eKLL+rxxx/Xrl279PTTT7tvQTt8+LCuvPJKTZw4UR999JGeeuoprVmzRo888oh7/4KCAj3//PMqKSnRzp07NX/+fN1888165513FBMTo+rqavXv319FRUWqrq5WRkaGWYeKTmIzDMMwuwjgtKamJg0cOFBr167VjTfeKEk6deqUYmNjdffdd2vixIm64oordPz4cQ0YMEA33XST6urq9MYbb7hf4/7779fGjRu1c+dOSd9d6bn44ov1yiuv/OB7r1q1SuvXr9cHH3zQdQcIoEtMmTJFjY2N2r59uySpsLBQTz/9tD799FP17t3b5OoAdIYpU6YoISFBc+fO1YUXXqg333xTaWlpbeYtXLhQL7/8snbt2iWbzSZJevLJJ7VgwQI1NDTo1KlTCg8P11tvvaXU1FT3frfffrtOnjypdevWSZIGDBigoqIizZ49u1uOD12LKz3oUfbv369Tp07p0ksvdY/17t1bycnJ2rVrV5v5u3bt8pgrSZdeeqn27t2rlpYW91hSUlKbfcvKynTppZcqKipKoaGhWrRokaqqqjrxaAB0p8TERPefZ86cqW+++UbDhw9Xdna2XnnlFY9bWwD4rh07digwMFCTJ09ud/uuXbuUmprqDjzSd/83OHHihL788kvt27dPJ0+e1NSpUxUaGupenn/+ee3fv7+7DgPdjKe3wS/07dvXY72yslI33XSTHn74YaWnpyssLEzr169v830gAL7j7/+dx8TEaM+ePXrrrbf05ptvau7cuXr00Uf1zjvvcOUH8HF9+vQ5p/1PnDghSdq4caOio6M9ttnt9nN6bfRcXOlBjzJixAj3PfmnnTp1Su+//77i4uLazB8zZozHXOm75+qPHj1agYGBZ3yfLVu2aNiwYVq4cKGSkpI0atQoHTx4sPMOBIDp+vTpo+nTp+vxxx9XRUWFKisr9cknn5hdFoBzNG7cOLW2tuqdd95pd/uYMWNUWVmpv/8Gx+bNm9WvXz8NHTpUcXFxstvtqqqq0siRIz2WmJiY7joMdDOu9KBH6du3r+644w7dd999Cg8P1wUXXKCVK1fq5MmTuu222/TRRx95zL/nnns0ceJELV26VBkZGaqsrNQTTzyhJ5988gffZ9SoUaqqqtL69es1ceJEbdy48Ue/8wPAd6xdu1YtLS1KSUlRSEiIXnjhBfXp00fDhg0zuzQA5yg2NlazZs3Srbfeqscff1zx8fE6ePCgjhw5ouuuu05z585VUVGR/uM//kM5OTnas2eP8vPz5XA4FBAQoH79+unee+/V/Pnz1draqssuu0wNDQ3avHmz+vfvr1mzZpl9iOgChB70OCtWrFBra6tuueUWff3110pKStLrr7+ugQMHtpk7YcIE/dd//Zfy8vK0dOlSDRkyREuWLPnRLx1effXVmj9/vnJycuRyuXTVVVdp8eLFeuihh7rmoAB0qwEDBmjFihVyOBxqaWnRuHHj9N///d8677zzzC4NQCd46qmn9OCDD2ru3Lk6evSoLrjgAj344IOSpOjoaG3atEn33Xef4uPjFR4erttuu02LFi1y77906VINGjRIBQUF+vzzzzVgwABNmDDB/RqwHp7eBgAAAMDS+E4PAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNL8LPYZhqLGxUTypGwD9AIBELwD8gd+Fnq+//lphYWH6+uuvzS4FgMnoBwAkegHgD/wu9AAAAADwL4QeAAAAAJZG6AEAAABgaYQeAAAAAJZG6AEAAABgaYQeAAAAAJZG6AEAAABgaYQeAAAAAJZG6AEAAABgaYQeAAAAAJZG6AEAAABgaYQeAAAAAJbWy+wCAHSMYRhqampyr/ft21c2m83EitCT8XkBAPgz06/0FBcXKzY2VsHBwUpJSdHWrVt/cH5RUZEuvPBC9enTRzExMZo/f77+9re/dVO1QM/R1NSka665xr38/X9ogX/E5wUArM8wDJ04ccK9GIZhdkk9hqlXesrKyuRwOFRSUqKUlBQVFRUpPT1de/bs0eDBg9vMX7dunR544AGVlpZq0qRJ+uyzzzR79mzZbDYVFhaacAQAAABAz3D6B1yn/eEPf1BoaKiJFfUcpl7pKSwsVHZ2trKyshQXF6eSkhKFhISotLS03flbtmzRpZdeqhtvvFGxsbH62c9+phtuuOFHrw4BAACAKwHwX6Zd6Wlubta2bduUm5vrHgsICFBaWpoqKyvb3WfSpEl64YUXtHXrViUnJ+vzzz/Xpk2bdMstt5zxfVwul1wul3u9sbGx8w4CgE+hH8Cq+M6Wd/y5F3AlAP7KtNBTX1+vlpYWRUZGeoxHRkZq9+7d7e5z4403qr6+XpdddpkMw9C3336rX/ziF3rwwQfP+D4FBQV6+OGHO7V2AL6JfgCr4j+y3qEXAP7H9AcZeKOiokLLly/Xk08+qe3bt2vDhg3auHGjli5desZ9cnNz1dDQ4F4OHTrUjRUD6EnoBwAkegHgj0y70hMREaHAwEDV1tZ6jNfW1ioqKqrdfRYvXqxbbrlFt99+uyRp3Lhxampq0pw5c7Rw4UIFBLTNcHa7XXa7vfMPAIDPoR8AkOgFgD8y7UpPUFCQEhMT5XQ63WOtra1yOp1KTU1td5+TJ0+2CTaBgYGSxBfx2sGXFQEAAACTH1ntcDg0a9YsJSUlKTk5WUVFRWpqalJWVpYkKTMzU9HR0SooKJAkTZ8+XYWFhbr44ouVkpKiffv2afHixZo+fbo7/OB73OMNAAAAmBx6MjIyVFdXp7y8PNXU1CghIUHl5eXuhxtUVVV5XNlZtGiRbDabFi1apMOHD2vQoEGaPn26li1bZtYhAAAAAOjhTA09kpSTk6OcnJx2t1VUVHis9+rVS/n5+crPz++GygAAAABYgU89vQ0AAAAAvEXoAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBpvcwuADDbZ6tmm11Ch5w81eqxvu/XcxXS2/d+jjH63rVmlwAAACyO0AMAXrgxr8LsEjqk9du/eazfvvw9BfQKNqmajlu3ZIrZJQAAfJDv/VgYAAAAALxA6AEAAABgaYQeAAAAAJbGd3oAAAC8xPf7zNXV3+/jIUfm6oqHHPne3wIAAAAAeIHQAwAAAMDSCD0AAAAALK1HhJ7i4mLFxsYqODhYKSkp2rp16xnnTpkyRTabrc1y1VVXdWPFAAAAAHyF6aGnrKxMDodD+fn52r59u+Lj45Wenq4jR460O3/Dhg2qrq52L59++qkCAwM1c+bMbq4cAAAAgC8w/elthYWFys7OVlZWliSppKREGzduVGlpqR544IE288PDwz3W169fr5CQEEIPAOCc8cQm83TF05oA4DRTQ09zc7O2bdum3Nxc91hAQIDS0tJUWVl5Vq+xZs0aXX/99erbt2+7210ul1wul3u9sbHx3IoG4LPoBwAkegHgj0z9MVB9fb1aWloUGRnpMR4ZGamampof3X/r1q369NNPdfvtt59xTkFBgcLCwtxLTEzMOdcNwDfRDwBI9ALAH5l+e9u5WLNmjcaNG6fk5OQzzsnNzZXD4XCvNzY2et3c+AVk5urqX0AG/9EZ/QCA76MXAP7H1NATERGhwMBA1dbWeozX1tYqKirqB/dtamrS+vXrtWTJkh+cZ7fbZbfbz7lWAL6PfgBAohcA/sjU29uCgoKUmJgop9PpHmttbZXT6VRqauoP7vvSSy/J5XLp5ptv7uoyAQAAAPgw029vczgcmjVrlpKSkpScnKyioiI1NTW5n+aWmZmp6OhoFRQUeOy3Zs0azZgxQ+edd54ZZQMAAADwEaaHnoyMDNXV1SkvL081NTVKSEhQeXm5++EGVVVVCgjwvCC1Z88evffee3rjjTfMKBkAAACADzE99EhSTk6OcnJy2t1WUVHRZuzCCy+UYRhdXBUAAAAAK/Ct31wGAAAAAF4i9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwNEIPAAAAAEsj9AAAAACwtF5mFwAA6Hq2QLsGpdznsQ4AgL8g9AA+qk8vm36VFu2xDpyJzWaTrVew2WUAAGAKQg/go2w2m0J6E3QAAAB+DN/pAQAAAGBphB4AAAAAlkboAQAAAGBpfKcHAADAT/AkR/grQg8AAICf4EmO8Ffc3gYAAADA0gg9AAAAACyN29sAAAAAC+AXl58ZoQcAAACwAH5x+ZlxexsAAAAASzM99BQXFys2NlbBwcFKSUnR1q1bf3D+V199pTvvvFNDhgyR3W7X6NGjtWnTpm6qFgAAAICvMfX2trKyMjkcDpWUlCglJUVFRUVKT0/Xnj17NHjw4Dbzm5ubNXXqVA0ePFi///3vFR0drYMHD2rAgAHdXzwAAAAAn2Bq6CksLFR2draysrIkSSUlJdq4caNKS0v1wAMPtJlfWlqqY8eOacuWLerdu7ckKTY2tjtLBgCgx+HLywDww0y7va25uVnbtm1TWlra98UEBCgtLU2VlZXt7vPaa68pNTVVd955pyIjIzV27FgtX75cLS0t3VU2AAA9zndfXg5wLzYboQcA/p5pV3rq6+vV0tKiyMhIj/HIyEjt3r273X0+//xz/e///q9uuukmbdq0Sfv27dPcuXN16tQp5efnt7uPy+WSy+Vyrzc2NnbeQQDwKfQDABK9APBHpj/IwButra0aPHiwnnnmGSUmJiojI0MLFy5USUnJGfcpKChQWFiYe4mJienGigH0JPQDABK9APBHpoWeiIgIBQYGqra21mO8trZWUVFR7e4zZMgQjR49WoGBge6xMWPGqKamRs3Nze3uk5ubq4aGBvdy6NChzjuIHs4WaNeglPvciy3QbnZJgKn8uR8A+B69APA/poWeoKAgJSYmyul0usdaW1vldDqVmpra7j6XXnqp9u3bp9bWVvfYZ599piFDhigoKKjdfex2u/r37++x+AubzaaAXsHuhXu84e/8uR8A+B69APA/pt7e5nA49Oyzz+q5557Trl27dMcdd6ipqcn9NLfMzEzl5ua6599xxx06duyY5s2bp88++0wbN27U8uXLdeedd5p1CAAAAAB6OFMfWZ2RkaG6ujrl5eWppqZGCQkJKi8vdz/coKqqSgEB3+eymJgYvf7665o/f77Gjx+v6OhozZs3TwsWLDDrEAAAAAD0cKaGHknKyclRTk5Ou9sqKirajKWmpurPf/5zF1cFAAAAwCp86ultAAAAAOAtQg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALA0Qg8AAAAASyP0AAAAALC0HhF6iouLFRsbq+DgYKWkpGjr1q1nnLt27VrZbDaPJTg4uBurBQAAAOBLTA89ZWVlcjgcys/P1/bt2xUfH6/09HQdOXLkjPv0799f1dXV7uXgwYPdWDEAAAAAX2J66CksLFR2draysrIUFxenkpIShYSEqLS09Iz72Gw2RUVFuZfIyMhurBgAAACALzE19DQ3N2vbtm1KS0tzjwUEBCgtLU2VlZVn3O/EiRMaNmyYYmJidM0112jnzp3dUS4AAAAAH9TLzDevr69XS0tLmys1kZGR2r17d7v7XHjhhSotLdX48ePV0NCgVatWadKkSdq5c6eGDh3aZr7L5ZLL5XKvNzY2du5BAPAZ9AMAEr0A8Eem397mrdTUVGVmZiohIUGTJ0/Whg0bNGjQID399NPtzi8oKFBYWJh7iYmJ6eaKAfQU9AMAEr0A8Eemhp6IiAgFBgaqtrbWY7y2tlZRUVFn9Rq9e/fWxRdfrH379rW7PTc3Vw0NDe7l0KFD51w3AN9EPwAg0QsAf2Rq6AkKClJiYqKcTqd7rLW1VU6nU6mpqWf1Gi0tLfrkk080ZMiQdrfb7Xb179/fYwHgn+gHACR6AeCPTP1OjyQ5HA7NmjVLSUlJSk5OVlFRkZqampSVlSVJyszMVHR0tAoKCiRJS5Ys0SWXXKKRI0fqq6++0qOPPqqDBw/q9ttvN/MwAAAAAPRQpoeejIwM1dXVKS8vTzU1NUpISFB5ebn74QZVVVUKCPj+gtTx48eVnZ2tmpoaDRw4UImJidqyZYvi4uLMOgQAAAAAPZjpoUeScnJylJOT0+62iooKj/XVq1dr9erV3VAVAAAAACvwuae3AQAAAIA3CD0AAAAALI3QAwAAAMDSCD0AAAAALK3DoWffvn16/fXX9c0330iSDMPotKIAAAAAoLN4HXqOHj2qtLQ0jR49WldeeaWqq6slSbfddpvuueeeTi8QAAAAAM6F16Fn/vz56tWrl6qqqhQSEuIez8jIUHl5eacWBwAAAADnyuvf0/PGG2/o9ddf19ChQz3GR40apYMHD3ZaYQAAAADQGby+0tPU1ORxhee0Y8eOyW63d0pRAAAAANBZvA49l19+uZ5//nn3us1mU2trq1auXKkrrriiU4sDAAAAgHPl9e1tK1eu1L/8y7/ogw8+UHNzs+6//37t3LlTx44d0+bNm7uiRgAAAADoMK+v9IwdO1afffaZLrvsMl1zzTVqamrSv/3bv+nDDz/UiBEjuqJGAAAAAOgwr6/0SFJYWJgWLlzY2bUAAAAAQKfzOvS8++67P7j9Jz/5SYeLAQAAAIDO5nXomTJlSpsxm83m/nNLS8s5FQQAAAAAncnr7/QcP37cYzly5IjKy8s1ceJEvfHGG11RIwAAAAB0mNdXesLCwtqMTZ06VUFBQXI4HNq2bVunFAYAAAAAncHrKz1nEhkZqT179nTWywEAAABAp/D6Ss/HH3/ssW4Yhqqrq7VixQolJCR0Vl0AAAAA0Cm8Dj0JCQmy2WwyDMNj/JJLLlFpaWmnFQYAAAAAncHr0PPFF194rAcEBGjQoEEKDg7utKIAAAAAoLN4HXqGDRvWFXUAAAAAQJc4q9Dz+OOPn/UL3nXXXR0uBgAAAAA621mFntWrV5/Vi9lsNkIPAAAAgB7lrELPP36PBwAAAAB8Raf9nh4AAAAA6Im8fpCBJH355Zd67bXXVFVVpebmZo9thYWFXr9ecXGxHn30UdXU1Cg+Pl6//vWvlZyc/KP7rV+/XjfccIOuueYavfrqq16/LwAAAADr8zr0OJ1OXX311Ro+fLh2796tsWPH6sCBAzIMQxMmTPC6gLKyMjkcDpWUlCglJUVFRUVKT0/Xnj17NHjw4DPud+DAAd177726/PLLvX5PAAAAAP7D69vbcnNzde+99+qTTz5RcHCwXn75ZR06dEiTJ0/WzJkzvS6gsLBQ2dnZysrKUlxcnEpKShQSEvKDv+i0paVFN910kx5++GENHz7c6/cEAAAA4D+8Dj27du1SZmamJKlXr1765ptvFBoaqiVLluiXv/ylV6/V3Nysbdu2KS0t7fuCAgKUlpamysrKM+63ZMkSDR48WLfddtuPvofL5VJjY6PHAsA/0Q8ASPQCwB95HXr69u3r/h7PkCFDtH//fve2+vp6r16rvr5eLS0tioyM9BiPjIxUTU1Nu/u89957WrNmjZ599tmzeo+CggKFhYW5l5iYGK9qBGAd9AMAEr0A8Edeh55LLrlE7733niTpyiuv1D333KNly5bp1ltv1SWXXNLpBf69r7/+WrfccoueffZZRUREnNU+ubm5amhocC+HDh3q0hoB9Fz0AwASvQDwR14/yKCwsFAnTpyQJD388MM6ceKEysrKNGrUKK+f3BYREaHAwEDV1tZ6jNfW1ioqKqrN/P379+vAgQOaPn26e6y1tfW7A+nVS3v27NGIESM89rHb7bLb7V7VBcCa6AcAJHoB4I+8Dj3Lly/XzTffLOm7W91KSko6/OZBQUFKTEyU0+nUjBkzJH0XYpxOp3JyctrMv+iii/TJJ594jC1atEhff/21HnvsMS5PAwAAAGjD69BTV1enadOmadCgQbr++ut18803Kz4+vsMFOBwOzZo1S0lJSUpOTlZRUZGampqUlZUlScrMzFR0dLQKCgoUHByssWPHeuw/YMAASWozDgAAAABSB0LPH/7wBx0/flwvvfSS1q1bp8LCQl100UW66aabdOONNyo2Ntar18vIyFBdXZ3y8vJUU1OjhIQElZeXux9uUFVVpYAAr796BAAAAACSOhB6JGngwIGaM2eO5syZoy+//FIvvviiSktLlZeXp2+//dbr18vJyWn3djZJqqio+MF9165d6/X7AQAAAPAf53QJ5dSpU/rggw/0f//3fzpw4ECbR08DAAAAgNk6FHrefvttZWdnKzIyUrNnz1b//v31P//zP/ryyy87uz4AAAAAOCde394WHR2tY8eOadq0aXrmmWc0ffp0HvsIAAAAoMfyOvQ89NBDmjlzpvupaQAAAADQk3kderKzs7uiDgAAAADoEjwLGgAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWBqhBwAAAIClEXoAAAAAWFqPCD3FxcWKjY1VcHCwUlJStHXr1jPO3bBhg5KSkjRgwAD17dtXCQkJ+u1vf9uN1QIAAADwJaaHnrKyMjkcDuXn52v79u2Kj49Xenq6jhw50u788PBwLVy4UJWVlfr444+VlZWlrKwsvf76691cOQAAAABfYHroKSwsVHZ2trKyshQXF6eSkhKFhISotLS03flTpkzRz3/+c40ZM0YjRozQvHnzNH78eL333nvdXDkAAAAAX2Bq6Glubta2bduUlpbmHgsICFBaWpoqKyt/dH/DMOR0OrVnzx795Cc/aXeOy+VSY2OjxwLAP9EPAEj0AsAfmRp66uvr1dLSosjISI/xyMhI1dTUnHG/hoYGhYaGKigoSFdddZV+/etfa+rUqe3OLSgoUFhYmHuJiYnp1GMA4DvoBwAkegHgj0y/va0j+vXrpx07duj999/XsmXL5HA4VFFR0e7c3NxcNTQ0uJdDhw51b7EAegz6AQCJXgD4o15mvnlERIQCAwNVW1vrMV5bW6uoqKgz7hcQEKCRI0dKkhISErRr1y4VFBRoypQpbeba7XbZ7fZOrRuAb6IfAJDoBYA/MvVKT1BQkBITE+V0Ot1jra2tcjqdSk1NPevXaW1tlcvl6ooSAQAAAPg4U6/0SJLD4dCsWbOUlJSk5ORkFRUVqampSVlZWZKkzMxMRUdHq6CgQNJ39+EmJSVpxIgRcrlc2rRpk37729/qqaeeMvMwAAAAAPRQpoeejIwM1dXVKS8vTzU1NUpISFB5ebn74QZVVVUKCPj+glRTU5Pmzp2rL7/8Un369NFFF12kF154QRkZGWYdAgAAAIAezPTQI0k5OTnKyclpd9s/PqDgkUce0SOPPNINVQEAAACwAp98ehsAAAAAnC1CDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsLQeEXqKi4sVGxur4OBgpaSkaOvWrWec++yzz+ryyy/XwIEDNXDgQKWlpf3gfAAAAAD+zfTQU1ZWJofDofz8fG3fvl3x8fFKT0/XkSNH2p1fUVGhG264QW+//bYqKysVExOjn/3sZzp8+HA3Vw4AAADAF5geegoLC5Wdna2srCzFxcWppKREISEhKi0tbXf+7373O82dO1cJCQm66KKL9J//+Z9qbW2V0+ns5soBAAAA+IJeZr55c3Oztm3bptzcXPdYQECA0tLSVFlZeVavcfLkSZ06dUrh4eHtbne5XHK5XO71xsbGcysagM+iHwCQ6AWAPzL1Sk99fb1aWloUGRnpMR4ZGamampqzeo0FCxbo/PPPV1paWrvbCwoKFBYW5l5iYmLOuW4Avol+AECiFwD+yPTb287FihUrtH79er3yyisKDg5ud05ubq4aGhrcy6FDh7q5SgA9Bf0AgEQvAPyRqbe3RUREKDAwULW1tR7jtbW1ioqK+sF9V61apRUrVuitt97S+PHjzzjPbrfLbrd3Sr0AfBv9AIBELwD8kalXeoKCgpSYmOjxEILTDyVITU09434rV67U0qVLVV5erqSkpO4oFQAAAICPMvVKjyQ5HA7NmjVLSUlJSk5OVlFRkZqampSVlSVJyszMVHR0tAoKCiRJv/zlL5WXl6d169YpNjbW/d2f0NBQhYaGmnYcAAAAAHom00NPRkaG6urqlJeXp5qaGiUkJKi8vNz9cIOqqioFBHx/Qeqpp55Sc3Oz/v3f/93jdfLz8/XQQw91Z+kAAAAAfIDpoUeScnJylJOT0+62iooKj/UDBw50fUEAAAAALMOnn94GAAAAAD+G0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACyN0AMAAADA0gg9AAAAACzN9NBTXFys2NhYBQcHKyUlRVu3bj3j3J07d+raa69VbGysbDabioqKuq9QAAAAAD7J1NBTVlYmh8Oh/Px8bd++XfHx8UpPT9eRI0fanX/y5EkNHz5cK1asUFRUVDdXCwAAAMAXmRp6CgsLlZ2draysLMXFxamkpEQhISEqLS1td/7EiRP16KOP6vrrr5fdbu/magEAAAD4ItNCT3Nzs7Zt26a0tLTviwkIUFpamiorK80qCwAAAIDF9DLrjevr69XS0qLIyEiP8cjISO3evbvT3sflcsnlcrnXGxsbO+21AfgW+gEAiV4A+CPTH2TQ1QoKChQWFuZeYmJizC4JgEnoBwAkegHgj0wLPREREQoMDFRtba3HeG1tbac+pCA3N1cNDQ3u5dChQ5322gB8C/0AgEQvAPyRabe3BQUFKTExUU6nUzNmzJAktba2yul0Kicnp9Pex26389ADAJLoBwC+Qy8A/I9poUeSHA6HZs2apaSkJCUnJ6uoqEhNTU3KysqSJGVmZio6OloFBQWSvnv4wV/+8hf3nw8fPqwdO3YoNDRUI0eONO04AAAAAPRcpoaejIwM1dXVKS8vTzU1NUpISFB5ebn74QZVVVUKCPj+Dry//vWvuvjii93rq1at0qpVqzR58mRVVFR0d/kAAAAAfICpoUeScnJyzng72z8GmdjYWBmG0Q1VAQAAALAKyz+9DQAAAIB/I/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABLI/QAAAAAsDRCDwAAAABL6xGhp7i4WLGxsQoODlZKSoq2bt36g/NfeuklXXTRRQoODta4ceO0adOmbqoUAAAAgK8xPfSUlZXJ4XAoPz9f27dvV3x8vNLT03XkyJF252/ZskU33HCDbrvtNn344YeaMWOGZsyYoU8//bSbKwcAAADgC0wPPYWFhcrOzlZWVpbi4uJUUlKikJAQlZaWtjv/scce07Rp03TfffdpzJgxWrp0qSZMmKAnnniimysHAAAA4AtMDT3Nzc3atm2b0tLS3GMBAQFKS0tTZWVlu/tUVlZ6zJek9PT0M84HAAAA4N96mfnm9fX1amlpUWRkpMd4ZGSkdu/e3e4+NTU17c6vqalpd77L5ZLL5XKvNzQ0SJIaGxvPus5TrqaznovO58256ogTf2vu0tfHD+vI+e3Xr59sNpvX+9EPfB/9wLroBfAGvcDauqQfGCY6fPiwIcnYsmWLx/h9991nJCcnt7tP7969jXXr1nmMFRcXG4MHD253fn5+viGJhYXFQktDQ0OHeg79gIXFWgu9gIWF5fTyY/3A1Cs9ERERCgwMVG1trcd4bW2toqKi2t0nKirKq/m5ublyOBzu9dbWVh07dkznnXdeh3465GsaGxsVExOjQ4cOqX///maXg07mr+e3X79+HdqPfuCfnxd/4Y/nl17QMf74WfEn/np+f6wfmBp6goKClJiYKKfTqRkzZkj6rvE4nU7l5OS0u09qaqqcTqfuvvtu99ibb76p1NTUdufb7XbZ7XaPsQEDBnRG+T6lf//+fvXB9zec37NDP/gOnxdr4/z+OHrBd/isWBvn15OpoUeSHA6HZs2apaSkJCUnJ6uoqEhNTU3KysqSJGVmZio6OloFBQWSpHnz5mny5Mn61a9+pauuukrr16/XBx98oGeeecbMwwAAAADQQ5keejIyMlRXV6e8vDzV1NQoISFB5eXl7ocVVFVVKSDg+4fMTZo0SevWrdOiRYv04IMPatSoUXr11Vc1duxYsw4BAAAAQA9meuiRpJycnDPezlZRUdFmbObMmZo5c2YXV2UNdrtd+fn5bS7jwxo4v/AGnxdr4/zibPFZsTbOb/tshmEYZhcBAAAAAF3F1F9OCgAAAABdjdADAAAAwNIIPYAFnDx5Utdee6369+8vm82mr776qt0xANZHPwAg0Qv+EaHHIg4dOqRbb71V559/voKCgjRs2DDNmzdPR48eNbs0nKOzObfPPfec/vSnP2nLli2qrq5WWFhYu2PwD/QD66IfwBv0AuuiF3iP0GMBn3/+uZKSkrR37169+OKL2rdvn0pKSuR0OpWamqpjx46ZXSI66GzP7f79+zVmzBiNHTtWUVFRstls7Y7B+ugH1kU/gDfoBdZFL+ggAz5v2rRpxtChQ42TJ096jFdXVxshISHGL37xC8MwDGPYsGHGsmXLjKysLCM0NNSIiYkxnn76aTNKxlk6m3M7efJkQ5J7mTx5crtj8A/0A+uiH8Ab9ALrohd0DKHHxx09etSw2WzG8uXL292enZ1tDBw40GhtbTWGDRtmhIeHG8XFxcbevXuNgoICIyAgwNi9e3c3V42zcbbntr6+3sjOzjZSU1ON6upq4+jRo8bRo0fbjMH66AfWRT+AN+gF1kUv6Dhub/Nxe/fulWEYGjNmTLvbx4wZo+PHj6uurk6SdOWVV2ru3LkaOXKkFixYoIiICL399tvdWTLO0tme25aWFoWEhCgoKEhRUVEKDw9XeHh4mzFYH/3AuugH8Aa9wLroBR1H6LEI4yx/x+z48ePdf7bZbIqKitKRI0e6qix0grM9t8Bp9AProh/AG/QC66IXeI/Q4+NGjhwpm82mXbt2tbt9165dGjhwoAYNGiRJ6t27t8d2m82m1tbWLq8T3vP23AL0A+uiH8Ab9ALrohd0HKHHx5133nmaOnWqnnzySX3zzTce22pqavS73/1OGRkZ/vV0Dovg3MJbfGasi3MLb/B5sS7ObccReizgiSeekMvlUnp6ut59910dOnRI5eXlmjp1qqKjo7Vs2TKzS0QHcW7hLT4z1sW5hTf4vFgX57ZjCD0WMGrUKH3wwQcaPny4rrvuOo0YMUJz5szRFVdcocrKSr/7opqVcG7hLT4z1sW5hTf4vFgX57ZjbAbfhAIAAABgYVzpAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB4AAAAAlkboAQAAAGBphB6Yrq6uTnfccYcuuOAC2e12RUVFKT09XZs3b5Yk2Ww2vfrqq16/bmxsrIqKijq3WABdhl4A4DT6ATpbL7MLAK699lo1Nzfrueee0/Dhw1VbWyun06mjR4+aXRqAbkQvAHAa/QCdzgBMdPz4cUOSUVFR0e72YcOGGZLcy7BhwwzDMIx9+/YZV199tTF48GCjb9++RlJSkvHmm2+695s8ebLHfqc/6vn5+UZ8fLzHe6xevdr9uoZhGG+//bYxceJEIyQkxAgLCzMmTZpkHDhwoFOPG4AnegGA0+gH6Arc3gZThYaGKjQ0VK+++qpcLleb7e+//74k6Te/+Y2qq6vd6ydOnNCVV14pp9OpDz/8UNOmTdP06dNVVVUlSdqwYYOGDh2qJUuWqLq6WtXV1WdVz7fffqsZM2Zo8uTJ+vjjj1VZWak5c+bIZrN10hEDaA+9AMBp9AN0BW5vg6l69eqltWvXKjs7WyUlJZowYYImT56s66+/XuPHj9egQYMkSQMGDFBUVJR7v/j4eMXHx7vXly5dqldeeUWvvfaacnJyFB4ersDAQPXr189jvx/T2NiohoYG/eu//qtGjBghSRozZkwnHS2AM6EXADiNfoCuwJUemO7aa6/VX//6V7322muaNm2aKioqNGHCBK1du/aM+5w4cUL33nuvxowZowEDBig0NFS7du1y/zSno8LDwzV79mylp6dr+vTpeuyxx876J0EAzg29AMBp9AN0NkIPeoTg4GBNnTpVixcv1pYtWzR79mzl5+efcf69996rV155RcuXL9ef/vQn7dixQ+PGjVNzc/MPvk9AQIAMw/AYO3XqlMf6b37zG1VWVmrSpEkqKyvT6NGj9ec//7njBwfgrNELAJxGP0BnIvSgR4qLi1NTU5MkqXfv3mppafHYvnnzZs2ePVs///nPNW7cOEVFRenAgQMec4KCgtrsN2jQINXU1Hg0tx07drR5/4svvli5ubnasmWLxo4dq3Xr1nXOgQHwCr0AwGn0A5wLQg9MdfToUf30pz/VCy+8oI8//lhffPGFXnrpJa1cuVLXXHONpO+eqe90OlVTU6Pjx49LkkaNGqUNGzZox44d+uijj3TjjTeqtbXV47VjY2P17rvv6vDhw6qvr5ckTZkyRXV1dVq5cqX279+v4uJi/fGPf3Tv88UXXyg3N1eVlZU6ePCg3njjDe3du5d7d4EuRi8AcBr9AF3CzEfHAX/729+MBx54wJgwYYIRFhZmhISEGBdeeKGxaNEi4+TJk4ZhGMZrr71mjBw50ujVq5f78ZFffPGFccUVVxh9+vQxYmJijCeeeMKYPHmyMW/ePPdrV1ZWGuPHjzfsdrvx9x/1p556yoiJiTH69u1rZGZmGsuWLXO/bk1NjTFjxgxjyJAhRlBQkDFs2DAjLy/PaGlp6a6/EsAv0QsAnEY/QFewGcY/3MQIAAAAABbC7W0AAAAALI3QAwAAAMDSCD0AAAAALI3QAwAAAMDSCD0AAAAALI3QAwAAAMDSCD0AAAAALI3QAwAAAMDSCD0AAAAALI3QAwAAAMDSCD0AAAAALI3QAwAAAMDS/h9eR5fiwDxjAAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 840x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melt the data for visualization\n",
    "plot_data = []\n",
    "for f in features:\n",
    "    subset = df_simple[[f, 'value', 'task']].copy()\n",
    "    subset['Feature_Name'] = f\n",
    "    subset = subset.rename(columns={f: 'Status'})\n",
    "    subset['Status'] = subset['Status'].map({True: 'On', False: 'Off'})\n",
    "    plot_data.append(subset)\n",
    "\n",
    "df_plot = pd.concat(plot_data)\n",
    "\n",
    "# Create a FacetGrid to see On/Off for each feature across tasks\n",
    "g = sns.catplot(\n",
    "    data=df_plot, x='Status', y='value',\n",
    "    col='Feature_Name', kind='bar',\n",
    "    palette='muted', height=4, aspect=0.7\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370cc5235e224ab",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf48a86140a816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:10.595609Z",
     "start_time": "2026-02-09T04:58:10.582585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  0.296637  0.296529 -0.000108\n",
      "1      rs  0.296559  0.296619  0.000060\n",
      "2   lcoef  0.296545  0.296645  0.000100\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['params'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570453e5699aa3",
   "metadata": {},
   "source": [
    "### Traintime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c002fa7d60b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.256511Z",
     "start_time": "2026-02-09T04:58:11.231191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg      Delta\n",
      "0   olora  762.321481  790.991176  28.669695\n",
      "1      rs  743.191765  792.417407  49.225643\n",
      "2   lcoef  794.388182  752.408636 -41.979545\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['traintime'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0571e908c87d",
   "metadata": {},
   "source": [
    "1. Olora cuts traintime.\n",
    "2. rs add traintime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357b36f540c8e5",
   "metadata": {},
   "source": [
    "### GPUMEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155dd12a1a8cea22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.416928Z",
     "start_time": "2026-02-09T04:58:11.408028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg     Delta\n",
      "0   olora  761.648519  761.655882  0.007364\n",
      "1      rs  761.649412  761.652593  0.003181\n",
      "2   lcoef  761.626364  761.676364  0.050000\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['gpumem'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c37fed59d5101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:12.147491Z",
     "start_time": "2026-02-09T04:58:12.143853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([761.65, 761.68, 761.53, 761.56, 761.67, 761.69])"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.gpumem.unique() # Almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c736e089edac5e7",
   "metadata": {},
   "source": [
    "## Compare with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998732af3a0030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:36.666812Z",
     "start_time": "2026-02-09T04:58:35.763401Z"
    }
   },
   "outputs": [],
   "source": [
    "df_base = aggregate_experiment_results('./results')\n",
    "df_base = df_base[df_base.variant == 'kd-lora']\n",
    "df_base = df_base[df_base.task.isin(df.task.unique())]\n",
    "df_base = df_base[df_base.family.isin(df.family.unique())]\n",
    "df_base = df_base[df_base.seed == 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f61536854053fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:39.339410Z",
     "start_time": "2026-02-09T04:58:39.337459Z"
    }
   },
   "outputs": [],
   "source": [
    "df_our = df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f0f541cd088db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:40.957626Z",
     "start_time": "2026-02-09T04:58:40.917101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "      <th>rs</th>\n",
       "      <th>lcoef</th>\n",
       "      <th>olora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1171.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>636.53</td>\n",
       "      <td>0.35</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>604.82</td>\n",
       "      <td>0.35</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>665.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1831.38</td>\n",
       "      <td>3.43</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9270</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2439.52</td>\n",
       "      <td>3.15</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1567.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1240.95</td>\n",
       "      <td>3.06</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1276.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1464.76</td>\n",
       "      <td>3.23</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1510.17</td>\n",
       "      <td>3.57</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1639.25</td>\n",
       "      <td>3.13</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>453.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>505.50</td>\n",
       "      <td>0.23</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>369.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>mismatched_accuracy</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>1949.50</td>\n",
       "      <td>3.47</td>\n",
       "      <td>761.67</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>mismatched_accuracy</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>2002.56</td>\n",
       "      <td>3.37</td>\n",
       "      <td>761.69</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>matched_accuracy</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>2002.56</td>\n",
       "      <td>3.37</td>\n",
       "      <td>761.69</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>matched_accuracy</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>1949.50</td>\n",
       "      <td>3.47</td>\n",
       "      <td>761.67</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>417.77</td>\n",
       "      <td>0.25</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>378.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>465.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>761.56</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>395.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>348.85</td>\n",
       "      <td>0.27</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>346.84</td>\n",
       "      <td>0.21</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>275.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>292.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>333.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>403.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1048.18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>313.23</td>\n",
       "      <td>0.51</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>358.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>240.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>315.06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>820.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>291.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>240.60</td>\n",
       "      <td>13.97</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>251.89</td>\n",
       "      <td>13.82</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>243.73</td>\n",
       "      <td>13.46</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>256.68</td>\n",
       "      <td>14.91</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3295</td>\n",
       "      <td>mismatched_accuracy</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>168.64</td>\n",
       "      <td>2.82</td>\n",
       "      <td>761.67</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3295</td>\n",
       "      <td>mismatched_accuracy</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>187.34</td>\n",
       "      <td>3.44</td>\n",
       "      <td>761.69</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>matched_accuracy</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>168.64</td>\n",
       "      <td>2.82</td>\n",
       "      <td>761.67</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>mnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>matched_accuracy</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>187.34</td>\n",
       "      <td>3.44</td>\n",
       "      <td>761.69</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                   peft  task variant   value                     metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path     rs  lcoef  olora\n",
       "32  deberta        mrlora-rs-olora  sst2    lora  0.9507              eval_accuracy  0.2964    1171.05      0.33  761.65     8    42   ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "33  deberta        mrlora-rs-lcoef  sst2    lora  0.9461              eval_accuracy  0.2965     636.53      0.35  761.68     8    42   ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "34  deberta              mrlora-rs  sst2    lora  0.9461              eval_accuracy  0.2964     604.82      0.35  761.65     8    42         ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "35  deberta           mrlora-lcoef  sst2    lora  0.9438              eval_accuracy  0.2965     665.48      0.36  761.68     8    42      ablation3/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "0   deberta        mrlora-rs-olora  qnli    lora  0.9275              eval_accuracy  0.2964    1831.38      3.43  761.65     8    42   ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "6   deberta           mrlora-olora  qnli    lora  0.9270              eval_accuracy  0.2964    2439.52      3.15  761.65     8    42      ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "4   deberta  mrlora-rs-olora-lcoef  qnli    lora  0.9251              eval_accuracy  0.2965    1567.67      3.25  761.68     8    42  ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...   True   True   True\n",
       "3   deberta              mrlora-rs  qnli    lora  0.9209              eval_accuracy  0.2964    1240.95      3.06  761.65     8    42         ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "1   deberta        mrlora-rs-lcoef  qnli    lora  0.9204              eval_accuracy  0.2965    1276.00      3.63  761.68     8    42   ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "2   deberta                 mrlora  qnli    lora  0.9193              eval_accuracy  0.2964    1464.76      3.23  761.53     8    42            ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "7   deberta           mrlora-lcoef  qnli    lora  0.9191              eval_accuracy  0.2965    1510.17      3.57  761.68     8    42      ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "5   deberta     mrlora-olora-lcoef  qnli    lora  0.9171              eval_accuracy  0.2965    1639.25      3.13  761.68     8    42  ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...  False   True   True\n",
       "18  deberta        mrlora-rs-lcoef  mrpc    lora  0.8725              eval_accuracy  0.2965     453.61      0.23  761.68     8    42   ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "20  deberta              mrlora-rs  mrpc    lora  0.8676              eval_accuracy  0.2964     505.50      0.23  761.53     8    42         ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "16  deberta        mrlora-rs-olora  mrpc    lora  0.8627              eval_accuracy  0.2964     369.33      0.25  761.65     8    42   ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "49  deberta              mrlora-rs  mnli    lora  0.8587        mismatched_accuracy  0.2972    1949.50      3.47  761.67     8    42         ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "47  deberta        mrlora-rs-lcoef  mnli    lora  0.8585        mismatched_accuracy  0.2973    2002.56      3.37  761.69     8    42   ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "46  deberta        mrlora-rs-lcoef  mnli    lora  0.8547           matched_accuracy  0.2973    2002.56      3.37  761.69     8    42   ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "48  deberta              mrlora-rs  mnli    lora  0.8542           matched_accuracy  0.2972    1949.50      3.47  761.67     8    42         ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "22  deberta           mrlora-lcoef  mrpc    lora  0.8529              eval_accuracy  0.2965     417.77      0.25  761.68     8    42      ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "43  deberta           mrlora-lcoef   rte    lora  0.7617              eval_accuracy  0.2965     378.37      0.23  761.68     8    42       ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "37  deberta        mrlora-rs-lcoef   rte    lora  0.7509              eval_accuracy  0.2965     465.71      0.19  761.56     8    42    ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "38  deberta                 mrlora   rte    lora  0.7509              eval_accuracy  0.2964     395.73      0.27  761.53     8    42             ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "39  deberta              mrlora-rs   rte    lora  0.7437              eval_accuracy  0.2964     348.85      0.27  761.65     8    42          ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "40  deberta  mrlora-rs-olora-lcoef   rte    lora  0.6751              eval_accuracy  0.2965     346.84      0.21  761.68     8    42  ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metri...   True   True   True\n",
       "41  deberta     mrlora-olora-lcoef   rte    lora  0.6751              eval_accuracy  0.2965     275.37      0.19  761.68     8    42  ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....  False   True   True\n",
       "42  deberta           mrlora-olora   rte    lora  0.6715              eval_accuracy  0.2964     292.34      0.25  761.65     8    42       ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "36  deberta        mrlora-rs-olora   rte    lora  0.6715              eval_accuracy  0.2964     333.42      0.14  761.53     8    42    ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "28  deberta  mrlora-rs-olora-lcoef  cola    lora  0.6700  eval_matthews_correlation  0.2965     403.36      0.73  761.68     8    42  ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...   True   True   True\n",
       "29  deberta     mrlora-olora-lcoef  cola    lora  0.6632  eval_matthews_correlation  0.2965    1048.18      0.54  761.68     8    42  ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...  False   True   True\n",
       "31  deberta           mrlora-lcoef  cola    lora  0.6606  eval_matthews_correlation  0.2965     313.23      0.51  761.68     8    42      ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "26  deberta                 mrlora  cola    lora  0.6580  eval_matthews_correlation  0.2964     358.69      0.53  761.53     8    42            ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "27  deberta              mrlora-rs  cola    lora  0.6579  eval_matthews_correlation  0.2964     240.17      0.50  761.65     8    42         ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "24  deberta        mrlora-rs-olora  cola    lora  0.6579  eval_matthews_correlation  0.2964     315.06      0.57  761.65     8    42   ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "30  deberta           mrlora-olora  cola    lora  0.6567  eval_matthews_correlation  0.2964     820.12      0.50  761.65     8    42      ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "25  deberta        mrlora-rs-lcoef  cola    lora  0.6555  eval_matthews_correlation  0.2965     291.32      0.60  761.68     8    42   ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "14  deberta           mrlora-lcoef   qqp    lora  0.3717              eval_accuracy  0.2965     240.60     13.97  761.68     8    42       ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "12  deberta              mrlora-rs   qqp    lora  0.3682              eval_accuracy  0.2964     251.89     13.82  761.65     8    42          ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "10  deberta        mrlora-rs-lcoef   qqp    lora  0.3682              eval_accuracy  0.2965     243.73     13.46  761.68     8    42    ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "8   deberta        mrlora-rs-olora   qqp    lora  0.3682              eval_accuracy  0.2964     256.68     14.91  761.65     8    42    ablation3/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "45  deberta        mrlora-rs-olora  mnli    lora  0.3295        mismatched_accuracy  0.2972     168.64      2.82  761.67     8    42   ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "51  deberta           mrlora-lcoef  mnli    lora  0.3295        mismatched_accuracy  0.2973     187.34      3.44  761.69     8    42      ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "44  deberta        mrlora-rs-olora  mnli    lora  0.3275           matched_accuracy  0.2972     168.64      2.82  761.67     8    42   ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "50  deberta           mrlora-lcoef  mnli    lora  0.3275           matched_accuracy  0.2973     187.34      3.44  761.69     8    42      ablation3/lora/task_mnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_our.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e08081d96b22fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:42.997489Z",
     "start_time": "2026-02-09T04:58:42.988918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1029.29</td>\n",
       "      <td>0.21</td>\n",
       "      <td>762.42</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>deberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1003.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>762.42</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>1.1812</td>\n",
       "      <td>898.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>775.63</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>848.89</td>\n",
       "      <td>0.45</td>\n",
       "      <td>761.63</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_rslora_8_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>sst2</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>860.29</td>\n",
       "      <td>0.45</td>\n",
       "      <td>761.63</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_lora_8_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>388.64</td>\n",
       "      <td>20.57</td>\n",
       "      <td>761.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_8_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>1.1812</td>\n",
       "      <td>340.16</td>\n",
       "      <td>18.80</td>\n",
       "      <td>775.63</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>deberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>418.94</td>\n",
       "      <td>19.24</td>\n",
       "      <td>767.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>343.37</td>\n",
       "      <td>16.85</td>\n",
       "      <td>762.42</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>344.17</td>\n",
       "      <td>17.05</td>\n",
       "      <td>763.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      family     peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                     path\n",
       "573  deberta   rslora  sst2    lora  0.9599  eval_accuracy  0.2964    1029.29      0.21  762.42     8    42  results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "571  deberta    olora  sst2    lora  0.9587  eval_accuracy  0.2964    1003.90      0.20  762.42     8    42   results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "567  deberta     lora  sst2    lora  0.9576  eval_accuracy  1.1812     898.53      0.44  775.63    32    42   results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json\n",
       "566  deberta   rslora  sst2    lora  0.9576  eval_accuracy  0.2964     848.89      0.45  761.63     8    42   results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_rslora_8_0.05_8/metrics.json\n",
       "575  deberta     lora  sst2    lora  0.9564  eval_accuracy  0.2964     860.29      0.45  761.63     8    42     results/lora/task_sst2_deberta_42/base_32_2e-05_0.01/peft_lora_8_0.05_8/metrics.json\n",
       "..       ...      ...   ...     ...     ...            ...     ...        ...       ...     ...   ...   ...                                                                                      ...\n",
       "412  deberta     dora   qqp    lora  0.3682  eval_accuracy  0.3149     388.64     20.57  761.91     8    42      results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_8_0.05_8/metrics.json\n",
       "398  deberta     lora   qqp    lora  0.3682  eval_accuracy  1.1812     340.16     18.80  775.63    32    42    results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json\n",
       "400  deberta  adalora   qqp    lora  0.3682  eval_accuracy  0.5917     418.94     19.24  767.34     8    42  results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "410  deberta   rslora   qqp    lora  0.3682  eval_accuracy  0.2964     343.37     16.85  762.42     8    42   results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "404  deberta     lora   qqp    lora  0.3682  eval_accuracy  0.2964     344.17     17.05  763.20     8    42     results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "\n",
       "[163 rows x 13 columns]"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.sort_values('value', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
