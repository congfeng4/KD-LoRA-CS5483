{
 "cells": [
  {
   "cell_type": "code",
   "id": "95587a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.250580Z",
     "start_time": "2026-02-07T16:08:33.248357Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ],
   "outputs": [],
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "id": "9375c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.265974Z",
     "start_time": "2026-02-07T16:08:33.262078Z"
    }
   },
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-rs': 'MR-LoRA-RS',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ],
   "outputs": [],
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.284193Z",
     "start_time": "2026-02-07T16:08:33.269750Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./ablation/')"
   ],
   "outputs": [],
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "id": "51ab95559e913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.289983Z",
     "start_time": "2026-02-07T16:08:33.287634Z"
    }
   },
   "source": [
    "df.family.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['roberta'], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "id": "14a30665e40b194d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.304422Z",
     "start_time": "2026-02-07T16:08:33.302223Z"
    }
   },
   "source": [
    "df.peft.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrlora-olora', 'mrlora-lcoef', 'mrlora', 'mrlora-olora-lcoef',\n",
       "       'mrlora-rs-lcoef', 'mrlora-olora-rs', 'mrlora-rs',\n",
       "       'mrlora-olora-rs-lcoef'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "id": "8fbe73398833aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.315029Z",
     "start_time": "2026-02-07T16:08:33.312859Z"
    }
   },
   "source": [
    "df['rank'].unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  8])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "id": "44c0212dc379992b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.328545Z",
     "start_time": "2026-02-07T16:08:33.326703Z"
    }
   },
   "source": [
    "df.task.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qqp', 'cola'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "id": "440790b4a0f827b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.343276Z",
     "start_time": "2026-02-07T16:08:33.339341Z"
    }
   },
   "source": [
    "df.groupby('task').count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      family  peft  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "task                                                                                             \n",
       "cola      16    16       16     16      16      16         16        16      16    16    16    16\n",
       "qqp       32    32       32     32      32      32         32        32      32    32    32    32"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "id": "57a931016c9ee7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.372428Z",
     "start_time": "2026-02-07T16:08:33.370382Z"
    }
   },
   "source": [
    "df.metric.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eval_accuracy', 'eval_f1', 'eval_matthews_correlation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "id": "c34344c47bffaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.413641Z",
     "start_time": "2026-02-07T16:08:33.411725Z"
    }
   },
   "source": [
    "df.seed.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "cell_type": "code",
   "id": "8a075dbd861ae3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.440266Z",
     "start_time": "2026-02-07T16:08:33.438232Z"
    }
   },
   "source": [
    "df.variant.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lora'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "id": "1798adbfcbc94c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.471946Z",
     "start_time": "2026-02-07T16:08:33.469947Z"
    }
   },
   "source": [
    "df.params.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.182 , 1.1821, 0.887 , 0.8871])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.504573Z",
     "start_time": "2026-02-07T16:08:33.497886Z"
    }
   },
   "cell_type": "code",
   "source": "df[df.metric == 'eval_accuracy'].describe()",
   "id": "97703ef3d88747f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           value     params   traintime   evaltime      gpumem       rank  seed\n",
       "count  16.000000  16.000000    16.00000  16.000000   16.000000  16.000000  16.0\n",
       "mean    0.870256   1.034550  1659.12500  11.318750  533.758750  12.000000  42.0\n",
       "std     0.005457   0.152337   298.88528   0.841617    2.416559   4.131182   0.0\n",
       "min     0.858500   0.887000   757.75000   9.910000  530.330000   8.000000  42.0\n",
       "25%     0.867075   0.887075  1604.72000  10.860000  531.240000   8.000000  42.0\n",
       "50%     0.869850   1.034550  1687.69500  11.305000  533.980000  12.000000  42.0\n",
       "75%     0.874775   1.182025  1813.87750  11.997500  535.690000  16.000000  42.0\n",
       "max     0.879500   1.182100  2124.06000  12.820000  537.370000  16.000000  42.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.870256</td>\n",
       "      <td>1.034550</td>\n",
       "      <td>1659.12500</td>\n",
       "      <td>11.318750</td>\n",
       "      <td>533.758750</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.152337</td>\n",
       "      <td>298.88528</td>\n",
       "      <td>0.841617</td>\n",
       "      <td>2.416559</td>\n",
       "      <td>4.131182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>757.75000</td>\n",
       "      <td>9.910000</td>\n",
       "      <td>530.330000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.867075</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>1604.72000</td>\n",
       "      <td>10.860000</td>\n",
       "      <td>531.240000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.869850</td>\n",
       "      <td>1.034550</td>\n",
       "      <td>1687.69500</td>\n",
       "      <td>11.305000</td>\n",
       "      <td>533.980000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.874775</td>\n",
       "      <td>1.182025</td>\n",
       "      <td>1813.87750</td>\n",
       "      <td>11.997500</td>\n",
       "      <td>535.690000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.879500</td>\n",
       "      <td>1.182100</td>\n",
       "      <td>2124.06000</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>537.370000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.539316Z",
     "start_time": "2026-02-07T16:08:33.536270Z"
    }
   },
   "cell_type": "code",
   "source": "df[(df.metric == 'eval_f1') & (df.value == 0.0)]",
   "id": "c05606017ed6c66f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [family, peft, task, variant, value, metric, params, traintime, evaltime, gpumem, rank, seed, path]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.600182Z",
     "start_time": "2026-02-07T16:08:33.597837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_simple = df[(df.task != 'stsb') & (df['rank'] == 8)]\n",
    "df_simple = df_simple[df.metric != 'eval_f1']"
   ],
   "id": "59c649ba972b5c51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_74410/1960551128.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_simple = df_simple[df.metric != 'eval_f1']\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.623531Z",
     "start_time": "2026-02-07T16:08:33.615059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Expand the 'peft' strings into feature columns\n",
    "features = [ 'rs', 'lcoef', 'olora', ]\n",
    "\n",
    "for f in features:\n",
    "    # Checks if the feature name exists as a standalone word in the string\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))\n",
    "\n",
    "# 2. Create a Pivot Table\n",
    "# We group by the feature flags and show the mean 'value' for each 'task'\n",
    "pivot_df = df_simple.pivot_table(\n",
    "    index=features,\n",
    "    columns='task',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# 3. Apply Styling (Conditional Formatting)\n",
    "styled_table = pivot_df.style.background_gradient(axis=0, cmap='YlGnBu') \\\n",
    "                             .format(\"{:.4f}\") \\\n",
    "                             .set_caption(\"MrLoRA Feature Ablation Study\")\n",
    "\n",
    "# Display in Jupyter/Colab\n",
    "styled_table"
   ],
   "id": "6e62273245330afe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1065cb230>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_13b94_row0_col0, #T_13b94_row1_col1 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row0_col1 {\n",
       "  background-color: #aedfb6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row1_col0 {\n",
       "  background-color: #1e8bbd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13b94_row2_col0 {\n",
       "  background-color: #fdfed4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row2_col1 {\n",
       "  background-color: #78cbbc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row3_col0 {\n",
       "  background-color: #1e88bc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13b94_row3_col1 {\n",
       "  background-color: #a2dbb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row4_col0 {\n",
       "  background-color: #cbebb4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row4_col1 {\n",
       "  background-color: #87d0ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row5_col0, #T_13b94_row6_col1 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13b94_row5_col1 {\n",
       "  background-color: #eef8b3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row6_col0 {\n",
       "  background-color: #d4eeb3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13b94_row7_col0 {\n",
       "  background-color: #1e85ba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13b94_row7_col1 {\n",
       "  background-color: #eff9b6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_13b94\">\n",
       "  <caption>MrLoRA Feature Ablation Study</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_13b94_level0_col0\" class=\"col_heading level0 col0\" >cola</th>\n",
       "      <th id=\"T_13b94_level0_col1\" class=\"col_heading level0 col1\" >qqp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >rs</th>\n",
       "      <th class=\"index_name level1\" >lcoef</th>\n",
       "      <th class=\"index_name level2\" >olora</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">False</th>\n",
       "      <th id=\"T_13b94_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_13b94_level2_row0\" class=\"row_heading level2 row0\" >False</th>\n",
       "      <td id=\"T_13b94_row0_col0\" class=\"data row0 col0\" >0.5806</td>\n",
       "      <td id=\"T_13b94_row0_col1\" class=\"data row0 col1\" >0.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level2_row1\" class=\"row_heading level2 row1\" >True</th>\n",
       "      <td id=\"T_13b94_row1_col0\" class=\"data row1 col0\" >0.6034</td>\n",
       "      <td id=\"T_13b94_row1_col1\" class=\"data row1 col1\" >0.8658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_13b94_level2_row2\" class=\"row_heading level2 row2\" >False</th>\n",
       "      <td id=\"T_13b94_row2_col0\" class=\"data row2 col0\" >0.5812</td>\n",
       "      <td id=\"T_13b94_row2_col1\" class=\"data row2 col1\" >0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level2_row3\" class=\"row_heading level2 row3\" >True</th>\n",
       "      <td id=\"T_13b94_row3_col0\" class=\"data row3 col0\" >0.6036</td>\n",
       "      <td id=\"T_13b94_row3_col1\" class=\"data row3 col1\" >0.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">True</th>\n",
       "      <th id=\"T_13b94_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_13b94_level2_row4\" class=\"row_heading level2 row4\" >False</th>\n",
       "      <td id=\"T_13b94_row4_col0\" class=\"data row4 col0\" >0.5890</td>\n",
       "      <td id=\"T_13b94_row4_col1\" class=\"data row4 col1\" >0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level2_row5\" class=\"row_heading level2 row5\" >True</th>\n",
       "      <td id=\"T_13b94_row5_col0\" class=\"data row5 col0\" >0.6162</td>\n",
       "      <td id=\"T_13b94_row5_col1\" class=\"data row5 col1\" >0.8671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_13b94_level2_row6\" class=\"row_heading level2 row6\" >False</th>\n",
       "      <td id=\"T_13b94_row6_col0\" class=\"data row6 col0\" >0.5880</td>\n",
       "      <td id=\"T_13b94_row6_col1\" class=\"data row6 col1\" >0.8766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b94_level2_row7\" class=\"row_heading level2 row7\" >True</th>\n",
       "      <td id=\"T_13b94_row7_col0\" class=\"data row7 col0\" >0.6039</td>\n",
       "      <td id=\"T_13b94_row7_col1\" class=\"data row7 col1\" >0.8670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.642548Z",
     "start_time": "2026-02-07T16:08:33.640596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features to isolate\n",
    "features = ['olora', 'rs', 'lcoef']\n",
    "\n",
    "# Create boolean columns: True if feature name is in the 'peft' string\n",
    "for f in features:\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))"
   ],
   "id": "c9a54ce04a4a75ad",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metric",
   "id": "bae3e0cfa4b46888"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:13:06.247558Z",
     "start_time": "2026-02-07T16:13:06.237678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['value'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ],
   "id": "bcb5854cd105ad44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  0.728012  0.737025  0.009013\n",
      "1      rs  0.730350  0.734687  0.004337\n",
      "2   lcoef  0.732600  0.732437 -0.000163\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "cell_type": "markdown",
   "id": "e1f145e2e877ecd1",
   "metadata": {},
   "source": [
    "1. bias cause obvious drop.\n",
    "2. rs and lcoef boost perf."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.883482Z",
     "start_time": "2026-02-07T16:08:33.679464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Melt the data for visualization\n",
    "plot_data = []\n",
    "for f in features:\n",
    "    subset = df_simple[[f, 'value', 'task']].copy()\n",
    "    subset['Feature_Name'] = f\n",
    "    subset = subset.rename(columns={f: 'Status'})\n",
    "    subset['Status'] = subset['Status'].map({True: 'On', False: 'Off'})\n",
    "    plot_data.append(subset)\n",
    "\n",
    "df_plot = pd.concat(plot_data)\n",
    "\n",
    "# Create a FacetGrid to see On/Off for each feature across tasks\n",
    "g = sns.catplot(\n",
    "    data=df_plot, x='Status', y='value',\n",
    "    col='Feature_Name', kind='bar',\n",
    "    palette='muted', height=4, aspect=0.7\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n"
   ],
   "id": "f12b207fde3f9e13",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_74410/3376707498.py:13: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  g = sns.catplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x314a78740>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 840x400 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Params",
   "id": "f370cc5235e224ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.897386Z",
     "start_time": "2026-02-07T16:08:33.893961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['params'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ],
   "id": "91bf48a86140a816",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Off_Avg   On_Avg   Delta\n",
      "0   olora  0.88705  0.88705  0.0000\n",
      "1      rs  0.88705  0.88705  0.0000\n",
      "2   lcoef  0.88700  0.88710  0.0001\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Traintime",
   "id": "d8570453e5699aa3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:13:49.656552Z",
     "start_time": "2026-02-07T16:13:49.650142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['traintime'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ],
   "id": "7e9c002fa7d60b95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg    Delta\n",
      "0   olora  1093.27500  1090.53250  -2.7425\n",
      "1      rs  1060.43500  1123.37250  62.9375\n",
      "2   lcoef  1073.91375  1109.89375  35.9800\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0571e908c87d",
   "metadata": {},
   "source": [
    "1. Olora cuts traintime.\n",
    "2. rs add traintime."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPUMEM",
   "id": "6357b36f540c8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.919080Z",
     "start_time": "2026-02-07T16:08:33.914732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['gpumem'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ],
   "id": "155dd12a1a8cea22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature    Off_Avg     On_Avg    Delta\n",
      "0   olora  531.32750  530.88625 -0.44125\n",
      "1      rs  531.13125  531.08250 -0.04875\n",
      "2   lcoef  531.31375  530.90000 -0.41375\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:33.929665Z",
     "start_time": "2026-02-07T16:08:33.927027Z"
    }
   },
   "cell_type": "code",
   "source": "df_simple.gpumem.unique() # Almost the same.",
   "id": "301c37fed59d5101",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([532.26, 531.24, 532.29, 531.21, 530.33, 531.09, 531.11, 530.3 ])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 174
  },
  {
   "cell_type": "markdown",
   "id": "6c736e089edac5e7",
   "metadata": {},
   "source": [
    "## Compare with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "id": "f998732af3a0030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:34.326169Z",
     "start_time": "2026-02-07T16:08:33.939937Z"
    }
   },
   "source": [
    "df_base = aggregate_experiment_results('./results')\n",
    "df_base = df_base[df_base.variant == 'lora']\n",
    "df_base = df_base[df_base.task.isin(df.task.unique())]\n",
    "df_base = df_base[df_base.family.isin(df.family.unique())]\n",
    "df_base = df_base[df_base.seed == 42]"
   ],
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:34.329757Z",
     "start_time": "2026-02-07T16:08:34.328542Z"
    }
   },
   "cell_type": "code",
   "source": "df_our = df_simple",
   "id": "d2f61536854053fa",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:34.338065Z",
     "start_time": "2026-02-07T16:08:34.332613Z"
    }
   },
   "cell_type": "code",
   "source": "df_our.sort_values('value', ascending=False)",
   "id": "b70f0f541cd088db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     family                   peft  task variant   value                     metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path     rs  lcoef  olora\n",
       "8   roberta        mrlora-rs-lcoef   qqp    lora  0.8766              eval_accuracy  0.8871    2124.06     12.27  532.29     8    42     ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "16  roberta           mrlora-lcoef   qqp    lora  0.8700              eval_accuracy  0.8871    1703.82     12.20  531.24     8    42        ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "14  roberta              mrlora-rs   qqp    lora  0.8697              eval_accuracy  0.8870    1834.27     12.82  531.21     8    42           ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "6   roberta     mrlora-olora-lcoef   qqp    lora  0.8692              eval_accuracy  0.8871    1879.59     10.56  531.24     8    42  ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "4   roberta                 mrlora   qqp    lora  0.8690              eval_accuracy  0.8870    1775.22     10.04  532.26     8    42              ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "12  roberta        mrlora-olora-rs   qqp    lora  0.8671              eval_accuracy  0.8870    1807.08     10.31  531.21     8    42     ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "30  roberta  mrlora-olora-rs-lcoef   qqp    lora  0.8670              eval_accuracy  0.8871    1876.91     11.17  530.33     8    42  ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...   True   True   True\n",
       "28  roberta           mrlora-olora   qqp    lora  0.8658              eval_accuracy  0.8870    1769.52     12.14  532.26     8    42        ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "38  roberta        mrlora-olora-rs  cola    lora  0.6162  eval_matthews_correlation  0.8870     355.85      0.36  531.09     8    42    ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "47  roberta  mrlora-olora-rs-lcoef  cola    lora  0.6039  eval_matthews_correlation  0.8871     371.62      0.32  530.33     8    42  ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...   True   True   True\n",
       "35  roberta     mrlora-olora-lcoef  cola    lora  0.6036  eval_matthews_correlation  0.8871     289.08      0.37  530.33     8    42  ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....  False   True   True\n",
       "46  roberta           mrlora-olora  cola    lora  0.6034  eval_matthews_correlation  0.8870     374.61      0.34  530.30     8    42       ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "39  roberta              mrlora-rs  cola    lora  0.5890  eval_matthews_correlation  0.8870     271.63      0.35  531.09     8    42          ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "36  roberta        mrlora-rs-lcoef  cola    lora  0.5880  eval_matthews_correlation  0.8871     345.56      0.32  531.11     8    42    ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "40  roberta           mrlora-lcoef  cola    lora  0.5812  eval_matthews_correlation  0.8871     288.51      0.32  530.33     8    42       ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "34  roberta                 mrlora  cola    lora  0.5806  eval_matthews_correlation  0.8870     403.13      0.32  531.09     8    42             ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "      <th>rs</th>\n",
       "      <th>lcoef</th>\n",
       "      <th>olora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>2124.06</td>\n",
       "      <td>12.27</td>\n",
       "      <td>532.29</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1703.82</td>\n",
       "      <td>12.20</td>\n",
       "      <td>531.24</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1834.27</td>\n",
       "      <td>12.82</td>\n",
       "      <td>531.21</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1879.59</td>\n",
       "      <td>10.56</td>\n",
       "      <td>531.24</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1775.22</td>\n",
       "      <td>10.04</td>\n",
       "      <td>532.26</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1807.08</td>\n",
       "      <td>10.31</td>\n",
       "      <td>531.21</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1876.91</td>\n",
       "      <td>11.17</td>\n",
       "      <td>530.33</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1769.52</td>\n",
       "      <td>12.14</td>\n",
       "      <td>532.26</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6162</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>355.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>531.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6039</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>371.62</td>\n",
       "      <td>0.32</td>\n",
       "      <td>530.33</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>289.08</td>\n",
       "      <td>0.37</td>\n",
       "      <td>530.33</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>374.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>530.30</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>271.63</td>\n",
       "      <td>0.35</td>\n",
       "      <td>531.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>345.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>531.11</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>288.51</td>\n",
       "      <td>0.32</td>\n",
       "      <td>530.33</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5806</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>403.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>531.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T16:08:34.364034Z",
     "start_time": "2026-02-07T16:08:34.358664Z"
    }
   },
   "cell_type": "code",
   "source": "df_base.sort_values('value', ascending=False)",
   "id": "e0e08081d96b22fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       family     peft  task variant   value                     metric  params  traintime  evaltime  gpumem  rank  seed                                                                                      path\n",
       "1653  roberta    olora   qqp    lora  0.8632              eval_accuracy  0.8870    1754.58     14.68  534.59     8    42     results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "1657  roberta     dora   qqp    lora  0.8615              eval_accuracy  0.9055    2235.78     12.15  534.09     8    42      results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "1651  roberta     lora   qqp    lora  0.8505              eval_accuracy  0.8870    1238.98     14.06  533.81     8    42      results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "1649  roberta   rslora   qqp    lora  0.8504              eval_accuracy  0.8870    1091.74      8.90  534.59     8    42    results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "1654  roberta    olora   qqp    lora  0.8287                    eval_f1  0.8870    1754.58     14.68  534.59     8    42     results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "1658  roberta     dora   qqp    lora  0.8225                    eval_f1  0.9055    2235.78     12.15  534.09     8    42      results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "1650  roberta   rslora   qqp    lora  0.8130                    eval_f1  0.8870    1091.74      8.90  534.59     8    42    results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "1652  roberta     lora   qqp    lora  0.8104                    eval_f1  0.8870    1238.98     14.06  533.81     8    42      results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "1655  roberta  adalora   qqp    lora  0.6318              eval_accuracy  1.1823     293.23     11.24  538.20     8    42   results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "1854  roberta   rslora  cola    lora  0.6185  eval_matthews_correlation  0.8870     409.00      0.15  533.81     8    42   results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "1858  roberta     dora  cola    lora  0.6157  eval_matthews_correlation  0.9055     492.61      0.21  534.09     8    42     results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "1856  roberta    olora  cola    lora  0.5938  eval_matthews_correlation  0.8870     330.71      0.16  533.81     8    42    results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "1855  roberta     lora  cola    lora  0.5908  eval_matthews_correlation  0.8870     322.72      0.22  533.02     8    42     results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "1857  roberta  adalora  cola    lora  0.5732  eval_matthews_correlation  1.1823     845.33      0.20  538.55     8    42  results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "1656  roberta  adalora   qqp    lora  0.0000                    eval_f1  1.1823     293.23     11.24  538.20     8    42   results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>roberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1754.58</td>\n",
       "      <td>14.68</td>\n",
       "      <td>534.59</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>roberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>2235.78</td>\n",
       "      <td>12.15</td>\n",
       "      <td>534.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>roberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1238.98</td>\n",
       "      <td>14.06</td>\n",
       "      <td>533.81</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>roberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1091.74</td>\n",
       "      <td>8.90</td>\n",
       "      <td>534.59</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>roberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1754.58</td>\n",
       "      <td>14.68</td>\n",
       "      <td>534.59</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>roberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>2235.78</td>\n",
       "      <td>12.15</td>\n",
       "      <td>534.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>roberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1091.74</td>\n",
       "      <td>8.90</td>\n",
       "      <td>534.59</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>roberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1238.98</td>\n",
       "      <td>14.06</td>\n",
       "      <td>533.81</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>roberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>293.23</td>\n",
       "      <td>11.24</td>\n",
       "      <td>538.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>roberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>409.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>533.81</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>roberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>492.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>534.09</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>roberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>330.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>533.81</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>roberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5908</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>322.72</td>\n",
       "      <td>0.22</td>\n",
       "      <td>533.02</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>roberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.5732</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>845.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>538.55</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_cola_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>roberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>293.23</td>\n",
       "      <td>11.24</td>\n",
       "      <td>538.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 178
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
