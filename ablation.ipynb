{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "95587a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:50.112595Z",
     "start_time": "2026-02-09T04:57:50.110148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "9375c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.062695Z",
     "start_time": "2026-02-09T04:57:51.046231Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-rs': 'MR-LoRA-RS',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.191694Z",
     "start_time": "2026-02-09T04:57:51.138931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"metrics.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./ablation3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "51ab95559e913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.673632Z",
     "start_time": "2026-02-09T04:57:51.667832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['deberta'], dtype=object)"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "14a30665e40b194d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:52.765619Z",
     "start_time": "2026-02-09T04:57:52.762058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrlora-rs-olora', 'mrlora-rs-lcoef', 'mrlora', 'mrlora-rs',\n",
       "       'mrlora-rs-olora-lcoef', 'mrlora-olora-lcoef', 'mrlora-olora',\n",
       "       'mrlora-lcoef'], dtype=object)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.peft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "8fbe73398833aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:55.404732Z",
     "start_time": "2026-02-09T04:57:55.398687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "44c0212dc379992b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.090823Z",
     "start_time": "2026-02-09T04:57:56.074050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qnli', 'mrpc', 'cola', 'rte', 'qqp', 'mnli', 'stsb'], dtype=object)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "440790b4a0f827b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.706572Z",
     "start_time": "2026-02-09T04:57:56.696235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stsb</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family  peft  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "task                                                                                             \n",
       "cola      11    11       11     11      11      11         11        11      11    11    11    11\n",
       "mnli       2     2        2      2       2       2          2         2       2     2     2     2\n",
       "mrpc       4     4        4      4       4       4          4         4       4     4     4     4\n",
       "qnli      16    16       16     16      16      16         16        16      16    16    16    16\n",
       "qqp        2     2        2      2       2       2          2         2       2     2     2     2\n",
       "rte       10    10       10     10      10      10         10        10      10    10    10    10\n",
       "stsb       2     2        2      2       2       2          2         2       2     2     2     2"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('task').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "57a931016c9ee7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:57.885715Z",
     "start_time": "2026-02-09T04:57:57.881657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eval_accuracy', 'eval_f1', 'eval_matthews_correlation',\n",
       "       'matched_accuracy', 'mismatched_accuracy', 'eval_pearson',\n",
       "       'eval_spearman'], dtype=object)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "c34344c47bffaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:58.600312Z",
     "start_time": "2026-02-09T04:57:58.596519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.seed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "8a075dbd861ae3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:59.829409Z",
     "start_time": "2026-02-09T04:57:59.826027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lora', 'kd-lora'], dtype=object)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.variant.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "1798adbfcbc94c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:00.436344Z",
     "start_time": "2026-02-09T04:58:00.430225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2964, 0.2965, 0.149 , 0.1498, 0.1482])"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.params.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "97703ef3d88747f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:01.086444Z",
     "start_time": "2026-02-09T04:58:01.068406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.714217</td>\n",
       "      <td>0.235434</td>\n",
       "      <td>623.052069</td>\n",
       "      <td>1.759310</td>\n",
       "      <td>690.413793</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.169599</td>\n",
       "      <td>0.073905</td>\n",
       "      <td>662.625986</td>\n",
       "      <td>2.109589</td>\n",
       "      <td>86.271781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>114.160000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>589.310000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>127.680000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>589.580000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>333.420000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>761.530000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.917100</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>1240.950000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>761.650000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>2439.520000</td>\n",
       "      <td>10.430000</td>\n",
       "      <td>761.680000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value     params    traintime   evaltime      gpumem  rank  seed\n",
       "count  29.000000  29.000000    29.000000  29.000000   29.000000  29.0  29.0\n",
       "mean    0.714217   0.235434   623.052069   1.759310  690.413793   8.0  42.0\n",
       "std     0.169599   0.073905   662.625986   2.109589   86.271781   0.0   0.0\n",
       "min     0.494600   0.149000   114.160000   0.120000  589.310000   8.0  42.0\n",
       "25%     0.494600   0.149000   127.680000   0.230000  589.580000   8.0  42.0\n",
       "50%     0.685900   0.296400   333.420000   1.380000  761.530000   8.0  42.0\n",
       "75%     0.917100   0.296500  1240.950000   3.130000  761.650000   8.0  42.0\n",
       "max     0.927500   0.296500  2439.520000  10.430000  761.680000   8.0  42.0"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.metric == 'eval_accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "c05606017ed6c66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:02.217068Z",
     "start_time": "2026-02-09T04:58:02.187377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.149</td>\n",
       "      <td>158.38</td>\n",
       "      <td>10.43</td>\n",
       "      <td>589.58</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family             peft task  variant  value   metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path\n",
       "35  deberta  mrlora-rs-olora  qqp  kd-lora    0.0  eval_f1   0.149     158.38     10.43  589.58     8    42  ablation3/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics...."
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.value == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "59c649ba972b5c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.154327Z",
     "start_time": "2026-02-09T04:58:03.150492Z"
    }
   },
   "outputs": [],
   "source": [
    "df_simple = df[(df.task != 'stsb') & (df['rank'] == 8) & (df.variant == 'lora')]\n",
    "df_simple = df_simple[df_simple.metric != 'eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "6e62273245330afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.895450Z",
     "start_time": "2026-02-09T04:58:03.835295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0a5f_row0_col0, #T_f0a5f_row0_col1, #T_f0a5f_row1_col1, #T_f0a5f_row1_col2, #T_f0a5f_row2_col1, #T_f0a5f_row2_col3, #T_f0a5f_row3_col1 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0a5f_row0_col2 {\n",
       "  background-color: #24449c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0a5f_row0_col3 {\n",
       "  background-color: #97d6b9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0a5f_row1_col0 {\n",
       "  background-color: #243f99;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0a5f_row1_col3, #T_f0a5f_row2_col2, #T_f0a5f_row3_col0 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0a5f_row2_col0 {\n",
       "  background-color: #f0f9b8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0a5f_row3_col2 {\n",
       "  background-color: #2259a6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0a5f_row3_col3 {\n",
       "  background-color: #40b5c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0a5f\">\n",
       "  <caption>MrLoRA Feature Ablation Study</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_f0a5f_level0_col0\" class=\"col_heading level0 col0\" >cola</th>\n",
       "      <th id=\"T_f0a5f_level0_col1\" class=\"col_heading level0 col1\" >mrpc</th>\n",
       "      <th id=\"T_f0a5f_level0_col2\" class=\"col_heading level0 col2\" >qnli</th>\n",
       "      <th id=\"T_f0a5f_level0_col3\" class=\"col_heading level0 col3\" >rte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >rs</th>\n",
       "      <th class=\"index_name level1\" >lcoef</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a5f_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_f0a5f_level1_row0\" class=\"row_heading level1 row0\" >False</th>\n",
       "      <td id=\"T_f0a5f_row0_col0\" class=\"data row0 col0\" >0.6573</td>\n",
       "      <td id=\"T_f0a5f_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_f0a5f_row0_col2\" class=\"data row0 col2\" >0.9232</td>\n",
       "      <td id=\"T_f0a5f_row0_col3\" class=\"data row0 col3\" >0.7112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a5f_level1_row1\" class=\"row_heading level1 row1\" >True</th>\n",
       "      <td id=\"T_f0a5f_row1_col0\" class=\"data row1 col0\" >0.6619</td>\n",
       "      <td id=\"T_f0a5f_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_f0a5f_row1_col2\" class=\"data row1 col2\" >0.9181</td>\n",
       "      <td id=\"T_f0a5f_row1_col3\" class=\"data row1 col3\" >0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a5f_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_f0a5f_level1_row2\" class=\"row_heading level1 row2\" >False</th>\n",
       "      <td id=\"T_f0a5f_row2_col0\" class=\"data row2 col0\" >0.6579</td>\n",
       "      <td id=\"T_f0a5f_row2_col1\" class=\"data row2 col1\" >0.8627</td>\n",
       "      <td id=\"T_f0a5f_row2_col2\" class=\"data row2 col2\" >0.9242</td>\n",
       "      <td id=\"T_f0a5f_row2_col3\" class=\"data row2 col3\" >0.7076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a5f_level1_row3\" class=\"row_heading level1 row3\" >True</th>\n",
       "      <td id=\"T_f0a5f_row3_col0\" class=\"data row3 col0\" >0.6627</td>\n",
       "      <td id=\"T_f0a5f_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_f0a5f_row3_col2\" class=\"data row3 col2\" >0.9227</td>\n",
       "      <td id=\"T_f0a5f_row3_col3\" class=\"data row3 col3\" >0.7130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f97c3cd7460>"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Expand the 'peft' strings into feature columns\n",
    "features = [ 'rs', 'lcoef',]# 'olora', ]\n",
    "\n",
    "for f in features:\n",
    "    # Checks if the feature name exists as a standalone word in the string\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))\n",
    "\n",
    "# 2. Create a Pivot Table\n",
    "# We group by the feature flags and show the mean 'value' for each 'task'\n",
    "pivot_df = df_simple.pivot_table(\n",
    "    index=features,\n",
    "    columns='task',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# 3. Apply Styling (Conditional Formatting)\n",
    "styled_table = pivot_df.style.background_gradient(axis=0, cmap='YlGnBu') \\\n",
    "                             .format(\"{:.4f}\") \\\n",
    "                             .set_caption(\"MrLoRA Feature Ablation Study\")\n",
    "\n",
    "# Display in Jupyter/Colab\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "c9a54ce04a4a75ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:04.594457Z",
     "start_time": "2026-02-09T04:58:04.537143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features to isolate\n",
    "features = ['olora', 'rs', 'lcoef']\n",
    "\n",
    "# Create boolean columns: True if feature name is in the 'peft' string\n",
    "for f in features:\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e0cfa4b46888",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "bcb5854cd105ad44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:05.185286Z",
     "start_time": "2026-02-09T04:58:05.178940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  0.776575  0.761569 -0.015006\n",
      "1      rs  0.765017  0.772238  0.007222\n",
      "2   lcoef  0.771192  0.766150 -0.005042\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['value'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f145e2e877ecd1",
   "metadata": {},
   "source": [
    "1. bias cause obvious drop.\n",
    "2. rs and lcoef boost perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "f12b207fde3f9e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:06.505857Z",
     "start_time": "2026-02-09T04:58:05.983960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_564228/1667137800.py:13: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  g = sns.catplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9732fd9b50>"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melt the data for visualization\n",
    "plot_data = []\n",
    "for f in features:\n",
    "    subset = df_simple[[f, 'value', 'task']].copy()\n",
    "    subset['Feature_Name'] = f\n",
    "    subset = subset.rename(columns={f: 'Status'})\n",
    "    subset['Status'] = subset['Status'].map({True: 'On', False: 'Off'})\n",
    "    plot_data.append(subset)\n",
    "\n",
    "df_plot = pd.concat(plot_data)\n",
    "\n",
    "# Create a FacetGrid to see On/Off for each feature across tasks\n",
    "g = sns.catplot(\n",
    "    data=df_plot, x='Status', y='value',\n",
    "    col='Feature_Name', kind='bar',\n",
    "    palette='muted', height=4, aspect=0.7\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370cc5235e224ab",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "91bf48a86140a816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:10.595609Z",
     "start_time": "2026-02-09T04:58:10.582585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Off_Avg    On_Avg     Delta\n",
      "0   olora  0.29645  0.296446 -0.000004\n",
      "1      rs  0.29645  0.296446 -0.000004\n",
      "2   lcoef  0.29640  0.296500  0.000100\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['params'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570453e5699aa3",
   "metadata": {},
   "source": [
    "### Traintime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "7e9c002fa7d60b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.256511Z",
     "start_time": "2026-02-09T04:58:11.231191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg       Delta\n",
      "0   olora  690.329167  898.603077  208.273910\n",
      "1      rs  911.310833  694.620000 -216.690833\n",
      "2   lcoef  803.870769  792.955833  -10.914936\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['traintime'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0571e908c87d",
   "metadata": {},
   "source": [
    "1. Olora cuts traintime.\n",
    "2. rs add traintime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357b36f540c8e5",
   "metadata": {},
   "source": [
    "### GPUMEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "155dd12a1a8cea22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.416928Z",
     "start_time": "2026-02-09T04:58:11.408028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg     Delta\n",
      "0   olora  761.625000  761.654615  0.029615\n",
      "1      rs  761.635000  761.645385  0.010385\n",
      "2   lcoef  761.613077  761.670000  0.056923\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['gpumem'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "301c37fed59d5101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:12.147491Z",
     "start_time": "2026-02-09T04:58:12.143853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([761.65, 761.68, 761.53, 761.56])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.gpumem.unique() # Almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c736e089edac5e7",
   "metadata": {},
   "source": [
    "## Compare with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "f998732af3a0030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:36.666812Z",
     "start_time": "2026-02-09T04:58:35.763401Z"
    }
   },
   "outputs": [],
   "source": [
    "df_base = aggregate_experiment_results('./results')\n",
    "df_base = df_base[df_base.variant == 'lora']\n",
    "df_base = df_base[df_base.task.isin(df.task.unique())]\n",
    "df_base = df_base[df_base.family.isin(df.family.unique())]\n",
    "df_base = df_base[df_base.seed == 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "d2f61536854053fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:39.339410Z",
     "start_time": "2026-02-09T04:58:39.337459Z"
    }
   },
   "outputs": [],
   "source": [
    "df_our = df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "b70f0f541cd088db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:40.957626Z",
     "start_time": "2026-02-09T04:58:40.917101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "      <th>rs</th>\n",
       "      <th>lcoef</th>\n",
       "      <th>olora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1831.38</td>\n",
       "      <td>3.43</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9270</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2439.52</td>\n",
       "      <td>3.15</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1567.67</td>\n",
       "      <td>3.25</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1240.95</td>\n",
       "      <td>3.06</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1276.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1464.76</td>\n",
       "      <td>3.23</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1510.17</td>\n",
       "      <td>3.57</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1639.25</td>\n",
       "      <td>3.13</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>mrpc</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>369.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>378.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>465.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>761.56</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>395.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>348.85</td>\n",
       "      <td>0.27</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>346.84</td>\n",
       "      <td>0.21</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>275.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>333.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>292.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>403.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1048.18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>313.23</td>\n",
       "      <td>0.51</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>358.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>761.53</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>315.06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>240.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>820.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>cola</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>eval_matthews_correlation</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>291.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>761.68</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                   peft  task variant   value                     metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path     rs  lcoef  olora\n",
       "0   deberta        mrlora-rs-olora  qnli    lora  0.9275              eval_accuracy  0.2964    1831.38      3.43  761.65     8    42   ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "6   deberta           mrlora-olora  qnli    lora  0.9270              eval_accuracy  0.2964    2439.52      3.15  761.65     8    42      ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "4   deberta  mrlora-rs-olora-lcoef  qnli    lora  0.9251              eval_accuracy  0.2965    1567.67      3.25  761.68     8    42  ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...   True   True   True\n",
       "3   deberta              mrlora-rs  qnli    lora  0.9209              eval_accuracy  0.2964    1240.95      3.06  761.65     8    42         ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "1   deberta        mrlora-rs-lcoef  qnli    lora  0.9204              eval_accuracy  0.2965    1276.00      3.63  761.68     8    42   ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "2   deberta                 mrlora  qnli    lora  0.9193              eval_accuracy  0.2964    1464.76      3.23  761.53     8    42            ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "7   deberta           mrlora-lcoef  qnli    lora  0.9191              eval_accuracy  0.2965    1510.17      3.57  761.68     8    42      ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "5   deberta     mrlora-olora-lcoef  qnli    lora  0.9171              eval_accuracy  0.2965    1639.25      3.13  761.68     8    42  ablation3/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...  False   True   True\n",
       "8   deberta        mrlora-rs-olora  mrpc    lora  0.8627              eval_accuracy  0.2964     369.33      0.25  761.65     8    42   ablation3/lora/task_mrpc_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "25  deberta           mrlora-lcoef   rte    lora  0.7617              eval_accuracy  0.2965     378.37      0.23  761.68     8    42       ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "19  deberta        mrlora-rs-lcoef   rte    lora  0.7509              eval_accuracy  0.2965     465.71      0.19  761.56     8    42    ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "20  deberta                 mrlora   rte    lora  0.7509              eval_accuracy  0.2964     395.73      0.27  761.53     8    42             ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "21  deberta              mrlora-rs   rte    lora  0.7437              eval_accuracy  0.2964     348.85      0.27  761.65     8    42          ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "22  deberta  mrlora-rs-olora-lcoef   rte    lora  0.6751              eval_accuracy  0.2965     346.84      0.21  761.68     8    42  ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metri...   True   True   True\n",
       "23  deberta     mrlora-olora-lcoef   rte    lora  0.6751              eval_accuracy  0.2965     275.37      0.19  761.68     8    42  ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....  False   True   True\n",
       "18  deberta        mrlora-rs-olora   rte    lora  0.6715              eval_accuracy  0.2964     333.42      0.14  761.53     8    42    ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "24  deberta           mrlora-olora   rte    lora  0.6715              eval_accuracy  0.2964     292.34      0.25  761.65     8    42       ablation3/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "14  deberta  mrlora-rs-olora-lcoef  cola    lora  0.6700  eval_matthews_correlation  0.2965     403.36      0.73  761.68     8    42  ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora-lcoef_16_0.05_8/metr...   True   True   True\n",
       "15  deberta     mrlora-olora-lcoef  cola    lora  0.6632  eval_matthews_correlation  0.2965    1048.18      0.54  761.68     8    42  ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics...  False   True   True\n",
       "17  deberta           mrlora-lcoef  cola    lora  0.6606  eval_matthews_correlation  0.2965     313.23      0.51  761.68     8    42      ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "12  deberta                 mrlora  cola    lora  0.6580  eval_matthews_correlation  0.2964     358.69      0.53  761.53     8    42            ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "10  deberta        mrlora-rs-olora  cola    lora  0.6579  eval_matthews_correlation  0.2964     315.06      0.57  761.65     8    42   ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json   True  False   True\n",
       "13  deberta              mrlora-rs  cola    lora  0.6579  eval_matthews_correlation  0.2964     240.17      0.50  761.65     8    42         ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "16  deberta           mrlora-olora  cola    lora  0.6567  eval_matthews_correlation  0.2964     820.12      0.50  761.65     8    42      ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "11  deberta        mrlora-rs-lcoef  cola    lora  0.6555  eval_matthews_correlation  0.2965     291.32      0.60  761.68     8    42   ablation3/lora/task_cola_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_our.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "e0e08081d96b22fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:42.997489Z",
     "start_time": "2026-02-09T04:58:42.988918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>1.1812</td>\n",
       "      <td>1638.15</td>\n",
       "      <td>2.48</td>\n",
       "      <td>775.63</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1663.23</td>\n",
       "      <td>1.91</td>\n",
       "      <td>761.37</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>2.3608</td>\n",
       "      <td>1385.57</td>\n",
       "      <td>2.05</td>\n",
       "      <td>794.41</td>\n",
       "      <td>64</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_64_0.05_64/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>2775.19</td>\n",
       "      <td>3.27</td>\n",
       "      <td>761.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_8_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1838.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>762.15</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>344.17</td>\n",
       "      <td>17.05</td>\n",
       "      <td>763.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>1.1812</td>\n",
       "      <td>340.16</td>\n",
       "      <td>18.80</td>\n",
       "      <td>775.63</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>deberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>418.94</td>\n",
       "      <td>19.24</td>\n",
       "      <td>767.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>353.36</td>\n",
       "      <td>19.68</td>\n",
       "      <td>766.35</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_16/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>327.53</td>\n",
       "      <td>19.25</td>\n",
       "      <td>761.63</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_8_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      family     peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                     path\n",
       "335  deberta     lora  qnli    lora  0.9390  eval_accuracy  1.1812    1638.15      2.48  775.63    32    42   results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json\n",
       "341  deberta   rslora  qnli    lora  0.9389  eval_accuracy  0.2964    1663.23      1.91  761.37     8    42  results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "337  deberta     lora  qnli    lora  0.9381  eval_accuracy  2.3608    1385.57      2.05  794.41    64    42   results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_64_0.05_64/metrics.json\n",
       "342  deberta     dora  qnli    lora  0.9379  eval_accuracy  0.3149    2775.19      3.27  761.91     8    42     results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_8_0.05_8/metrics.json\n",
       "338  deberta     lora  qnli    lora  0.9363  eval_accuracy  0.2964    1838.87      1.79  762.15     8    42    results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "..       ...      ...   ...     ...     ...            ...     ...        ...       ...     ...   ...   ...                                                                                      ...\n",
       "404  deberta     lora   qqp    lora  0.3682  eval_accuracy  0.2964     344.17     17.05  763.20     8    42     results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "398  deberta     lora   qqp    lora  0.3682  eval_accuracy  1.1812     340.16     18.80  775.63    32    42    results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_32_0.05_32/metrics.json\n",
       "400  deberta  adalora   qqp    lora  0.3682  eval_accuracy  0.5917     418.94     19.24  767.34     8    42  results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "416  deberta     lora   qqp    lora  0.3682  eval_accuracy  0.5914     353.36     19.68  766.35    16    42    results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_16/metrics.json\n",
       "414  deberta     lora   qqp    lora  0.3682  eval_accuracy  0.2964     327.53     19.25  761.63     8    42      results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_8_0.05_8/metrics.json\n",
       "\n",
       "[150 rows x 13 columns]"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.sort_values('value', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
