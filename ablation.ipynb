{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95587a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:50.112595Z",
     "start_time": "2026-02-09T04:57:50.110148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9375c819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.062695Z",
     "start_time": "2026-02-09T04:57:51.046231Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-rs': 'MR-LoRA-RS',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.191694Z",
     "start_time": "2026-02-09T04:57:51.138931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./ablation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ab95559e913b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:51.673632Z",
     "start_time": "2026-02-09T04:57:51.667832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['roberta', 'bert', 'deberta'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a30665e40b194d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:52.765619Z",
     "start_time": "2026-02-09T04:57:52.762058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrlora', 'mrlora-olora-lcoef', 'mrlora-rs-lcoef',\n",
       "       'mrlora-olora-rs', 'mrlora-rs', 'mrlora-lcoef', 'mrlora-olora',\n",
       "       'mrlora-olora-rs-lcoef'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.peft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbe73398833aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:55.404732Z",
     "start_time": "2026-02-09T04:57:55.398687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c0212dc379992b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.090823Z",
     "start_time": "2026-02-09T04:57:56.074050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mrpc', 'rte', 'stsb', 'qnli', 'qqp', 'mnli'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.task.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440790b4a0f827b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:56.706572Z",
     "start_time": "2026-02-09T04:57:56.696235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stsb</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family  peft  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "task                                                                                             \n",
       "mnli       4     4        4      4       4       4          4         4       4     4     4     4\n",
       "mrpc      48    48       48     48      48      48         48        48      48    48    48    48\n",
       "qnli      44    44       44     44      44      44         44        44      44    44    44    44\n",
       "qqp       48    48       48     48      48      48         48        48      48    48    48    48\n",
       "rte       48    48       48     48      48      48         48        48      48    48    48    48\n",
       "stsb      48    48       48     48      48      48         48        48      48    48    48    48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('task').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a931016c9ee7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:57.885715Z",
     "start_time": "2026-02-09T04:57:57.881657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eval_accuracy', 'eval_f1', 'eval_pearson', 'eval_spearman',\n",
       "       'matched_accuracy', 'mismatched_accuracy'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34344c47bffaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:58.600312Z",
     "start_time": "2026-02-09T04:57:58.596519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.seed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a075dbd861ae3d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:57:59.829409Z",
     "start_time": "2026-02-09T04:57:59.826027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kd-lora', 'lora'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.variant.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1798adbfcbc94c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:00.436344Z",
     "start_time": "2026-02-09T04:58:00.430225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7396, 0.7388, 0.7389, 0.149 , 0.7404, 0.1482, 0.1483, 0.887 ,\n",
       "       0.8871, 0.2964, 0.2965])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.params.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97703ef3d88747f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:01.086444Z",
     "start_time": "2026-02-09T04:58:01.068406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.759441</td>\n",
       "      <td>0.532826</td>\n",
       "      <td>528.425000</td>\n",
       "      <td>1.636357</td>\n",
       "      <td>464.030929</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128920</td>\n",
       "      <td>0.281603</td>\n",
       "      <td>584.587366</td>\n",
       "      <td>2.245599</td>\n",
       "      <td>144.006020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>85.570000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>296.950000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.631800</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>137.262500</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>358.740000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.823300</td>\n",
       "      <td>0.739600</td>\n",
       "      <td>270.040000</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>463.100000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.874200</td>\n",
       "      <td>0.739600</td>\n",
       "      <td>806.585000</td>\n",
       "      <td>2.165000</td>\n",
       "      <td>588.660000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.941800</td>\n",
       "      <td>0.887100</td>\n",
       "      <td>2904.210000</td>\n",
       "      <td>9.130000</td>\n",
       "      <td>763.490000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value      params    traintime    evaltime      gpumem   rank   seed\n",
       "count  140.000000  140.000000   140.000000  140.000000  140.000000  140.0  140.0\n",
       "mean     0.759441    0.532826   528.425000    1.636357  464.030929    8.0   42.0\n",
       "std      0.128920    0.281603   584.587366    2.245599  144.006020    0.0    0.0\n",
       "min      0.494600    0.149000    85.570000    0.070000  296.950000    8.0   42.0\n",
       "25%      0.631800    0.296400   137.262500    0.120000  358.740000    8.0   42.0\n",
       "50%      0.823300    0.739600   270.040000    0.305000  463.100000    8.0   42.0\n",
       "75%      0.874200    0.739600   806.585000    2.165000  588.660000    8.0   42.0\n",
       "max      0.941800    0.887100  2904.210000    9.130000  763.490000    8.0   42.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.metric == 'eval_accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c05606017ed6c66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:02.217068Z",
     "start_time": "2026-02-09T04:58:02.187377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>94.89</td>\n",
       "      <td>4.62</td>\n",
       "      <td>357.95</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>99.24</td>\n",
       "      <td>5.05</td>\n",
       "      <td>357.97</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>99.12</td>\n",
       "      <td>4.92</td>\n",
       "      <td>358.75</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>95.76</td>\n",
       "      <td>4.55</td>\n",
       "      <td>358.74</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>93.46</td>\n",
       "      <td>4.54</td>\n",
       "      <td>358.74</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>98.16</td>\n",
       "      <td>4.42</td>\n",
       "      <td>358.75</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>96.02</td>\n",
       "      <td>4.47</td>\n",
       "      <td>358.74</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>97.55</td>\n",
       "      <td>5.28</td>\n",
       "      <td>358.75</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>137.94</td>\n",
       "      <td>7.94</td>\n",
       "      <td>588.66</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>142.54</td>\n",
       "      <td>7.65</td>\n",
       "      <td>587.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>137.46</td>\n",
       "      <td>7.27</td>\n",
       "      <td>587.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>131.93</td>\n",
       "      <td>7.59</td>\n",
       "      <td>587.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>140.01</td>\n",
       "      <td>7.27</td>\n",
       "      <td>587.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>137.59</td>\n",
       "      <td>7.24</td>\n",
       "      <td>587.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>134.19</td>\n",
       "      <td>8.56</td>\n",
       "      <td>587.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>160.89</td>\n",
       "      <td>9.13</td>\n",
       "      <td>587.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>116.74</td>\n",
       "      <td>6.38</td>\n",
       "      <td>297.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>102.50</td>\n",
       "      <td>5.14</td>\n",
       "      <td>296.95</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>113.48</td>\n",
       "      <td>6.47</td>\n",
       "      <td>297.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qqp</td>\n",
       "      <td>kd-lora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>113.87</td>\n",
       "      <td>5.56</td>\n",
       "      <td>297.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family                   peft task  variant  value   metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path\n",
       "65   roberta                 mrlora  qqp  kd-lora    0.0  eval_f1  0.7396      94.89      4.62  357.95     8    42           ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json\n",
       "67   roberta     mrlora-olora-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396      99.24      5.05  357.97     8    42  ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metric...\n",
       "69   roberta        mrlora-rs-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396      99.12      4.92  358.75     8    42  ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json\n",
       "71   roberta        mrlora-olora-rs  qqp  kd-lora    0.0  eval_f1  0.7396      95.76      4.55  358.74     8    42  ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json\n",
       "73   roberta              mrlora-rs  qqp  kd-lora    0.0  eval_f1  0.7396      93.46      4.54  358.74     8    42        ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json\n",
       "75   roberta           mrlora-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396      98.16      4.42  358.75     8    42     ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json\n",
       "77   roberta           mrlora-olora  qqp  kd-lora    0.0  eval_f1  0.7396      96.02      4.47  358.74     8    42     ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json\n",
       "79   roberta  mrlora-olora-rs-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396      97.55      5.28  358.75     8    42  ablation/kd-lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/met...\n",
       "101  deberta                 mrlora  qqp  kd-lora    0.0  eval_f1  0.1490     137.94      7.94  588.66     8    42           ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json\n",
       "103  deberta     mrlora-olora-lcoef  qqp  kd-lora    0.0  eval_f1  0.1490     142.54      7.65  587.88     8    42  ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metric...\n",
       "105  deberta        mrlora-rs-lcoef  qqp  kd-lora    0.0  eval_f1  0.1490     137.46      7.27  587.88     8    42  ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json\n",
       "107  deberta        mrlora-olora-rs  qqp  kd-lora    0.0  eval_f1  0.1490     131.93      7.59  587.87     8    42  ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json\n",
       "109  deberta              mrlora-rs  qqp  kd-lora    0.0  eval_f1  0.1490     140.01      7.27  587.87     8    42        ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json\n",
       "111  deberta           mrlora-lcoef  qqp  kd-lora    0.0  eval_f1  0.1490     137.59      7.24  587.88     8    42     ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json\n",
       "113  deberta           mrlora-olora  qqp  kd-lora    0.0  eval_f1  0.1490     134.19      8.56  587.87     8    42     ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json\n",
       "115  deberta  mrlora-olora-rs-lcoef  qqp  kd-lora    0.0  eval_f1  0.1490     160.89      9.13  587.88     8    42  ablation/kd-lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/met...\n",
       "165     bert                 mrlora  qqp  kd-lora    0.0  eval_f1  0.7396     116.74      6.38  297.73     8    42              ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json\n",
       "169     bert        mrlora-rs-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396     102.50      5.14  296.95     8    42     ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json\n",
       "173     bert              mrlora-rs  qqp  kd-lora    0.0  eval_f1  0.7396     113.48      6.47  297.73     8    42           ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json\n",
       "175     bert           mrlora-lcoef  qqp  kd-lora    0.0  eval_f1  0.7396     113.87      5.56  297.71     8    42        ablation/kd-lora/task_qqp_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.value == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59c649ba972b5c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.154327Z",
     "start_time": "2026-02-09T04:58:03.150492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_55066/3469448867.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_simple = df_simple[df.metric != 'eval_f1']\n"
     ]
    }
   ],
   "source": [
    "df_simple = df[(df.task != 'stsb') & (df['rank'] == 8) & (df.variant == 'lora')]\n",
    "df_simple = df_simple[df.metric != 'eval_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e62273245330afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:03.895450Z",
     "start_time": "2026-02-09T04:58:03.835295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_20738_row0_col0 {\n",
       "  background-color: #1d91c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row0_col1 {\n",
       "  background-color: #102369;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row1_col0 {\n",
       "  background-color: #243c98;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row1_col1, #T_20738_row7_col0 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_20738_row2_col0 {\n",
       "  background-color: #24439b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row2_col1 {\n",
       "  background-color: #0b1f5e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row3_col0 {\n",
       "  background-color: #1f7bb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row3_col1, #T_20738_row7_col1 {\n",
       "  background-color: #fafdce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_20738_row4_col0, #T_20738_row6_col1 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row4_col1 {\n",
       "  background-color: #142670;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_20738_row5_col0 {\n",
       "  background-color: #7cccbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_20738_row5_col1 {\n",
       "  background-color: #f1faba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_20738_row6_col0 {\n",
       "  background-color: #216aad;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_20738\">\n",
       "  <caption>MrLoRA Feature Ablation Study</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th id=\"T_20738_level0_col0\" class=\"col_heading level0 col0\" >qnli</th>\n",
       "      <th id=\"T_20738_level0_col1\" class=\"col_heading level0 col1\" >rte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >rs</th>\n",
       "      <th class=\"index_name level1\" >lcoef</th>\n",
       "      <th class=\"index_name level2\" >olora</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">False</th>\n",
       "      <th id=\"T_20738_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_20738_level2_row0\" class=\"row_heading level2 row0\" >False</th>\n",
       "      <td id=\"T_20738_row0_col0\" class=\"data row0 col0\" >0.9043</td>\n",
       "      <td id=\"T_20738_row0_col1\" class=\"data row0 col1\" >0.7497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level2_row1\" class=\"row_heading level2 row1\" >True</th>\n",
       "      <td id=\"T_20738_row1_col0\" class=\"data row1 col0\" >0.9124</td>\n",
       "      <td id=\"T_20738_row1_col1\" class=\"data row1 col1\" >0.6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_20738_level2_row2\" class=\"row_heading level2 row2\" >False</th>\n",
       "      <td id=\"T_20738_row2_col0\" class=\"data row2 col0\" >0.9117</td>\n",
       "      <td id=\"T_20738_row2_col1\" class=\"data row2 col1\" >0.7521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level2_row3\" class=\"row_heading level2 row3\" >True</th>\n",
       "      <td id=\"T_20738_row3_col0\" class=\"data row3 col0\" >0.9062</td>\n",
       "      <td id=\"T_20738_row3_col1\" class=\"data row3 col1\" >0.6618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">True</th>\n",
       "      <th id=\"T_20738_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_20738_level2_row4\" class=\"row_heading level2 row4\" >False</th>\n",
       "      <td id=\"T_20738_row4_col0\" class=\"data row4 col0\" >0.9179</td>\n",
       "      <td id=\"T_20738_row4_col1\" class=\"data row4 col1\" >0.7485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level2_row5\" class=\"row_heading level2 row5\" >True</th>\n",
       "      <td id=\"T_20738_row5_col0\" class=\"data row5 col0\" >0.8955</td>\n",
       "      <td id=\"T_20738_row5_col1\" class=\"data row5 col1\" >0.6678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_20738_level2_row6\" class=\"row_heading level2 row6\" >False</th>\n",
       "      <td id=\"T_20738_row6_col0\" class=\"data row6 col0\" >0.9078</td>\n",
       "      <td id=\"T_20738_row6_col1\" class=\"data row6 col1\" >0.7533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_20738_level2_row7\" class=\"row_heading level2 row7\" >True</th>\n",
       "      <td id=\"T_20738_row7_col0\" class=\"data row7 col0\" >0.8818</td>\n",
       "      <td id=\"T_20738_row7_col1\" class=\"data row7 col1\" >0.6618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x30deff4d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Expand the 'peft' strings into feature columns\n",
    "features = [ 'rs', 'lcoef', 'olora', ]\n",
    "\n",
    "for f in features:\n",
    "    # Checks if the feature name exists as a standalone word in the string\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))\n",
    "\n",
    "# 2. Create a Pivot Table\n",
    "# We group by the feature flags and show the mean 'value' for each 'task'\n",
    "pivot_df = df_simple.pivot_table(\n",
    "    index=features,\n",
    "    columns='task',\n",
    "    values='value',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# 3. Apply Styling (Conditional Formatting)\n",
    "styled_table = pivot_df.style.background_gradient(axis=0, cmap='YlGnBu') \\\n",
    "                             .format(\"{:.4f}\") \\\n",
    "                             .set_caption(\"MrLoRA Feature Ablation Study\")\n",
    "\n",
    "# Display in Jupyter/Colab\n",
    "styled_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9a54ce04a4a75ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:04.594457Z",
     "start_time": "2026-02-09T04:58:04.537143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features to isolate\n",
    "features = ['olora', 'rs', 'lcoef']\n",
    "\n",
    "# Create boolean columns: True if feature name is in the 'peft' string\n",
    "for f in features:\n",
    "    df_simple[f] = df_simple['peft'].apply(lambda x: f in x.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e0cfa4b46888",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcb5854cd105ad44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:05.185286Z",
     "start_time": "2026-02-09T04:58:05.178940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  0.827304  0.764457 -0.062847\n",
      "1      rs  0.802757  0.791343 -0.011414\n",
      "2   lcoef  0.802939  0.791143 -0.011796\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['value'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f145e2e877ecd1",
   "metadata": {},
   "source": [
    "1. bias cause obvious drop.\n",
    "2. rs and lcoef boost perf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f12b207fde3f9e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:06.505857Z",
     "start_time": "2026-02-09T04:58:05.983960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_55066/1667137800.py:13: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  g = sns.catplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x30ddd8ce0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 840x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melt the data for visualization\n",
    "plot_data = []\n",
    "for f in features:\n",
    "    subset = df_simple[[f, 'value', 'task']].copy()\n",
    "    subset['Feature_Name'] = f\n",
    "    subset = subset.rename(columns={f: 'Status'})\n",
    "    subset['Status'] = subset['Status'].map({True: 'On', False: 'Off'})\n",
    "    plot_data.append(subset)\n",
    "\n",
    "df_plot = pd.concat(plot_data)\n",
    "\n",
    "# Create a FacetGrid to see On/Off for each feature across tasks\n",
    "g = sns.catplot(\n",
    "    data=df_plot, x='Status', y='value',\n",
    "    col='Feature_Name', kind='bar',\n",
    "    palette='muted', height=4, aspect=0.7\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370cc5235e224ab",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91bf48a86140a816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:10.595609Z",
     "start_time": "2026-02-09T04:58:10.582585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature   Off_Avg    On_Avg     Delta\n",
      "0   olora  0.501874  0.521438  0.019564\n",
      "1      rs  0.501874  0.521438  0.019564\n",
      "2   lcoef  0.501826  0.521490  0.019664\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['params'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570453e5699aa3",
   "metadata": {},
   "source": [
    "### Traintime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e9c002fa7d60b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.256511Z",
     "start_time": "2026-02-09T04:58:11.231191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg       Delta\n",
      "0   olora  996.479130  830.101429 -166.377702\n",
      "1      rs  983.180870  844.666190 -138.514679\n",
      "2   lcoef  947.496522  883.749048  -63.747474\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['traintime'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0571e908c87d",
   "metadata": {},
   "source": [
    "1. Olora cuts traintime.\n",
    "2. rs add traintime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357b36f540c8e5",
   "metadata": {},
   "source": [
    "### GPUMEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "155dd12a1a8cea22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:11.416928Z",
     "start_time": "2026-02-09T04:58:11.408028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature     Off_Avg      On_Avg      Delta\n",
      "0   olora  579.115217  561.598571 -17.516646\n",
      "1      rs  579.092609  561.623333 -17.469275\n",
      "2   lcoef  579.036522  561.684762 -17.351760\n"
     ]
    }
   ],
   "source": [
    "impact_results = []\n",
    "\n",
    "for f in features:\n",
    "    # Calculate Mean for 'On' vs 'Off' across all tasks\n",
    "    summary = df_simple.groupby(f)['gpumem'].mean()\n",
    "    impact_results.append({\n",
    "        'Feature': f,\n",
    "        'Off_Avg': summary[False],\n",
    "        'On_Avg': summary[True],\n",
    "        'Delta': summary[True] - summary[False]\n",
    "    })\n",
    "\n",
    "df_impact = pd.DataFrame(impact_results)\n",
    "print(df_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301c37fed59d5101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:12.147491Z",
     "start_time": "2026-02-09T04:58:12.143853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([534.1 , 534.91, 534.12, 534.88, 763.49, 762.71, 762.73, 533.31,\n",
       "       533.34, 534.62, 763.11, 463.08, 463.1 , 462.03, 463.89, 463.87])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.gpumem.unique() # Almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c736e089edac5e7",
   "metadata": {},
   "source": [
    "## Compare with SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f998732af3a0030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:36.666812Z",
     "start_time": "2026-02-09T04:58:35.763401Z"
    }
   },
   "outputs": [],
   "source": [
    "df_base = aggregate_experiment_results('./results')\n",
    "df_base = df_base[df_base.variant == 'lora']\n",
    "df_base = df_base[df_base.task.isin(df.task.unique())]\n",
    "df_base = df_base[df_base.family.isin(df.family.unique())]\n",
    "df_base = df_base[df_base.seed == 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2f61536854053fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:39.339410Z",
     "start_time": "2026-02-09T04:58:39.337459Z"
    }
   },
   "outputs": [],
   "source": [
    "df_our = df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b70f0f541cd088db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:40.957626Z",
     "start_time": "2026-02-09T04:58:40.917101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "      <th>rs</th>\n",
       "      <th>lcoef</th>\n",
       "      <th>olora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2904.21</td>\n",
       "      <td>3.05</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2335.51</td>\n",
       "      <td>3.69</td>\n",
       "      <td>763.49</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9295</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>2204.85</td>\n",
       "      <td>3.21</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>2296.15</td>\n",
       "      <td>3.36</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1497.80</td>\n",
       "      <td>2.15</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1921.80</td>\n",
       "      <td>2.08</td>\n",
       "      <td>533.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>1512.78</td>\n",
       "      <td>2.13</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1480.16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1259.06</td>\n",
       "      <td>2.18</td>\n",
       "      <td>534.62</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>2197.91</td>\n",
       "      <td>2.20</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>839.51</td>\n",
       "      <td>2.06</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1813.79</td>\n",
       "      <td>2.41</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1656.87</td>\n",
       "      <td>2.21</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1511.81</td>\n",
       "      <td>1.79</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1895.72</td>\n",
       "      <td>2.22</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>777.28</td>\n",
       "      <td>2.06</td>\n",
       "      <td>533.31</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>775.92</td>\n",
       "      <td>1.87</td>\n",
       "      <td>533.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>801.39</td>\n",
       "      <td>2.60</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>947.99</td>\n",
       "      <td>2.10</td>\n",
       "      <td>463.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>946.44</td>\n",
       "      <td>2.36</td>\n",
       "      <td>463.08</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>504.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>763.11</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>523.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8231</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>521.92</td>\n",
       "      <td>0.33</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>510.73</td>\n",
       "      <td>0.30</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>308.40</td>\n",
       "      <td>0.19</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>325.97</td>\n",
       "      <td>0.15</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>344.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.12</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>300.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>414.78</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>415.82</td>\n",
       "      <td>0.30</td>\n",
       "      <td>762.73</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>513.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>341.81</td>\n",
       "      <td>0.16</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>414.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>762.71</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>296.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>462.03</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>330.31</td>\n",
       "      <td>0.21</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>307.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>264.39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>534.10</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>343.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>242.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>267.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>296.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>463.87</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>301.52</td>\n",
       "      <td>0.17</td>\n",
       "      <td>534.88</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>bert</td>\n",
       "      <td>mrlora-olora-rs-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>343.76</td>\n",
       "      <td>0.22</td>\n",
       "      <td>463.89</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>roberta</td>\n",
       "      <td>mrlora-olora-lcoef</td>\n",
       "      <td>rte</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>341.93</td>\n",
       "      <td>0.16</td>\n",
       "      <td>534.91</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      family                   peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                                 path     rs  lcoef  olora\n",
       "205  deberta              mrlora-rs  qnli    lora  0.9418  eval_accuracy  0.2964    2904.21      3.05  762.71     8    42          ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "204  deberta                 mrlora  qnli    lora  0.9352  eval_accuracy  0.2964    2335.51      3.69  763.49     8    42             ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "206  deberta           mrlora-lcoef  qnli    lora  0.9295  eval_accuracy  0.2965    2204.85      3.21  762.73     8    42       ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "207  deberta           mrlora-olora  qnli    lora  0.9255  eval_accuracy  0.2964    2296.15      3.36  762.71     8    42       ablation/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "211  roberta        mrlora-olora-rs  qnli    lora  0.9171  eval_accuracy  0.8870    1497.80      2.15  533.31     8    42    ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "209  roberta     mrlora-olora-lcoef  qnli    lora  0.9165  eval_accuracy  0.8871    1921.80      2.08  533.34     8    42  ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics....  False   True   True\n",
       "210  roberta        mrlora-rs-lcoef  qnli    lora  0.9162  eval_accuracy  0.8871    1512.78      2.13  534.12     8    42    ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "214  roberta           mrlora-olora  qnli    lora  0.9140  eval_accuracy  0.8870    1480.16      2.16  533.31     8    42       ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "212  roberta              mrlora-rs  qnli    lora  0.9134  eval_accuracy  0.8870    1259.06      2.18  534.62     8    42          ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "229     bert           mrlora-lcoef  qnli    lora  0.9057  eval_accuracy  0.2965    2197.91      2.20  463.10     8    42          ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "213  roberta           mrlora-lcoef  qnli    lora  0.8999  eval_accuracy  0.8871     839.51      2.06  534.12     8    42       ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "226     bert        mrlora-rs-lcoef  qnli    lora  0.8993  eval_accuracy  0.2965    1813.79      2.41  463.10     8    42       ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "228     bert              mrlora-rs  qnli    lora  0.8984  eval_accuracy  0.2964    1656.87      2.21  463.08     8    42             ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "230     bert           mrlora-olora  qnli    lora  0.8977  eval_accuracy  0.2964    1511.81      1.79  463.08     8    42          ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "225     bert     mrlora-olora-lcoef  qnli    lora  0.8960  eval_accuracy  0.2965    1895.72      2.22  463.10     8    42    ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "208  roberta                 mrlora  qnli    lora  0.8960  eval_accuracy  0.8870     777.28      2.06  533.31     8    42             ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "215  roberta  mrlora-olora-rs-lcoef  qnli    lora  0.8894  eval_accuracy  0.8871     775.92      1.87  533.34     8    42  ablation/lora/task_qnli_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metri...   True   True   True\n",
       "224     bert                 mrlora  qnli    lora  0.8817  eval_accuracy  0.2964     801.39      2.60  463.08     8    42                ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "231     bert  mrlora-olora-rs-lcoef  qnli    lora  0.8742  eval_accuracy  0.2965     947.99      2.10  463.10     8    42  ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics....   True   True   True\n",
       "227     bert        mrlora-olora-rs  qnli    lora  0.8739  eval_accuracy  0.2964     946.44      2.36  463.08     8    42       ablation/lora/task_qnli_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "216  deberta                 mrlora   rte    lora  0.8303  eval_accuracy  0.2964     504.58      0.27  763.11     8    42              ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "221  deberta           mrlora-lcoef   rte    lora  0.8303  eval_accuracy  0.2965     523.60      0.27  762.73     8    42        ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "218  deberta        mrlora-rs-lcoef   rte    lora  0.8231  eval_accuracy  0.2965     521.92      0.33  762.73     8    42     ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "220  deberta              mrlora-rs   rte    lora  0.8195  eval_accuracy  0.2964     510.73      0.30  762.71     8    42           ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "201  roberta           mrlora-lcoef   rte    lora  0.7581  eval_accuracy  0.8871     308.40      0.19  534.91     8    42        ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "200  roberta              mrlora-rs   rte    lora  0.7437  eval_accuracy  0.8870     325.97      0.15  534.10     8    42           ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "198  roberta        mrlora-rs-lcoef   rte    lora  0.7401  eval_accuracy  0.8871     344.14      0.16  534.12     8    42     ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "196  roberta                 mrlora   rte    lora  0.7365  eval_accuracy  0.8870     300.92      0.16  534.10     8    42              ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "217  deberta     mrlora-olora-lcoef   rte    lora  0.7112  eval_accuracy  0.2965     414.78      0.27  762.73     8    42  ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "223  deberta  mrlora-olora-rs-lcoef   rte    lora  0.7076  eval_accuracy  0.2965     415.82      0.30  762.73     8    42  ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...   True   True   True\n",
       "222  deberta           mrlora-olora   rte    lora  0.7076  eval_accuracy  0.2964     513.65      0.31  762.71     8    42        ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "234     bert        mrlora-rs-lcoef   rte    lora  0.6968  eval_accuracy  0.2965     341.81      0.16  463.89     8    42        ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs-lcoef_16_0.05_8/metrics.json   True   True  False\n",
       "219  deberta        mrlora-olora-rs   rte    lora  0.6931  eval_accuracy  0.2964     414.05      0.27  762.71     8    42     ablation/lora/task_rte_deberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "232     bert                 mrlora   rte    lora  0.6823  eval_accuracy  0.2964     296.45      0.19  462.03     8    42                 ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora_16_0.05_8/metrics.json  False  False  False\n",
       "236     bert              mrlora-rs   rte    lora  0.6823  eval_accuracy  0.2964     330.31      0.21  463.87     8    42              ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-rs_16_0.05_8/metrics.json   True  False  False\n",
       "237     bert           mrlora-lcoef   rte    lora  0.6679  eval_accuracy  0.2965     307.03      0.19  463.89     8    42           ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-lcoef_16_0.05_8/metrics.json  False   True  False\n",
       "199  roberta        mrlora-olora-rs   rte    lora  0.6570  eval_accuracy  0.8870     264.39      0.10  534.10     8    42     ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "203  roberta  mrlora-olora-rs-lcoef   rte    lora  0.6534  eval_accuracy  0.8871     343.14      0.15  534.91     8    42  ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metric...   True   True   True\n",
       "233     bert     mrlora-olora-lcoef   rte    lora  0.6534  eval_accuracy  0.2965     242.13      0.17  463.89     8    42     ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True\n",
       "235     bert        mrlora-olora-rs   rte    lora  0.6534  eval_accuracy  0.2964     267.09      0.19  463.87     8    42        ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs_16_0.05_8/metrics.json   True  False   True\n",
       "238     bert           mrlora-olora   rte    lora  0.6354  eval_accuracy  0.2964     296.08      0.18  463.87     8    42           ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "202  roberta           mrlora-olora   rte    lora  0.6318  eval_accuracy  0.8870     301.52      0.17  534.88     8    42        ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora_16_0.05_8/metrics.json  False  False   True\n",
       "239     bert  mrlora-olora-rs-lcoef   rte    lora  0.6245  eval_accuracy  0.2965     343.76      0.22  463.89     8    42  ablation/lora/task_rte_bert_42/base_32_2e-05_0.01/peft_mrlora-olora-rs-lcoef_16_0.05_8/metrics.json   True   True   True\n",
       "197  roberta     mrlora-olora-lcoef   rte    lora  0.6209  eval_accuracy  0.8871     341.93      0.16  534.91     8    42  ablation/lora/task_rte_roberta_42/base_32_2e-05_0.01/peft_mrlora-olora-lcoef_16_0.05_8/metrics.json  False   True   True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_our.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0e08081d96b22fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:58:42.997489Z",
     "start_time": "2026-02-09T04:58:42.988918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>peft</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>deberta</td>\n",
       "      <td>rslora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1663.23</td>\n",
       "      <td>1.91</td>\n",
       "      <td>761.37</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1838.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>762.15</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>1962.25</td>\n",
       "      <td>2.87</td>\n",
       "      <td>761.65</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>deberta</td>\n",
       "      <td>mrlora-rs-olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1606.84</td>\n",
       "      <td>4.00</td>\n",
       "      <td>761.66</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>deberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qnli</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>1302.84</td>\n",
       "      <td>2.27</td>\n",
       "      <td>761.37</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>deberta</td>\n",
       "      <td>olora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>346.63</td>\n",
       "      <td>15.82</td>\n",
       "      <td>762.42</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>deberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>418.94</td>\n",
       "      <td>19.24</td>\n",
       "      <td>767.34</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>deberta</td>\n",
       "      <td>dora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>422.37</td>\n",
       "      <td>18.90</td>\n",
       "      <td>762.70</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>deberta</td>\n",
       "      <td>lora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>344.17</td>\n",
       "      <td>17.05</td>\n",
       "      <td>763.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>roberta</td>\n",
       "      <td>adalora</td>\n",
       "      <td>qqp</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>eval_f1</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>293.23</td>\n",
       "      <td>11.24</td>\n",
       "      <td>538.20</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       family             peft  task variant   value         metric  params  traintime  evaltime  gpumem  rank  seed                                                                                              path\n",
       "1995  deberta           rslora  qnli    lora  0.9389  eval_accuracy  0.2964    1663.23      1.91  761.37     8    42           results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_rslora_16_0.05_8/metrics.json\n",
       "1996  deberta             lora  qnli    lora  0.9363  eval_accuracy  0.2964    1838.87      1.79  762.15     8    42             results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "2000  deberta             dora  qnli    lora  0.9337  eval_accuracy  0.3149    1962.25      2.87  761.65     8    42             results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "1997  deberta  mrlora-rs-olora  qnli    lora  0.9319  eval_accuracy  0.2964    1606.84      4.00  761.66     8    42  results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_mrlora-rs-olora_16_0.05_8/metrics.json\n",
       "1998  deberta            olora  qnli    lora  0.9317  eval_accuracy  0.2964    1302.84      2.27  761.37     8    42            results/lora/task_qnli_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "...       ...              ...   ...     ...     ...            ...     ...        ...       ...     ...   ...   ...                                                                                               ...\n",
       "2397  deberta            olora   qqp    lora  0.3682  eval_accuracy  0.2964     346.63     15.82  762.42     8    42             results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_olora_16_0.05_8/metrics.json\n",
       "2399  deberta          adalora   qqp    lora  0.3682  eval_accuracy  0.5917     418.94     19.24  767.34     8    42           results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "2401  deberta             dora   qqp    lora  0.3682  eval_accuracy  0.3149     422.37     18.90  762.70     8    42              results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_dora_16_0.05_8/metrics.json\n",
       "2393  deberta             lora   qqp    lora  0.3682  eval_accuracy  0.2964     344.17     17.05  763.20     8    42              results/lora/task_qqp_deberta_42/base_32_2e-05_0.01/peft_lora_16_0.05_8/metrics.json\n",
       "2135  roberta          adalora   qqp    lora  0.0000        eval_f1  1.1823     293.23     11.24  538.20     8    42           results/lora/task_qqp_roberta_42/base_32_2e-05_0.01/peft_adalora_16_0.05_8/metrics.json\n",
       "\n",
       "[214 rows x 13 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.sort_values('value', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
