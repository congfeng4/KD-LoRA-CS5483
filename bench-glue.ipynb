{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# 1. 指向你截图中的那个文件夹路径\n",
    "lora_model_path = \"./distilbert-base-uncased-finetuned-LoRA-WNLI\"\n",
    "\n",
    "# 2. 自动从 adapter_config.json 中读取底座模型的名字\n",
    "# 这一步会发现底座模型是 \"distilbert-base-uncased\"\n",
    "config = PeftConfig.from_pretrained(lora_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cf8edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./distilbert-base-uncased'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.base_model_name_or_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0104e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./distilbert-base-uncased/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./distilbert-base-uncased/model.safetensors\n",
      "Some weights of the model checkpoint at ./distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 3. 加载底座模型 (Base Model)\n",
    "# 注意：如果是分类任务，Num_labels 要与你微调时一致\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# 4. 加载 LoRA 权重 (Adapter)\n",
    "model = PeftModel.from_pretrained(base_model, lora_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9356bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): DistilBertSdpaAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 加载分词器 (Tokenizer)\n",
    "# 截图显示文件夹里有 tokenizer.json 等文件，直接从该目录加载即可\n",
    "tokenizer = AutoTokenizer.from_pretrained(lora_model_path)\n",
    "\n",
    "# 此时的 model 已经加载了 LoRA 权重，可以进行推理了\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1bf2d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd87c472ea24008bfa57aa5b594088a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ef08809fe6402b9d526e7baffdae2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/38.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1377ec964eb4bbaa6e9ecffef351305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccae793200c475eaef7958c281e0dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/13.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c12302e0a54a01b0d275c3ef934126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/635 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a924a03878634ae4839b28ea39a44bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d6a92ec8b946829edff14ce760e585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 635\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 71\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 146\n",
      "    })\n",
      "})\n",
      "{'sentence1': 'I stuck a pin through a carrot. When I pulled the pin out, it had a hole.', 'sentence2': 'The carrot had a hole.', 'label': 1, 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 下载并加载 GLUE 的 WNLI 子集\n",
    "dataset = load_dataset(\"glue\", \"wnli\", cache_dir='./dataset')\n",
    "\n",
    "# 查看数据集结构\n",
    "print(dataset)\n",
    "\n",
    "# 打印一个训练集样本\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ec6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb1be92ffca4a26a1d280f6d9594708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行推理...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_data = dataset[\"validation\"]  # 如果要生成提交文件，请换成 dataset[\"test\"]\n",
    "\n",
    "# 4. 预处理函数\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], \n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_test = test_data.map(preprocess_function, batched=True)\n",
    "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# 5. 推理循环\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "dataloader = DataLoader(tokenized_test, batch_size=16)\n",
    "\n",
    "print(\"正在进行推理...\")\n",
    "for batch in tqdm(dataloader):\n",
    "    inputs = {k: v.to(model.device) for k, v in batch.items() if k != \"label\"}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    references.extend(batch[\"label\"].cpu().numpy())\n",
    "\n",
    "# 6. 计算准确率 (仅适用于 validation)\n",
    "correct = sum(1 for p, r in zip(predictions, references) if p == r)\n",
    "accuracy = correct / len(references)\n",
    "print(f\"\\nValidation Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
