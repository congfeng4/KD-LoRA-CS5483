{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95587a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9375c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T07:17:15.910759Z",
     "start_time": "2026-01-26T07:17:15.782704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_experiment_data(json_file):\n",
    "    variant = Path(json_file).relative_to('./results').parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data['variant'] = variant\n",
    "    # with open(json_file, 'w') as f:\n",
    "    #     json.dump(data, f, indent=4)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    eval_runtime = data.get('eval_runtime', -1)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', -1)\n",
    "    train_runtime = dictor(data, 'train.train_time', -1)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else -1\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "    if 'mrlora' in peft_method:\n",
    "        rank = 2*rank - 1 # r = 2*R - 1\n",
    "        \n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb26f5",
   "metadata": {},
   "source": [
    "## FFT, KD-LoRA, LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59549e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RANKS = [15, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0363da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.variant == 'fft') | (df.peft.str.contains('mrlora') & df['rank'].isin(TOTAL_RANKS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b780cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bert', 'deberta', 'roberta'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c3aeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in METRIC_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in TASK_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in FAMILY_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6cf5213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df.value * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c252280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15, 31,  8]),\n",
       " array(['BERT-b', 'DeB-b', 'RoB-b'], dtype=object),\n",
       " array(['mrlora', 'mrlora-rs', 'lora'], dtype=object),\n",
       " array(['wnli', 'MNLI', 'CoLA', 'MRPC', 'QQP', 'SST-2', 'RTE', 'QNLI',\n",
       "        'STS-B'], dtype=object),\n",
       " array(['Acc', 'm', 'mm', 'Mcc', 'F1', 'Corr_p', 'Corr_s'], dtype=object))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique(), df.family.unique(), df.peft.unique(), df.task.unique(), df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd94db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 格式化 params 的函数\n",
    "def format_params(x):\n",
    "    val = float(x)\n",
    "    # 如果是整数（如 184.0），显示为 184M\n",
    "    if val.is_integer():\n",
    "        return f\"{int(val)}M\"\n",
    "    # 如果有小数（如 0.312），保留两位显示为 0.31M\n",
    "    else:\n",
    "        return f\"{val:.2f}M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5790017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     MNLI  SST-2   CoLA          QQP   QNLI    RTE   MRPC  STS-B    All\n",
      "                                     m/mm    Acc    Mcc       Acc/F1    Acc    Acc    Acc   Corr   Ave.\n",
      "BERT-b FFT           109.48M  83.27/83.58  92.55  55.21  90.93/88.01  90.74  64.98  87.01  88.03  77.57\n",
      "       KD$_{r=31}$   1.16M    80.02/80.44  89.68  44.28  87.72/83.40  86.53  55.23  71.81  83.34  74.38\n",
      "       KD$_{r=15}$   0.87M    79.24/80.04  90.60  42.10  87.44/82.96  86.14  53.07  72.55  83.29  73.12\n",
      "       LoRA$_{r=31}$ 1.14M    82.80/83.43  91.28  50.23  89.07/85.27  90.44  55.96  78.92  87.70  77.05\n",
      "       LoRA$_{r=15}$ 0.55M    83.16/83.54  91.51  48.60  88.64/84.63  90.26  56.32  79.66  87.22  76.94\n",
      "DeB-b  FFT           184.42M  89.21/89.52  95.87  64.58  92.30/89.81  93.68  80.14  89.46  91.23  83.54\n",
      "       KD$_{r=31}$   0.57M    87.39/86.95  93.46  55.73  89.96/86.45  91.36  52.71  69.61  81.95  77.34\n",
      "       KD$_{r=15}$   0.28M    86.94/86.71  93.35  54.43  89.55/85.99  91.12  52.71  77.70  86.53  76.40\n",
      "       LoRA$_{r=31}$ 1.15M    90.19/90.01  95.30  62.16  90.77/87.72  94.22  59.21  77.70  84.41  80.71\n",
      "       LoRA$_{r=15}$ 0.56M    90.16/90.05  95.76  63.60  90.61/87.58  94.12  63.18  78.19  86.48  78.47\n",
      "RoB-b  FFT           124.65M  87.09/87.21  92.55  59.89  90.70/87.66  92.28  62.45  90.44  90.51  80.09\n",
      "       KD$_{r=31}$   1.16M    82.09/82.40  91.74  43.19  87.75/83.11  88.41  53.79  71.57  83.67  75.04\n",
      "       KD$_{r=15}$   0.87M    81.81/82.49  91.74  47.20  87.86/83.16  88.14  54.87  73.28  84.46  73.94\n",
      "       LoRA$_{r=31}$ 1.74M    86.63/86.78  93.46  54.69  89.25/85.89  92.22  60.65  80.88  87.79  72.56\n",
      "       LoRA$_{r=15}$ 1.15M    86.75/86.99  93.69  54.96  89.34/85.91  92.17  64.26  81.86  87.12  77.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_2592/1804414829.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_transformed = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define the Method Label logic\n",
    "def get_method_name(row):\n",
    "    if row['variant'] == 'fft':\n",
    "        return 'FFT'\n",
    "    elif row['variant'] == 'lora':\n",
    "        return f\"LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    elif row['variant'] == 'kd-lora':\n",
    "        return f\"KD$_{{r={int(row['rank'])}}}$\"\n",
    "        # return f\"KD-LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    return row['variant']\n",
    "\n",
    "df['Method'] = df.apply(get_method_name, axis=1)\n",
    "df['params'] = df.groupby(['variant', 'rank', 'family'])['params'].transform('first')\n",
    "df['params_formatted'] = df['params'].apply(format_params)\n",
    "\n",
    "# 2. Combine multi-metric tasks (MNLI m/mm and QQP Acc/F1)\n",
    "# We create a helper function to merge values into strings\n",
    "def format_values(group):\n",
    "    task = group['task'].iloc[0]\n",
    "    if task == 'MNLI':\n",
    "        # Assumes 'm' and 'mm' metrics exist for MNLI\n",
    "        m = group[group['metric'] == 'm']['value'].iloc[0]\n",
    "        mm = group[group['metric'] == 'mm']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{m:.2f}/{mm:.2f}\", 'met': 'm/mm'})\n",
    "    elif task == 'QQP':\n",
    "        # Assumes 'Acc' and 'F1' metrics exist for QQP\n",
    "        acc = group[group['metric'] == 'Acc']['value'].iloc[0]\n",
    "        f1 = group[group['metric'] == 'F1']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{acc:.2f}/{f1:.2f}\", 'met': 'Acc/F1'})\n",
    "    elif task == 'STS-B':\n",
    "        corr_s = group[group['metric'] == 'Corr_s']['value'].iloc[0]\n",
    "        corr_p = group[group['metric'] == 'Corr_p']['value'].iloc[0]\n",
    "        corr_mean = (corr_s + corr_p) / 2\n",
    "        return pd.Series({'val': f\"{corr_mean:.2f}\", 'met': 'Corr'})\n",
    "    else:\n",
    "        # Standard tasks with single metrics\n",
    "        return pd.Series({'val': f\"{group['value'].iloc[0]:.2f}\", 'met': group['metric'].iloc[0]})\n",
    "# 1. Update the transformations to include 'family'\n",
    "# Modify your groupby to include the family field\n",
    "df_transformed = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n",
    "\n",
    "# 1. Create a numeric version of the task scores for averaging\n",
    "def get_task_score(group):\n",
    "    # Average the 'value' column for the task (e.g., average of m and mm for MNLI)\n",
    "    return group['value'].mean()\n",
    "\n",
    "# Update task means for averaging\n",
    "task_means = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'])['value'].mean().reset_index()\n",
    "\n",
    "# Update 'All' average to be family-specific\n",
    "all_avg = task_means.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted'])['value'].mean().reset_index()\n",
    "all_avg['task'] = 'All'\n",
    "all_avg['met'] = 'Ave.'\n",
    "all_avg['val'] = all_avg['value'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Append with family preserved\n",
    "df_with_avg = pd.concat([df_transformed, all_avg[['family', 'variant', 'rank', 'Method', 'params_formatted', 'task', 'met', 'val']]], ignore_index=True)\n",
    "\n",
    "# 2. Pivot with 'family' as the top index level\n",
    "pivot_df = df_with_avg.pivot(\n",
    "    index=['family', 'variant', 'rank', 'Method', 'params_formatted'],\n",
    "    columns=['task', 'met'],\n",
    "    values='val'\n",
    ")\n",
    "\n",
    "# 3. Custom Sorting: Family first, then your existing logic\n",
    "pivot_df = pivot_df.sort_index(level=['family', 'variant', 'rank'], ascending=[True, True, False])\n",
    "\n",
    "# 4. Clean up Index\n",
    "# Keep 'family', 'Method', and 'params_formatted'\n",
    "pivot_df.index = pivot_df.index.droplevel(['variant', 'rank'])\n",
    "\n",
    "# Set index names (you can leave family as a label or remove it for a cleaner look)\n",
    "pivot_df.index.names = ['Family', 'Method', r'\\# Params']\n",
    "\n",
    "# 5. Column Ordering (to match the image)\n",
    "task_order = ['MNLI', 'SST-2', 'CoLA', 'QQP', 'QNLI', 'RTE', 'MRPC', 'STS-B', 'All']\n",
    "# Filter tasks to only those present in your data\n",
    "existing_tasks = [t for t in task_order if t in pivot_df.columns.get_level_values(0)]\n",
    "pivot_df = pivot_df.reindex(columns=existing_tasks, level=0)\n",
    "\n",
    "pivot_df.columns.names = [None, None]\n",
    "pivot_df.index.names = [None, None, None]\n",
    "\n",
    "# Display result\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fd63c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use Styler to generate the LaTeX code\n",
    "latex_code = pivot_df.style.to_latex(\n",
    "    column_format='l|l|c|' + 'c' * len(pivot_df.columns),\n",
    "    hrules=True,\n",
    "    multicol_align=\"c\",\n",
    "    multirow_align=\"c\"\n",
    ")\n",
    "\n",
    "# 3. Adjust spacing for the 'tight' look in the image\n",
    "final_latex = (\n",
    "    \"\\\\begin{table}[h]\\n\"\n",
    "    \"\\\\centering\\n\"\n",
    "    \"\\\\setlength{\\\\tabcolsep}{4pt} % Smaller column gap\\n\"\n",
    "    \"\\\\renewcommand{\\\\arraystretch}{1.2} % Better vertical spacing\\n\"\n",
    "    f\"{latex_code}\\n\"\n",
    "    \"\\\\end{table}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8ab321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_latex = final_latex.replace('&  &  &',\n",
    " r'\\multirow{2}{*}{\\textbf{Model}} & \\multirow{2}{*}{\\textbf{Method}} & \\multirow{2}{*}{\\textbf{\\# Params}} &', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "719df74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{4pt} % Smaller column gap\n",
      "\\renewcommand{\\arraystretch}{1.2} % Better vertical spacing\n",
      "\\begin{tabular}{l|l|c|ccccccccc}\n",
      "\\toprule\n",
      " \\multirow{2}{*}{\\textbf{Model}} & \\multirow{2}{*}{\\textbf{Method}} & \\multirow{2}{*}{\\textbf{\\# Params}} & \\textbf{MNLI} & \\textbf{SST-2} & \\textbf{CoLA} & \\textbf{QQP} & \\textbf{QNLI} & \\textbf{RTE} & \\textbf{MRPC} & \\textbf{STS-B} & \\textbf{All} \\\\\n",
      " &  &  & m/mm & Acc & Mcc & Acc/F1 & Acc & Acc & Acc & Corr & Ave. \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{5}{*}{BERT-b} & FFT & 109.48M & 83.27/83.58 & 92.55 & 55.21 & 90.93/88.01 & 90.74 & 64.98 & 87.01 & 88.03 & 77.57 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 80.02/80.44 & 89.68 & 44.28 & 87.72/83.40 & 86.53 & 55.23 & 71.81 & 83.34 & 74.38 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 79.24/80.04 & 90.60 & 42.10 & 87.44/82.96 & 86.14 & 53.07 & 72.55 & 83.29 & 73.12 \\\\\n",
      " & LoRA$_{r=31}$ & 1.14M & 82.80/83.43 & 91.28 & 50.23 & 89.07/85.27 & 90.44 & 55.96 & 78.92 & 87.70 & 77.05 \\\\\n",
      " & LoRA$_{r=15}$ & 0.55M & 83.16/83.54 & 91.51 & 48.60 & 88.64/84.63 & 90.26 & 56.32 & 79.66 & 87.22 & 76.94 \\\\\n",
      "\\multirow[c]{5}{*}{DeB-b} & FFT & 184.42M & 89.21/89.52 & 95.87 & 64.58 & 92.30/89.81 & 93.68 & 80.14 & 89.46 & 91.23 & 83.54 \\\\\n",
      " & KD$_{r=31}$ & 0.57M & 87.39/86.95 & 93.46 & 55.73 & 89.96/86.45 & 91.36 & 52.71 & 69.61 & 81.95 & 77.34 \\\\\n",
      " & KD$_{r=15}$ & 0.28M & 86.94/86.71 & 93.35 & 54.43 & 89.55/85.99 & 91.12 & 52.71 & 77.70 & 86.53 & 76.40 \\\\\n",
      " & LoRA$_{r=31}$ & 1.15M & 90.19/90.01 & 95.30 & 62.16 & 90.77/87.72 & 94.22 & 59.21 & 77.70 & 84.41 & 80.71 \\\\\n",
      " & LoRA$_{r=15}$ & 0.56M & 90.16/90.05 & 95.76 & 63.60 & 90.61/87.58 & 94.12 & 63.18 & 78.19 & 86.48 & 78.47 \\\\\n",
      "\\multirow[c]{5}{*}{RoB-b} & FFT & 124.65M & 87.09/87.21 & 92.55 & 59.89 & 90.70/87.66 & 92.28 & 62.45 & 90.44 & 90.51 & 80.09 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 82.09/82.40 & 91.74 & 43.19 & 87.75/83.11 & 88.41 & 53.79 & 71.57 & 83.67 & 75.04 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 81.81/82.49 & 91.74 & 47.20 & 87.86/83.16 & 88.14 & 54.87 & 73.28 & 84.46 & 73.94 \\\\\n",
      " & LoRA$_{r=31}$ & 1.74M & 86.63/86.78 & 93.46 & 54.69 & 89.25/85.89 & 92.22 & 60.65 & 80.88 & 87.79 & 72.56 \\\\\n",
      " & LoRA$_{r=15}$ & 1.15M & 86.75/86.99 & 93.69 & 54.96 & 89.34/85.91 & 92.17 & 64.26 & 81.86 & 87.12 & 77.58 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "task_values = list(TASK_NAME_MAP.values()) + ['All']\n",
    "for task in task_values:\n",
    "    final_latex = final_latex.replace(task, r'\\textbf{'+task+'}')\n",
    "\n",
    "print(final_latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
