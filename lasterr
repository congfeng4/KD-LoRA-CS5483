Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5749/5749 [00:02<00:00, 2337.24 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 2145.40 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 2162.21 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1379/1379 [00:00<00:00, 2431.23 examples/s]
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1379/1379 [00:00<00:00, 2498.37 examples/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./models/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loaded pretrained model ./models/distilbert-base-uncased
Loaded pretrained model with LoRA ./models/distilbert-base-uncased
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./models/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loaded dataset & model #train 5749 #eval 1500 #param 0.738817
Loaded pretrained model ./models/distilbert-base-uncased
Loaded pretrained model with LoRA ./models/distilbert-base-uncased
Loaded dataset & model #train 5749 #eval 1500 #param 0.738817
  0%|                                                                                                                                                   | 0/270 [00:00<?, ?it/s][rank0]:[W126 17:25:36.884727555 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W126 17:25:36.892209149 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
"nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
[rank0]: Traceback (most recent call last):
[rank0]:   File "src/BERT_Distill_LoRA.py", line 471, in <module>
[rank0]:     main_lora(args_cmd, is_student=True)
[rank0]:   File "src/BERT_Distill_LoRA.py", line 418, in main_lora
[rank0]:     raise e
[rank0]:   File "src/BERT_Distill_LoRA.py", line 413, in main_lora
[rank0]:     pipe.run_student_lora()
[rank0]:   File "src/BERT_Distill_LoRA.py", line 356, in run_student_lora
[rank0]:     student_trainer, train_metrics = self.train_distill_lora(student_model, student_train_dataset,
[rank0]:   File "src/BERT_Distill_LoRA.py", line 164, in train_distill_lora
[rank0]:     train_output = student_trainer.train()
[rank0]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/mnt/data2/congfeng/kd-lora/src/utils.py", line 152, in compute_loss
[rank0]:     loss = distillation_loss(student_logits, teacher_logits, labels)
[rank0]:   File "/mnt/data2/congfeng/kd-lora/src/utils.py", line 136, in distillation_loss
[rank0]:     hard_loss = F.cross_entropy(student_logits, labels)
[rank0]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/torch/nn/functional.py", line 3104, in cross_entropy
[rank0]:     return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
[rank0]: RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
"nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
[rank1]: Traceback (most recent call last):
[rank1]:   File "src/BERT_Distill_LoRA.py", line 471, in <module>
[rank1]:     main_lora(args_cmd, is_student=True)
[rank1]:   File "src/BERT_Distill_LoRA.py", line 418, in main_lora
[rank1]:     raise e
[rank1]:   File "src/BERT_Distill_LoRA.py", line 413, in main_lora
[rank1]:     pipe.run_student_lora()
[rank1]:   File "src/BERT_Distill_LoRA.py", line 356, in run_student_lora
[rank1]:     student_trainer, train_metrics = self.train_distill_lora(student_model, student_train_dataset,
[rank1]:   File "src/BERT_Distill_LoRA.py", line 164, in train_distill_lora
[rank1]:     train_output = student_trainer.train()
[rank1]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
[rank1]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank1]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
[rank1]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank1]:   File "/mnt/data2/congfeng/kd-lora/src/utils.py", line 152, in compute_loss
[rank1]:     loss = distillation_loss(student_logits, teacher_logits, labels)
[rank1]:   File "/mnt/data2/congfeng/kd-lora/src/utils.py", line 136, in distillation_loss
[rank1]:     hard_loss = F.cross_entropy(student_logits, labels)
[rank1]:   File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/torch/nn/functional.py", line 3104, in cross_entropy
[rank1]:     return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
[rank1]: RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
  0%|                                                                                                                                                   | 0/270 [00:00<?, ?it/s]
W0126 17:25:37.145671 140091654588224 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 211307 closing signal SIGTERM
E0126 17:25:40.164600 140091654588224 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 211304) of binary: /mnt/data2/congfeng/miniconda3/envs/lora/bin/python
Traceback (most recent call last):
  File "/mnt/data2/congfeng/miniconda3/envs/lora/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    multi_gpu_launcher(args)
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
    distrib_run.run(args)
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/data2/congfeng/miniconda3/envs/lora/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/BERT_Distill_LoRA.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-26_17:25:37
  host      : gpu25.buaanlsde.org
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 211304)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
