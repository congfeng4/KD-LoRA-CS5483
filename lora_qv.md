PEFT 里 LoRA 的 `target_modules` 默认只钩住 `"q_proj", "v_proj"`（或 `"query_key_value"`）并不是拍脑袋，而是综合了“效率 + 效果 + 经验”三点考虑：

1. 参数性价比最高  
   注意力 Q/K/V 三个矩阵里，Q 和 V 对“任务相关信号”的放大/筛选最直接：  
   - Q 决定“查什么”，V 决定“取什么”。微调它们即可让模型在不同任务里重新分配注意力和输出分布，而不必动占参数量大头的 FFN。  
   - 即使只用 2% 可训练参数，也能在大多数下游任务上逼近全量微调效果 。

2. 历史经验沉淀  
   原版 LoRA 论文与后续 HuggingFace 的多次消融实验都表明：  
   - 只调 Q+V 就能拿到 ≥ 调 Q+K+V 的 95% 性能；  
   - 把 K 也加进来通常只是涨点噪声，却要多 1/3 参数；  
   - 把 FFN 也打开，参数翻倍，收益递减 。  
   于是社区干脆把“Q+V”设成默认，让小白用户“开箱即用”不踩坑。

3. 实现层面最省心  
   不同模型对同一矩阵取名不一样（GPT 叫 `c_attn`，T5 叫 `q_proj/v_proj`，BLOOM 叫 `query_key_value`）。PEFT 内置的 `LoraConfig` 先按最常见名字匹配；若匹配不到就报错提示，让你手动填 `target_modules`，避免误改其他层 。

一句话：默认只动 Q、V 是在“参数少→速度快”与“效果够好”之间权衡后的最优解，你可以随时把 `target_modules=` 扩成 `["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]`，只是参数和显存会线性上涨，收益不一定成正比 。