{
    "eval_loss": 0.6679297089576721,
    "eval_accuracy": 0.6381109280615047,
    "eval_runtime": 1.6794,
    "eval_samples_per_second": 3252.982,
    "eval_steps_per_second": 25.605,
    "epoch": 5.128205128205128,
    "log_history": [
        {
            "loss": 0.6989,
            "grad_norm": 0.42625099420547485,
            "learning_rate": 4.8840048840048845e-06,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "eval_loss": 0.6932327151298523,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 1.84,
            "eval_samples_per_second": 2969.058,
            "eval_steps_per_second": 23.37,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "loss": 0.6939,
            "grad_norm": 0.3289217948913574,
            "learning_rate": 9.768009768009769e-06,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "eval_loss": 0.6923016309738159,
            "eval_accuracy": 0.543108182317408,
            "eval_runtime": 1.8085,
            "eval_samples_per_second": 3020.817,
            "eval_steps_per_second": 23.777,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "loss": 0.6936,
            "grad_norm": 0.6452199816703796,
            "learning_rate": 1.4652014652014653e-05,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "eval_loss": 0.6915799379348755,
            "eval_accuracy": 0.5464030752333883,
            "eval_runtime": 1.7922,
            "eval_samples_per_second": 3048.13,
            "eval_steps_per_second": 23.992,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "loss": 0.6918,
            "grad_norm": 0.4893227815628052,
            "learning_rate": 1.9536019536019538e-05,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "eval_loss": 0.6906880140304565,
            "eval_accuracy": 0.5599487461101958,
            "eval_runtime": 1.892,
            "eval_samples_per_second": 2887.438,
            "eval_steps_per_second": 22.727,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "loss": 0.6907,
            "grad_norm": 0.2989160716533661,
            "learning_rate": 2.442002442002442e-05,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "eval_loss": 0.6890829801559448,
            "eval_accuracy": 0.5403624382207578,
            "eval_runtime": 1.8304,
            "eval_samples_per_second": 2984.635,
            "eval_steps_per_second": 23.492,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "loss": 0.6903,
            "grad_norm": 0.37464797496795654,
            "learning_rate": 2.9304029304029305e-05,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "eval_loss": 0.6878660321235657,
            "eval_accuracy": 0.615046677649643,
            "eval_runtime": 1.8728,
            "eval_samples_per_second": 2917.042,
            "eval_steps_per_second": 22.96,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "loss": 0.6889,
            "grad_norm": 0.7457212805747986,
            "learning_rate": 3.418803418803419e-05,
            "epoch": 1.7094017094017095,
            "step": 1400
        },
        {
            "eval_loss": 0.6863681674003601,
            "eval_accuracy": 0.6157788760754165,
            "eval_runtime": 1.8507,
            "eval_samples_per_second": 2951.923,
            "eval_steps_per_second": 23.235,
            "epoch": 1.7094017094017095,
            "step": 1400
        },
        {
            "loss": 0.6871,
            "grad_norm": 0.5382586717605591,
            "learning_rate": 3.9072039072039076e-05,
            "epoch": 1.9536019536019538,
            "step": 1600
        },
        {
            "eval_loss": 0.6840676665306091,
            "eval_accuracy": 0.6196229178107268,
            "eval_runtime": 1.8711,
            "eval_samples_per_second": 2919.654,
            "eval_steps_per_second": 22.981,
            "epoch": 1.9536019536019538,
            "step": 1600
        },
        {
            "loss": 0.6851,
            "grad_norm": 0.885679304599762,
            "learning_rate": 4.3956043956043955e-05,
            "epoch": 2.197802197802198,
            "step": 1800
        },
        {
            "eval_loss": 0.6828279495239258,
            "eval_accuracy": 0.5907010799926781,
            "eval_runtime": 1.7773,
            "eval_samples_per_second": 3073.768,
            "eval_steps_per_second": 24.194,
            "epoch": 2.197802197802198,
            "step": 1800
        },
        {
            "loss": 0.6854,
            "grad_norm": 0.30946871638298035,
            "learning_rate": 4.884004884004884e-05,
            "epoch": 2.442002442002442,
            "step": 2000
        },
        {
            "eval_loss": 0.6803291440010071,
            "eval_accuracy": 0.6221856123009335,
            "eval_runtime": 1.8451,
            "eval_samples_per_second": 2960.847,
            "eval_steps_per_second": 23.305,
            "epoch": 2.442002442002442,
            "step": 2000
        },
        {
            "loss": 0.6846,
            "grad_norm": 0.47863927483558655,
            "learning_rate": 5.3724053724053725e-05,
            "epoch": 2.6862026862026864,
            "step": 2200
        },
        {
            "eval_loss": 0.6785309910774231,
            "eval_accuracy": 0.5817316492769541,
            "eval_runtime": 1.7964,
            "eval_samples_per_second": 3041.121,
            "eval_steps_per_second": 23.937,
            "epoch": 2.6862026862026864,
            "step": 2200
        },
        {
            "loss": 0.6846,
            "grad_norm": 1.9195573329925537,
            "learning_rate": 5.860805860805861e-05,
            "epoch": 2.9304029304029307,
            "step": 2400
        },
        {
            "eval_loss": 0.6769073605537415,
            "eval_accuracy": 0.6216364634816035,
            "eval_runtime": 1.8662,
            "eval_samples_per_second": 2927.27,
            "eval_steps_per_second": 23.041,
            "epoch": 2.9304029304029307,
            "step": 2400
        },
        {
            "loss": 0.6813,
            "grad_norm": 0.5562864542007446,
            "learning_rate": 6.349206349206349e-05,
            "epoch": 3.1746031746031744,
            "step": 2600
        },
        {
            "eval_loss": 0.6745431423187256,
            "eval_accuracy": 0.6236500091524804,
            "eval_runtime": 1.7912,
            "eval_samples_per_second": 3049.956,
            "eval_steps_per_second": 24.007,
            "epoch": 3.1746031746031744,
            "step": 2600
        },
        {
            "loss": 0.6812,
            "grad_norm": 0.6402971744537354,
            "learning_rate": 6.837606837606838e-05,
            "epoch": 3.4188034188034186,
            "step": 2800
        },
        {
            "eval_loss": 0.6720117926597595,
            "eval_accuracy": 0.6317041918359876,
            "eval_runtime": 1.8734,
            "eval_samples_per_second": 2916.06,
            "eval_steps_per_second": 22.953,
            "epoch": 3.4188034188034186,
            "step": 2800
        },
        {
            "loss": 0.6813,
            "grad_norm": 0.5330264568328857,
            "learning_rate": 7.326007326007326e-05,
            "epoch": 3.663003663003663,
            "step": 3000
        },
        {
            "eval_loss": 0.6700472831726074,
            "eval_accuracy": 0.6267618524620172,
            "eval_runtime": 1.9096,
            "eval_samples_per_second": 2860.74,
            "eval_steps_per_second": 22.517,
            "epoch": 3.663003663003663,
            "step": 3000
        },
        {
            "loss": 0.6783,
            "grad_norm": 0.991879403591156,
            "learning_rate": 7.814407814407815e-05,
            "epoch": 3.907203907203907,
            "step": 3200
        },
        {
            "eval_loss": 0.6685346961021423,
            "eval_accuracy": 0.6370126304228446,
            "eval_runtime": 1.8193,
            "eval_samples_per_second": 3002.853,
            "eval_steps_per_second": 23.636,
            "epoch": 3.907203907203907,
            "step": 3200
        },
        {
            "loss": 0.6774,
            "grad_norm": 0.646793007850647,
            "learning_rate": 8.302808302808303e-05,
            "epoch": 4.151404151404152,
            "step": 3400
        },
        {
            "eval_loss": 0.6688977479934692,
            "eval_accuracy": 0.604429800475929,
            "eval_runtime": 1.8182,
            "eval_samples_per_second": 3004.67,
            "eval_steps_per_second": 23.65,
            "epoch": 4.151404151404152,
            "step": 3400
        },
        {
            "loss": 0.6766,
            "grad_norm": 0.386078804731369,
            "learning_rate": 8.791208791208791e-05,
            "epoch": 4.395604395604396,
            "step": 3600
        },
        {
            "eval_loss": 0.6649759411811829,
            "eval_accuracy": 0.6317041918359876,
            "eval_runtime": 1.8459,
            "eval_samples_per_second": 2959.47,
            "eval_steps_per_second": 23.294,
            "epoch": 4.395604395604396,
            "step": 3600
        },
        {
            "loss": 0.6755,
            "grad_norm": 1.451184630393982,
            "learning_rate": 9.27960927960928e-05,
            "epoch": 4.639804639804639,
            "step": 3800
        },
        {
            "eval_loss": 0.6657609939575195,
            "eval_accuracy": 0.6042467508694856,
            "eval_runtime": 1.749,
            "eval_samples_per_second": 3123.539,
            "eval_steps_per_second": 24.586,
            "epoch": 4.639804639804639,
            "step": 3800
        },
        {
            "loss": 0.6763,
            "grad_norm": 0.3102002441883087,
            "learning_rate": 9.768009768009768e-05,
            "epoch": 4.884004884004884,
            "step": 4000
        },
        {
            "eval_loss": 0.660530686378479,
            "eval_accuracy": 0.6302397949844408,
            "eval_runtime": 1.8817,
            "eval_samples_per_second": 2903.252,
            "eval_steps_per_second": 22.852,
            "epoch": 4.884004884004884,
            "step": 4000
        },
        {
            "loss": 0.6755,
            "grad_norm": 0.2366379350423813,
            "learning_rate": 0.00010256410256410256,
            "epoch": 5.128205128205128,
            "step": 4200
        },
        {
            "eval_loss": 0.6635496616363525,
            "eval_accuracy": 0.613948380010983,
            "eval_runtime": 1.8857,
            "eval_samples_per_second": 2897.1,
            "eval_steps_per_second": 22.803,
            "epoch": 5.128205128205128,
            "step": 4200
        },
        {
            "train_runtime": 463.6854,
            "train_samples_per_second": 22589.236,
            "train_steps_per_second": 176.628,
            "total_flos": 3.583498702238515e+16,
            "train_loss": 0.6846770222981771,
            "epoch": 5.128205128205128,
            "step": 4200
        },
        {
            "eval_loss": 0.6679297089576721,
            "eval_accuracy": 0.6381109280615047,
            "eval_runtime": 1.6794,
            "eval_samples_per_second": 3252.982,
            "eval_steps_per_second": 25.605,
            "epoch": 5.128205128205128,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "qnli",
        "peft": "mrlora-olora",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 104743,
        "use_lcoef": false,
        "use_bias": false
    },
    "train": {
        "train_time": 463.6854,
        "trainable_params_count": 0.592226,
        "memory_allocated": [
            527.443968,
            527.443968,
            527.443968,
            527.443968,
            527.443968,
            527.443968
        ],
        "memory_reserved": [
            2518.679552,
            2518.679552,
            2518.679552,
            2518.679552,
            2518.679552,
            2518.679552
        ]
    },
    "variant": "lora"
}