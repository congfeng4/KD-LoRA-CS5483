{
    "eval_loss": 0.6949520111083984,
    "eval_accuracy": 0.4946000366099213,
    "eval_runtime": 1.9979,
    "eval_samples_per_second": 2734.421,
    "eval_steps_per_second": 21.523,
    "epoch": 1.4652014652014653,
    "log_history": [
        {
            "loss": 0.6975,
            "grad_norm": 1.3721970319747925,
            "learning_rate": 4.8840048840048845e-06,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "eval_loss": 0.6949520111083984,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 2.0111,
            "eval_samples_per_second": 2716.37,
            "eval_steps_per_second": 21.381,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "loss": 0.6973,
            "grad_norm": 0.8342914581298828,
            "learning_rate": 9.768009768009769e-06,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "eval_loss": 0.6933861970901489,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 1.7603,
            "eval_samples_per_second": 3103.419,
            "eval_steps_per_second": 24.427,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "loss": 0.6977,
            "grad_norm": 1.4392610788345337,
            "learning_rate": 1.4652014652014653e-05,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "eval_loss": 0.6924257874488831,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 1.8507,
            "eval_samples_per_second": 2951.78,
            "eval_steps_per_second": 23.234,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "loss": 0.698,
            "grad_norm": 1.0369484424591064,
            "learning_rate": 1.9536019536019538e-05,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "eval_loss": 0.693699300289154,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 2.0443,
            "eval_samples_per_second": 2672.257,
            "eval_steps_per_second": 21.034,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "loss": 0.696,
            "grad_norm": 0.5424296855926514,
            "learning_rate": 2.442002442002442e-05,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "eval_loss": 0.693420946598053,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 2.1141,
            "eval_samples_per_second": 2584.017,
            "eval_steps_per_second": 20.339,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "loss": 0.6968,
            "grad_norm": 0.9213849306106567,
            "learning_rate": 2.9304029304029305e-05,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "eval_loss": 0.693871796131134,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 2.0399,
            "eval_samples_per_second": 2678.118,
            "eval_steps_per_second": 21.08,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "train_runtime": 147.6869,
            "train_samples_per_second": 70922.313,
            "train_steps_per_second": 554.551,
            "total_flos": 1.0247306905387008e+16,
            "train_loss": 0.6972383626302083,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "eval_loss": 0.6949520111083984,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 1.9979,
            "eval_samples_per_second": 2734.421,
            "eval_steps_per_second": 21.523,
            "epoch": 1.4652014652014653,
            "step": 1200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "qnli",
        "peft": "mrlora-rs-bias",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 104743,
        "use_lcoef": false,
        "use_bias": true
    },
    "train": {
        "train_time": 147.6869,
        "trainable_params_count": 0.592226,
        "memory_allocated": [
            527.788032,
            527.788032
        ],
        "memory_reserved": [
            2520.776704,
            2520.776704
        ]
    },
    "variant": "lora"
}