{
    "eval_loss": 0.5671706795692444,
    "eval_matthews_correlation": 0.5755353914692196,
    "eval_runtime": 0.3922,
    "eval_samples_per_second": 2659.21,
    "eval_steps_per_second": 22.946,
    "epoch": 32.83582089552239,
    "log_history": [
        {
            "loss": 0.645,
            "grad_norm": 1.698207139968872,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6172807812690735,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3519,
            "eval_samples_per_second": 2964.022,
            "eval_steps_per_second": 25.576,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.5604,
            "grad_norm": 11.168377876281738,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.5544142127037048,
            "eval_matthews_correlation": 0.3853198145814999,
            "eval_runtime": 0.3512,
            "eval_samples_per_second": 2970.053,
            "eval_steps_per_second": 25.628,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4449,
            "grad_norm": 7.651738166809082,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5314817428588867,
            "eval_matthews_correlation": 0.5241189660673692,
            "eval_runtime": 0.3076,
            "eval_samples_per_second": 3390.239,
            "eval_steps_per_second": 29.254,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3643,
            "grad_norm": 6.7831597328186035,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.42364099621772766,
            "eval_matthews_correlation": 0.5496129885311101,
            "eval_runtime": 0.3449,
            "eval_samples_per_second": 3024.359,
            "eval_steps_per_second": 26.097,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2982,
            "grad_norm": 7.804420471191406,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5585538744926453,
            "eval_matthews_correlation": 0.5351033849356494,
            "eval_runtime": 0.3393,
            "eval_samples_per_second": 3073.983,
            "eval_steps_per_second": 26.525,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2467,
            "grad_norm": 12.029494285583496,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.44161105155944824,
            "eval_matthews_correlation": 0.6089852308846828,
            "eval_runtime": 0.3192,
            "eval_samples_per_second": 3267.741,
            "eval_steps_per_second": 28.197,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2055,
            "grad_norm": 8.072114944458008,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.48986244201660156,
            "eval_matthews_correlation": 0.5832008422729765,
            "eval_runtime": 0.3892,
            "eval_samples_per_second": 2679.709,
            "eval_steps_per_second": 23.123,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1751,
            "grad_norm": 9.63163948059082,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6180464029312134,
            "eval_matthews_correlation": 0.5778590180299453,
            "eval_runtime": 0.3766,
            "eval_samples_per_second": 2769.82,
            "eval_steps_per_second": 23.901,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1445,
            "grad_norm": 7.383085250854492,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.6255210041999817,
            "eval_matthews_correlation": 0.6032121451400153,
            "eval_runtime": 0.3145,
            "eval_samples_per_second": 3315.987,
            "eval_steps_per_second": 28.614,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1323,
            "grad_norm": 6.539628982543945,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6773871183395386,
            "eval_matthews_correlation": 0.6032056943524631,
            "eval_runtime": 0.3872,
            "eval_samples_per_second": 2693.434,
            "eval_steps_per_second": 23.242,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1156,
            "grad_norm": 3.861252546310425,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6724807620048523,
            "eval_matthews_correlation": 0.5880720138805856,
            "eval_runtime": 0.3939,
            "eval_samples_per_second": 2647.959,
            "eval_steps_per_second": 22.849,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "train_runtime": 245.9421,
            "train_samples_per_second": 3476.835,
            "train_steps_per_second": 27.242,
            "total_flos": 1.877868002095923e+16,
            "train_loss": 0.30296126105568627,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5671706795692444,
            "eval_matthews_correlation": 0.5755353914692196,
            "eval_runtime": 0.3922,
            "eval_samples_per_second": 2659.21,
            "eval_steps_per_second": 22.946,
            "epoch": 32.83582089552239,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-olora",
        "seed": 42,
        "rank": 16,
        "lora_alpha": 32,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 245.9421,
        "trainable_params_count": 1.181954,
        "memory_allocated": [
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176,
            535.666176
        ],
        "memory_reserved": [
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464,
            2531.262464
        ]
    },
    "variant": "lora"
}