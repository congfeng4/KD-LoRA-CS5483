{
    "eval_loss": 0.9087274074554443,
    "eval_matthews_correlation": 0.6162367490845745,
    "eval_runtime": 0.3582,
    "eval_samples_per_second": 2911.988,
    "eval_steps_per_second": 25.127,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.6452,
            "grad_norm": 4.509726047515869,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6151231527328491,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3593,
            "eval_samples_per_second": 2902.586,
            "eval_steps_per_second": 25.046,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.5563,
            "grad_norm": 6.978231906890869,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.49619850516319275,
            "eval_matthews_correlation": 0.4063400389101911,
            "eval_runtime": 0.3565,
            "eval_samples_per_second": 2925.274,
            "eval_steps_per_second": 25.242,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4312,
            "grad_norm": 4.10946798324585,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.516534149646759,
            "eval_matthews_correlation": 0.5153179547856604,
            "eval_runtime": 0.3795,
            "eval_samples_per_second": 2748.599,
            "eval_steps_per_second": 23.718,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.36,
            "grad_norm": 5.090360641479492,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.43938884139060974,
            "eval_matthews_correlation": 0.5468625515611443,
            "eval_runtime": 0.3867,
            "eval_samples_per_second": 2697.055,
            "eval_steps_per_second": 23.273,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3021,
            "grad_norm": 6.7776970863342285,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.46993759274482727,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.3588,
            "eval_samples_per_second": 2906.663,
            "eval_steps_per_second": 25.081,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2531,
            "grad_norm": 6.35291862487793,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.476331889629364,
            "eval_matthews_correlation": 0.5955860617587142,
            "eval_runtime": 0.3688,
            "eval_samples_per_second": 2828.317,
            "eval_steps_per_second": 24.405,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2163,
            "grad_norm": 6.529040813446045,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.49016010761260986,
            "eval_matthews_correlation": 0.5949616176965895,
            "eval_runtime": 0.3422,
            "eval_samples_per_second": 3047.513,
            "eval_steps_per_second": 26.297,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1833,
            "grad_norm": 9.60709285736084,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6616671085357666,
            "eval_matthews_correlation": 0.5804530426643317,
            "eval_runtime": 0.3608,
            "eval_samples_per_second": 2890.966,
            "eval_steps_per_second": 24.946,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1565,
            "grad_norm": 5.413478851318359,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5948596596717834,
            "eval_matthews_correlation": 0.5968831586006677,
            "eval_runtime": 0.357,
            "eval_samples_per_second": 2921.324,
            "eval_steps_per_second": 25.208,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1422,
            "grad_norm": 11.060194969177246,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.73201984167099,
            "eval_matthews_correlation": 0.6157593279004692,
            "eval_runtime": 0.3624,
            "eval_samples_per_second": 2877.912,
            "eval_steps_per_second": 24.833,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1256,
            "grad_norm": 3.899259567260742,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6796714663505554,
            "eval_matthews_correlation": 0.6007916142827379,
            "eval_runtime": 0.3647,
            "eval_samples_per_second": 2860.092,
            "eval_steps_per_second": 24.68,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1137,
            "grad_norm": 10.140669822692871,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.7894924283027649,
            "eval_matthews_correlation": 0.5997113648588693,
            "eval_runtime": 0.3245,
            "eval_samples_per_second": 3213.863,
            "eval_steps_per_second": 27.732,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0996,
            "grad_norm": 7.299887180328369,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.7310340404510498,
            "eval_matthews_correlation": 0.6134818519595254,
            "eval_runtime": 0.331,
            "eval_samples_per_second": 3150.687,
            "eval_steps_per_second": 27.187,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.093,
            "grad_norm": 5.516995906829834,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.779309093952179,
            "eval_matthews_correlation": 0.5950325563897697,
            "eval_runtime": 0.3568,
            "eval_samples_per_second": 2923.335,
            "eval_steps_per_second": 25.225,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0827,
            "grad_norm": 9.32924747467041,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.9087274074554443,
            "eval_matthews_correlation": 0.6162367490845745,
            "eval_runtime": 0.4269,
            "eval_samples_per_second": 2443.145,
            "eval_steps_per_second": 21.082,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 355.8488,
            "train_samples_per_second": 2402.987,
            "train_steps_per_second": 18.828,
            "total_flos": 2.552030375706624e+16,
            "train_loss": 0.2507446562449137,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.9087274074554443,
            "eval_matthews_correlation": 0.6162367490845745,
            "eval_runtime": 0.3582,
            "eval_samples_per_second": 2911.988,
            "eval_steps_per_second": 25.127,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-olora-rs",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 355.8488,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408
        ],
        "memory_reserved": [
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064
        ]
    },
    "variant": "lora"
}