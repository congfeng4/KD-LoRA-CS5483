{
    "eval_loss": 0.9157406091690063,
    "eval_matthews_correlation": 0.5805514135255713,
    "eval_runtime": 0.318,
    "eval_samples_per_second": 3279.775,
    "eval_steps_per_second": 28.301,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 0.6107,
            "grad_norm": 3.7254323959350586,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5832782983779907,
            "eval_matthews_correlation": 0.37190508740673506,
            "eval_runtime": 0.3367,
            "eval_samples_per_second": 3097.904,
            "eval_steps_per_second": 26.732,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.426,
            "grad_norm": 7.028194427490234,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4682687222957611,
            "eval_matthews_correlation": 0.5442570546927161,
            "eval_runtime": 0.3462,
            "eval_samples_per_second": 3012.469,
            "eval_steps_per_second": 25.994,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3794,
            "grad_norm": 3.774839162826538,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5061423182487488,
            "eval_matthews_correlation": 0.5259287977773666,
            "eval_runtime": 0.311,
            "eval_samples_per_second": 3353.581,
            "eval_steps_per_second": 28.938,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3316,
            "grad_norm": 4.071935176849365,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5612241625785828,
            "eval_matthews_correlation": 0.529206928614411,
            "eval_runtime": 0.3341,
            "eval_samples_per_second": 3121.862,
            "eval_steps_per_second": 26.938,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2937,
            "grad_norm": 5.076902389526367,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.6568857431411743,
            "eval_matthews_correlation": 0.5219316798836575,
            "eval_runtime": 0.3358,
            "eval_samples_per_second": 3106.327,
            "eval_steps_per_second": 26.804,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2592,
            "grad_norm": 6.066837787628174,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.486975759267807,
            "eval_matthews_correlation": 0.585467058423594,
            "eval_runtime": 0.3236,
            "eval_samples_per_second": 3223.103,
            "eval_steps_per_second": 27.812,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2131,
            "grad_norm": 4.423849105834961,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4766715168952942,
            "eval_matthews_correlation": 0.601243977092561,
            "eval_runtime": 0.3916,
            "eval_samples_per_second": 2663.676,
            "eval_steps_per_second": 22.985,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1916,
            "grad_norm": 5.050440788269043,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6160162091255188,
            "eval_matthews_correlation": 0.5651937994450119,
            "eval_runtime": 0.3577,
            "eval_samples_per_second": 2916.091,
            "eval_steps_per_second": 25.163,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.16,
            "grad_norm": 5.397916316986084,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.6487689018249512,
            "eval_matthews_correlation": 0.5855361143791362,
            "eval_runtime": 0.3726,
            "eval_samples_per_second": 2799.481,
            "eval_steps_per_second": 24.157,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1504,
            "grad_norm": 7.086667537689209,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5971449613571167,
            "eval_matthews_correlation": 0.6095582268996396,
            "eval_runtime": 0.3162,
            "eval_samples_per_second": 3298.192,
            "eval_steps_per_second": 28.46,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1299,
            "grad_norm": 6.72818660736084,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7636794447898865,
            "eval_matthews_correlation": 0.5780839016534659,
            "eval_runtime": 0.3497,
            "eval_samples_per_second": 2982.719,
            "eval_steps_per_second": 25.738,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1166,
            "grad_norm": 4.411410808563232,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.7673925161361694,
            "eval_matthews_correlation": 0.6106810410474487,
            "eval_runtime": 0.351,
            "eval_samples_per_second": 2971.764,
            "eval_steps_per_second": 25.643,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1079,
            "grad_norm": 6.383315086364746,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.7007011771202087,
            "eval_matthews_correlation": 0.6214080153834024,
            "eval_runtime": 0.3425,
            "eval_samples_per_second": 3045.692,
            "eval_steps_per_second": 26.281,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0991,
            "grad_norm": 3.6548004150390625,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.7505050301551819,
            "eval_matthews_correlation": 0.5810381850664859,
            "eval_runtime": 0.3484,
            "eval_samples_per_second": 2993.357,
            "eval_steps_per_second": 25.83,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0904,
            "grad_norm": 6.763138294219971,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.9231061339378357,
            "eval_matthews_correlation": 0.5727969336224868,
            "eval_runtime": 0.3263,
            "eval_samples_per_second": 3196.56,
            "eval_steps_per_second": 27.583,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.081,
            "grad_norm": 3.288222312927246,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.8875932097434998,
            "eval_matthews_correlation": 0.5966820103744048,
            "eval_runtime": 0.3525,
            "eval_samples_per_second": 2959.248,
            "eval_steps_per_second": 25.535,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0765,
            "grad_norm": 3.5635557174682617,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.937825620174408,
            "eval_matthews_correlation": 0.5857509882742485,
            "eval_runtime": 0.3382,
            "eval_samples_per_second": 3083.971,
            "eval_steps_per_second": 26.611,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.0702,
            "grad_norm": 5.207544803619385,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.9744241833686829,
            "eval_matthews_correlation": 0.5807606001872874,
            "eval_runtime": 0.308,
            "eval_samples_per_second": 3385.825,
            "eval_steps_per_second": 29.216,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 403.1289,
            "train_samples_per_second": 2121.158,
            "train_steps_per_second": 16.62,
            "total_flos": 3.062436450847949e+16,
            "train_loss": 0.21042277759975858,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.9157406091690063,
            "eval_matthews_correlation": 0.5805514135255713,
            "eval_runtime": 0.318,
            "eval_samples_per_second": 3279.775,
            "eval_steps_per_second": 28.301,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 403.1289,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408,
            531.089408
        ],
        "memory_reserved": [
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064,
            2373.976064
        ]
    },
    "variant": "lora"
}