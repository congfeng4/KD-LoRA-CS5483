{
    "eval_loss": 0.891233503818512,
    "eval_matthews_correlation": 0.5932024506783026,
    "eval_runtime": 0.329,
    "eval_samples_per_second": 3169.91,
    "eval_steps_per_second": 27.353,
    "epoch": 41.791044776119406,
    "log_history": [
        {
            "loss": 0.5849,
            "grad_norm": 5.391043186187744,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5390775799751282,
            "eval_matthews_correlation": 0.4304260866765428,
            "eval_runtime": 0.3951,
            "eval_samples_per_second": 2640.143,
            "eval_steps_per_second": 22.782,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4154,
            "grad_norm": 11.264074325561523,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4971380829811096,
            "eval_matthews_correlation": 0.5107428879748117,
            "eval_runtime": 0.3799,
            "eval_samples_per_second": 2745.513,
            "eval_steps_per_second": 23.691,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3604,
            "grad_norm": 29.89084243774414,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4223821461200714,
            "eval_matthews_correlation": 0.5632084517291658,
            "eval_runtime": 0.3439,
            "eval_samples_per_second": 3033.222,
            "eval_steps_per_second": 26.174,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2916,
            "grad_norm": 4.8529181480407715,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5544880628585815,
            "eval_matthews_correlation": 0.5158001386531648,
            "eval_runtime": 0.3095,
            "eval_samples_per_second": 3370.152,
            "eval_steps_per_second": 29.081,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.23,
            "grad_norm": 8.195992469787598,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.7655430436134338,
            "eval_matthews_correlation": 0.5248466844154049,
            "eval_runtime": 0.3386,
            "eval_samples_per_second": 3080.553,
            "eval_steps_per_second": 26.582,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.1764,
            "grad_norm": 4.388866901397705,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5710296034812927,
            "eval_matthews_correlation": 0.5598395777855655,
            "eval_runtime": 0.3678,
            "eval_samples_per_second": 2836.117,
            "eval_steps_per_second": 24.473,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1342,
            "grad_norm": 7.939481258392334,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.60007643699646,
            "eval_matthews_correlation": 0.6120851273043227,
            "eval_runtime": 0.3517,
            "eval_samples_per_second": 2965.85,
            "eval_steps_per_second": 25.592,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1153,
            "grad_norm": 5.863795280456543,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.8568323850631714,
            "eval_matthews_correlation": 0.5681420673133338,
            "eval_runtime": 0.3525,
            "eval_samples_per_second": 2959.206,
            "eval_steps_per_second": 25.535,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0929,
            "grad_norm": 6.714240550994873,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.6938901543617249,
            "eval_matthews_correlation": 0.6206942584175241,
            "eval_runtime": 0.3432,
            "eval_samples_per_second": 3038.99,
            "eval_steps_per_second": 26.223,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.083,
            "grad_norm": 4.723334312438965,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.787658154964447,
            "eval_matthews_correlation": 0.6134664665689209,
            "eval_runtime": 0.3291,
            "eval_samples_per_second": 3169.106,
            "eval_steps_per_second": 27.346,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0708,
            "grad_norm": 5.789243221282959,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.9168074727058411,
            "eval_matthews_correlation": 0.5857056435790745,
            "eval_runtime": 0.3568,
            "eval_samples_per_second": 2923.133,
            "eval_steps_per_second": 25.224,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.061,
            "grad_norm": 4.149348258972168,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.0146290063858032,
            "eval_matthews_correlation": 0.5906042341193154,
            "eval_runtime": 0.3458,
            "eval_samples_per_second": 3015.775,
            "eval_steps_per_second": 26.023,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0538,
            "grad_norm": 3.812072277069092,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.088278889656067,
            "eval_matthews_correlation": 0.5861230013380985,
            "eval_runtime": 0.3582,
            "eval_samples_per_second": 2911.625,
            "eval_steps_per_second": 25.124,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0509,
            "grad_norm": 5.05553674697876,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.9924491047859192,
            "eval_matthews_correlation": 0.5907675928559818,
            "eval_runtime": 0.3774,
            "eval_samples_per_second": 2763.697,
            "eval_steps_per_second": 23.848,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "train_runtime": 326.9193,
            "train_samples_per_second": 2615.63,
            "train_steps_per_second": 20.494,
            "total_flos": 2.390013820849357e+16,
            "train_loss": 0.19433476141520908,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.891233503818512,
            "eval_matthews_correlation": 0.5932024506783026,
            "eval_runtime": 0.329,
            "eval_samples_per_second": 3169.91,
            "eval_steps_per_second": 27.353,
            "epoch": 41.791044776119406,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-lcoef",
        "seed": 42,
        "rank": 16,
        "lora_alpha": 32,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 326.9193,
        "trainable_params_count": 1.18205,
        "memory_allocated": [
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752
        ],
        "memory_reserved": [
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224
        ]
    },
    "variant": "lora"
}