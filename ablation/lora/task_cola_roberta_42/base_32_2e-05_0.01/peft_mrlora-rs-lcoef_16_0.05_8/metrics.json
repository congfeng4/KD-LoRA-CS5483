{
    "eval_loss": 0.8665257096290588,
    "eval_matthews_correlation": 0.5879880120258366,
    "eval_runtime": 0.3187,
    "eval_samples_per_second": 3272.811,
    "eval_steps_per_second": 28.241,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.5986,
            "grad_norm": 4.429943561553955,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5826136469841003,
            "eval_matthews_correlation": 0.3880516330500076,
            "eval_runtime": 0.3386,
            "eval_samples_per_second": 3080.728,
            "eval_steps_per_second": 26.583,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4203,
            "grad_norm": 7.204285621643066,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.47075071930885315,
            "eval_matthews_correlation": 0.5425982560876161,
            "eval_runtime": 0.3586,
            "eval_samples_per_second": 2908.165,
            "eval_steps_per_second": 25.094,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.372,
            "grad_norm": 5.850187301635742,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5089085698127747,
            "eval_matthews_correlation": 0.5099519351292859,
            "eval_runtime": 0.3589,
            "eval_samples_per_second": 2906.132,
            "eval_steps_per_second": 25.077,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3146,
            "grad_norm": 3.7467997074127197,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4980281591415405,
            "eval_matthews_correlation": 0.5779841591999347,
            "eval_runtime": 0.3377,
            "eval_samples_per_second": 3088.875,
            "eval_steps_per_second": 26.654,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2643,
            "grad_norm": 6.531301498413086,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.6662850379943848,
            "eval_matthews_correlation": 0.5441478833696352,
            "eval_runtime": 0.3427,
            "eval_samples_per_second": 3043.459,
            "eval_steps_per_second": 26.262,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2221,
            "grad_norm": 6.5955705642700195,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.48966866731643677,
            "eval_matthews_correlation": 0.5786416039440073,
            "eval_runtime": 0.3297,
            "eval_samples_per_second": 3163.921,
            "eval_steps_per_second": 27.301,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1798,
            "grad_norm": 4.427792549133301,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4927152097225189,
            "eval_matthews_correlation": 0.6031932328167873,
            "eval_runtime": 0.3335,
            "eval_samples_per_second": 3127.705,
            "eval_steps_per_second": 26.989,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1542,
            "grad_norm": 4.186472415924072,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6683739423751831,
            "eval_matthews_correlation": 0.5779841591999347,
            "eval_runtime": 0.3478,
            "eval_samples_per_second": 2998.728,
            "eval_steps_per_second": 25.876,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1265,
            "grad_norm": 6.126214504241943,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.7240633368492126,
            "eval_matthews_correlation": 0.5701181924229938,
            "eval_runtime": 0.371,
            "eval_samples_per_second": 2811.333,
            "eval_steps_per_second": 24.259,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1146,
            "grad_norm": 7.8768768310546875,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6207695007324219,
            "eval_matthews_correlation": 0.608482323961046,
            "eval_runtime": 0.3296,
            "eval_samples_per_second": 3164.846,
            "eval_steps_per_second": 27.309,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0988,
            "grad_norm": 8.54211711883545,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7290593981742859,
            "eval_matthews_correlation": 0.608558135506955,
            "eval_runtime": 0.3407,
            "eval_samples_per_second": 3061.079,
            "eval_steps_per_second": 26.414,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0904,
            "grad_norm": 5.924213409423828,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.7035097479820251,
            "eval_matthews_correlation": 0.5961631748633855,
            "eval_runtime": 0.3277,
            "eval_samples_per_second": 3183.216,
            "eval_steps_per_second": 27.468,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0808,
            "grad_norm": 6.067655086517334,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.8087548017501831,
            "eval_matthews_correlation": 0.5832008422729765,
            "eval_runtime": 0.3376,
            "eval_samples_per_second": 3089.8,
            "eval_steps_per_second": 26.662,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0753,
            "grad_norm": 5.875633716583252,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.8130531907081604,
            "eval_matthews_correlation": 0.5855730181125508,
            "eval_runtime": 0.3726,
            "eval_samples_per_second": 2799.106,
            "eval_steps_per_second": 24.153,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0668,
            "grad_norm": 7.518239498138428,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.9065780639648438,
            "eval_matthews_correlation": 0.5905123335559759,
            "eval_runtime": 0.3083,
            "eval_samples_per_second": 3382.684,
            "eval_steps_per_second": 29.189,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 345.5603,
            "train_samples_per_second": 2474.532,
            "train_steps_per_second": 19.389,
            "total_flos": 2.552030375706624e+16,
            "train_loss": 0.21194505977630615,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.8665257096290588,
            "eval_matthews_correlation": 0.5879880120258366,
            "eval_runtime": 0.3187,
            "eval_samples_per_second": 3272.811,
            "eval_steps_per_second": 28.241,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-rs-lcoef",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 345.5603,
        "trainable_params_count": 0.887114,
        "memory_allocated": [
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984,
            531.113984
        ],
        "memory_reserved": [
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896,
            2826.960896
        ]
    },
    "variant": "lora"
}