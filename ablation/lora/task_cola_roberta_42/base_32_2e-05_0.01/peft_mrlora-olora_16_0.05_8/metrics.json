{
    "eval_loss": 0.7561314702033997,
    "eval_matthews_correlation": 0.6034053904179437,
    "eval_runtime": 0.3409,
    "eval_samples_per_second": 3059.628,
    "eval_steps_per_second": 26.401,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.6454,
            "grad_norm": 1.472163200378418,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6179819703102112,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.32,
            "eval_samples_per_second": 3259.276,
            "eval_steps_per_second": 28.124,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.5594,
            "grad_norm": 7.243725776672363,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.5070670247077942,
            "eval_matthews_correlation": 0.38317232301443055,
            "eval_runtime": 0.3419,
            "eval_samples_per_second": 3050.448,
            "eval_steps_per_second": 26.322,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4356,
            "grad_norm": 4.128357410430908,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5368926525115967,
            "eval_matthews_correlation": 0.5032393365588423,
            "eval_runtime": 0.3139,
            "eval_samples_per_second": 3322.828,
            "eval_steps_per_second": 28.673,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3687,
            "grad_norm": 6.309803485870361,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4627058506011963,
            "eval_matthews_correlation": 0.5442645975519255,
            "eval_runtime": 0.3314,
            "eval_samples_per_second": 3146.967,
            "eval_steps_per_second": 27.155,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3188,
            "grad_norm": 5.8297600746154785,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4864356219768524,
            "eval_matthews_correlation": 0.5732541217080575,
            "eval_runtime": 0.3728,
            "eval_samples_per_second": 2797.54,
            "eval_steps_per_second": 24.14,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2785,
            "grad_norm": 6.978891849517822,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4849408268928528,
            "eval_matthews_correlation": 0.5627810283916928,
            "eval_runtime": 0.371,
            "eval_samples_per_second": 2811.096,
            "eval_steps_per_second": 24.257,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2456,
            "grad_norm": 7.517133712768555,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.435552179813385,
            "eval_matthews_correlation": 0.6113480644070322,
            "eval_runtime": 0.3665,
            "eval_samples_per_second": 2845.52,
            "eval_steps_per_second": 24.554,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2151,
            "grad_norm": 10.495503425598145,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5673050880432129,
            "eval_matthews_correlation": 0.5804132033917235,
            "eval_runtime": 0.339,
            "eval_samples_per_second": 3076.768,
            "eval_steps_per_second": 26.549,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1892,
            "grad_norm": 5.897667407989502,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5394445061683655,
            "eval_matthews_correlation": 0.6064593797294897,
            "eval_runtime": 0.3467,
            "eval_samples_per_second": 3008.754,
            "eval_steps_per_second": 25.962,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1741,
            "grad_norm": 13.542632102966309,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5977768898010254,
            "eval_matthews_correlation": 0.6106988552195535,
            "eval_runtime": 0.349,
            "eval_samples_per_second": 2988.516,
            "eval_steps_per_second": 25.788,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1568,
            "grad_norm": 7.702625274658203,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6347631812095642,
            "eval_matthews_correlation": 0.6132022979495473,
            "eval_runtime": 0.3149,
            "eval_samples_per_second": 3311.672,
            "eval_steps_per_second": 28.576,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.142,
            "grad_norm": 7.740559101104736,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6220019459724426,
            "eval_matthews_correlation": 0.6279335660611044,
            "eval_runtime": 0.3311,
            "eval_samples_per_second": 3150.448,
            "eval_steps_per_second": 27.185,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1248,
            "grad_norm": 15.433406829833984,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.7209831476211548,
            "eval_matthews_correlation": 0.605712540622093,
            "eval_runtime": 0.3411,
            "eval_samples_per_second": 3058.126,
            "eval_steps_per_second": 26.388,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1128,
            "grad_norm": 5.0973992347717285,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.6986561417579651,
            "eval_matthews_correlation": 0.6233292848646662,
            "eval_runtime": 0.3404,
            "eval_samples_per_second": 3064.139,
            "eval_steps_per_second": 26.44,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1073,
            "grad_norm": 11.22240924835205,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.7760539650917053,
            "eval_matthews_correlation": 0.6120851273043227,
            "eval_runtime": 0.3222,
            "eval_samples_per_second": 3236.956,
            "eval_steps_per_second": 27.932,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0999,
            "grad_norm": 10.085594177246094,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.8091960549354553,
            "eval_matthews_correlation": 0.5985732294542903,
            "eval_runtime": 0.3561,
            "eval_samples_per_second": 2928.846,
            "eval_steps_per_second": 25.273,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0886,
            "grad_norm": 6.272638320922852,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.833846390247345,
            "eval_matthews_correlation": 0.6109671005868332,
            "eval_runtime": 0.3214,
            "eval_samples_per_second": 3245.347,
            "eval_steps_per_second": 28.004,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 374.6107,
            "train_samples_per_second": 2282.636,
            "train_steps_per_second": 17.885,
            "total_flos": 2.892301092467507e+16,
            "train_loss": 0.25074157602646774,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.7561314702033997,
            "eval_matthews_correlation": 0.6034053904179437,
            "eval_runtime": 0.3409,
            "eval_samples_per_second": 3059.628,
            "eval_steps_per_second": 26.401,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-olora",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 374.6107,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976,
            530.302976
        ],
        "memory_reserved": [
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176,
            2369.78176
        ]
    },
    "variant": "lora"
}