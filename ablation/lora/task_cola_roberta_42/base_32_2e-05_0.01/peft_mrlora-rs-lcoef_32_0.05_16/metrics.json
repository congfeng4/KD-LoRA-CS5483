{
    "eval_loss": 1.2713043689727783,
    "eval_matthews_correlation": 0.6309028031172018,
    "eval_runtime": 0.3428,
    "eval_samples_per_second": 3042.763,
    "eval_steps_per_second": 26.256,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 0.5674,
            "grad_norm": 6.554076194763184,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5356496572494507,
            "eval_matthews_correlation": 0.4856735000283885,
            "eval_runtime": 0.3605,
            "eval_samples_per_second": 2892.826,
            "eval_steps_per_second": 24.962,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4127,
            "grad_norm": 14.693733215332031,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.5149893760681152,
            "eval_matthews_correlation": 0.48312183684741317,
            "eval_runtime": 0.3584,
            "eval_samples_per_second": 2909.863,
            "eval_steps_per_second": 25.109,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3404,
            "grad_norm": 5.158599376678467,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.49106863141059875,
            "eval_matthews_correlation": 0.547116568580723,
            "eval_runtime": 0.3701,
            "eval_samples_per_second": 2818.517,
            "eval_steps_per_second": 24.321,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2582,
            "grad_norm": 6.220801830291748,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5826818346977234,
            "eval_matthews_correlation": 0.5498156591139931,
            "eval_runtime": 0.3629,
            "eval_samples_per_second": 2873.909,
            "eval_steps_per_second": 24.799,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.1832,
            "grad_norm": 6.099259853363037,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.7589704990386963,
            "eval_matthews_correlation": 0.5650034395953757,
            "eval_runtime": 0.3375,
            "eval_samples_per_second": 3090.804,
            "eval_steps_per_second": 26.67,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.1361,
            "grad_norm": 5.6026129722595215,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.6568052768707275,
            "eval_matthews_correlation": 0.5981008799238268,
            "eval_runtime": 0.3508,
            "eval_samples_per_second": 2972.967,
            "eval_steps_per_second": 25.654,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1027,
            "grad_norm": 10.057696342468262,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.6249188780784607,
            "eval_matthews_correlation": 0.5799504696103684,
            "eval_runtime": 0.3688,
            "eval_samples_per_second": 2827.881,
            "eval_steps_per_second": 24.402,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.0897,
            "grad_norm": 4.649042129516602,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.9148850440979004,
            "eval_matthews_correlation": 0.5879759000771466,
            "eval_runtime": 0.3204,
            "eval_samples_per_second": 3255.025,
            "eval_steps_per_second": 28.087,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0691,
            "grad_norm": 6.2514262199401855,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.8907201290130615,
            "eval_matthews_correlation": 0.5803968070604221,
            "eval_runtime": 0.3423,
            "eval_samples_per_second": 3047.381,
            "eval_steps_per_second": 26.296,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0612,
            "grad_norm": 11.100122451782227,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.9791515469551086,
            "eval_matthews_correlation": 0.6006974680936171,
            "eval_runtime": 0.3447,
            "eval_samples_per_second": 3025.714,
            "eval_steps_per_second": 26.109,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0553,
            "grad_norm": 6.588974952697754,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.9383072257041931,
            "eval_matthews_correlation": 0.5879759000771466,
            "eval_runtime": 0.3075,
            "eval_samples_per_second": 3391.382,
            "eval_steps_per_second": 29.264,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0523,
            "grad_norm": 10.96789836883545,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.9449707865715027,
            "eval_matthews_correlation": 0.6057667685387335,
            "eval_runtime": 0.3541,
            "eval_samples_per_second": 2945.678,
            "eval_steps_per_second": 25.418,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0449,
            "grad_norm": 10.755302429199219,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.885383665561676,
            "eval_matthews_correlation": 0.6207242502214079,
            "eval_runtime": 0.3649,
            "eval_samples_per_second": 2858.576,
            "eval_steps_per_second": 24.667,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0418,
            "grad_norm": 11.78339958190918,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.1949831247329712,
            "eval_matthews_correlation": 0.5915941303407497,
            "eval_runtime": 0.3653,
            "eval_samples_per_second": 2854.935,
            "eval_steps_per_second": 24.635,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0409,
            "grad_norm": 11.644968032836914,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.9870803356170654,
            "eval_matthews_correlation": 0.6081725386037139,
            "eval_runtime": 0.3034,
            "eval_samples_per_second": 3437.381,
            "eval_steps_per_second": 29.661,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0326,
            "grad_norm": 0.8155510425567627,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.1522763967514038,
            "eval_matthews_correlation": 0.623185623360598,
            "eval_runtime": 0.3441,
            "eval_samples_per_second": 3031.39,
            "eval_steps_per_second": 26.158,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0329,
            "grad_norm": 4.047809600830078,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.1849993467330933,
            "eval_matthews_correlation": 0.5940754350972381,
            "eval_runtime": 0.3131,
            "eval_samples_per_second": 3331.195,
            "eval_steps_per_second": 28.745,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.0282,
            "grad_norm": 4.038315296173096,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.0597244501113892,
            "eval_matthews_correlation": 0.6214080153834024,
            "eval_runtime": 0.3537,
            "eval_samples_per_second": 2949.066,
            "eval_steps_per_second": 25.447,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.0266,
            "grad_norm": 5.402822494506836,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.1200532913208008,
            "eval_matthews_correlation": 0.6335019524098836,
            "eval_runtime": 0.3458,
            "eval_samples_per_second": 3015.933,
            "eval_steps_per_second": 26.024,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.0244,
            "grad_norm": 10.42578125,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.3215442895889282,
            "eval_matthews_correlation": 0.6109671005868332,
            "eval_runtime": 0.3296,
            "eval_samples_per_second": 3164.906,
            "eval_steps_per_second": 27.31,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.0266,
            "grad_norm": 7.377424240112305,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.1915838718414307,
            "eval_matthews_correlation": 0.5963876159868886,
            "eval_runtime": 0.3655,
            "eval_samples_per_second": 2853.921,
            "eval_steps_per_second": 24.626,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.021,
            "grad_norm": 1.9453853368759155,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.2025033235549927,
            "eval_matthews_correlation": 0.6182197264087645,
            "eval_runtime": 0.3448,
            "eval_samples_per_second": 3025.151,
            "eval_steps_per_second": 26.104,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.0228,
            "grad_norm": 1.3675862550735474,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.312696099281311,
            "eval_matthews_correlation": 0.6031431608368663,
            "eval_runtime": 0.3454,
            "eval_samples_per_second": 3019.566,
            "eval_steps_per_second": 26.056,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.0191,
            "grad_norm": 0.20304448902606964,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.265999674797058,
            "eval_matthews_correlation": 0.6283219912268083,
            "eval_runtime": 0.3408,
            "eval_samples_per_second": 3060.3,
            "eval_steps_per_second": 26.407,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 568.7112,
            "train_samples_per_second": 1503.575,
            "train_steps_per_second": 11.781,
            "total_flos": 4.097166550027469e+16,
            "train_loss": 0.11208254302541415,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.2713043689727783,
            "eval_matthews_correlation": 0.6309028031172018,
            "eval_runtime": 0.3428,
            "eval_samples_per_second": 3042.763,
            "eval_steps_per_second": 26.256,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-rs-lcoef",
        "seed": 42,
        "rank": 16,
        "lora_alpha": 32,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 568.7112,
        "trainable_params_count": 1.18205,
        "memory_allocated": [
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752,
            535.690752
        ],
        "memory_reserved": [
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224,
            3135.24224
        ]
    },
    "variant": "lora"
}