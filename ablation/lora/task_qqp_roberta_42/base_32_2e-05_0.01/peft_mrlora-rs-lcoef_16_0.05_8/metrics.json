{
    "eval_loss": 0.6630103588104248,
    "eval_accuracy": 0.6318327974276527,
    "eval_f1": 0.0,
    "eval_runtime": 11.4686,
    "eval_samples_per_second": 3525.267,
    "eval_steps_per_second": 27.553,
    "epoch": 0.4220893422441083,
    "log_history": [
        {
            "loss": 0.6673,
            "grad_norm": 1.398656964302063,
            "learning_rate": 1.406964474147028e-06,
            "epoch": 0.07034822370735139,
            "step": 200
        },
        {
            "eval_loss": 0.6630103588104248,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.4959,
            "eval_samples_per_second": 3516.921,
            "eval_steps_per_second": 27.488,
            "epoch": 0.07034822370735139,
            "step": 200
        },
        {
            "loss": 0.6626,
            "grad_norm": 0.5511188507080078,
            "learning_rate": 2.813928948294056e-06,
            "epoch": 0.14069644741470277,
            "step": 400
        },
        {
            "eval_loss": 0.6586757302284241,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.5683,
            "eval_samples_per_second": 3494.882,
            "eval_steps_per_second": 27.316,
            "epoch": 0.14069644741470277,
            "step": 400
        },
        {
            "loss": 0.6628,
            "grad_norm": 0.9178484678268433,
            "learning_rate": 4.220893422441084e-06,
            "epoch": 0.21104467112205416,
            "step": 600
        },
        {
            "eval_loss": 0.6578489542007446,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.7617,
            "eval_samples_per_second": 3437.436,
            "eval_steps_per_second": 26.867,
            "epoch": 0.21104467112205416,
            "step": 600
        },
        {
            "loss": 0.6599,
            "grad_norm": 0.5257242321968079,
            "learning_rate": 5.627857896588112e-06,
            "epoch": 0.28139289482940555,
            "step": 800
        },
        {
            "eval_loss": 0.656158983707428,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.4804,
            "eval_samples_per_second": 3521.643,
            "eval_steps_per_second": 27.525,
            "epoch": 0.28139289482940555,
            "step": 800
        },
        {
            "loss": 0.6599,
            "grad_norm": 0.47736355662345886,
            "learning_rate": 7.034822370735139e-06,
            "epoch": 0.35174111853675694,
            "step": 1000
        },
        {
            "eval_loss": 0.6550742387771606,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.299,
            "eval_samples_per_second": 3578.206,
            "eval_steps_per_second": 27.967,
            "epoch": 0.35174111853675694,
            "step": 1000
        },
        {
            "loss": 0.6543,
            "grad_norm": 0.5158263444900513,
            "learning_rate": 8.441786844882167e-06,
            "epoch": 0.4220893422441083,
            "step": 1200
        },
        {
            "eval_loss": 0.6531612277030945,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.7536,
            "eval_samples_per_second": 3439.793,
            "eval_steps_per_second": 26.885,
            "epoch": 0.4220893422441083,
            "step": 1200
        },
        {
            "train_runtime": 179.5234,
            "train_samples_per_second": 202673.279,
            "train_steps_per_second": 1583.637,
            "total_flos": 1.0238567720681472e+16,
            "train_loss": 0.661126708984375,
            "epoch": 0.4220893422441083,
            "step": 1200
        },
        {
            "eval_loss": 0.6630103588104248,
            "eval_accuracy": 0.6318327974276527,
            "eval_f1": 0.0,
            "eval_runtime": 11.4686,
            "eval_samples_per_second": 3525.267,
            "eval_steps_per_second": 27.553,
            "epoch": 0.4220893422441083,
            "step": 1200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "qqp",
        "peft": "mrlora-rs-lcoef",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 363846,
        "use_lcoef": true,
        "use_bias": false
    },
    "train": {
        "train_time": 179.5234,
        "trainable_params_count": 0.592226,
        "memory_allocated": [
            528.2304
        ],
        "memory_reserved": [
            2518.679552
        ]
    },
    "variant": "lora"
}