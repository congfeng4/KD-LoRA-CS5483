{
    "eval_loss": 2.5572614669799805,
    "eval_pearson": 0.8547841033628244,
    "eval_spearman": 0.8529683225003312,
    "eval_runtime": 0.2396,
    "eval_samples_per_second": 6261.277,
    "eval_steps_per_second": 50.09,
    "epoch": 44.44444444444444,
    "log_history": [
        {
            "loss": 4.8843,
            "grad_norm": 6.8590617179870605,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.4692091941833496,
            "eval_pearson": 0.5937877379452143,
            "eval_spearman": 0.5920104965595498,
            "eval_runtime": 0.2491,
            "eval_samples_per_second": 6020.97,
            "eval_steps_per_second": 48.168,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.9791,
            "grad_norm": 10.009590148925781,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.4489572048187256,
            "eval_pearson": 0.8399408337280581,
            "eval_spearman": 0.8381228176186855,
            "eval_runtime": 0.2444,
            "eval_samples_per_second": 6137.569,
            "eval_steps_per_second": 49.101,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.7342,
            "grad_norm": 4.613583087921143,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.4789273738861084,
            "eval_pearson": 0.8560177394196844,
            "eval_spearman": 0.8530764277921776,
            "eval_runtime": 0.2389,
            "eval_samples_per_second": 6278.153,
            "eval_steps_per_second": 50.225,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6332,
            "grad_norm": 7.3727850914001465,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.5383379459381104,
            "eval_pearson": 0.8589668079391168,
            "eval_spearman": 0.8565957901960437,
            "eval_runtime": 0.3012,
            "eval_samples_per_second": 4979.825,
            "eval_steps_per_second": 39.839,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5635,
            "grad_norm": 4.976437568664551,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.572446584701538,
            "eval_pearson": 0.861191632257886,
            "eval_spearman": 0.8584972361093601,
            "eval_runtime": 0.2307,
            "eval_samples_per_second": 6501.883,
            "eval_steps_per_second": 52.015,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5096,
            "grad_norm": 11.597283363342285,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.5263330936431885,
            "eval_pearson": 0.8613034795185952,
            "eval_spearman": 0.8594370718434301,
            "eval_runtime": 0.2801,
            "eval_samples_per_second": 5354.932,
            "eval_steps_per_second": 42.839,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4608,
            "grad_norm": 5.946404457092285,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.4892873764038086,
            "eval_pearson": 0.8610901349941363,
            "eval_spearman": 0.8586943403722339,
            "eval_runtime": 0.2756,
            "eval_samples_per_second": 5441.763,
            "eval_steps_per_second": 43.534,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4281,
            "grad_norm": 3.9807112216949463,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.5872440338134766,
            "eval_pearson": 0.8589420498726246,
            "eval_spearman": 0.8571177836967352,
            "eval_runtime": 0.2391,
            "eval_samples_per_second": 6273.02,
            "eval_steps_per_second": 50.184,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4022,
            "grad_norm": 3.332813262939453,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.5869393348693848,
            "eval_pearson": 0.8597949939451794,
            "eval_spearman": 0.8576850237251923,
            "eval_runtime": 0.2749,
            "eval_samples_per_second": 5456.644,
            "eval_steps_per_second": 43.653,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3706,
            "grad_norm": 5.705937385559082,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.567213296890259,
            "eval_pearson": 0.8572263675481118,
            "eval_spearman": 0.8552211669912905,
            "eval_runtime": 0.239,
            "eval_samples_per_second": 6275.998,
            "eval_steps_per_second": 50.208,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "train_runtime": 120.0056,
            "train_samples_per_second": 4790.609,
            "train_steps_per_second": 37.498,
            "total_flos": 8623034025902080.0,
            "train_loss": 0.9965588989257812,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.5572614669799805,
            "eval_pearson": 0.8547841033628244,
            "eval_spearman": 0.8529683225003312,
            "eval_runtime": 0.2396,
            "eval_samples_per_second": 6261.277,
            "eval_steps_per_second": 50.09,
            "epoch": 44.44444444444444,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "bert",
        "task": "stsb",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 5749
    },
    "train": {
        "train_time": 120.0056,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528,
            296.918528
        ],
        "memory_reserved": [
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224,
            1231.028224
        ]
    },
    "variant": "kd-lora"
}