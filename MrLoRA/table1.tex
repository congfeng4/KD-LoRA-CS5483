\begin{table}[h]
\centering
\setlength{\tabcolsep}{4pt} % Smaller column gap
\renewcommand{\arraystretch}{1.2} % Better vertical spacing
\caption{Results on GLUE development set for BERT-base (BERT-b), DeBERTa-v3-base (DeB-b), and RoBERTa-base (RoB-b). We compare different fine-tuning strategies: Fully Fine-Tuning (FFT), MR-LoRA Fine-Tuning (MR), and Knowledge Distillation MR-LoRA Fine-Tuning (KD). Results of two total ranks $r=15, 31$ are reported. We report the average correlation for STS-B. We report mean of 3 runs using different random seeds. }
\label{tab:perf-params}
\resizebox{\textwidth}{!}{% <--- Start resize
\begin{tabular}{l|l|c|ccccccccc}
\toprule
 \multirow{2}{*}{\textbf{Model}} & \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\# Params}} & \textbf{MNLI} & \textbf{SST-2} & \textbf{CoLA} & \textbf{QQP} & \textbf{QNLI} & \textbf{RTE} & \textbf{MRPC} & \textbf{STS-B} & \textbf{All} \\
 &  &  & m/mm & Acc & Mcc & Acc/F1 & Acc & Acc & Acc & Corr & Ave. \\
\midrule
\multirow[c]{2}{*}{BERT-b} & FFT & 109.48M & 82.26/82.43 & 91.91 & 60.36 & 89.05/85.77 & 91.06 & 65.97 & 84.99 & 89.11 & 81.94 \\
 & MR$_{r=15}$ & 0.26M & nan & nan & nan & nan & nan & 66.79 & nan & nan & 66.79 \\
DeB-b & FFT & 184.42M & 89.72/89.78 & 95.70 & 71.58 & 90.33/87.34 & 93.84 & 83.30 & 89.40 & 90.94 & 88.11 \\
RoB-b & FFT & 124.65M & 86.48/86.47 & 94.66 & 62.34 & 89.11/85.99 & 92.45 & 78.43 & 88.42 & 90.88 & 85.36 \\
\bottomrule
\end{tabular}% <--- End resize
}
\end{table}