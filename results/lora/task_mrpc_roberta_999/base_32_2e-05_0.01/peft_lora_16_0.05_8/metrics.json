{
    "eval_loss": 0.5110459327697754,
    "eval_accuracy": 0.875,
    "eval_f1": 0.9094138543516875,
    "eval_runtime": 0.1092,
    "eval_samples_per_second": 3735.513,
    "eval_steps_per_second": 36.623,
    "epoch": 68.96551724137932,
    "log_history": [
        {
            "loss": 0.5897,
            "grad_norm": 4.363391876220703,
            "learning_rate": 0.00013793103448275863,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.4126996099948883,
            "eval_accuracy": 0.8063725490196079,
            "eval_f1": 0.8667790893760541,
            "eval_runtime": 0.132,
            "eval_samples_per_second": 3092.066,
            "eval_steps_per_second": 30.314,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.338,
            "grad_norm": 1.3491381406784058,
            "learning_rate": 0.00019157088122605365,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.36255431175231934,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.8986013986013986,
            "eval_runtime": 0.2418,
            "eval_samples_per_second": 1687.419,
            "eval_steps_per_second": 16.543,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.2467,
            "grad_norm": 2.6804349422454834,
            "learning_rate": 0.00017624521072796937,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.37720787525177,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8954128440366973,
            "eval_runtime": 0.2342,
            "eval_samples_per_second": 1741.872,
            "eval_steps_per_second": 17.077,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.1727,
            "grad_norm": 8.004400253295898,
            "learning_rate": 0.00016091954022988506,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.5263326168060303,
            "eval_accuracy": 0.8676470588235294,
            "eval_f1": 0.9072164948453608,
            "eval_runtime": 0.1085,
            "eval_samples_per_second": 3759.898,
            "eval_steps_per_second": 36.862,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.1212,
            "grad_norm": 6.235481262207031,
            "learning_rate": 0.00014559386973180078,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.5110459327697754,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9094138543516875,
            "eval_runtime": 0.1401,
            "eval_samples_per_second": 2911.71,
            "eval_steps_per_second": 28.546,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.086,
            "grad_norm": 2.6988654136657715,
            "learning_rate": 0.00013026819923371647,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.6672261357307434,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9065255731922399,
            "eval_runtime": 0.2452,
            "eval_samples_per_second": 1663.979,
            "eval_steps_per_second": 16.314,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.0756,
            "grad_norm": 9.909350395202637,
            "learning_rate": 0.00011494252873563218,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.6735178828239441,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9065255731922399,
            "eval_runtime": 0.1389,
            "eval_samples_per_second": 2937.364,
            "eval_steps_per_second": 28.798,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.0544,
            "grad_norm": 2.5037453174591064,
            "learning_rate": 9.96168582375479e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.6769365072250366,
            "eval_accuracy": 0.8651960784313726,
            "eval_f1": 0.9026548672566371,
            "eval_runtime": 0.1261,
            "eval_samples_per_second": 3235.354,
            "eval_steps_per_second": 31.719,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.0431,
            "grad_norm": 2.454160213470459,
            "learning_rate": 8.42911877394636e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.7963610887527466,
            "eval_accuracy": 0.8651960784313726,
            "eval_f1": 0.9036777583187391,
            "eval_runtime": 0.1445,
            "eval_samples_per_second": 2823.319,
            "eval_steps_per_second": 27.68,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.0406,
            "grad_norm": 1.9594697952270508,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.8217048048973083,
            "eval_accuracy": 0.8676470588235294,
            "eval_f1": 0.9039145907473309,
            "eval_runtime": 0.1922,
            "eval_samples_per_second": 2122.913,
            "eval_steps_per_second": 20.813,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "train_runtime": 231.2549,
            "train_samples_per_second": 1586.128,
            "train_steps_per_second": 12.54,
            "total_flos": 1.701350765232128e+16,
            "train_loss": 0.17682077836990356,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.5110459327697754,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9094138543516875,
            "eval_runtime": 0.1092,
            "eval_samples_per_second": 3735.513,
            "eval_steps_per_second": 36.623,
            "epoch": 68.96551724137932,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 999,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 3668
    },
    "train": {
        "train_time": 231.2549,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184
        ],
        "memory_reserved": [
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176
        ]
    },
    "variant": "lora"
}