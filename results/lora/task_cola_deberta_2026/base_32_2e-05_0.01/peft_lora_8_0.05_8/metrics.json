{
    "eval_loss": 0.4092811644077301,
    "eval_matthews_correlation": 0.6732477678270925,
    "eval_runtime": 0.5206,
    "eval_samples_per_second": 2003.34,
    "eval_steps_per_second": 17.287,
    "epoch": 47.76119402985075,
    "log_history": [
        {
            "loss": 0.6349,
            "grad_norm": 0.33977678418159485,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5892146229743958,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.6603,
            "eval_samples_per_second": 1579.587,
            "eval_steps_per_second": 13.63,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4339,
            "grad_norm": 0.7778159976005554,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.39363157749176025,
            "eval_matthews_correlation": 0.6157364530398333,
            "eval_runtime": 0.6428,
            "eval_samples_per_second": 1622.66,
            "eval_steps_per_second": 14.002,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3396,
            "grad_norm": 0.856266438961029,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.3682509660720825,
            "eval_matthews_correlation": 0.6331400794803589,
            "eval_runtime": 0.7176,
            "eval_samples_per_second": 1453.356,
            "eval_steps_per_second": 12.541,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2956,
            "grad_norm": 0.856497585773468,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.34868139028549194,
            "eval_matthews_correlation": 0.6583078404306316,
            "eval_runtime": 0.7124,
            "eval_samples_per_second": 1463.965,
            "eval_steps_per_second": 12.632,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2626,
            "grad_norm": 0.8822007775306702,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3514149785041809,
            "eval_matthews_correlation": 0.6635559502590729,
            "eval_runtime": 0.6091,
            "eval_samples_per_second": 1712.398,
            "eval_steps_per_second": 14.776,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2343,
            "grad_norm": 0.8179634213447571,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.3906557261943817,
            "eval_matthews_correlation": 0.6580702636158169,
            "eval_runtime": 0.4504,
            "eval_samples_per_second": 2315.649,
            "eval_steps_per_second": 19.982,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2183,
            "grad_norm": 0.8248167037963867,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.38357850909233093,
            "eval_matthews_correlation": 0.665274646611453,
            "eval_runtime": 0.5452,
            "eval_samples_per_second": 1913.053,
            "eval_steps_per_second": 16.508,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1951,
            "grad_norm": 0.78389972448349,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.42171648144721985,
            "eval_matthews_correlation": 0.6578435355005723,
            "eval_runtime": 0.5183,
            "eval_samples_per_second": 2012.452,
            "eval_steps_per_second": 17.365,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1849,
            "grad_norm": 1.1428221464157104,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.39409345388412476,
            "eval_matthews_correlation": 0.6626617035374891,
            "eval_runtime": 0.5827,
            "eval_samples_per_second": 1790.058,
            "eval_steps_per_second": 15.446,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1739,
            "grad_norm": 1.3265888690948486,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.43782514333724976,
            "eval_matthews_correlation": 0.6455219823779293,
            "eval_runtime": 0.4713,
            "eval_samples_per_second": 2212.973,
            "eval_steps_per_second": 19.096,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1557,
            "grad_norm": 1.7187681198120117,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4092811644077301,
            "eval_matthews_correlation": 0.6732477678270925,
            "eval_runtime": 0.5392,
            "eval_samples_per_second": 1934.179,
            "eval_steps_per_second": 16.69,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1501,
            "grad_norm": 1.5959351062774658,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.44607338309288025,
            "eval_matthews_correlation": 0.6511813794482872,
            "eval_runtime": 0.648,
            "eval_samples_per_second": 1609.641,
            "eval_steps_per_second": 13.89,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.141,
            "grad_norm": 1.697754144668579,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.45491111278533936,
            "eval_matthews_correlation": 0.6409676231335113,
            "eval_runtime": 0.5791,
            "eval_samples_per_second": 1800.977,
            "eval_steps_per_second": 15.541,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1345,
            "grad_norm": 1.5024099349975586,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.48478859663009644,
            "eval_matthews_correlation": 0.6433364564823282,
            "eval_runtime": 0.7278,
            "eval_samples_per_second": 1433.02,
            "eval_steps_per_second": 12.365,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1274,
            "grad_norm": 1.2738664150238037,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.47190651297569275,
            "eval_matthews_correlation": 0.6618939398663453,
            "eval_runtime": 0.5721,
            "eval_samples_per_second": 1823.161,
            "eval_steps_per_second": 15.732,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1236,
            "grad_norm": 1.2047871351242065,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.5102928876876831,
            "eval_matthews_correlation": 0.6553837937800786,
            "eval_runtime": 0.572,
            "eval_samples_per_second": 1823.571,
            "eval_steps_per_second": 15.736,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "train_runtime": 621.6085,
            "train_samples_per_second": 1375.625,
            "train_steps_per_second": 10.778,
            "total_flos": 2.7036310174695424e+16,
            "train_loss": 0.2378291255235672,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4092811644077301,
            "eval_matthews_correlation": 0.6732477678270925,
            "eval_runtime": 0.5206,
            "eval_samples_per_second": 2003.34,
            "eval_steps_per_second": 17.287,
            "epoch": 47.76119402985075,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 621.6085,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184
        ],
        "memory_reserved": [
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232
        ]
    },
    "variant": "lora"
}