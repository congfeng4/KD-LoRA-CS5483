{
    "eval_loss": 0.3636915683746338,
    "eval_matthews_correlation": 0.6725572081041828,
    "eval_runtime": 0.7085,
    "eval_samples_per_second": 1472.163,
    "eval_steps_per_second": 12.703,
    "epoch": 83.58208955223881,
    "log_history": [
        {
            "loss": 1.8973,
            "grad_norm": 0.2163114994764328,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.571935772895813,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.8824,
            "eval_samples_per_second": 1182.018,
            "eval_steps_per_second": 10.2,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.8955,
            "grad_norm": 0.30734381079673767,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6202035546302795,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.8855,
            "eval_samples_per_second": 1177.895,
            "eval_steps_per_second": 10.164,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.6037,
            "grad_norm": 0.4094425439834595,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.6116898655891418,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.8786,
            "eval_samples_per_second": 1187.18,
            "eval_steps_per_second": 10.244,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.589,
            "grad_norm": 0.4097255766391754,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5745337009429932,
            "eval_matthews_correlation": 0.0463559874942472,
            "eval_runtime": 1.0715,
            "eval_samples_per_second": 973.377,
            "eval_steps_per_second": 8.399,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4823,
            "grad_norm": 0.28000399470329285,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4228568971157074,
            "eval_matthews_correlation": 0.5604411498024476,
            "eval_runtime": 0.9933,
            "eval_samples_per_second": 1050.067,
            "eval_steps_per_second": 9.061,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4138,
            "grad_norm": 0.3930329978466034,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4057188928127289,
            "eval_matthews_correlation": 0.5758037831117457,
            "eval_runtime": 0.7668,
            "eval_samples_per_second": 1360.278,
            "eval_steps_per_second": 11.738,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3803,
            "grad_norm": 0.2740292549133301,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4136892557144165,
            "eval_matthews_correlation": 0.5993174841218436,
            "eval_runtime": 0.6011,
            "eval_samples_per_second": 1735.165,
            "eval_steps_per_second": 14.973,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3633,
            "grad_norm": 0.4283478856086731,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.3765445947647095,
            "eval_matthews_correlation": 0.6132379591518842,
            "eval_runtime": 0.5985,
            "eval_samples_per_second": 1742.833,
            "eval_steps_per_second": 15.039,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3409,
            "grad_norm": 0.3892837166786194,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.3768607974052429,
            "eval_matthews_correlation": 0.6107363335829461,
            "eval_runtime": 0.8217,
            "eval_samples_per_second": 1269.394,
            "eval_steps_per_second": 10.954,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3286,
            "grad_norm": 0.4724125564098358,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.3632034659385681,
            "eval_matthews_correlation": 0.6381004342223774,
            "eval_runtime": 0.5448,
            "eval_samples_per_second": 1914.434,
            "eval_steps_per_second": 16.52,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3227,
            "grad_norm": 0.4072474241256714,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.3663330376148224,
            "eval_matthews_correlation": 0.6306906620617413,
            "eval_runtime": 0.4971,
            "eval_samples_per_second": 2098.038,
            "eval_steps_per_second": 18.104,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3132,
            "grad_norm": 0.7025442719459534,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.3703293204307556,
            "eval_matthews_correlation": 0.6405767700619004,
            "eval_runtime": 0.6721,
            "eval_samples_per_second": 1551.881,
            "eval_steps_per_second": 13.391,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3034,
            "grad_norm": 0.5580565333366394,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.3736705183982849,
            "eval_matthews_correlation": 0.6380902412628672,
            "eval_runtime": 0.6758,
            "eval_samples_per_second": 1543.361,
            "eval_steps_per_second": 13.318,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.2952,
            "grad_norm": 0.49866294860839844,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.3841838538646698,
            "eval_matthews_correlation": 0.638254769958794,
            "eval_runtime": 0.7247,
            "eval_samples_per_second": 1439.176,
            "eval_steps_per_second": 12.419,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.2907,
            "grad_norm": 0.3317924439907074,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.3754647970199585,
            "eval_matthews_correlation": 0.6331400794803589,
            "eval_runtime": 0.6061,
            "eval_samples_per_second": 1720.765,
            "eval_steps_per_second": 14.848,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.2872,
            "grad_norm": 0.45018187165260315,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.3766922354698181,
            "eval_matthews_correlation": 0.6356215524304684,
            "eval_runtime": 0.7421,
            "eval_samples_per_second": 1405.466,
            "eval_steps_per_second": 12.128,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.2815,
            "grad_norm": 0.48585280776023865,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.3774511218070984,
            "eval_matthews_correlation": 0.6454833331679224,
            "eval_runtime": 0.7334,
            "eval_samples_per_second": 1422.14,
            "eval_steps_per_second": 12.272,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.2738,
            "grad_norm": 0.4618464708328247,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.3700919449329376,
            "eval_matthews_correlation": 0.6481069022642968,
            "eval_runtime": 0.6907,
            "eval_samples_per_second": 1509.98,
            "eval_steps_per_second": 13.03,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.2713,
            "grad_norm": 0.502173662185669,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.38315144181251526,
            "eval_matthews_correlation": 0.6504099683042353,
            "eval_runtime": 0.6786,
            "eval_samples_per_second": 1536.993,
            "eval_steps_per_second": 13.263,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.2664,
            "grad_norm": 0.4826086759567261,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.37514665722846985,
            "eval_matthews_correlation": 0.6578036520402312,
            "eval_runtime": 0.8042,
            "eval_samples_per_second": 1296.908,
            "eval_steps_per_second": 11.191,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.2611,
            "grad_norm": 0.495553195476532,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.37078091502189636,
            "eval_matthews_correlation": 0.6553462265049138,
            "eval_runtime": 0.7084,
            "eval_samples_per_second": 1472.377,
            "eval_steps_per_second": 12.705,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.2569,
            "grad_norm": 0.5399359464645386,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.37216392159461975,
            "eval_matthews_correlation": 0.6555128829335255,
            "eval_runtime": 0.6978,
            "eval_samples_per_second": 1494.617,
            "eval_steps_per_second": 12.897,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.2556,
            "grad_norm": 0.6296777725219727,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.3636915683746338,
            "eval_matthews_correlation": 0.6725572081041828,
            "eval_runtime": 0.7543,
            "eval_samples_per_second": 1382.79,
            "eval_steps_per_second": 11.932,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.2488,
            "grad_norm": 0.8516609072685242,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.36773499846458435,
            "eval_matthews_correlation": 0.6701797985979863,
            "eval_runtime": 0.6964,
            "eval_samples_per_second": 1497.663,
            "eval_steps_per_second": 12.923,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.2459,
            "grad_norm": 0.564350426197052,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.3770361542701721,
            "eval_matthews_correlation": 0.660301076782038,
            "eval_runtime": 0.8803,
            "eval_samples_per_second": 1184.869,
            "eval_steps_per_second": 10.224,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.2476,
            "grad_norm": 0.6621992588043213,
            "learning_rate": 4.975124378109453e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.3743877112865448,
            "eval_matthews_correlation": 0.660301076782038,
            "eval_runtime": 0.7491,
            "eval_samples_per_second": 1392.347,
            "eval_steps_per_second": 12.015,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.2435,
            "grad_norm": 0.5271209478378296,
            "learning_rate": 4.311774461028192e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 0.3800413906574249,
            "eval_matthews_correlation": 0.66271185211871,
            "eval_runtime": 0.7898,
            "eval_samples_per_second": 1320.575,
            "eval_steps_per_second": 11.395,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "loss": 0.2433,
            "grad_norm": 1.1348545551300049,
            "learning_rate": 3.6484245439469325e-05,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 0.3765469491481781,
            "eval_matthews_correlation": 0.667660908939119,
            "eval_runtime": 0.7958,
            "eval_samples_per_second": 1310.588,
            "eval_steps_per_second": 11.309,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "train_runtime": 1458.3196,
            "train_samples_per_second": 586.36,
            "train_steps_per_second": 4.594,
            "total_flos": 4.747611805528883e+16,
            "train_loss": 0.40010267393929616,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 0.3636915683746338,
            "eval_matthews_correlation": 0.6725572081041828,
            "eval_runtime": 0.7085,
            "eval_samples_per_second": 1472.163,
            "eval_steps_per_second": 12.703,
            "epoch": 83.58208955223881,
            "step": 5600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 1458.3196,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}