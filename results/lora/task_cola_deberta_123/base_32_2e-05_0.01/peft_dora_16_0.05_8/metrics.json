{
    "eval_loss": 0.46344196796417236,
    "eval_matthews_correlation": 0.6836713490127815,
    "eval_runtime": 0.4796,
    "eval_samples_per_second": 2174.604,
    "eval_steps_per_second": 18.765,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.6277,
            "grad_norm": 0.38725772500038147,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.568271815776825,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.7021,
            "eval_samples_per_second": 1485.573,
            "eval_steps_per_second": 12.819,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3986,
            "grad_norm": 1.1059517860412598,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.37007394433021545,
            "eval_matthews_correlation": 0.6282019580480633,
            "eval_runtime": 0.8182,
            "eval_samples_per_second": 1274.687,
            "eval_steps_per_second": 10.999,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.311,
            "grad_norm": 1.4998024702072144,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.3920488953590393,
            "eval_matthews_correlation": 0.6405928483307023,
            "eval_runtime": 0.9098,
            "eval_samples_per_second": 1146.413,
            "eval_steps_per_second": 9.892,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2632,
            "grad_norm": 1.1664643287658691,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.40870100259780884,
            "eval_matthews_correlation": 0.6430274487762421,
            "eval_runtime": 0.7532,
            "eval_samples_per_second": 1384.742,
            "eval_steps_per_second": 11.949,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2306,
            "grad_norm": 0.6816561818122864,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3757234811782837,
            "eval_matthews_correlation": 0.677548658476666,
            "eval_runtime": 0.8778,
            "eval_samples_per_second": 1188.262,
            "eval_steps_per_second": 10.253,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2015,
            "grad_norm": 1.5718199014663696,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.3833000957965851,
            "eval_matthews_correlation": 0.6717126042883813,
            "eval_runtime": 0.8431,
            "eval_samples_per_second": 1237.113,
            "eval_steps_per_second": 10.675,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1755,
            "grad_norm": 2.108060359954834,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.526016354560852,
            "eval_matthews_correlation": 0.6430274487762421,
            "eval_runtime": 0.4962,
            "eval_samples_per_second": 2102.158,
            "eval_steps_per_second": 18.139,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1637,
            "grad_norm": 1.9570788145065308,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.44455304741859436,
            "eval_matthews_correlation": 0.6494699358828817,
            "eval_runtime": 0.5507,
            "eval_samples_per_second": 1894.057,
            "eval_steps_per_second": 16.344,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1434,
            "grad_norm": 1.0904066562652588,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.44260868430137634,
            "eval_matthews_correlation": 0.669573406815581,
            "eval_runtime": 0.6891,
            "eval_samples_per_second": 1513.579,
            "eval_steps_per_second": 13.061,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1284,
            "grad_norm": 1.6769660711288452,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.46344196796417236,
            "eval_matthews_correlation": 0.6836713490127815,
            "eval_runtime": 0.6154,
            "eval_samples_per_second": 1694.838,
            "eval_steps_per_second": 14.625,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1188,
            "grad_norm": 2.7236580848693848,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.47696661949157715,
            "eval_matthews_correlation": 0.6809673250835145,
            "eval_runtime": 0.6965,
            "eval_samples_per_second": 1497.52,
            "eval_steps_per_second": 12.922,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1144,
            "grad_norm": 1.0186878442764282,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5442213416099548,
            "eval_matthews_correlation": 0.665274646611453,
            "eval_runtime": 0.6185,
            "eval_samples_per_second": 1686.285,
            "eval_steps_per_second": 14.551,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0986,
            "grad_norm": 1.156299114227295,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.5217400193214417,
            "eval_matthews_correlation": 0.6780033342159347,
            "eval_runtime": 0.5429,
            "eval_samples_per_second": 1921.014,
            "eval_steps_per_second": 16.576,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0935,
            "grad_norm": 1.004223346710205,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.5616917610168457,
            "eval_matthews_correlation": 0.6754048707881031,
            "eval_runtime": 0.7112,
            "eval_samples_per_second": 1466.468,
            "eval_steps_per_second": 12.654,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0844,
            "grad_norm": 1.2070188522338867,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.6126399040222168,
            "eval_matthews_correlation": 0.6603613028668636,
            "eval_runtime": 0.612,
            "eval_samples_per_second": 1704.319,
            "eval_steps_per_second": 14.706,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 764.4083,
            "train_samples_per_second": 1118.643,
            "train_steps_per_second": 8.765,
            "total_flos": 2.535197660676096e+16,
            "train_loss": 0.21022054481506347,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.46344196796417236,
            "eval_matthews_correlation": 0.6836713490127815,
            "eval_runtime": 0.4796,
            "eval_samples_per_second": 2174.604,
            "eval_steps_per_second": 18.765,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 764.4083,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824
        ],
        "memory_reserved": [
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792
        ]
    },
    "variant": "lora"
}