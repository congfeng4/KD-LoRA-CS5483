{
    "eval_loss": 0.4568355977535248,
    "eval_pearson": 0.9065495521113826,
    "eval_spearman": 0.9060822705605818,
    "eval_runtime": 0.4773,
    "eval_samples_per_second": 3142.443,
    "eval_steps_per_second": 25.14,
    "epoch": 53.333333333333336,
    "log_history": [
        {
            "loss": 6.2942,
            "grad_norm": 4.82219934463501,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.11623477935791,
            "eval_pearson": 0.629015175353309,
            "eval_spearman": 0.6342265128483318,
            "eval_runtime": 0.5358,
            "eval_samples_per_second": 2799.606,
            "eval_steps_per_second": 22.397,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.8601,
            "grad_norm": 7.283865451812744,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.6958932876586914,
            "eval_pearson": 0.8688327074368206,
            "eval_spearman": 0.8745666693482897,
            "eval_runtime": 0.5209,
            "eval_samples_per_second": 2879.866,
            "eval_steps_per_second": 23.039,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.45,
            "grad_norm": 1.4428049325942993,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.6008349657058716,
            "eval_pearson": 0.8935996426294127,
            "eval_spearman": 0.8969556015244243,
            "eval_runtime": 0.5888,
            "eval_samples_per_second": 2547.703,
            "eval_steps_per_second": 20.382,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3495,
            "grad_norm": 1.4140512943267822,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5195662379264832,
            "eval_pearson": 0.9019614753887226,
            "eval_spearman": 0.90393262066389,
            "eval_runtime": 0.43,
            "eval_samples_per_second": 3488.43,
            "eval_steps_per_second": 27.907,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.295,
            "grad_norm": 1.2159570455551147,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.47595563530921936,
            "eval_pearson": 0.899626977540191,
            "eval_spearman": 0.9024600922802914,
            "eval_runtime": 0.461,
            "eval_samples_per_second": 3253.773,
            "eval_steps_per_second": 26.03,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.2635,
            "grad_norm": 1.7155492305755615,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4772140383720398,
            "eval_pearson": 0.9049130814101655,
            "eval_spearman": 0.9042224725387623,
            "eval_runtime": 0.5909,
            "eval_samples_per_second": 2538.565,
            "eval_steps_per_second": 20.309,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.2435,
            "grad_norm": 1.309592604637146,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.4568355977535248,
            "eval_pearson": 0.9065495521113826,
            "eval_spearman": 0.9060822705605818,
            "eval_runtime": 0.5184,
            "eval_samples_per_second": 2893.58,
            "eval_steps_per_second": 23.149,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.2159,
            "grad_norm": 1.3342642784118652,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.4574544131755829,
            "eval_pearson": 0.9029193125321076,
            "eval_spearman": 0.9041520736040471,
            "eval_runtime": 0.5021,
            "eval_samples_per_second": 2987.605,
            "eval_steps_per_second": 23.901,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.1978,
            "grad_norm": 2.2797980308532715,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.4582759737968445,
            "eval_pearson": 0.9031788478221188,
            "eval_spearman": 0.9031020869134431,
            "eval_runtime": 0.4488,
            "eval_samples_per_second": 3342.455,
            "eval_steps_per_second": 26.74,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.1817,
            "grad_norm": 1.719028115272522,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.4405534267425537,
            "eval_pearson": 0.9041243559067575,
            "eval_spearman": 0.9041589183903568,
            "eval_runtime": 0.4918,
            "eval_samples_per_second": 3050.097,
            "eval_steps_per_second": 24.401,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.1737,
            "grad_norm": 2.0656752586364746,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.42326775193214417,
            "eval_pearson": 0.902954874252519,
            "eval_spearman": 0.904265619122747,
            "eval_runtime": 0.4817,
            "eval_samples_per_second": 3113.657,
            "eval_steps_per_second": 24.909,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.1622,
            "grad_norm": 0.9804877638816833,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.44576650857925415,
            "eval_pearson": 0.9003252210662249,
            "eval_spearman": 0.9016300616777153,
            "eval_runtime": 0.4466,
            "eval_samples_per_second": 3359.049,
            "eval_steps_per_second": 26.872,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "train_runtime": 480.5262,
            "train_samples_per_second": 1196.397,
            "train_steps_per_second": 9.365,
            "total_flos": 2.027687024315597e+16,
            "train_loss": 0.8072343413035075,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4568355977535248,
            "eval_pearson": 0.9065495521113826,
            "eval_spearman": 0.9060822705605818,
            "eval_runtime": 0.4773,
            "eval_samples_per_second": 3142.443,
            "eval_steps_per_second": 25.14,
            "epoch": 53.333333333333336,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 480.5262,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688,
            763.186688
        ],
        "memory_reserved": [
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496,
            4766.826496
        ]
    },
    "variant": "lora"
}