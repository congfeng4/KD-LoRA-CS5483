{
    "eval_loss": 0.44929951429367065,
    "eval_pearson": 0.9074120488048791,
    "eval_spearman": 0.9082952711032976,
    "eval_runtime": 0.7842,
    "eval_samples_per_second": 1912.864,
    "eval_steps_per_second": 15.303,
    "epoch": 53.333333333333336,
    "log_history": [
        {
            "loss": 6.6763,
            "grad_norm": 8.411335945129395,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.4358913898468018,
            "eval_pearson": 0.06052476187780851,
            "eval_spearman": 0.09502152594443602,
            "eval_runtime": 0.9371,
            "eval_samples_per_second": 1600.723,
            "eval_steps_per_second": 12.806,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.0401,
            "grad_norm": 8.337136268615723,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.721666693687439,
            "eval_pearson": 0.8483502078979326,
            "eval_spearman": 0.8632227340134834,
            "eval_runtime": 0.7442,
            "eval_samples_per_second": 2015.552,
            "eval_steps_per_second": 16.124,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.5176,
            "grad_norm": 1.4195716381072998,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.5509388446807861,
            "eval_pearson": 0.8873639966212395,
            "eval_spearman": 0.8923323056617131,
            "eval_runtime": 0.7654,
            "eval_samples_per_second": 1959.71,
            "eval_steps_per_second": 15.678,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.4017,
            "grad_norm": 3.1103429794311523,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.4654976725578308,
            "eval_pearson": 0.8953831397714919,
            "eval_spearman": 0.9005925308592858,
            "eval_runtime": 0.731,
            "eval_samples_per_second": 2052.078,
            "eval_steps_per_second": 16.417,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.3477,
            "grad_norm": 1.1758097410202026,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.45140206813812256,
            "eval_pearson": 0.9001206576045314,
            "eval_spearman": 0.9027067133999684,
            "eval_runtime": 0.7889,
            "eval_samples_per_second": 1901.392,
            "eval_steps_per_second": 15.211,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.3116,
            "grad_norm": 1.839546799659729,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4775984585285187,
            "eval_pearson": 0.9036712958136968,
            "eval_spearman": 0.9048431914170028,
            "eval_runtime": 0.77,
            "eval_samples_per_second": 1948.132,
            "eval_steps_per_second": 15.585,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.2868,
            "grad_norm": 1.5738521814346313,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.44929951429367065,
            "eval_pearson": 0.9074120488048791,
            "eval_spearman": 0.9082952711032976,
            "eval_runtime": 0.8234,
            "eval_samples_per_second": 1821.76,
            "eval_steps_per_second": 14.574,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.2574,
            "grad_norm": 3.053312301635742,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.4297233819961548,
            "eval_pearson": 0.9026669971228974,
            "eval_spearman": 0.9076104180573704,
            "eval_runtime": 0.7583,
            "eval_samples_per_second": 1977.987,
            "eval_steps_per_second": 15.824,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.2432,
            "grad_norm": 3.373877763748169,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.407033771276474,
            "eval_pearson": 0.9061489461822231,
            "eval_spearman": 0.9079934833117065,
            "eval_runtime": 0.7644,
            "eval_samples_per_second": 1962.397,
            "eval_steps_per_second": 15.699,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.2302,
            "grad_norm": 1.639985203742981,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.4274318516254425,
            "eval_pearson": 0.907013310961332,
            "eval_spearman": 0.9081999418045369,
            "eval_runtime": 0.8584,
            "eval_samples_per_second": 1747.48,
            "eval_steps_per_second": 13.98,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.218,
            "grad_norm": 1.936336874961853,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.4049666225910187,
            "eval_pearson": 0.9071240984748792,
            "eval_spearman": 0.9082003982460176,
            "eval_runtime": 0.8342,
            "eval_samples_per_second": 1798.146,
            "eval_steps_per_second": 14.385,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.2061,
            "grad_norm": 0.821316659450531,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.42311081290245056,
            "eval_pearson": 0.9058495526221608,
            "eval_spearman": 0.9065621798295693,
            "eval_runtime": 0.7464,
            "eval_samples_per_second": 2009.529,
            "eval_steps_per_second": 16.076,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "train_runtime": 418.8179,
            "train_samples_per_second": 1372.673,
            "train_steps_per_second": 10.745,
            "total_flos": 2.027687024315597e+16,
            "train_loss": 0.8947168811162313,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.44929951429367065,
            "eval_pearson": 0.9074120488048791,
            "eval_spearman": 0.9082952711032976,
            "eval_runtime": 0.7842,
            "eval_samples_per_second": 1912.864,
            "eval_steps_per_second": 15.303,
            "epoch": 53.333333333333336,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 418.8179,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824
        ],
        "memory_reserved": [
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232
        ]
    },
    "variant": "lora"
}