{
    "eval_loss": 0.4706689715385437,
    "eval_pearson": 0.902719663554449,
    "eval_spearman": 0.9062926195404144,
    "eval_runtime": 0.4565,
    "eval_samples_per_second": 3286.049,
    "eval_steps_per_second": 26.288,
    "epoch": 93.33333333333333,
    "log_history": [
        {
            "loss": 8.425,
            "grad_norm": 20.74443817138672,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 4.2830305099487305,
            "eval_pearson": 0.03686828114459554,
            "eval_spearman": 0.04452526977033511,
            "eval_runtime": 0.5143,
            "eval_samples_per_second": 2916.503,
            "eval_steps_per_second": 23.332,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.8119,
            "grad_norm": 1.5055267810821533,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.444410562515259,
            "eval_pearson": 0.4942910260685443,
            "eval_spearman": 0.512675979059139,
            "eval_runtime": 0.5687,
            "eval_samples_per_second": 2637.487,
            "eval_steps_per_second": 21.1,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.6764,
            "grad_norm": 2.1741931438446045,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.8940305113792419,
            "eval_pearson": 0.8712373077555146,
            "eval_spearman": 0.8747635938541061,
            "eval_runtime": 0.5154,
            "eval_samples_per_second": 2910.52,
            "eval_steps_per_second": 23.284,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6749,
            "grad_norm": 0.5934213995933533,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.6527559161186218,
            "eval_pearson": 0.88171585741179,
            "eval_spearman": 0.8830820912306762,
            "eval_runtime": 0.5638,
            "eval_samples_per_second": 2660.528,
            "eval_steps_per_second": 21.284,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5503,
            "grad_norm": 1.0465595722198486,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5936340093612671,
            "eval_pearson": 0.8839872651862412,
            "eval_spearman": 0.8867449026038865,
            "eval_runtime": 0.5093,
            "eval_samples_per_second": 2945.491,
            "eval_steps_per_second": 23.564,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.4898,
            "grad_norm": 0.7387375235557556,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.6268198490142822,
            "eval_pearson": 0.887257336508375,
            "eval_spearman": 0.8919743731757929,
            "eval_runtime": 0.5028,
            "eval_samples_per_second": 2983.335,
            "eval_steps_per_second": 23.867,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.446,
            "grad_norm": 1.2773933410644531,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.5634879469871521,
            "eval_pearson": 0.8885373632145346,
            "eval_spearman": 0.8932358199202217,
            "eval_runtime": 0.5892,
            "eval_samples_per_second": 2545.751,
            "eval_steps_per_second": 20.366,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4205,
            "grad_norm": 0.9637326598167419,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5238460898399353,
            "eval_pearson": 0.8936104389543669,
            "eval_spearman": 0.8973486699638222,
            "eval_runtime": 0.6078,
            "eval_samples_per_second": 2467.856,
            "eval_steps_per_second": 19.743,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.3988,
            "grad_norm": 0.537740170955658,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5355505347251892,
            "eval_pearson": 0.8933526025952652,
            "eval_spearman": 0.8979935406302181,
            "eval_runtime": 0.4988,
            "eval_samples_per_second": 3007.009,
            "eval_steps_per_second": 24.056,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3809,
            "grad_norm": 2.257309913635254,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.48276957869529724,
            "eval_pearson": 0.8950680189272632,
            "eval_spearman": 0.8995336388096744,
            "eval_runtime": 0.7513,
            "eval_samples_per_second": 1996.56,
            "eval_steps_per_second": 15.972,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3639,
            "grad_norm": 0.8065046072006226,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.48864632844924927,
            "eval_pearson": 0.8970041857625438,
            "eval_spearman": 0.9013674044783355,
            "eval_runtime": 0.7414,
            "eval_samples_per_second": 2023.328,
            "eval_steps_per_second": 16.187,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.355,
            "grad_norm": 1.9703437089920044,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.47494739294052124,
            "eval_pearson": 0.8976006033617048,
            "eval_spearman": 0.9022108472953105,
            "eval_runtime": 0.7445,
            "eval_samples_per_second": 2014.66,
            "eval_steps_per_second": 16.117,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3447,
            "grad_norm": 0.6222991943359375,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.47691041231155396,
            "eval_pearson": 0.8994040316499299,
            "eval_spearman": 0.9034047722787368,
            "eval_runtime": 0.5734,
            "eval_samples_per_second": 2616.17,
            "eval_steps_per_second": 20.929,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3341,
            "grad_norm": 0.9345864653587341,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.47681379318237305,
            "eval_pearson": 0.8996198358263853,
            "eval_spearman": 0.9034673649526554,
            "eval_runtime": 0.5185,
            "eval_samples_per_second": 2892.941,
            "eval_steps_per_second": 23.144,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.3283,
            "grad_norm": 0.9276752471923828,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.4727534055709839,
            "eval_pearson": 0.9003066916018301,
            "eval_spearman": 0.9040292391592857,
            "eval_runtime": 0.5968,
            "eval_samples_per_second": 2513.572,
            "eval_steps_per_second": 20.109,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3203,
            "grad_norm": 0.6802120208740234,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.4866549074649811,
            "eval_pearson": 0.9018523648387357,
            "eval_spearman": 0.9052507582358551,
            "eval_runtime": 0.5196,
            "eval_samples_per_second": 2886.928,
            "eval_steps_per_second": 23.095,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3146,
            "grad_norm": 1.619605541229248,
            "learning_rate": 5.4320987654320986e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.46144580841064453,
            "eval_pearson": 0.9023341053750428,
            "eval_spearman": 0.9059641798495149,
            "eval_runtime": 0.58,
            "eval_samples_per_second": 2586.183,
            "eval_steps_per_second": 20.689,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "loss": 0.3108,
            "grad_norm": 1.3907901048660278,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "eval_loss": 0.47419294714927673,
            "eval_pearson": 0.9021871952367635,
            "eval_spearman": 0.9059074194270647,
            "eval_runtime": 0.7937,
            "eval_samples_per_second": 1889.978,
            "eval_steps_per_second": 15.12,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "loss": 0.3062,
            "grad_norm": 1.149868369102478,
            "learning_rate": 3.45679012345679e-05,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 0.46393415331840515,
            "eval_pearson": 0.9020257700572675,
            "eval_spearman": 0.9059327756721645,
            "eval_runtime": 0.5992,
            "eval_samples_per_second": 2503.439,
            "eval_steps_per_second": 20.028,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "loss": 0.301,
            "grad_norm": 1.4263134002685547,
            "learning_rate": 2.4691358024691357e-05,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "eval_loss": 0.4584944546222687,
            "eval_pearson": 0.9024395855079683,
            "eval_spearman": 0.906219679639362,
            "eval_runtime": 0.4501,
            "eval_samples_per_second": 3332.364,
            "eval_steps_per_second": 26.659,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "loss": 0.2978,
            "grad_norm": 0.6017064452171326,
            "learning_rate": 1.4814814814814815e-05,
            "epoch": 93.33333333333333,
            "step": 4200
        },
        {
            "eval_loss": 0.4706689715385437,
            "eval_pearson": 0.902719663554449,
            "eval_spearman": 0.9062926195404144,
            "eval_runtime": 0.5258,
            "eval_samples_per_second": 2852.538,
            "eval_steps_per_second": 22.82,
            "epoch": 93.33333333333333,
            "step": 4200
        },
        {
            "train_runtime": 953.9323,
            "train_samples_per_second": 602.663,
            "train_steps_per_second": 4.717,
            "total_flos": 3.5606454362701824e+16,
            "train_loss": 0.9452987325759161,
            "epoch": 93.33333333333333,
            "step": 4200
        },
        {
            "eval_loss": 0.4706689715385437,
            "eval_pearson": 0.902719663554449,
            "eval_spearman": 0.9062926195404144,
            "eval_runtime": 0.4565,
            "eval_samples_per_second": 3286.049,
            "eval_steps_per_second": 26.288,
            "epoch": 93.33333333333333,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 953.9323,
        "trainable_params_count": 0.590977,
        "memory_allocated": [
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}