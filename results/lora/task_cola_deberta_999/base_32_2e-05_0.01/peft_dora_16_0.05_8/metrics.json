{
    "eval_loss": 0.3892158269882202,
    "eval_matthews_correlation": 0.6826253049219981,
    "eval_runtime": 0.7053,
    "eval_samples_per_second": 1478.735,
    "eval_steps_per_second": 12.76,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.6412,
            "grad_norm": 0.48512157797813416,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5727477073669434,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.7766,
            "eval_samples_per_second": 1343.012,
            "eval_steps_per_second": 11.589,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3984,
            "grad_norm": 0.8412935137748718,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.37591657042503357,
            "eval_matthews_correlation": 0.6306644810568987,
            "eval_runtime": 0.8486,
            "eval_samples_per_second": 1229.148,
            "eval_steps_per_second": 10.606,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3119,
            "grad_norm": 1.0026733875274658,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.353794664144516,
            "eval_matthews_correlation": 0.6701100574575558,
            "eval_runtime": 0.8711,
            "eval_samples_per_second": 1197.352,
            "eval_steps_per_second": 10.332,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2701,
            "grad_norm": 1.6260122060775757,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.3362298011779785,
            "eval_matthews_correlation": 0.6757073194553476,
            "eval_runtime": 0.7941,
            "eval_samples_per_second": 1313.454,
            "eval_steps_per_second": 11.334,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2297,
            "grad_norm": 1.4717347621917725,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3631347715854645,
            "eval_matthews_correlation": 0.6752785726504847,
            "eval_runtime": 0.8213,
            "eval_samples_per_second": 1269.879,
            "eval_steps_per_second": 10.958,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2014,
            "grad_norm": 1.5224533081054688,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.3893226981163025,
            "eval_matthews_correlation": 0.6778579662562668,
            "eval_runtime": 0.775,
            "eval_samples_per_second": 1345.87,
            "eval_steps_per_second": 11.613,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1806,
            "grad_norm": 1.0975940227508545,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.3892158269882202,
            "eval_matthews_correlation": 0.6826253049219981,
            "eval_runtime": 0.8294,
            "eval_samples_per_second": 1257.591,
            "eval_steps_per_second": 10.852,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1585,
            "grad_norm": 1.1458971500396729,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.4512012302875519,
            "eval_matthews_correlation": 0.6797549826002157,
            "eval_runtime": 0.9115,
            "eval_samples_per_second": 1144.239,
            "eval_steps_per_second": 9.874,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1435,
            "grad_norm": 1.810938835144043,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4718545079231262,
            "eval_matthews_correlation": 0.6750024002589107,
            "eval_runtime": 0.868,
            "eval_samples_per_second": 1201.567,
            "eval_steps_per_second": 10.368,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1312,
            "grad_norm": 0.8034369349479675,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.47354400157928467,
            "eval_matthews_correlation": 0.670371653486617,
            "eval_runtime": 0.8951,
            "eval_samples_per_second": 1165.223,
            "eval_steps_per_second": 10.055,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1183,
            "grad_norm": 1.9071528911590576,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5016738176345825,
            "eval_matthews_correlation": 0.6677282266080609,
            "eval_runtime": 0.815,
            "eval_samples_per_second": 1279.804,
            "eval_steps_per_second": 11.043,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.109,
            "grad_norm": 1.8653514385223389,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5398097634315491,
            "eval_matthews_correlation": 0.6724688526255549,
            "eval_runtime": 0.8376,
            "eval_samples_per_second": 1245.261,
            "eval_steps_per_second": 10.745,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 550.2367,
            "train_samples_per_second": 1554.058,
            "train_steps_per_second": 12.177,
            "total_flos": 2.028158128540877e+16,
            "train_loss": 0.24115277846654257,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.3892158269882202,
            "eval_matthews_correlation": 0.6826253049219981,
            "eval_runtime": 0.7053,
            "eval_samples_per_second": 1478.735,
            "eval_steps_per_second": 12.76,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 550.2367,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824
        ],
        "memory_reserved": [
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792,
            5129.633792
        ]
    },
    "variant": "lora"
}