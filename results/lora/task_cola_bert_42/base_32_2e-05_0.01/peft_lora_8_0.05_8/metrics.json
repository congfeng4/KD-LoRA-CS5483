{
    "eval_loss": 0.49704432487487793,
    "eval_matthews_correlation": 0.5682065493651185,
    "eval_runtime": 0.1642,
    "eval_samples_per_second": 6351.426,
    "eval_steps_per_second": 54.806,
    "epoch": 41.791044776119406,
    "log_history": [
        {
            "loss": 0.6215,
            "grad_norm": 0.7529883980751038,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6102420091629028,
            "eval_matthews_correlation": 0.0463559874942472,
            "eval_runtime": 0.2549,
            "eval_samples_per_second": 4092.18,
            "eval_steps_per_second": 35.311,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.5125,
            "grad_norm": 0.8736739158630371,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.49728134274482727,
            "eval_matthews_correlation": 0.44176088083850046,
            "eval_runtime": 0.2331,
            "eval_samples_per_second": 4474.984,
            "eval_steps_per_second": 38.614,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4335,
            "grad_norm": 2.0947208404541016,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4505210220813751,
            "eval_matthews_correlation": 0.5235990316279782,
            "eval_runtime": 0.321,
            "eval_samples_per_second": 3248.74,
            "eval_steps_per_second": 28.033,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3849,
            "grad_norm": 1.0622917413711548,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.43225789070129395,
            "eval_matthews_correlation": 0.5547002704668513,
            "eval_runtime": 0.4149,
            "eval_samples_per_second": 2513.632,
            "eval_steps_per_second": 21.69,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3452,
            "grad_norm": 1.4968317747116089,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.44488954544067383,
            "eval_matthews_correlation": 0.5496311083440725,
            "eval_runtime": 0.2387,
            "eval_samples_per_second": 4369.83,
            "eval_steps_per_second": 37.707,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.3139,
            "grad_norm": 1.1322256326675415,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.46793878078460693,
            "eval_matthews_correlation": 0.5420036503219092,
            "eval_runtime": 0.2519,
            "eval_samples_per_second": 4139.753,
            "eval_steps_per_second": 35.722,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2891,
            "grad_norm": 0.7549558281898499,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4786010980606079,
            "eval_matthews_correlation": 0.5624732266073051,
            "eval_runtime": 0.2533,
            "eval_samples_per_second": 4117.997,
            "eval_steps_per_second": 35.534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2606,
            "grad_norm": 2.0775246620178223,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5363596081733704,
            "eval_matthews_correlation": 0.5207572018426233,
            "eval_runtime": 0.3297,
            "eval_samples_per_second": 3163.061,
            "eval_steps_per_second": 27.294,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2435,
            "grad_norm": 1.7337287664413452,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.49704432487487793,
            "eval_matthews_correlation": 0.5682065493651185,
            "eval_runtime": 0.316,
            "eval_samples_per_second": 3300.441,
            "eval_steps_per_second": 28.479,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2265,
            "grad_norm": 1.8887336254119873,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5259945392608643,
            "eval_matthews_correlation": 0.5420036503219092,
            "eval_runtime": 0.2198,
            "eval_samples_per_second": 4744.281,
            "eval_steps_per_second": 40.938,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2142,
            "grad_norm": 1.2306933403015137,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5574295520782471,
            "eval_matthews_correlation": 0.5521589562965672,
            "eval_runtime": 0.4206,
            "eval_samples_per_second": 2479.673,
            "eval_steps_per_second": 21.397,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1953,
            "grad_norm": 1.6474114656448364,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5960847735404968,
            "eval_matthews_correlation": 0.5548237186354423,
            "eval_runtime": 0.3082,
            "eval_samples_per_second": 3384.34,
            "eval_steps_per_second": 29.203,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1834,
            "grad_norm": 2.684433937072754,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.6319689154624939,
            "eval_matthews_correlation": 0.5675517176765141,
            "eval_runtime": 0.4134,
            "eval_samples_per_second": 2523.178,
            "eval_steps_per_second": 21.772,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1817,
            "grad_norm": 1.621209979057312,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.5977048277854919,
            "eval_matthews_correlation": 0.5576106804001113,
            "eval_runtime": 0.2419,
            "eval_samples_per_second": 4311.466,
            "eval_steps_per_second": 37.203,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "train_runtime": 402.8711,
            "train_samples_per_second": 2122.515,
            "train_steps_per_second": 16.631,
            "total_flos": 2.3656348617015296e+16,
            "train_loss": 0.3147038813999721,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.49704432487487793,
            "eval_matthews_correlation": 0.5682065493651185,
            "eval_runtime": 0.1642,
            "eval_samples_per_second": 6351.426,
            "eval_steps_per_second": 54.806,
            "epoch": 41.791044776119406,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 402.8711,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408,
            463.313408
        ],
        "memory_reserved": [
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016,
            2002.78016
        ]
    },
    "variant": "lora"
}