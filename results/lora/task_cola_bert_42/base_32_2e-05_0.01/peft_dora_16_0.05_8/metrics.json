{
    "eval_loss": 0.562463641166687,
    "eval_matthews_correlation": 0.5711178585424906,
    "eval_runtime": 0.2297,
    "eval_samples_per_second": 4541.67,
    "eval_steps_per_second": 39.19,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.6179,
            "grad_norm": 0.5776925086975098,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5880665183067322,
            "eval_matthews_correlation": 0.08036809130702588,
            "eval_runtime": 0.4087,
            "eval_samples_per_second": 2551.829,
            "eval_steps_per_second": 22.02,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4822,
            "grad_norm": 1.248899221420288,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.49526745080947876,
            "eval_matthews_correlation": 0.46404096692342206,
            "eval_runtime": 0.2549,
            "eval_samples_per_second": 4092.088,
            "eval_steps_per_second": 35.31,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4123,
            "grad_norm": 2.189572334289551,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.462565153837204,
            "eval_matthews_correlation": 0.5313208986648889,
            "eval_runtime": 0.2789,
            "eval_samples_per_second": 3739.834,
            "eval_steps_per_second": 32.271,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3602,
            "grad_norm": 1.2416259050369263,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4488998353481293,
            "eval_matthews_correlation": 0.5235990316279782,
            "eval_runtime": 0.3046,
            "eval_samples_per_second": 3424.619,
            "eval_steps_per_second": 29.551,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3122,
            "grad_norm": 2.1514434814453125,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.46189284324645996,
            "eval_matthews_correlation": 0.5420036503219092,
            "eval_runtime": 0.3741,
            "eval_samples_per_second": 2787.87,
            "eval_steps_per_second": 24.056,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2734,
            "grad_norm": 1.3293213844299316,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4836139678955078,
            "eval_matthews_correlation": 0.5534186082067715,
            "eval_runtime": 0.3318,
            "eval_samples_per_second": 3143.584,
            "eval_steps_per_second": 27.126,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2461,
            "grad_norm": 1.1838140487670898,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4889093041419983,
            "eval_matthews_correlation": 0.5547002704668513,
            "eval_runtime": 0.2581,
            "eval_samples_per_second": 4041.136,
            "eval_steps_per_second": 34.871,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2155,
            "grad_norm": 2.8066964149475098,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5593728423118591,
            "eval_matthews_correlation": 0.5495443671948597,
            "eval_runtime": 0.2907,
            "eval_samples_per_second": 3587.774,
            "eval_steps_per_second": 30.959,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1959,
            "grad_norm": 2.2524335384368896,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5363671779632568,
            "eval_matthews_correlation": 0.5576106804001113,
            "eval_runtime": 0.3239,
            "eval_samples_per_second": 3220.049,
            "eval_steps_per_second": 27.786,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1791,
            "grad_norm": 1.883981704711914,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.562463641166687,
            "eval_matthews_correlation": 0.5711178585424906,
            "eval_runtime": 0.3054,
            "eval_samples_per_second": 3414.984,
            "eval_steps_per_second": 29.468,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1654,
            "grad_norm": 2.195927619934082,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5876500010490417,
            "eval_matthews_correlation": 0.5558086597524818,
            "eval_runtime": 0.304,
            "eval_samples_per_second": 3430.852,
            "eval_steps_per_second": 29.605,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1468,
            "grad_norm": 2.050321102142334,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6381303071975708,
            "eval_matthews_correlation": 0.5575034099514093,
            "eval_runtime": 0.4833,
            "eval_samples_per_second": 2158.125,
            "eval_steps_per_second": 18.622,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1364,
            "grad_norm": 4.052730560302734,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.7274397611618042,
            "eval_matthews_correlation": 0.565579540997454,
            "eval_runtime": 0.3477,
            "eval_samples_per_second": 2999.825,
            "eval_steps_per_second": 25.885,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1325,
            "grad_norm": 2.12849497795105,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.6671918034553528,
            "eval_matthews_correlation": 0.5472224847569017,
            "eval_runtime": 0.302,
            "eval_samples_per_second": 3453.587,
            "eval_steps_per_second": 29.801,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1247,
            "grad_norm": 3.217930316925049,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.6961974501609802,
            "eval_matthews_correlation": 0.5607990478394429,
            "eval_runtime": 0.3244,
            "eval_samples_per_second": 3214.711,
            "eval_steps_per_second": 27.74,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 548.5507,
            "train_samples_per_second": 1558.835,
            "train_steps_per_second": 12.214,
            "total_flos": 2.535152362192896e+16,
            "train_loss": 0.26671170552571616,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.562463641166687,
            "eval_matthews_correlation": 0.5711178585424906,
            "eval_runtime": 0.2297,
            "eval_samples_per_second": 4541.67,
            "eval_steps_per_second": 39.19,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 548.5507,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744
        ],
        "memory_reserved": [
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568
        ]
    },
    "variant": "lora"
}