{
    "eval_loss": 0.9131035208702087,
    "eval_matthews_correlation": 0.5675682416159784,
    "eval_runtime": 0.6775,
    "eval_samples_per_second": 1539.457,
    "eval_steps_per_second": 13.284,
    "epoch": 62.6865671641791,
    "log_history": [
        {
            "loss": 0.6052,
            "grad_norm": 1.5240015983581543,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5211085081100464,
            "eval_matthews_correlation": 0.3631515243396485,
            "eval_runtime": 0.6019,
            "eval_samples_per_second": 1732.711,
            "eval_steps_per_second": 14.951,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4536,
            "grad_norm": 1.6629512310028076,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.459865540266037,
            "eval_matthews_correlation": 0.5046216086478392,
            "eval_runtime": 0.5975,
            "eval_samples_per_second": 1745.555,
            "eval_steps_per_second": 15.062,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3806,
            "grad_norm": 2.4629106521606445,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5000216364860535,
            "eval_matthews_correlation": 0.5208528714430889,
            "eval_runtime": 0.6496,
            "eval_samples_per_second": 1605.694,
            "eval_steps_per_second": 13.855,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3196,
            "grad_norm": 2.207689046859741,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.48271599411964417,
            "eval_matthews_correlation": 0.5446169750397436,
            "eval_runtime": 0.7029,
            "eval_samples_per_second": 1483.903,
            "eval_steps_per_second": 12.805,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2628,
            "grad_norm": 5.166349411010742,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5693034529685974,
            "eval_matthews_correlation": 0.5502911396062787,
            "eval_runtime": 0.5345,
            "eval_samples_per_second": 1951.372,
            "eval_steps_per_second": 16.838,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2186,
            "grad_norm": 2.312166452407837,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.565406858921051,
            "eval_matthews_correlation": 0.5732046470010711,
            "eval_runtime": 0.6068,
            "eval_samples_per_second": 1718.712,
            "eval_steps_per_second": 14.831,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1866,
            "grad_norm": 2.3040835857391357,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5467155575752258,
            "eval_matthews_correlation": 0.5933815828411364,
            "eval_runtime": 0.5357,
            "eval_samples_per_second": 1946.852,
            "eval_steps_per_second": 16.799,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1543,
            "grad_norm": 4.020386219024658,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6284887790679932,
            "eval_matthews_correlation": 0.5828923211172198,
            "eval_runtime": 0.6053,
            "eval_samples_per_second": 1723.126,
            "eval_steps_per_second": 14.869,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1312,
            "grad_norm": 3.2330667972564697,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.628860592842102,
            "eval_matthews_correlation": 0.5880094937717885,
            "eval_runtime": 0.5904,
            "eval_samples_per_second": 1766.654,
            "eval_steps_per_second": 15.244,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1172,
            "grad_norm": 5.576225280761719,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6722538471221924,
            "eval_matthews_correlation": 0.5905123335559759,
            "eval_runtime": 0.5563,
            "eval_samples_per_second": 1874.743,
            "eval_steps_per_second": 16.177,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1052,
            "grad_norm": 2.1547956466674805,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6835331916809082,
            "eval_matthews_correlation": 0.5957258748412207,
            "eval_runtime": 0.6748,
            "eval_samples_per_second": 1545.568,
            "eval_steps_per_second": 13.337,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0887,
            "grad_norm": 4.391346454620361,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6933762431144714,
            "eval_matthews_correlation": 0.5905230992467433,
            "eval_runtime": 0.633,
            "eval_samples_per_second": 1647.726,
            "eval_steps_per_second": 14.218,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0785,
            "grad_norm": 6.024746417999268,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.8414309024810791,
            "eval_matthews_correlation": 0.5805300925831498,
            "eval_runtime": 0.6308,
            "eval_samples_per_second": 1653.427,
            "eval_steps_per_second": 14.267,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0744,
            "grad_norm": 2.7645325660705566,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.8084906339645386,
            "eval_matthews_correlation": 0.5651092792103851,
            "eval_runtime": 0.5768,
            "eval_samples_per_second": 1808.295,
            "eval_steps_per_second": 15.604,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0715,
            "grad_norm": 4.511653423309326,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.8213140964508057,
            "eval_matthews_correlation": 0.5882977917441249,
            "eval_runtime": 0.509,
            "eval_samples_per_second": 2049.239,
            "eval_steps_per_second": 17.683,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0609,
            "grad_norm": 1.8429938554763794,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.8112234473228455,
            "eval_matthews_correlation": 0.6011053198493792,
            "eval_runtime": 0.5954,
            "eval_samples_per_second": 1751.833,
            "eval_steps_per_second": 15.116,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0582,
            "grad_norm": 3.432698965072632,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.8583462238311768,
            "eval_matthews_correlation": 0.5832008422729765,
            "eval_runtime": 0.59,
            "eval_samples_per_second": 1767.823,
            "eval_steps_per_second": 15.254,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.0549,
            "grad_norm": 1.8607301712036133,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.9067322611808777,
            "eval_matthews_correlation": 0.572700939299986,
            "eval_runtime": 0.5269,
            "eval_samples_per_second": 1979.474,
            "eval_steps_per_second": 17.081,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.0491,
            "grad_norm": 0.9326911568641663,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.9731844067573547,
            "eval_matthews_correlation": 0.5854419516220256,
            "eval_runtime": 0.5317,
            "eval_samples_per_second": 1961.672,
            "eval_steps_per_second": 16.927,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.0445,
            "grad_norm": 3.9365882873535156,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.0013705492019653,
            "eval_matthews_correlation": 0.5931314229261737,
            "eval_runtime": 0.611,
            "eval_samples_per_second": 1706.902,
            "eval_steps_per_second": 14.729,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.0446,
            "grad_norm": 5.040862560272217,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.050592303276062,
            "eval_matthews_correlation": 0.5675517176765141,
            "eval_runtime": 0.5423,
            "eval_samples_per_second": 1923.456,
            "eval_steps_per_second": 16.597,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "train_runtime": 858.4826,
            "train_samples_per_second": 996.06,
            "train_steps_per_second": 7.804,
            "total_flos": 3.548458211554099e+16,
            "train_loss": 0.16952949092501685,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.9131035208702087,
            "eval_matthews_correlation": 0.5675682416159784,
            "eval_runtime": 0.6775,
            "eval_samples_per_second": 1539.457,
            "eval_steps_per_second": 13.284,
            "epoch": 62.6865671641791,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 858.4826,
        "trainable_params_count": 0.296522,
        "memory_allocated": [
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496
        ],
        "memory_reserved": [
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336
        ]
    },
    "variant": "lora"
}