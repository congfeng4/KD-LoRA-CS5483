{
    "eval_loss": 0.7028113603591919,
    "eval_matthews_correlation": 0.6089852308846828,
    "eval_runtime": 0.2126,
    "eval_samples_per_second": 4905.465,
    "eval_steps_per_second": 42.329,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.6304,
            "grad_norm": 0.6232895851135254,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5689544677734375,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2487,
            "eval_samples_per_second": 4193.311,
            "eval_steps_per_second": 36.184,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4589,
            "grad_norm": 2.366598129272461,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4982687830924988,
            "eval_matthews_correlation": 0.4860627149832655,
            "eval_runtime": 0.2194,
            "eval_samples_per_second": 4752.941,
            "eval_steps_per_second": 41.013,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3792,
            "grad_norm": 2.328573703765869,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.45524895191192627,
            "eval_matthews_correlation": 0.5551439282323715,
            "eval_runtime": 0.238,
            "eval_samples_per_second": 4381.696,
            "eval_steps_per_second": 37.809,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3254,
            "grad_norm": 4.951897621154785,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4784140884876251,
            "eval_matthews_correlation": 0.5727969336224868,
            "eval_runtime": 0.2885,
            "eval_samples_per_second": 3615.788,
            "eval_steps_per_second": 31.2,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2827,
            "grad_norm": 2.712204694747925,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5093153715133667,
            "eval_matthews_correlation": 0.5815775806078913,
            "eval_runtime": 0.2879,
            "eval_samples_per_second": 3622.972,
            "eval_steps_per_second": 31.262,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2428,
            "grad_norm": 2.633763074874878,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5078660845756531,
            "eval_matthews_correlation": 0.5753593483598531,
            "eval_runtime": 0.2734,
            "eval_samples_per_second": 3814.606,
            "eval_steps_per_second": 32.916,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2152,
            "grad_norm": 3.030470609664917,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5430733561515808,
            "eval_matthews_correlation": 0.5960380981891474,
            "eval_runtime": 0.3261,
            "eval_samples_per_second": 3198.374,
            "eval_steps_per_second": 27.599,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1913,
            "grad_norm": 3.2246150970458984,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5741764903068542,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.2077,
            "eval_samples_per_second": 5022.45,
            "eval_steps_per_second": 43.338,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1737,
            "grad_norm": 3.5395236015319824,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5823605060577393,
            "eval_matthews_correlation": 0.5924834238001306,
            "eval_runtime": 0.4494,
            "eval_samples_per_second": 2321.034,
            "eval_steps_per_second": 20.028,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1597,
            "grad_norm": 5.0881781578063965,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6259880065917969,
            "eval_matthews_correlation": 0.5888632696966735,
            "eval_runtime": 0.2539,
            "eval_samples_per_second": 4108.409,
            "eval_steps_per_second": 35.451,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.141,
            "grad_norm": 4.402832508087158,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6633612513542175,
            "eval_matthews_correlation": 0.5981135922805256,
            "eval_runtime": 0.2448,
            "eval_samples_per_second": 4260.433,
            "eval_steps_per_second": 36.763,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1284,
            "grad_norm": 2.2756969928741455,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.7028113603591919,
            "eval_matthews_correlation": 0.6089852308846828,
            "eval_runtime": 0.2486,
            "eval_samples_per_second": 4195.092,
            "eval_steps_per_second": 36.199,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1173,
            "grad_norm": 4.750125885009766,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.8013139367103577,
            "eval_matthews_correlation": 0.585467058423594,
            "eval_runtime": 0.2145,
            "eval_samples_per_second": 4863.44,
            "eval_steps_per_second": 41.966,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1101,
            "grad_norm": 1.5072505474090576,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.7629414200782776,
            "eval_matthews_correlation": 0.6033168402681877,
            "eval_runtime": 0.2157,
            "eval_samples_per_second": 4835.309,
            "eval_steps_per_second": 41.724,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1043,
            "grad_norm": 3.8487234115600586,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.7964671850204468,
            "eval_matthews_correlation": 0.5831040124744803,
            "eval_runtime": 0.4157,
            "eval_samples_per_second": 2509.178,
            "eval_steps_per_second": 21.652,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0988,
            "grad_norm": 2.399942636489868,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.7739136219024658,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.2525,
            "eval_samples_per_second": 4130.349,
            "eval_steps_per_second": 35.641,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0866,
            "grad_norm": 2.8071329593658447,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.8546872138977051,
            "eval_matthews_correlation": 0.5834463254140851,
            "eval_runtime": 0.2021,
            "eval_samples_per_second": 5159.557,
            "eval_steps_per_second": 44.522,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 332.8893,
            "train_samples_per_second": 2568.722,
            "train_steps_per_second": 20.127,
            "total_flos": 2.8922963008946176e+16,
            "train_loss": 0.2262136094710406,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.7028113603591919,
            "eval_matthews_correlation": 0.6089852308846828,
            "eval_runtime": 0.2126,
            "eval_samples_per_second": 4905.465,
            "eval_steps_per_second": 42.329,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 332.8893,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}