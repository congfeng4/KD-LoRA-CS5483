{
    "eval_loss": 0.4439465403556824,
    "eval_matthews_correlation": 0.5803450615832939,
    "eval_runtime": 0.3644,
    "eval_samples_per_second": 2862.498,
    "eval_steps_per_second": 24.7,
    "epoch": 74.6268656716418,
    "log_history": [
        {
            "loss": 1.8808,
            "grad_norm": 0.3152298927307129,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.526261568069458,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3292,
            "eval_samples_per_second": 3168.564,
            "eval_steps_per_second": 27.341,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.866,
            "grad_norm": 1.1989588737487793,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6085155606269836,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4571,
            "eval_samples_per_second": 2281.719,
            "eval_steps_per_second": 19.689,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5905,
            "grad_norm": 0.5464520454406738,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5861421823501587,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5338,
            "eval_samples_per_second": 1954.079,
            "eval_steps_per_second": 16.862,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5204,
            "grad_norm": 1.1546969413757324,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5014116764068604,
            "eval_matthews_correlation": 0.4008640567771217,
            "eval_runtime": 0.3879,
            "eval_samples_per_second": 2688.564,
            "eval_steps_per_second": 23.199,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4662,
            "grad_norm": 1.3771772384643555,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5055316686630249,
            "eval_matthews_correlation": 0.4279924761510222,
            "eval_runtime": 0.4262,
            "eval_samples_per_second": 2447.473,
            "eval_steps_per_second": 21.119,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4403,
            "grad_norm": 0.7587952613830566,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4506753385066986,
            "eval_matthews_correlation": 0.5074384885743003,
            "eval_runtime": 0.3264,
            "eval_samples_per_second": 3195.825,
            "eval_steps_per_second": 27.577,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4227,
            "grad_norm": 0.9216834306716919,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4606424570083618,
            "eval_matthews_correlation": 0.512703445942988,
            "eval_runtime": 0.6001,
            "eval_samples_per_second": 1737.948,
            "eval_steps_per_second": 14.997,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4085,
            "grad_norm": 0.6226375699043274,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.45859861373901367,
            "eval_matthews_correlation": 0.5289009468502264,
            "eval_runtime": 0.441,
            "eval_samples_per_second": 2364.989,
            "eval_steps_per_second": 20.407,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3975,
            "grad_norm": 0.8728654384613037,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4416475296020508,
            "eval_matthews_correlation": 0.5442924840114824,
            "eval_runtime": 0.4215,
            "eval_samples_per_second": 2474.548,
            "eval_steps_per_second": 21.353,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3893,
            "grad_norm": 1.2772506475448608,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.442974328994751,
            "eval_matthews_correlation": 0.5444111532535151,
            "eval_runtime": 0.4516,
            "eval_samples_per_second": 2309.517,
            "eval_steps_per_second": 19.929,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3845,
            "grad_norm": 0.6324074268341064,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.43081778287887573,
            "eval_matthews_correlation": 0.5575034099514093,
            "eval_runtime": 0.3686,
            "eval_samples_per_second": 2829.303,
            "eval_steps_per_second": 24.414,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3779,
            "grad_norm": 0.7319478988647461,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.44593682885169983,
            "eval_matthews_correlation": 0.547014428196921,
            "eval_runtime": 0.4727,
            "eval_samples_per_second": 2206.379,
            "eval_steps_per_second": 19.039,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3674,
            "grad_norm": 1.565730094909668,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.45109832286834717,
            "eval_matthews_correlation": 0.549825623859248,
            "eval_runtime": 0.3444,
            "eval_samples_per_second": 3028.661,
            "eval_steps_per_second": 26.134,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.365,
            "grad_norm": 0.8822433352470398,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4806593358516693,
            "eval_matthews_correlation": 0.5479049761018383,
            "eval_runtime": 0.4184,
            "eval_samples_per_second": 2492.858,
            "eval_steps_per_second": 21.511,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3638,
            "grad_norm": 0.6986396908760071,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.48781251907348633,
            "eval_matthews_correlation": 0.5479049761018383,
            "eval_runtime": 0.4873,
            "eval_samples_per_second": 2140.223,
            "eval_steps_per_second": 18.468,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3574,
            "grad_norm": 1.0589710474014282,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.46821361780166626,
            "eval_matthews_correlation": 0.5633880074988443,
            "eval_runtime": 0.37,
            "eval_samples_per_second": 2819.131,
            "eval_steps_per_second": 24.326,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3498,
            "grad_norm": 1.134639024734497,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.47618380188941956,
            "eval_matthews_correlation": 0.5683149665802574,
            "eval_runtime": 0.5539,
            "eval_samples_per_second": 1883.027,
            "eval_steps_per_second": 16.249,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3456,
            "grad_norm": 0.7636840343475342,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.47071415185928345,
            "eval_matthews_correlation": 0.5651092792103851,
            "eval_runtime": 0.3683,
            "eval_samples_per_second": 2831.912,
            "eval_steps_per_second": 24.436,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3416,
            "grad_norm": 1.170639157295227,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.43011149764060974,
            "eval_matthews_correlation": 0.5752615459764325,
            "eval_runtime": 0.3533,
            "eval_samples_per_second": 2952.117,
            "eval_steps_per_second": 25.474,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3427,
            "grad_norm": 1.6512349843978882,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.4439465403556824,
            "eval_matthews_correlation": 0.5803450615832939,
            "eval_runtime": 0.4701,
            "eval_samples_per_second": 2218.759,
            "eval_steps_per_second": 19.146,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3385,
            "grad_norm": 0.8782082796096802,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.49621301889419556,
            "eval_matthews_correlation": 0.5787058868715402,
            "eval_runtime": 0.6003,
            "eval_samples_per_second": 1737.437,
            "eval_steps_per_second": 14.992,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3349,
            "grad_norm": 1.7627842426300049,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.49415701627731323,
            "eval_matthews_correlation": 0.5736173416598102,
            "eval_runtime": 0.4448,
            "eval_samples_per_second": 2345.087,
            "eval_steps_per_second": 20.236,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.333,
            "grad_norm": 2.000972270965576,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.47265350818634033,
            "eval_matthews_correlation": 0.5728803433047456,
            "eval_runtime": 0.3923,
            "eval_samples_per_second": 2658.698,
            "eval_steps_per_second": 22.942,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.3277,
            "grad_norm": 1.341689109802246,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.46113908290863037,
            "eval_matthews_correlation": 0.5649812173768567,
            "eval_runtime": 0.3794,
            "eval_samples_per_second": 2749.178,
            "eval_steps_per_second": 23.723,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.3261,
            "grad_norm": 1.4342172145843506,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4640386700630188,
            "eval_matthews_correlation": 0.5727393770243,
            "eval_runtime": 0.3209,
            "eval_samples_per_second": 3250.176,
            "eval_steps_per_second": 28.046,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "train_runtime": 587.4747,
            "train_samples_per_second": 1455.552,
            "train_steps_per_second": 11.405,
            "total_flos": 4.2678922248192e+16,
            "train_loss": 0.46552725830078123,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4439465403556824,
            "eval_matthews_correlation": 0.5803450615832939,
            "eval_runtime": 0.3644,
            "eval_samples_per_second": 2862.498,
            "eval_steps_per_second": 24.7,
            "epoch": 74.6268656716418,
            "step": 5000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 587.4747,
        "trainable_params_count": 1.182338,
        "memory_allocated": [
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}