{
    "eval_loss": 0.5994023084640503,
    "eval_matthews_correlation": 0.6380902412628672,
    "eval_runtime": 0.3165,
    "eval_samples_per_second": 3295.811,
    "eval_steps_per_second": 28.439,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 0.6309,
            "grad_norm": 0.661441445350647,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5678946375846863,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.264,
            "eval_samples_per_second": 3951.251,
            "eval_steps_per_second": 34.095,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4553,
            "grad_norm": 1.6339027881622314,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.47184768319129944,
            "eval_matthews_correlation": 0.5339501336198276,
            "eval_runtime": 0.2746,
            "eval_samples_per_second": 3797.892,
            "eval_steps_per_second": 32.772,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3917,
            "grad_norm": 1.714577555656433,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.424261212348938,
            "eval_matthews_correlation": 0.5512772054945002,
            "eval_runtime": 0.5027,
            "eval_samples_per_second": 2074.973,
            "eval_steps_per_second": 17.905,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3584,
            "grad_norm": 3.0258796215057373,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4729633331298828,
            "eval_matthews_correlation": 0.5625095574827523,
            "eval_runtime": 0.5273,
            "eval_samples_per_second": 1978.005,
            "eval_steps_per_second": 17.068,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3289,
            "grad_norm": 2.0754129886627197,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.46093809604644775,
            "eval_matthews_correlation": 0.5551439282323715,
            "eval_runtime": 0.3143,
            "eval_samples_per_second": 3318.666,
            "eval_steps_per_second": 28.637,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2974,
            "grad_norm": 1.6360539197921753,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4392528235912323,
            "eval_matthews_correlation": 0.5854419516220256,
            "eval_runtime": 0.3235,
            "eval_samples_per_second": 3224.031,
            "eval_steps_per_second": 27.82,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2704,
            "grad_norm": 2.809279680252075,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4981738030910492,
            "eval_matthews_correlation": 0.5879880120258366,
            "eval_runtime": 0.3372,
            "eval_samples_per_second": 3093.149,
            "eval_steps_per_second": 26.691,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2468,
            "grad_norm": 2.7973995208740234,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5788851976394653,
            "eval_matthews_correlation": 0.5676767849560254,
            "eval_runtime": 0.3527,
            "eval_samples_per_second": 2956.964,
            "eval_steps_per_second": 25.516,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2286,
            "grad_norm": 2.2048726081848145,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4858894944190979,
            "eval_matthews_correlation": 0.59561622728651,
            "eval_runtime": 0.2677,
            "eval_samples_per_second": 3896.25,
            "eval_steps_per_second": 33.621,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2117,
            "grad_norm": 2.4180541038513184,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5122804045677185,
            "eval_matthews_correlation": 0.598349211554662,
            "eval_runtime": 0.3098,
            "eval_samples_per_second": 3366.295,
            "eval_steps_per_second": 29.048,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1944,
            "grad_norm": 2.0018601417541504,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4981229603290558,
            "eval_matthews_correlation": 0.6093514522222457,
            "eval_runtime": 0.3479,
            "eval_samples_per_second": 2997.754,
            "eval_steps_per_second": 25.867,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1783,
            "grad_norm": 3.7110328674316406,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5361608862876892,
            "eval_matthews_correlation": 0.5909585115904812,
            "eval_runtime": 0.2525,
            "eval_samples_per_second": 4130.766,
            "eval_steps_per_second": 35.644,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1651,
            "grad_norm": 2.517345428466797,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.5994023084640503,
            "eval_matthews_correlation": 0.6380902412628672,
            "eval_runtime": 0.5348,
            "eval_samples_per_second": 1950.308,
            "eval_steps_per_second": 16.829,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1555,
            "grad_norm": 1.7196305990219116,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.6443584561347961,
            "eval_matthews_correlation": 0.6058664045311455,
            "eval_runtime": 0.5339,
            "eval_samples_per_second": 1953.435,
            "eval_steps_per_second": 16.856,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1473,
            "grad_norm": 1.7595155239105225,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.662777841091156,
            "eval_matthews_correlation": 0.5913553018113701,
            "eval_runtime": 0.5756,
            "eval_samples_per_second": 1811.991,
            "eval_steps_per_second": 15.636,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1416,
            "grad_norm": 3.3204588890075684,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.6050102114677429,
            "eval_matthews_correlation": 0.6082315244746964,
            "eval_runtime": 0.2456,
            "eval_samples_per_second": 4246.533,
            "eval_steps_per_second": 36.643,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1281,
            "grad_norm": 3.0214896202087402,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.6586971282958984,
            "eval_matthews_correlation": 0.6007621359415751,
            "eval_runtime": 0.3521,
            "eval_samples_per_second": 2962.232,
            "eval_steps_per_second": 25.561,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1225,
            "grad_norm": 2.551640748977661,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.6835983395576477,
            "eval_matthews_correlation": 0.605723479357827,
            "eval_runtime": 0.3419,
            "eval_samples_per_second": 3051.02,
            "eval_steps_per_second": 26.327,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 499.0756,
            "train_samples_per_second": 1713.368,
            "train_steps_per_second": 13.425,
            "total_flos": 3.0630836755759104e+16,
            "train_loss": 0.25849052482181123,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.5994023084640503,
            "eval_matthews_correlation": 0.6380902412628672,
            "eval_runtime": 0.3165,
            "eval_samples_per_second": 3295.811,
            "eval_steps_per_second": 28.439,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 499.0756,
        "trainable_params_count": 0.905474,
        "memory_allocated": [
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024
        ],
        "memory_reserved": [
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328
        ]
    },
    "variant": "lora"
}