{
    "eval_loss": 0.5738220810890198,
    "eval_matthews_correlation": 0.5934998758283692,
    "eval_runtime": 0.3731,
    "eval_samples_per_second": 2795.411,
    "eval_steps_per_second": 24.121,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.6089,
            "grad_norm": 2.517223834991455,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5106683969497681,
            "eval_matthews_correlation": 0.4039586817617069,
            "eval_runtime": 0.3586,
            "eval_samples_per_second": 2908.727,
            "eval_steps_per_second": 25.099,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4302,
            "grad_norm": 4.543735980987549,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.5289708375930786,
            "eval_matthews_correlation": 0.4965059450357497,
            "eval_runtime": 0.5436,
            "eval_samples_per_second": 1918.82,
            "eval_steps_per_second": 16.557,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3793,
            "grad_norm": 2.8716652393341064,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.444225013256073,
            "eval_matthews_correlation": 0.5554433905906734,
            "eval_runtime": 0.4294,
            "eval_samples_per_second": 2429.088,
            "eval_steps_per_second": 20.96,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3387,
            "grad_norm": 3.2473576068878174,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4568861126899719,
            "eval_matthews_correlation": 0.5598743897878832,
            "eval_runtime": 0.384,
            "eval_samples_per_second": 2716.054,
            "eval_steps_per_second": 23.437,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.289,
            "grad_norm": 3.713383913040161,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4460431933403015,
            "eval_matthews_correlation": 0.5825149539847667,
            "eval_runtime": 0.3713,
            "eval_samples_per_second": 2808.775,
            "eval_steps_per_second": 24.237,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2427,
            "grad_norm": 2.7436015605926514,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.47855278849601746,
            "eval_matthews_correlation": 0.6256673855627156,
            "eval_runtime": 0.403,
            "eval_samples_per_second": 2588.0,
            "eval_steps_per_second": 22.332,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2112,
            "grad_norm": 7.675168037414551,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4456844925880432,
            "eval_matthews_correlation": 0.6465665473508779,
            "eval_runtime": 0.368,
            "eval_samples_per_second": 2833.945,
            "eval_steps_per_second": 24.454,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1859,
            "grad_norm": 4.308790683746338,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.548588216304779,
            "eval_matthews_correlation": 0.6081727293932068,
            "eval_runtime": 0.3934,
            "eval_samples_per_second": 2651.056,
            "eval_steps_per_second": 22.876,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1643,
            "grad_norm": 3.8574581146240234,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5876662731170654,
            "eval_matthews_correlation": 0.6207194911624668,
            "eval_runtime": 0.387,
            "eval_samples_per_second": 2695.405,
            "eval_steps_per_second": 23.259,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.15,
            "grad_norm": 6.079231262207031,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5946953892707825,
            "eval_matthews_correlation": 0.6060362102181063,
            "eval_runtime": 0.3972,
            "eval_samples_per_second": 2626.194,
            "eval_steps_per_second": 22.661,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1285,
            "grad_norm": 3.129169225692749,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.563742458820343,
            "eval_matthews_correlation": 0.6324452383009407,
            "eval_runtime": 0.356,
            "eval_samples_per_second": 2929.54,
            "eval_steps_per_second": 25.279,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1179,
            "grad_norm": 3.8134515285491943,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6265763640403748,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.3681,
            "eval_samples_per_second": 2833.488,
            "eval_steps_per_second": 24.45,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 405.0468,
            "train_samples_per_second": 2111.114,
            "train_steps_per_second": 16.541,
            "total_flos": 2.041624300565299e+16,
            "train_loss": 0.27054079532623293,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5738220810890198,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.3731,
            "eval_samples_per_second": 2795.411,
            "eval_steps_per_second": 24.121,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 405.0468,
        "trainable_params_count": 0.887114,
        "memory_allocated": [
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856
        ],
        "memory_reserved": [
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808
        ]
    },
    "variant": "lora"
}