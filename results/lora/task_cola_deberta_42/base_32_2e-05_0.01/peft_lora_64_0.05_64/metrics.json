{
    "eval_loss": 0.6564249992370605,
    "eval_matthews_correlation": 0.702858215354294,
    "eval_runtime": 0.5424,
    "eval_samples_per_second": 1923.017,
    "eval_steps_per_second": 16.594,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 0.5959,
            "grad_norm": 0.7130112051963806,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5013195276260376,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.7012,
            "eval_samples_per_second": 1487.553,
            "eval_steps_per_second": 12.836,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3553,
            "grad_norm": 0.6173160076141357,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.3671441078186035,
            "eval_matthews_correlation": 0.6402133529850765,
            "eval_runtime": 0.5716,
            "eval_samples_per_second": 1824.674,
            "eval_steps_per_second": 15.745,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.2829,
            "grad_norm": 0.6947728395462036,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.38273948431015015,
            "eval_matthews_correlation": 0.6511813794482872,
            "eval_runtime": 0.7303,
            "eval_samples_per_second": 1428.149,
            "eval_steps_per_second": 12.323,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2236,
            "grad_norm": 0.7419483661651611,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4318145513534546,
            "eval_matthews_correlation": 0.6504099683042353,
            "eval_runtime": 0.6694,
            "eval_samples_per_second": 1558.146,
            "eval_steps_per_second": 13.445,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.1715,
            "grad_norm": 0.9555373191833496,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4435015320777893,
            "eval_matthews_correlation": 0.6635559502590729,
            "eval_runtime": 0.6004,
            "eval_samples_per_second": 1737.202,
            "eval_steps_per_second": 14.99,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.1281,
            "grad_norm": 0.7926658987998962,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5420101881027222,
            "eval_matthews_correlation": 0.6748840055065489,
            "eval_runtime": 0.6404,
            "eval_samples_per_second": 1628.652,
            "eval_steps_per_second": 14.054,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1019,
            "grad_norm": 1.1549617052078247,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.553446888923645,
            "eval_matthews_correlation": 0.6750024002589107,
            "eval_runtime": 0.7187,
            "eval_samples_per_second": 1451.142,
            "eval_steps_per_second": 12.522,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.081,
            "grad_norm": 0.7094751000404358,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6262646913528442,
            "eval_matthews_correlation": 0.6775228594274805,
            "eval_runtime": 0.6127,
            "eval_samples_per_second": 1702.228,
            "eval_steps_per_second": 14.688,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0663,
            "grad_norm": 1.3523480892181396,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5888861417770386,
            "eval_matthews_correlation": 0.6919341236751171,
            "eval_runtime": 0.642,
            "eval_samples_per_second": 1624.629,
            "eval_steps_per_second": 14.019,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0574,
            "grad_norm": 0.6487995982170105,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5966443419456482,
            "eval_matthews_correlation": 0.695145083540597,
            "eval_runtime": 0.571,
            "eval_samples_per_second": 1826.665,
            "eval_steps_per_second": 15.762,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0492,
            "grad_norm": 0.359335333108902,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6382789611816406,
            "eval_matthews_correlation": 0.6944980407823975,
            "eval_runtime": 0.5939,
            "eval_samples_per_second": 1756.118,
            "eval_steps_per_second": 15.153,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0432,
            "grad_norm": 0.14695659279823303,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6259123682975769,
            "eval_matthews_correlation": 0.6949822920174475,
            "eval_runtime": 0.7565,
            "eval_samples_per_second": 1378.644,
            "eval_steps_per_second": 11.896,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0396,
            "grad_norm": 0.3347187340259552,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.6564249992370605,
            "eval_matthews_correlation": 0.702858215354294,
            "eval_runtime": 0.6795,
            "eval_samples_per_second": 1534.889,
            "eval_steps_per_second": 13.244,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.032,
            "grad_norm": 0.48389923572540283,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.718625009059906,
            "eval_matthews_correlation": 0.6904293388015901,
            "eval_runtime": 0.5764,
            "eval_samples_per_second": 1809.526,
            "eval_steps_per_second": 15.614,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0328,
            "grad_norm": 0.2642152011394501,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.697918713092804,
            "eval_matthews_correlation": 0.6825085570402176,
            "eval_runtime": 0.6288,
            "eval_samples_per_second": 1658.711,
            "eval_steps_per_second": 14.313,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0271,
            "grad_norm": 0.2514272630214691,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.709038496017456,
            "eval_matthews_correlation": 0.6809978493235761,
            "eval_runtime": 0.6099,
            "eval_samples_per_second": 1710.172,
            "eval_steps_per_second": 14.757,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0269,
            "grad_norm": 0.42284196615219116,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.7673420906066895,
            "eval_matthews_correlation": 0.6850707271866645,
            "eval_runtime": 0.6795,
            "eval_samples_per_second": 1534.959,
            "eval_steps_per_second": 13.245,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.0231,
            "grad_norm": 0.15552972257137299,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.836999237537384,
            "eval_matthews_correlation": 0.6803092970928678,
            "eval_runtime": 0.5759,
            "eval_samples_per_second": 1811.056,
            "eval_steps_per_second": 15.628,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 821.9665,
            "train_samples_per_second": 1040.31,
            "train_steps_per_second": 8.151,
            "total_flos": 3.114642288358195e+16,
            "train_loss": 0.12987347099516128,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.6564249992370605,
            "eval_matthews_correlation": 0.702858215354294,
            "eval_runtime": 0.5424,
            "eval_samples_per_second": 1923.017,
            "eval_steps_per_second": 16.594,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 64,
        "lora_alpha": 64,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 821.9665,
        "trainable_params_count": 2.360834,
        "memory_allocated": [
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376,
            794.405376
        ],
        "memory_reserved": [
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752,
            4825.546752
        ]
    },
    "variant": "lora"
}