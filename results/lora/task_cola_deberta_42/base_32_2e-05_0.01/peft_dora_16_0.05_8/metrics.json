{
    "eval_loss": 0.495175302028656,
    "eval_matthews_correlation": 0.6834570134701579,
    "eval_runtime": 0.3652,
    "eval_samples_per_second": 2856.288,
    "eval_steps_per_second": 24.647,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.6266,
            "grad_norm": 0.40733957290649414,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5831674933433533,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.6691,
            "eval_samples_per_second": 1558.722,
            "eval_steps_per_second": 13.45,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4159,
            "grad_norm": 0.8230387568473816,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.37633171677589417,
            "eval_matthews_correlation": 0.606823117358914,
            "eval_runtime": 0.6059,
            "eval_samples_per_second": 1721.274,
            "eval_steps_per_second": 14.853,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3225,
            "grad_norm": 0.7767841219902039,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.37887507677078247,
            "eval_matthews_correlation": 0.645568857149829,
            "eval_runtime": 0.6644,
            "eval_samples_per_second": 1569.775,
            "eval_steps_per_second": 13.546,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2742,
            "grad_norm": 1.4077720642089844,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.38925617933273315,
            "eval_matthews_correlation": 0.6504099683042353,
            "eval_runtime": 0.4595,
            "eval_samples_per_second": 2269.951,
            "eval_steps_per_second": 19.587,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2408,
            "grad_norm": 1.0930110216140747,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3805263340473175,
            "eval_matthews_correlation": 0.6581805893879898,
            "eval_runtime": 0.5049,
            "eval_samples_per_second": 2065.745,
            "eval_steps_per_second": 17.825,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2089,
            "grad_norm": 1.3501685857772827,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.45725730061531067,
            "eval_matthews_correlation": 0.6355999809484597,
            "eval_runtime": 0.6177,
            "eval_samples_per_second": 1688.406,
            "eval_steps_per_second": 14.569,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1917,
            "grad_norm": 1.0588749647140503,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4135083258152008,
            "eval_matthews_correlation": 0.662756458916661,
            "eval_runtime": 0.6152,
            "eval_samples_per_second": 1695.514,
            "eval_steps_per_second": 14.631,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1728,
            "grad_norm": 1.5957651138305664,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.48126184940338135,
            "eval_matthews_correlation": 0.6553265674254026,
            "eval_runtime": 0.4926,
            "eval_samples_per_second": 2117.371,
            "eval_steps_per_second": 18.271,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1514,
            "grad_norm": 1.433374047279358,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.47660285234451294,
            "eval_matthews_correlation": 0.6651338996433138,
            "eval_runtime": 0.4317,
            "eval_samples_per_second": 2416.182,
            "eval_steps_per_second": 20.849,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1408,
            "grad_norm": 1.0287435054779053,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.44277670979499817,
            "eval_matthews_correlation": 0.6757073194553476,
            "eval_runtime": 0.4452,
            "eval_samples_per_second": 2342.826,
            "eval_steps_per_second": 20.216,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1303,
            "grad_norm": 1.6204484701156616,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.49934980273246765,
            "eval_matthews_correlation": 0.6774456729394701,
            "eval_runtime": 0.4339,
            "eval_samples_per_second": 2403.516,
            "eval_steps_per_second": 20.74,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1183,
            "grad_norm": 1.604555606842041,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.495175302028656,
            "eval_matthews_correlation": 0.6834570134701579,
            "eval_runtime": 0.3896,
            "eval_samples_per_second": 2677.332,
            "eval_steps_per_second": 23.103,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1097,
            "grad_norm": 1.8943417072296143,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.5073015689849854,
            "eval_matthews_correlation": 0.6806212342778284,
            "eval_runtime": 0.3609,
            "eval_samples_per_second": 2889.984,
            "eval_steps_per_second": 24.938,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0992,
            "grad_norm": 0.7713932394981384,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.5413965582847595,
            "eval_matthews_correlation": 0.6662078251307878,
            "eval_runtime": 0.4626,
            "eval_samples_per_second": 2254.805,
            "eval_steps_per_second": 19.457,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0929,
            "grad_norm": 1.9192818403244019,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.5519760847091675,
            "eval_matthews_correlation": 0.6635559502590729,
            "eval_runtime": 0.6268,
            "eval_samples_per_second": 1663.906,
            "eval_steps_per_second": 14.358,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0882,
            "grad_norm": 1.8741979598999023,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.5542707443237305,
            "eval_matthews_correlation": 0.6732477678270925,
            "eval_runtime": 0.6225,
            "eval_samples_per_second": 1675.407,
            "eval_steps_per_second": 14.457,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0856,
            "grad_norm": 2.1560304164886475,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.5840556621551514,
            "eval_matthews_correlation": 0.6729499730568552,
            "eval_runtime": 0.4127,
            "eval_samples_per_second": 2527.213,
            "eval_steps_per_second": 21.807,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 853.3991,
            "train_samples_per_second": 1001.993,
            "train_steps_per_second": 7.851,
            "total_flos": 2.873224015432909e+16,
            "train_loss": 0.2041063190908993,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.495175302028656,
            "eval_matthews_correlation": 0.6834570134701579,
            "eval_runtime": 0.3652,
            "eval_samples_per_second": 2856.288,
            "eval_steps_per_second": 24.647,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 853.3991,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824,
            762.69824
        ],
        "memory_reserved": [
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616,
            5154.799616
        ]
    },
    "variant": "lora"
}