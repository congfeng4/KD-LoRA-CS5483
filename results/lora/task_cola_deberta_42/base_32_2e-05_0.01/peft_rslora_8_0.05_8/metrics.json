{
    "eval_loss": 0.46549516916275024,
    "eval_matthews_correlation": 0.6857135940625831,
    "eval_runtime": 0.6314,
    "eval_samples_per_second": 1652.015,
    "eval_steps_per_second": 14.255,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.6234,
            "grad_norm": 0.5387265682220459,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5586963891983032,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.7453,
            "eval_samples_per_second": 1399.524,
            "eval_steps_per_second": 12.076,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.398,
            "grad_norm": 0.8908100128173828,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.3697333037853241,
            "eval_matthews_correlation": 0.6290963746390851,
            "eval_runtime": 0.5918,
            "eval_samples_per_second": 1762.325,
            "eval_steps_per_second": 15.207,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3156,
            "grad_norm": 0.9279924631118774,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.38938280940055847,
            "eval_matthews_correlation": 0.6381004342223774,
            "eval_runtime": 0.7063,
            "eval_samples_per_second": 1476.719,
            "eval_steps_per_second": 12.743,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2665,
            "grad_norm": 1.54843270778656,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.40492039918899536,
            "eval_matthews_correlation": 0.6480906778081594,
            "eval_runtime": 0.6936,
            "eval_samples_per_second": 1503.821,
            "eval_steps_per_second": 12.976,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2318,
            "grad_norm": 1.452026605606079,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.387203574180603,
            "eval_matthews_correlation": 0.6660250068114778,
            "eval_runtime": 0.6519,
            "eval_samples_per_second": 1599.943,
            "eval_steps_per_second": 13.806,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.198,
            "grad_norm": 1.6754690408706665,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4850061237812042,
            "eval_matthews_correlation": 0.6405767700619004,
            "eval_runtime": 0.7403,
            "eval_samples_per_second": 1408.833,
            "eval_steps_per_second": 12.157,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1811,
            "grad_norm": 1.2983838319778442,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.42819952964782715,
            "eval_matthews_correlation": 0.6679153499290561,
            "eval_runtime": 0.5836,
            "eval_samples_per_second": 1787.314,
            "eval_steps_per_second": 15.423,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1598,
            "grad_norm": 1.9550511837005615,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5189169645309448,
            "eval_matthews_correlation": 0.6479601425074826,
            "eval_runtime": 0.5369,
            "eval_samples_per_second": 1942.497,
            "eval_steps_per_second": 16.762,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1387,
            "grad_norm": 1.7826510667800903,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.49168890714645386,
            "eval_matthews_correlation": 0.6725572081041828,
            "eval_runtime": 0.7157,
            "eval_samples_per_second": 1457.306,
            "eval_steps_per_second": 12.575,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1259,
            "grad_norm": 1.1381806135177612,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.46549516916275024,
            "eval_matthews_correlation": 0.6857135940625831,
            "eval_runtime": 0.5757,
            "eval_samples_per_second": 1811.658,
            "eval_steps_per_second": 15.633,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.117,
            "grad_norm": 1.7052727937698364,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5194888710975647,
            "eval_matthews_correlation": 0.6800639102004192,
            "eval_runtime": 0.8361,
            "eval_samples_per_second": 1247.516,
            "eval_steps_per_second": 10.765,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1051,
            "grad_norm": 2.0155580043792725,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5335759520530701,
            "eval_matthews_correlation": 0.6780033342159347,
            "eval_runtime": 0.637,
            "eval_samples_per_second": 1637.326,
            "eval_steps_per_second": 14.128,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0957,
            "grad_norm": 1.5013927221298218,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.5431914329528809,
            "eval_matthews_correlation": 0.6777292650485364,
            "eval_runtime": 0.5776,
            "eval_samples_per_second": 1805.72,
            "eval_steps_per_second": 15.581,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0838,
            "grad_norm": 0.8451706171035767,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.5815376043319702,
            "eval_matthews_correlation": 0.6758829936616813,
            "eval_runtime": 0.6673,
            "eval_samples_per_second": 1562.907,
            "eval_steps_per_second": 13.486,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0786,
            "grad_norm": 1.5312016010284424,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.628039538860321,
            "eval_matthews_correlation": 0.6773861896003048,
            "eval_runtime": 0.5617,
            "eval_samples_per_second": 1856.817,
            "eval_steps_per_second": 16.022,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 569.8589,
            "train_samples_per_second": 1500.547,
            "train_steps_per_second": 11.757,
            "total_flos": 2.534654078877696e+16,
            "train_loss": 0.2079462521870931,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.46549516916275024,
            "eval_matthews_correlation": 0.6857135940625831,
            "eval_runtime": 0.6314,
            "eval_samples_per_second": 1652.015,
            "eval_steps_per_second": 14.255,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 569.8589,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184,
            761.629184
        ],
        "memory_reserved": [
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232
        ]
    },
    "variant": "lora"
}