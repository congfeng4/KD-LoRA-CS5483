{
    "eval_loss": 0.47022631764411926,
    "eval_matthews_correlation": 0.6866109148734292,
    "eval_runtime": 0.6866,
    "eval_samples_per_second": 1519.081,
    "eval_steps_per_second": 13.108,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.6299,
            "grad_norm": 0.31200751662254333,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6050623655319214,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.899,
            "eval_samples_per_second": 1160.137,
            "eval_steps_per_second": 10.011,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4604,
            "grad_norm": 0.8632138967514038,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.39028865098953247,
            "eval_matthews_correlation": 0.6041033887691281,
            "eval_runtime": 0.7468,
            "eval_samples_per_second": 1396.57,
            "eval_steps_per_second": 12.051,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3363,
            "grad_norm": 0.582465648651123,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.37634626030921936,
            "eval_matthews_correlation": 0.6186174601668025,
            "eval_runtime": 0.83,
            "eval_samples_per_second": 1256.578,
            "eval_steps_per_second": 10.843,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2895,
            "grad_norm": 0.8720045685768127,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.3702043294906616,
            "eval_matthews_correlation": 0.6579771285992058,
            "eval_runtime": 0.8154,
            "eval_samples_per_second": 1279.066,
            "eval_steps_per_second": 11.037,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2603,
            "grad_norm": 0.765920102596283,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.3744763731956482,
            "eval_matthews_correlation": 0.6658582857909559,
            "eval_runtime": 0.9261,
            "eval_samples_per_second": 1126.193,
            "eval_steps_per_second": 9.718,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2314,
            "grad_norm": 0.8805361986160278,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4157664179801941,
            "eval_matthews_correlation": 0.6431581256935667,
            "eval_runtime": 0.7974,
            "eval_samples_per_second": 1307.951,
            "eval_steps_per_second": 11.286,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2145,
            "grad_norm": 0.7352678179740906,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.39386260509490967,
            "eval_matthews_correlation": 0.6726294020516,
            "eval_runtime": 0.7119,
            "eval_samples_per_second": 1465.154,
            "eval_steps_per_second": 12.643,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1984,
            "grad_norm": 1.1051404476165771,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.4622572064399719,
            "eval_matthews_correlation": 0.6602760042741034,
            "eval_runtime": 0.6675,
            "eval_samples_per_second": 1562.49,
            "eval_steps_per_second": 13.483,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.18,
            "grad_norm": 1.019647479057312,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4602237343788147,
            "eval_matthews_correlation": 0.6727191046782682,
            "eval_runtime": 0.7502,
            "eval_samples_per_second": 1390.325,
            "eval_steps_per_second": 11.997,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1688,
            "grad_norm": 1.0801361799240112,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.4195488691329956,
            "eval_matthews_correlation": 0.6841463068202717,
            "eval_runtime": 0.7199,
            "eval_samples_per_second": 1448.849,
            "eval_steps_per_second": 12.502,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.158,
            "grad_norm": 1.064822793006897,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4809344708919525,
            "eval_matthews_correlation": 0.6726294020516,
            "eval_runtime": 0.7846,
            "eval_samples_per_second": 1329.418,
            "eval_steps_per_second": 11.471,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1451,
            "grad_norm": 1.389251708984375,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.47022631764411926,
            "eval_matthews_correlation": 0.6866109148734292,
            "eval_runtime": 0.8115,
            "eval_samples_per_second": 1285.248,
            "eval_steps_per_second": 11.09,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1381,
            "grad_norm": 1.377947449684143,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.47797802090644836,
            "eval_matthews_correlation": 0.6684922014382504,
            "eval_runtime": 0.7497,
            "eval_samples_per_second": 1391.312,
            "eval_steps_per_second": 12.006,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1277,
            "grad_norm": 1.1122865676879883,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.5065639615058899,
            "eval_matthews_correlation": 0.6732477678270925,
            "eval_runtime": 0.8004,
            "eval_samples_per_second": 1303.039,
            "eval_steps_per_second": 11.244,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1211,
            "grad_norm": 1.323220133781433,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.5251352190971375,
            "eval_matthews_correlation": 0.670371653486617,
            "eval_runtime": 0.7065,
            "eval_samples_per_second": 1476.304,
            "eval_steps_per_second": 12.739,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1159,
            "grad_norm": 1.552595615386963,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.5082565546035767,
            "eval_matthews_correlation": 0.6706315782895295,
            "eval_runtime": 0.8666,
            "eval_samples_per_second": 1203.539,
            "eval_steps_per_second": 10.385,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1145,
            "grad_norm": 1.636406421661377,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.5209736227989197,
            "eval_matthews_correlation": 0.6655740849770345,
            "eval_runtime": 0.7557,
            "eval_samples_per_second": 1380.231,
            "eval_steps_per_second": 11.91,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 765.1919,
            "train_samples_per_second": 1117.497,
            "train_steps_per_second": 8.756,
            "total_flos": 2.873224015432909e+16,
            "train_loss": 0.22882452011108398,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.47022631764411926,
            "eval_matthews_correlation": 0.6866109148734292,
            "eval_runtime": 0.6866,
            "eval_samples_per_second": 1519.081,
            "eval_steps_per_second": 13.108,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 765.1919,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808,
            761.911808
        ],
        "memory_reserved": [
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096,
            5133.828096
        ]
    },
    "variant": "lora"
}