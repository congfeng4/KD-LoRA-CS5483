{
    "eval_loss": 0.3661022484302521,
    "eval_matthews_correlation": 0.6798870648078635,
    "eval_runtime": 0.3526,
    "eval_samples_per_second": 2958.395,
    "eval_steps_per_second": 25.528,
    "epoch": 89.55223880597015,
    "log_history": [
        {
            "loss": 1.8999,
            "grad_norm": 0.28963154554367065,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5846987962722778,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.49,
            "eval_samples_per_second": 2128.554,
            "eval_steps_per_second": 18.367,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.9051,
            "grad_norm": 0.5459920763969421,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6205456852912903,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4986,
            "eval_samples_per_second": 2091.908,
            "eval_steps_per_second": 18.051,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.6056,
            "grad_norm": 0.48339906334877014,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.6132619380950928,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5868,
            "eval_samples_per_second": 1777.377,
            "eval_steps_per_second": 15.337,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5935,
            "grad_norm": 0.308002769947052,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5860351324081421,
            "eval_matthews_correlation": 0.0463559874942472,
            "eval_runtime": 0.4715,
            "eval_samples_per_second": 2212.01,
            "eval_steps_per_second": 19.087,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4988,
            "grad_norm": 0.5457722544670105,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4446137249469757,
            "eval_matthews_correlation": 0.5385290213636863,
            "eval_runtime": 0.4182,
            "eval_samples_per_second": 2494.19,
            "eval_steps_per_second": 21.522,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4203,
            "grad_norm": 0.3395753800868988,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4120126962661743,
            "eval_matthews_correlation": 0.5736173416598102,
            "eval_runtime": 0.4828,
            "eval_samples_per_second": 2160.127,
            "eval_steps_per_second": 18.64,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3909,
            "grad_norm": 0.2970571219921112,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.40797168016433716,
            "eval_matthews_correlation": 0.5834280851949736,
            "eval_runtime": 0.4207,
            "eval_samples_per_second": 2479.183,
            "eval_steps_per_second": 21.393,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3657,
            "grad_norm": 0.44521594047546387,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.40735265612602234,
            "eval_matthews_correlation": 0.5936945766996267,
            "eval_runtime": 0.378,
            "eval_samples_per_second": 2759.203,
            "eval_steps_per_second": 23.809,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3449,
            "grad_norm": 0.34729865193367004,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.3705342710018158,
            "eval_matthews_correlation": 0.6281691768918801,
            "eval_runtime": 0.5701,
            "eval_samples_per_second": 1829.588,
            "eval_steps_per_second": 15.787,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3312,
            "grad_norm": 0.7653416395187378,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.36330828070640564,
            "eval_matthews_correlation": 0.6358835820536083,
            "eval_runtime": 0.4036,
            "eval_samples_per_second": 2584.23,
            "eval_steps_per_second": 22.299,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3216,
            "grad_norm": 0.5372229218482971,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.3673762381076813,
            "eval_matthews_correlation": 0.643050604687314,
            "eval_runtime": 0.5962,
            "eval_samples_per_second": 1749.468,
            "eval_steps_per_second": 15.096,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3138,
            "grad_norm": 0.42801570892333984,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.36511266231536865,
            "eval_matthews_correlation": 0.6430953658298718,
            "eval_runtime": 0.5975,
            "eval_samples_per_second": 1745.498,
            "eval_steps_per_second": 15.062,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3028,
            "grad_norm": 0.3789142072200775,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.36734992265701294,
            "eval_matthews_correlation": 0.6430241506749478,
            "eval_runtime": 0.4337,
            "eval_samples_per_second": 2404.95,
            "eval_steps_per_second": 20.752,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.2968,
            "grad_norm": 0.5901199579238892,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.3766448199748993,
            "eval_matthews_correlation": 0.6454833331679224,
            "eval_runtime": 0.3842,
            "eval_samples_per_second": 2714.812,
            "eval_steps_per_second": 23.426,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.2887,
            "grad_norm": 4.913266658782959,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.36464929580688477,
            "eval_matthews_correlation": 0.6530464576994947,
            "eval_runtime": 0.5861,
            "eval_samples_per_second": 1779.479,
            "eval_steps_per_second": 15.355,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.2853,
            "grad_norm": 0.47004351019859314,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.35399648547172546,
            "eval_matthews_correlation": 0.6513518849008124,
            "eval_runtime": 0.544,
            "eval_samples_per_second": 1917.411,
            "eval_steps_per_second": 16.545,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.2821,
            "grad_norm": 0.4872893989086151,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.3647685647010803,
            "eval_matthews_correlation": 0.6528865280950995,
            "eval_runtime": 0.6342,
            "eval_samples_per_second": 1644.543,
            "eval_steps_per_second": 14.191,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.2734,
            "grad_norm": 0.4620822072029114,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.3687737286090851,
            "eval_matthews_correlation": 0.6504099683042353,
            "eval_runtime": 0.3706,
            "eval_samples_per_second": 2814.051,
            "eval_steps_per_second": 24.282,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.2702,
            "grad_norm": 0.4334535598754883,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.35424238443374634,
            "eval_matthews_correlation": 0.6558371211545774,
            "eval_runtime": 0.4883,
            "eval_samples_per_second": 2135.984,
            "eval_steps_per_second": 18.431,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.263,
            "grad_norm": 0.47859251499176025,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.3621058464050293,
            "eval_matthews_correlation": 0.6629968602758599,
            "eval_runtime": 0.5023,
            "eval_samples_per_second": 2076.375,
            "eval_steps_per_second": 17.917,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.2614,
            "grad_norm": 0.4133496582508087,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.36356520652770996,
            "eval_matthews_correlation": 0.6578435355005723,
            "eval_runtime": 0.4601,
            "eval_samples_per_second": 2266.891,
            "eval_steps_per_second": 19.561,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.2544,
            "grad_norm": 0.7558248043060303,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.3590143620967865,
            "eval_matthews_correlation": 0.6679153499290561,
            "eval_runtime": 0.3928,
            "eval_samples_per_second": 2655.406,
            "eval_steps_per_second": 22.913,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.252,
            "grad_norm": 1.126564383506775,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.36342883110046387,
            "eval_matthews_correlation": 0.6701100574575558,
            "eval_runtime": 0.6006,
            "eval_samples_per_second": 1736.535,
            "eval_steps_per_second": 14.984,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.2497,
            "grad_norm": 0.5791134834289551,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.3603704571723938,
            "eval_matthews_correlation": 0.6751692219961993,
            "eval_runtime": 0.6011,
            "eval_samples_per_second": 1735.088,
            "eval_steps_per_second": 14.972,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.2451,
            "grad_norm": 0.6393347978591919,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.3661022484302521,
            "eval_matthews_correlation": 0.6798870648078635,
            "eval_runtime": 0.593,
            "eval_samples_per_second": 1758.996,
            "eval_steps_per_second": 15.178,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.2422,
            "grad_norm": 0.702824592590332,
            "learning_rate": 4.975124378109453e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.3691073954105377,
            "eval_matthews_correlation": 0.6773861896003048,
            "eval_runtime": 0.4188,
            "eval_samples_per_second": 2490.494,
            "eval_steps_per_second": 21.49,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.245,
            "grad_norm": 1.3055683374404907,
            "learning_rate": 4.311774461028192e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 0.37082555890083313,
            "eval_matthews_correlation": 0.6797549826002157,
            "eval_runtime": 0.3988,
            "eval_samples_per_second": 2615.042,
            "eval_steps_per_second": 22.565,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "loss": 0.2389,
            "grad_norm": 0.5779792070388794,
            "learning_rate": 3.6484245439469325e-05,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 0.369966059923172,
            "eval_matthews_correlation": 0.6797549826002157,
            "eval_runtime": 0.4079,
            "eval_samples_per_second": 2557.253,
            "eval_steps_per_second": 22.066,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "loss": 0.2377,
            "grad_norm": 0.4948576092720032,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "eval_loss": 0.3660275340080261,
            "eval_matthews_correlation": 0.6750770760772062,
            "eval_runtime": 0.5079,
            "eval_samples_per_second": 2053.471,
            "eval_steps_per_second": 17.719,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "loss": 0.2319,
            "grad_norm": 0.7522512674331665,
            "learning_rate": 2.3217247097844114e-05,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "eval_loss": 0.3670814335346222,
            "eval_matthews_correlation": 0.6774456729394701,
            "eval_runtime": 0.4206,
            "eval_samples_per_second": 2479.906,
            "eval_steps_per_second": 21.399,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "train_runtime": 1538.022,
            "train_samples_per_second": 555.974,
            "train_steps_per_second": 4.356,
            "total_flos": 5.086726934495232e+16,
            "train_loss": 0.39039853858947754,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "eval_loss": 0.3661022484302521,
            "eval_matthews_correlation": 0.6798870648078635,
            "eval_runtime": 0.3526,
            "eval_samples_per_second": 2958.395,
            "eval_steps_per_second": 25.528,
            "epoch": 89.55223880597015,
            "step": 6000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 1538.022,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128,
            767.344128
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}