{
    "eval_loss": 0.651383101940155,
    "eval_matthews_correlation": 0.6957299725374031,
    "eval_runtime": 0.5325,
    "eval_samples_per_second": 1958.757,
    "eval_steps_per_second": 16.902,
    "epoch": 56.71641791044776,
    "log_history": [
        {
            "loss": 0.6162,
            "grad_norm": 0.7057176828384399,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.512384831905365,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5365,
            "eval_samples_per_second": 1943.94,
            "eval_steps_per_second": 16.774,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3811,
            "grad_norm": 0.7117471694946289,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.38160812854766846,
            "eval_matthews_correlation": 0.6209103735772308,
            "eval_runtime": 0.7914,
            "eval_samples_per_second": 1317.974,
            "eval_steps_per_second": 11.373,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3049,
            "grad_norm": 0.600801408290863,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.37457922101020813,
            "eval_matthews_correlation": 0.6487003309322072,
            "eval_runtime": 0.7648,
            "eval_samples_per_second": 1363.781,
            "eval_steps_per_second": 11.768,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.2553,
            "grad_norm": 0.8812865614891052,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4158744812011719,
            "eval_matthews_correlation": 0.6479544437772453,
            "eval_runtime": 0.6602,
            "eval_samples_per_second": 1579.907,
            "eval_steps_per_second": 13.633,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2124,
            "grad_norm": 0.8217918872833252,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.40862807631492615,
            "eval_matthews_correlation": 0.6629968602758599,
            "eval_runtime": 0.6565,
            "eval_samples_per_second": 1588.608,
            "eval_steps_per_second": 13.708,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.1744,
            "grad_norm": 1.027933955192566,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.49399328231811523,
            "eval_matthews_correlation": 0.6554406339964501,
            "eval_runtime": 0.5,
            "eval_samples_per_second": 2086.142,
            "eval_steps_per_second": 18.001,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1516,
            "grad_norm": 0.9940102100372314,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4912252128124237,
            "eval_matthews_correlation": 0.6578036520402312,
            "eval_runtime": 0.696,
            "eval_samples_per_second": 1498.602,
            "eval_steps_per_second": 12.931,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1277,
            "grad_norm": 1.0346747636795044,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5346783399581909,
            "eval_matthews_correlation": 0.6455219823779293,
            "eval_runtime": 0.6408,
            "eval_samples_per_second": 1627.742,
            "eval_steps_per_second": 14.046,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1105,
            "grad_norm": 1.2775346040725708,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.527856707572937,
            "eval_matthews_correlation": 0.6749454683036585,
            "eval_runtime": 0.6,
            "eval_samples_per_second": 1738.266,
            "eval_steps_per_second": 14.999,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0932,
            "grad_norm": 0.7100234627723694,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5771281719207764,
            "eval_matthews_correlation": 0.6799667905057818,
            "eval_runtime": 0.6073,
            "eval_samples_per_second": 1717.571,
            "eval_steps_per_second": 14.821,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0862,
            "grad_norm": 0.554606556892395,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.5651513934135437,
            "eval_matthews_correlation": 0.6850707271866645,
            "eval_runtime": 0.7282,
            "eval_samples_per_second": 1432.29,
            "eval_steps_per_second": 12.359,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0748,
            "grad_norm": 0.8506407141685486,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.572068452835083,
            "eval_matthews_correlation": 0.6902553845672901,
            "eval_runtime": 0.5543,
            "eval_samples_per_second": 1881.503,
            "eval_steps_per_second": 16.235,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0685,
            "grad_norm": 1.145403265953064,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.5928440093994141,
            "eval_matthews_correlation": 0.6814373809945056,
            "eval_runtime": 0.5771,
            "eval_samples_per_second": 1807.277,
            "eval_steps_per_second": 15.595,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0574,
            "grad_norm": 0.590381920337677,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.651383101940155,
            "eval_matthews_correlation": 0.6957299725374031,
            "eval_runtime": 0.558,
            "eval_samples_per_second": 1869.154,
            "eval_steps_per_second": 16.129,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0563,
            "grad_norm": 0.9551553130149841,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.6773959398269653,
            "eval_matthews_correlation": 0.670267087346549,
            "eval_runtime": 0.5101,
            "eval_samples_per_second": 2044.829,
            "eval_steps_per_second": 17.645,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0482,
            "grad_norm": 0.9287413954734802,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.6700776815414429,
            "eval_matthews_correlation": 0.6742727208813145,
            "eval_runtime": 0.6105,
            "eval_samples_per_second": 1708.385,
            "eval_steps_per_second": 14.742,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0491,
            "grad_norm": 1.0457360744476318,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.7041268944740295,
            "eval_matthews_correlation": 0.6736105663147891,
            "eval_runtime": 0.5327,
            "eval_samples_per_second": 1958.087,
            "eval_steps_per_second": 16.896,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.0402,
            "grad_norm": 0.30275869369506836,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.7451368570327759,
            "eval_matthews_correlation": 0.670371653486617,
            "eval_runtime": 0.6923,
            "eval_samples_per_second": 1506.564,
            "eval_steps_per_second": 13.0,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.0387,
            "grad_norm": 0.7523494958877563,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.696105420589447,
            "eval_matthews_correlation": 0.6878082239507147,
            "eval_runtime": 0.5739,
            "eval_samples_per_second": 1817.52,
            "eval_steps_per_second": 15.683,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "train_runtime": 759.9524,
            "train_samples_per_second": 1125.202,
            "train_steps_per_second": 8.816,
            "total_flos": 3.2436116065878016e+16,
            "train_loss": 0.15509949244950946,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.651383101940155,
            "eval_matthews_correlation": 0.6957299725374031,
            "eval_runtime": 0.5325,
            "eval_samples_per_second": 1958.757,
            "eval_steps_per_second": 16.902,
            "epoch": 56.71641791044776,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 759.9524,
        "trainable_params_count": 1.181186,
        "memory_allocated": [
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312,
            775.629312
        ],
        "memory_reserved": [
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016,
            4787.798016
        ]
    },
    "variant": "lora"
}