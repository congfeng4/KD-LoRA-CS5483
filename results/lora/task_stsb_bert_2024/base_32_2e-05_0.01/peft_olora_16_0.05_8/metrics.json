{
    "eval_loss": 0.5282239317893982,
    "eval_pearson": 0.8874769065119656,
    "eval_spearman": 0.8829404828235571,
    "eval_runtime": 0.3295,
    "eval_samples_per_second": 4552.527,
    "eval_steps_per_second": 36.42,
    "epoch": 44.44444444444444,
    "log_history": [
        {
            "loss": 4.9517,
            "grad_norm": 2.180734157562256,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.8264948129653931,
            "eval_pearson": 0.8108134720695476,
            "eval_spearman": 0.8226214798804526,
            "eval_runtime": 0.3804,
            "eval_samples_per_second": 3942.746,
            "eval_steps_per_second": 31.542,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.6364,
            "grad_norm": 6.207235813140869,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.5363379716873169,
            "eval_pearson": 0.8760710324909727,
            "eval_spearman": 0.8728812079684544,
            "eval_runtime": 0.3954,
            "eval_samples_per_second": 3793.471,
            "eval_steps_per_second": 30.348,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.4397,
            "grad_norm": 1.5767631530761719,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.5366786122322083,
            "eval_pearson": 0.8807245401798858,
            "eval_spearman": 0.8768719175259506,
            "eval_runtime": 0.3047,
            "eval_samples_per_second": 4922.257,
            "eval_steps_per_second": 39.378,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3462,
            "grad_norm": 3.3988797664642334,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5005531311035156,
            "eval_pearson": 0.8844523995367061,
            "eval_spearman": 0.8810379767764316,
            "eval_runtime": 0.2837,
            "eval_samples_per_second": 5286.667,
            "eval_steps_per_second": 42.293,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.2839,
            "grad_norm": 4.004056453704834,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.515235960483551,
            "eval_pearson": 0.8858124225764744,
            "eval_spearman": 0.8825176018167457,
            "eval_runtime": 0.3573,
            "eval_samples_per_second": 4197.993,
            "eval_steps_per_second": 33.584,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.2378,
            "grad_norm": 1.4685062170028687,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5343648791313171,
            "eval_pearson": 0.8855215506777508,
            "eval_spearman": 0.8807999654917018,
            "eval_runtime": 0.3104,
            "eval_samples_per_second": 4831.895,
            "eval_steps_per_second": 38.655,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.2106,
            "grad_norm": 2.3452775478363037,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.5394902229309082,
            "eval_pearson": 0.8859128785022303,
            "eval_spearman": 0.8827762392568561,
            "eval_runtime": 0.3567,
            "eval_samples_per_second": 4204.993,
            "eval_steps_per_second": 33.64,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.1833,
            "grad_norm": 1.6373034715652466,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5328109264373779,
            "eval_pearson": 0.885536333379932,
            "eval_spearman": 0.8810885476689008,
            "eval_runtime": 0.5279,
            "eval_samples_per_second": 2841.286,
            "eval_steps_per_second": 22.73,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.165,
            "grad_norm": 1.8182069063186646,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5282239317893982,
            "eval_pearson": 0.8874769065119656,
            "eval_spearman": 0.8829404828235571,
            "eval_runtime": 0.5291,
            "eval_samples_per_second": 2834.838,
            "eval_steps_per_second": 22.679,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.153,
            "grad_norm": 4.06581974029541,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5112184286117554,
            "eval_pearson": 0.8867891094954327,
            "eval_spearman": 0.8822042037179013,
            "eval_runtime": 0.399,
            "eval_samples_per_second": 3759.667,
            "eval_steps_per_second": 30.077,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "train_runtime": 286.463,
            "train_samples_per_second": 2006.891,
            "train_steps_per_second": 15.709,
            "total_flos": 1.689708987940864e+16,
            "train_loss": 0.7607744388580322,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5282239317893982,
            "eval_pearson": 0.8874769065119656,
            "eval_spearman": 0.8829404828235571,
            "eval_runtime": 0.3295,
            "eval_samples_per_second": 4552.527,
            "eval_steps_per_second": 36.42,
            "epoch": 44.44444444444444,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 5749
    },
    "train": {
        "train_time": 286.463,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376,
            462.77376
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}