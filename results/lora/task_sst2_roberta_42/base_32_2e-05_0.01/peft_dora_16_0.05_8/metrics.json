{
    "eval_loss": 0.19605670869350433,
    "eval_accuracy": 0.9277522935779816,
    "eval_runtime": 0.4565,
    "eval_samples_per_second": 1910.021,
    "eval_steps_per_second": 15.333,
    "epoch": 4.554079696394687,
    "log_history": [
        {
            "loss": 0.7017,
            "grad_norm": 0.23502226173877716,
            "learning_rate": 7.590132827324478e-06,
            "epoch": 0.3795066413662239,
            "step": 200
        },
        {
            "eval_loss": 0.694167971611023,
            "eval_accuracy": 0.5091743119266054,
            "eval_runtime": 0.3976,
            "eval_samples_per_second": 2192.977,
            "eval_steps_per_second": 17.604,
            "epoch": 0.3795066413662239,
            "step": 200
        },
        {
            "loss": 0.6796,
            "grad_norm": 0.5019577145576477,
            "learning_rate": 1.5180265654648956e-05,
            "epoch": 0.7590132827324478,
            "step": 400
        },
        {
            "eval_loss": 0.6465409398078918,
            "eval_accuracy": 0.5160550458715596,
            "eval_runtime": 0.4211,
            "eval_samples_per_second": 2070.685,
            "eval_steps_per_second": 16.622,
            "epoch": 0.7590132827324478,
            "step": 400
        },
        {
            "loss": 0.3588,
            "grad_norm": 1.3876699209213257,
            "learning_rate": 2.2770398481973435e-05,
            "epoch": 1.1385199240986716,
            "step": 600
        },
        {
            "eval_loss": 0.24864831566810608,
            "eval_accuracy": 0.9025229357798165,
            "eval_runtime": 0.2372,
            "eval_samples_per_second": 3675.842,
            "eval_steps_per_second": 29.508,
            "epoch": 1.1385199240986716,
            "step": 600
        },
        {
            "loss": 0.2805,
            "grad_norm": 1.5282083749771118,
            "learning_rate": 3.0360531309297913e-05,
            "epoch": 1.5180265654648957,
            "step": 800
        },
        {
            "eval_loss": 0.21960987150669098,
            "eval_accuracy": 0.9105504587155964,
            "eval_runtime": 0.2665,
            "eval_samples_per_second": 3271.442,
            "eval_steps_per_second": 26.262,
            "epoch": 1.5180265654648957,
            "step": 800
        },
        {
            "loss": 0.2664,
            "grad_norm": 1.8292158842086792,
            "learning_rate": 3.795066413662239e-05,
            "epoch": 1.8975332068311195,
            "step": 1000
        },
        {
            "eval_loss": 0.2029336392879486,
            "eval_accuracy": 0.9220183486238532,
            "eval_runtime": 0.3389,
            "eval_samples_per_second": 2572.874,
            "eval_steps_per_second": 20.654,
            "epoch": 1.8975332068311195,
            "step": 1000
        },
        {
            "loss": 0.2508,
            "grad_norm": 2.739239454269409,
            "learning_rate": 4.554079696394687e-05,
            "epoch": 2.2770398481973433,
            "step": 1200
        },
        {
            "eval_loss": 0.20760847628116608,
            "eval_accuracy": 0.9162844036697247,
            "eval_runtime": 0.2534,
            "eval_samples_per_second": 3441.186,
            "eval_steps_per_second": 27.624,
            "epoch": 2.2770398481973433,
            "step": 1200
        },
        {
            "loss": 0.2394,
            "grad_norm": 2.6777024269104004,
            "learning_rate": 5.313092979127134e-05,
            "epoch": 2.656546489563567,
            "step": 1400
        },
        {
            "eval_loss": 0.19605670869350433,
            "eval_accuracy": 0.9277522935779816,
            "eval_runtime": 0.3204,
            "eval_samples_per_second": 2721.574,
            "eval_steps_per_second": 21.847,
            "epoch": 2.656546489563567,
            "step": 1400
        },
        {
            "loss": 0.2355,
            "grad_norm": 2.19827938079834,
            "learning_rate": 6.0721062618595825e-05,
            "epoch": 3.0360531309297913,
            "step": 1600
        },
        {
            "eval_loss": 0.20023523271083832,
            "eval_accuracy": 0.9254587155963303,
            "eval_runtime": 0.3727,
            "eval_samples_per_second": 2339.736,
            "eval_steps_per_second": 18.782,
            "epoch": 3.0360531309297913,
            "step": 1600
        },
        {
            "loss": 0.2309,
            "grad_norm": 2.860028028488159,
            "learning_rate": 6.83111954459203e-05,
            "epoch": 3.415559772296015,
            "step": 1800
        },
        {
            "eval_loss": 0.21180607378482819,
            "eval_accuracy": 0.9254587155963303,
            "eval_runtime": 0.2898,
            "eval_samples_per_second": 3009.052,
            "eval_steps_per_second": 24.155,
            "epoch": 3.415559772296015,
            "step": 1800
        },
        {
            "loss": 0.228,
            "grad_norm": 1.2700023651123047,
            "learning_rate": 7.590132827324479e-05,
            "epoch": 3.795066413662239,
            "step": 2000
        },
        {
            "eval_loss": 0.1987820863723755,
            "eval_accuracy": 0.9254587155963303,
            "eval_runtime": 0.2884,
            "eval_samples_per_second": 3023.699,
            "eval_steps_per_second": 24.273,
            "epoch": 3.795066413662239,
            "step": 2000
        },
        {
            "loss": 0.2202,
            "grad_norm": 1.453635811805725,
            "learning_rate": 8.349146110056927e-05,
            "epoch": 4.174573055028463,
            "step": 2200
        },
        {
            "eval_loss": 0.20378702878952026,
            "eval_accuracy": 0.9243119266055045,
            "eval_runtime": 0.3183,
            "eval_samples_per_second": 2739.515,
            "eval_steps_per_second": 21.992,
            "epoch": 4.174573055028463,
            "step": 2200
        },
        {
            "loss": 0.2131,
            "grad_norm": 1.5137296915054321,
            "learning_rate": 9.108159392789374e-05,
            "epoch": 4.554079696394687,
            "step": 2400
        },
        {
            "eval_loss": 0.19403810799121857,
            "eval_accuracy": 0.9277522935779816,
            "eval_runtime": 0.4591,
            "eval_samples_per_second": 1899.247,
            "eval_steps_per_second": 15.246,
            "epoch": 4.554079696394687,
            "step": 2400
        },
        {
            "train_runtime": 427.5346,
            "train_samples_per_second": 15752.876,
            "train_steps_per_second": 123.265,
            "total_flos": 2.0420557837172736e+16,
            "train_loss": 0.32542810281117757,
            "epoch": 4.554079696394687,
            "step": 2400
        },
        {
            "eval_loss": 0.19605670869350433,
            "eval_accuracy": 0.9277522935779816,
            "eval_runtime": 0.4565,
            "eval_samples_per_second": 1910.021,
            "eval_steps_per_second": 15.333,
            "epoch": 4.554079696394687,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "sst2",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 67349
    },
    "train": {
        "train_time": 427.5346,
        "trainable_params_count": 0.905474,
        "memory_allocated": [
            534.09024,
            534.09024,
            534.09024,
            534.09024,
            534.09024
        ],
        "memory_reserved": [
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328,
            2390.75328
        ]
    },
    "variant": "lora"
}