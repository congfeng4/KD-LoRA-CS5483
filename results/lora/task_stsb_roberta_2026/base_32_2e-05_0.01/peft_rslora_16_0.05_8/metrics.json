{
    "eval_loss": 0.4373854100704193,
    "eval_pearson": 0.903967718559129,
    "eval_spearman": 0.901569728019938,
    "eval_runtime": 0.4008,
    "eval_samples_per_second": 3742.707,
    "eval_steps_per_second": 29.942,
    "epoch": 44.44444444444444,
    "log_history": [
        {
            "loss": 4.158,
            "grad_norm": 13.638689994812012,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.5774539709091187,
            "eval_pearson": 0.8666876816141702,
            "eval_spearman": 0.8641800004193239,
            "eval_runtime": 0.365,
            "eval_samples_per_second": 4109.6,
            "eval_steps_per_second": 32.877,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.538,
            "grad_norm": 7.41152811050415,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.5772626399993896,
            "eval_pearson": 0.8943109542024108,
            "eval_spearman": 0.8918172418646425,
            "eval_runtime": 0.3816,
            "eval_samples_per_second": 3930.44,
            "eval_steps_per_second": 31.444,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.4205,
            "grad_norm": 14.008209228515625,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.6637645959854126,
            "eval_pearson": 0.9004079233515242,
            "eval_spearman": 0.8979199922947955,
            "eval_runtime": 0.4533,
            "eval_samples_per_second": 3308.872,
            "eval_steps_per_second": 26.471,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3522,
            "grad_norm": 6.645166873931885,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5784341096878052,
            "eval_pearson": 0.9024190049903353,
            "eval_spearman": 0.8990706642290979,
            "eval_runtime": 0.4911,
            "eval_samples_per_second": 3054.556,
            "eval_steps_per_second": 24.436,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.3165,
            "grad_norm": 10.110513687133789,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5008765459060669,
            "eval_pearson": 0.9051430482757352,
            "eval_spearman": 0.9014901360602677,
            "eval_runtime": 0.3362,
            "eval_samples_per_second": 4461.649,
            "eval_steps_per_second": 35.693,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.2616,
            "grad_norm": 3.677165985107422,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4915542006492615,
            "eval_pearson": 0.9015669365643215,
            "eval_spearman": 0.8976750450526042,
            "eval_runtime": 0.485,
            "eval_samples_per_second": 3092.783,
            "eval_steps_per_second": 24.742,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.2334,
            "grad_norm": 2.832862138748169,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.4373854100704193,
            "eval_pearson": 0.903967718559129,
            "eval_spearman": 0.901569728019938,
            "eval_runtime": 0.4476,
            "eval_samples_per_second": 3350.884,
            "eval_steps_per_second": 26.807,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.208,
            "grad_norm": 4.474489688873291,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.49677950143814087,
            "eval_pearson": 0.9027628404432793,
            "eval_spearman": 0.8988738601142998,
            "eval_runtime": 0.4207,
            "eval_samples_per_second": 3565.215,
            "eval_steps_per_second": 28.522,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.1849,
            "grad_norm": 3.8033528327941895,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.43643447756767273,
            "eval_pearson": 0.9022922443541804,
            "eval_spearman": 0.8998336040048031,
            "eval_runtime": 0.5399,
            "eval_samples_per_second": 2778.405,
            "eval_steps_per_second": 22.227,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.1708,
            "grad_norm": 5.296538352966309,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.44181960821151733,
            "eval_pearson": 0.9017986255688772,
            "eval_spearman": 0.8982127368477616,
            "eval_runtime": 0.347,
            "eval_samples_per_second": 4323.267,
            "eval_steps_per_second": 34.586,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "train_runtime": 179.932,
            "train_samples_per_second": 3195.095,
            "train_steps_per_second": 25.009,
            "total_flos": 1.7013204320256e+16,
            "train_loss": 0.6844005222320557,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.4373854100704193,
            "eval_pearson": 0.903967718559129,
            "eval_spearman": 0.901569728019938,
            "eval_runtime": 0.4008,
            "eval_samples_per_second": 3742.707,
            "eval_steps_per_second": 29.942,
            "epoch": 44.44444444444444,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 179.932,
        "trainable_params_count": 0.886273,
        "memory_allocated": [
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256,
            533.792256
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}