{
    "eval_loss": 0.4820486307144165,
    "eval_pearson": 0.9027391476354173,
    "eval_spearman": 0.903210240630413,
    "eval_runtime": 0.478,
    "eval_samples_per_second": 3138.293,
    "eval_steps_per_second": 25.106,
    "epoch": 71.11111111111111,
    "log_history": [
        {
            "loss": 6.6416,
            "grad_norm": 1.8532946109771729,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.594505548477173,
            "eval_pearson": 0.01939369944859124,
            "eval_spearman": 0.01915551425487212,
            "eval_runtime": 0.4003,
            "eval_samples_per_second": 3747.58,
            "eval_steps_per_second": 29.981,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.0806,
            "grad_norm": 4.185112476348877,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 1.9519834518432617,
            "eval_pearson": 0.4733906460766355,
            "eval_spearman": 0.4478302737507784,
            "eval_runtime": 0.4878,
            "eval_samples_per_second": 3074.881,
            "eval_steps_per_second": 24.599,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.1055,
            "grad_norm": 2.511920928955078,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.6220284104347229,
            "eval_pearson": 0.8614002736532794,
            "eval_spearman": 0.8617892908053287,
            "eval_runtime": 0.5545,
            "eval_samples_per_second": 2704.952,
            "eval_steps_per_second": 21.64,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7003,
            "grad_norm": 5.942532539367676,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5397942066192627,
            "eval_pearson": 0.8797411200597954,
            "eval_spearman": 0.8796662726758975,
            "eval_runtime": 0.3554,
            "eval_samples_per_second": 4221.023,
            "eval_steps_per_second": 33.768,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5976,
            "grad_norm": 3.017871618270874,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5119679570198059,
            "eval_pearson": 0.8870685722112274,
            "eval_spearman": 0.8874924048403002,
            "eval_runtime": 0.5627,
            "eval_samples_per_second": 2665.58,
            "eval_steps_per_second": 21.325,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5331,
            "grad_norm": 2.419062376022339,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4870406985282898,
            "eval_pearson": 0.8911949106225526,
            "eval_spearman": 0.8921703550148207,
            "eval_runtime": 0.4774,
            "eval_samples_per_second": 3142.336,
            "eval_steps_per_second": 25.139,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4962,
            "grad_norm": 2.0768511295318604,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.46817275881767273,
            "eval_pearson": 0.8961097645708773,
            "eval_spearman": 0.8974241748395497,
            "eval_runtime": 0.6375,
            "eval_samples_per_second": 2352.936,
            "eval_steps_per_second": 18.823,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4715,
            "grad_norm": 1.5251491069793701,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.4776025414466858,
            "eval_pearson": 0.8963335748177786,
            "eval_spearman": 0.8972290790230083,
            "eval_runtime": 0.6299,
            "eval_samples_per_second": 2381.303,
            "eval_steps_per_second": 19.05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4412,
            "grad_norm": 1.0500473976135254,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.4583900570869446,
            "eval_pearson": 0.8969872615999532,
            "eval_spearman": 0.8985202624722252,
            "eval_runtime": 0.396,
            "eval_samples_per_second": 3788.039,
            "eval_steps_per_second": 30.304,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4363,
            "grad_norm": 2.7117667198181152,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5211541056632996,
            "eval_pearson": 0.8994711211276314,
            "eval_spearman": 0.899309642134117,
            "eval_runtime": 0.446,
            "eval_samples_per_second": 3363.437,
            "eval_steps_per_second": 26.907,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4184,
            "grad_norm": 5.8254499435424805,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.44962528347969055,
            "eval_pearson": 0.9007034005092903,
            "eval_spearman": 0.9011231159090971,
            "eval_runtime": 0.552,
            "eval_samples_per_second": 2717.373,
            "eval_steps_per_second": 21.739,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4081,
            "grad_norm": 2.9445900917053223,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.44461262226104736,
            "eval_pearson": 0.9013573104505006,
            "eval_spearman": 0.9019816622190129,
            "eval_runtime": 0.479,
            "eval_samples_per_second": 3131.698,
            "eval_steps_per_second": 25.054,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4009,
            "grad_norm": 1.1548763513565063,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.4814375042915344,
            "eval_pearson": 0.9005937328328008,
            "eval_spearman": 0.9006594400316957,
            "eval_runtime": 0.4246,
            "eval_samples_per_second": 3533.146,
            "eval_steps_per_second": 28.265,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3943,
            "grad_norm": 5.290791988372803,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.4301532506942749,
            "eval_pearson": 0.9022127316404083,
            "eval_spearman": 0.9029101497991966,
            "eval_runtime": 0.6662,
            "eval_samples_per_second": 2251.554,
            "eval_steps_per_second": 18.012,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.3848,
            "grad_norm": 3.4476232528686523,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.4585864245891571,
            "eval_pearson": 0.9023741553033349,
            "eval_spearman": 0.9030905547535393,
            "eval_runtime": 0.534,
            "eval_samples_per_second": 2808.925,
            "eval_steps_per_second": 22.471,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3727,
            "grad_norm": 2.849094867706299,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.4820486307144165,
            "eval_pearson": 0.9027391476354173,
            "eval_spearman": 0.903210240630413,
            "eval_runtime": 0.4277,
            "eval_samples_per_second": 3507.438,
            "eval_steps_per_second": 28.06,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "train_runtime": 392.5748,
            "train_samples_per_second": 1464.434,
            "train_steps_per_second": 11.463,
            "total_flos": 2.731402705502208e+16,
            "train_loss": 0.9927053427696229,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.4820486307144165,
            "eval_pearson": 0.9027391476354173,
            "eval_spearman": 0.903210240630413,
            "eval_runtime": 0.478,
            "eval_samples_per_second": 3138.293,
            "eval_steps_per_second": 25.106,
            "epoch": 71.11111111111111,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 392.5748,
        "trainable_params_count": 1.181569,
        "memory_allocated": [
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936,
            538.535936
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}