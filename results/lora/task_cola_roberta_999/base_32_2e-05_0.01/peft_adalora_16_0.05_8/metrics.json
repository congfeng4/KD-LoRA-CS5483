{
    "eval_loss": 0.4300110638141632,
    "eval_matthews_correlation": 0.583024886611504,
    "eval_runtime": 0.3804,
    "eval_samples_per_second": 2741.884,
    "eval_steps_per_second": 23.66,
    "epoch": 62.6865671641791,
    "log_history": [
        {
            "loss": 1.88,
            "grad_norm": 0.5699946880340576,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.536350131034851,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4872,
            "eval_samples_per_second": 2140.674,
            "eval_steps_per_second": 18.472,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.8722,
            "grad_norm": 0.3270721137523651,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6106483936309814,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5509,
            "eval_samples_per_second": 1893.197,
            "eval_steps_per_second": 16.336,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5923,
            "grad_norm": 0.4231361448764801,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5891063213348389,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.554,
            "eval_samples_per_second": 1882.78,
            "eval_steps_per_second": 16.246,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5287,
            "grad_norm": 0.5340527892112732,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5060856342315674,
            "eval_matthews_correlation": 0.3978035301769796,
            "eval_runtime": 0.5787,
            "eval_samples_per_second": 1802.341,
            "eval_steps_per_second": 15.552,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.467,
            "grad_norm": 0.36047491431236267,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4661772847175598,
            "eval_matthews_correlation": 0.45831111658186324,
            "eval_runtime": 0.5826,
            "eval_samples_per_second": 1790.17,
            "eval_steps_per_second": 15.447,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4379,
            "grad_norm": 2.4222512245178223,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.449911892414093,
            "eval_matthews_correlation": 0.5126143737721263,
            "eval_runtime": 0.3486,
            "eval_samples_per_second": 2992.001,
            "eval_steps_per_second": 25.818,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4226,
            "grad_norm": 1.1141831874847412,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.451231449842453,
            "eval_matthews_correlation": 0.5311983410233877,
            "eval_runtime": 0.3756,
            "eval_samples_per_second": 2776.994,
            "eval_steps_per_second": 23.963,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4102,
            "grad_norm": 0.4731566607952118,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.47394049167633057,
            "eval_matthews_correlation": 0.5032393365588423,
            "eval_runtime": 0.6228,
            "eval_samples_per_second": 1674.786,
            "eval_steps_per_second": 14.452,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.401,
            "grad_norm": 0.8120437264442444,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4364197552204132,
            "eval_matthews_correlation": 0.5391948418977317,
            "eval_runtime": 0.4999,
            "eval_samples_per_second": 2086.264,
            "eval_steps_per_second": 18.002,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3913,
            "grad_norm": 1.2462159395217896,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.45098647475242615,
            "eval_matthews_correlation": 0.5365007161029405,
            "eval_runtime": 0.4511,
            "eval_samples_per_second": 2312.16,
            "eval_steps_per_second": 19.952,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3824,
            "grad_norm": 0.646977424621582,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4778909385204315,
            "eval_matthews_correlation": 0.5343001138193059,
            "eval_runtime": 0.4958,
            "eval_samples_per_second": 2103.662,
            "eval_steps_per_second": 18.152,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3736,
            "grad_norm": 0.6799149513244629,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.4752154052257538,
            "eval_matthews_correlation": 0.5476972834600634,
            "eval_runtime": 0.5233,
            "eval_samples_per_second": 1992.977,
            "eval_steps_per_second": 17.197,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3727,
            "grad_norm": 0.6909650564193726,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.47875741124153137,
            "eval_matthews_correlation": 0.5341602366353293,
            "eval_runtime": 0.5262,
            "eval_samples_per_second": 1982.187,
            "eval_steps_per_second": 17.104,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.3645,
            "grad_norm": 1.490294337272644,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4542810916900635,
            "eval_matthews_correlation": 0.5469451017688902,
            "eval_runtime": 0.5129,
            "eval_samples_per_second": 2033.636,
            "eval_steps_per_second": 17.548,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3642,
            "grad_norm": 0.7852309942245483,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.42773517966270447,
            "eval_matthews_correlation": 0.5599999927061219,
            "eval_runtime": 0.5375,
            "eval_samples_per_second": 1940.633,
            "eval_steps_per_second": 16.746,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3557,
            "grad_norm": 0.7818423509597778,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4300110638141632,
            "eval_matthews_correlation": 0.583024886611504,
            "eval_runtime": 0.4052,
            "eval_samples_per_second": 2574.137,
            "eval_steps_per_second": 22.212,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3545,
            "grad_norm": 1.2640827894210815,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.53824782371521,
            "eval_matthews_correlation": 0.5269760296374377,
            "eval_runtime": 0.4241,
            "eval_samples_per_second": 2459.524,
            "eval_steps_per_second": 21.223,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3442,
            "grad_norm": 1.2999365329742432,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.47708600759506226,
            "eval_matthews_correlation": 0.5651092792103851,
            "eval_runtime": 0.454,
            "eval_samples_per_second": 2297.555,
            "eval_steps_per_second": 19.825,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3454,
            "grad_norm": 0.8114604353904724,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.5075512528419495,
            "eval_matthews_correlation": 0.5475140727239077,
            "eval_runtime": 0.3948,
            "eval_samples_per_second": 2641.639,
            "eval_steps_per_second": 22.795,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3402,
            "grad_norm": 1.631005883216858,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.449141263961792,
            "eval_matthews_correlation": 0.5752407929937235,
            "eval_runtime": 0.3918,
            "eval_samples_per_second": 2662.091,
            "eval_steps_per_second": 22.971,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3413,
            "grad_norm": 1.1767395734786987,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.4959293007850647,
            "eval_matthews_correlation": 0.5601566135203125,
            "eval_runtime": 0.5908,
            "eval_samples_per_second": 1765.372,
            "eval_steps_per_second": 15.233,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "train_runtime": 660.8791,
            "train_samples_per_second": 1293.883,
            "train_steps_per_second": 10.138,
            "total_flos": 3.585029468848128e+16,
            "train_loss": 0.4924663689022972,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.4300110638141632,
            "eval_matthews_correlation": 0.583024886611504,
            "eval_runtime": 0.3804,
            "eval_samples_per_second": 2741.884,
            "eval_steps_per_second": 23.66,
            "epoch": 62.6865671641791,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 660.8791,
        "trainable_params_count": 1.182338,
        "memory_allocated": [
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}