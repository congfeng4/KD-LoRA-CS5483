{
    "eval_loss": 0.5115830898284912,
    "eval_matthews_correlation": 0.5937869861492439,
    "eval_runtime": 0.1635,
    "eval_samples_per_second": 6380.644,
    "eval_steps_per_second": 55.058,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.6385,
            "grad_norm": 0.6084221601486206,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5773122906684875,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2227,
            "eval_samples_per_second": 4682.806,
            "eval_steps_per_second": 40.408,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4599,
            "grad_norm": 2.7683353424072266,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4728488028049469,
            "eval_matthews_correlation": 0.5073664747016221,
            "eval_runtime": 0.238,
            "eval_samples_per_second": 4383.136,
            "eval_steps_per_second": 37.822,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3799,
            "grad_norm": 2.322057008743286,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4873521327972412,
            "eval_matthews_correlation": 0.5206867487527611,
            "eval_runtime": 0.3849,
            "eval_samples_per_second": 2710.001,
            "eval_steps_per_second": 23.384,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3266,
            "grad_norm": 2.4973881244659424,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4844227433204651,
            "eval_matthews_correlation": 0.5546666671852067,
            "eval_runtime": 0.2048,
            "eval_samples_per_second": 5091.567,
            "eval_steps_per_second": 43.935,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2839,
            "grad_norm": 2.212637186050415,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4843880236148834,
            "eval_matthews_correlation": 0.567550266689718,
            "eval_runtime": 0.2539,
            "eval_samples_per_second": 4107.696,
            "eval_steps_per_second": 35.445,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2481,
            "grad_norm": 3.9524779319763184,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5060781240463257,
            "eval_matthews_correlation": 0.5879880120258366,
            "eval_runtime": 0.217,
            "eval_samples_per_second": 4805.607,
            "eval_steps_per_second": 41.467,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2174,
            "grad_norm": 3.297734260559082,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5115830898284912,
            "eval_matthews_correlation": 0.5937869861492439,
            "eval_runtime": 0.264,
            "eval_samples_per_second": 3950.634,
            "eval_steps_per_second": 34.09,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1923,
            "grad_norm": 3.544710397720337,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6697490215301514,
            "eval_matthews_correlation": 0.5601566135203125,
            "eval_runtime": 0.4084,
            "eval_samples_per_second": 2553.579,
            "eval_steps_per_second": 22.035,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.17,
            "grad_norm": 3.1515820026397705,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.7233344316482544,
            "eval_matthews_correlation": 0.5855361143791362,
            "eval_runtime": 0.2303,
            "eval_samples_per_second": 4528.239,
            "eval_steps_per_second": 39.074,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1599,
            "grad_norm": 4.166540622711182,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.7705109715461731,
            "eval_matthews_correlation": 0.5779057511117575,
            "eval_runtime": 0.3021,
            "eval_samples_per_second": 3452.47,
            "eval_steps_per_second": 29.791,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1399,
            "grad_norm": 2.941511869430542,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7466252446174622,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.2969,
            "eval_samples_per_second": 3512.987,
            "eval_steps_per_second": 30.313,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1279,
            "grad_norm": 4.5130534172058105,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.8460897207260132,
            "eval_matthews_correlation": 0.5879831868448624,
            "eval_runtime": 0.2644,
            "eval_samples_per_second": 3944.204,
            "eval_steps_per_second": 34.034,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 330.7129,
            "train_samples_per_second": 2585.626,
            "train_steps_per_second": 20.259,
            "total_flos": 2.0416209182785536e+16,
            "train_loss": 0.27869086821873984,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.5115830898284912,
            "eval_matthews_correlation": 0.5937869861492439,
            "eval_runtime": 0.1635,
            "eval_samples_per_second": 6380.644,
            "eval_steps_per_second": 55.058,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 330.7129,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}