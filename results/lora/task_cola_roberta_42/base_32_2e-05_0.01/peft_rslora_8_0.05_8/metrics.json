{
    "eval_loss": 0.43203702569007874,
    "eval_matthews_correlation": 0.6077372338480053,
    "eval_runtime": 0.1509,
    "eval_samples_per_second": 6913.342,
    "eval_steps_per_second": 59.655,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.6341,
            "grad_norm": 1.37356436252594,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5260096192359924,
            "eval_matthews_correlation": 0.08036809130702588,
            "eval_runtime": 0.3164,
            "eval_samples_per_second": 3296.542,
            "eval_steps_per_second": 28.446,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4463,
            "grad_norm": 2.674166679382324,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4616098701953888,
            "eval_matthews_correlation": 0.4869134372691264,
            "eval_runtime": 0.2328,
            "eval_samples_per_second": 4480.474,
            "eval_steps_per_second": 38.662,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3912,
            "grad_norm": 1.541542649269104,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5124167799949646,
            "eval_matthews_correlation": 0.5019330701750789,
            "eval_runtime": 0.2625,
            "eval_samples_per_second": 3973.149,
            "eval_steps_per_second": 34.284,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3473,
            "grad_norm": 1.7769460678100586,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5340293049812317,
            "eval_matthews_correlation": 0.5262632923748388,
            "eval_runtime": 0.2966,
            "eval_samples_per_second": 3516.132,
            "eval_steps_per_second": 30.341,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3193,
            "grad_norm": 1.7939085960388184,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5209500193595886,
            "eval_matthews_correlation": 0.5572449322954699,
            "eval_runtime": 0.3022,
            "eval_samples_per_second": 3451.533,
            "eval_steps_per_second": 29.783,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2785,
            "grad_norm": 3.37636661529541,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5056970715522766,
            "eval_matthews_correlation": 0.5675682416159784,
            "eval_runtime": 0.2355,
            "eval_samples_per_second": 4429.236,
            "eval_steps_per_second": 38.22,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2482,
            "grad_norm": 4.754763126373291,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.43203702569007874,
            "eval_matthews_correlation": 0.6077372338480053,
            "eval_runtime": 0.3108,
            "eval_samples_per_second": 3355.662,
            "eval_steps_per_second": 28.956,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2298,
            "grad_norm": 3.3809597492218018,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5458650588989258,
            "eval_matthews_correlation": 0.5701789905913004,
            "eval_runtime": 0.4794,
            "eval_samples_per_second": 2175.685,
            "eval_steps_per_second": 18.774,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2059,
            "grad_norm": 4.226490497589111,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5798607468605042,
            "eval_matthews_correlation": 0.5930551868478077,
            "eval_runtime": 0.2733,
            "eval_samples_per_second": 3816.74,
            "eval_steps_per_second": 32.934,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1881,
            "grad_norm": 2.3903019428253174,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5645563006401062,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.2283,
            "eval_samples_per_second": 4568.214,
            "eval_steps_per_second": 39.419,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1695,
            "grad_norm": 8.963830947875977,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.8265493512153625,
            "eval_matthews_correlation": 0.5610450749202449,
            "eval_runtime": 0.2284,
            "eval_samples_per_second": 4566.44,
            "eval_steps_per_second": 39.404,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1592,
            "grad_norm": 3.2480661869049072,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.705872118473053,
            "eval_matthews_correlation": 0.5754342635449895,
            "eval_runtime": 0.213,
            "eval_samples_per_second": 4896.882,
            "eval_steps_per_second": 42.255,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 335.7138,
            "train_samples_per_second": 2547.11,
            "train_steps_per_second": 19.957,
            "total_flos": 2.0416209182785536e+16,
            "train_loss": 0.3014440941810608,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.43203702569007874,
            "eval_matthews_correlation": 0.6077372338480053,
            "eval_runtime": 0.1509,
            "eval_samples_per_second": 6913.342,
            "eval_steps_per_second": 59.655,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 335.7138,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472,
            533.545472
        ],
        "memory_reserved": [
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872
        ]
    },
    "variant": "lora"
}