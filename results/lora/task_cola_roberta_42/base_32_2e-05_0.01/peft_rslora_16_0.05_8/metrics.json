{
    "eval_loss": 0.5893334746360779,
    "eval_matthews_correlation": 0.6185029155864712,
    "eval_runtime": 0.148,
    "eval_samples_per_second": 7047.331,
    "eval_steps_per_second": 60.811,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 0.613,
            "grad_norm": 2.2104246616363525,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5819044709205627,
            "eval_matthews_correlation": 0.3709051211840688,
            "eval_runtime": 0.2368,
            "eval_samples_per_second": 4405.28,
            "eval_steps_per_second": 38.013,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4307,
            "grad_norm": 3.3471767902374268,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.44358012080192566,
            "eval_matthews_correlation": 0.5268397211224343,
            "eval_runtime": 0.3191,
            "eval_samples_per_second": 3268.159,
            "eval_steps_per_second": 28.201,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3809,
            "grad_norm": 2.3898518085479736,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5099998712539673,
            "eval_matthews_correlation": 0.5261452181661114,
            "eval_runtime": 0.2293,
            "eval_samples_per_second": 4548.039,
            "eval_steps_per_second": 39.245,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.329,
            "grad_norm": 3.31770658493042,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5320837497711182,
            "eval_matthews_correlation": 0.5633880074988443,
            "eval_runtime": 0.3112,
            "eval_samples_per_second": 3351.027,
            "eval_steps_per_second": 28.916,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2854,
            "grad_norm": 3.390655040740967,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.6132588982582092,
            "eval_matthews_correlation": 0.5528800923802824,
            "eval_runtime": 0.4146,
            "eval_samples_per_second": 2515.661,
            "eval_steps_per_second": 21.708,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2434,
            "grad_norm": 5.734097480773926,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4731643795967102,
            "eval_matthews_correlation": 0.5881989399089292,
            "eval_runtime": 0.194,
            "eval_samples_per_second": 5376.698,
            "eval_steps_per_second": 46.395,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.209,
            "grad_norm": 3.124082565307617,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4692530333995819,
            "eval_matthews_correlation": 0.6061605762137284,
            "eval_runtime": 0.2182,
            "eval_samples_per_second": 4779.204,
            "eval_steps_per_second": 41.24,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1861,
            "grad_norm": 7.850140571594238,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6572505831718445,
            "eval_matthews_correlation": 0.5692493487540154,
            "eval_runtime": 0.321,
            "eval_samples_per_second": 3249.145,
            "eval_steps_per_second": 28.037,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1621,
            "grad_norm": 4.485579967498779,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.6427184343338013,
            "eval_matthews_correlation": 0.5828923211172198,
            "eval_runtime": 0.2307,
            "eval_samples_per_second": 4520.079,
            "eval_steps_per_second": 39.004,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1467,
            "grad_norm": 2.4973695278167725,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5893334746360779,
            "eval_matthews_correlation": 0.6185029155864712,
            "eval_runtime": 0.4188,
            "eval_samples_per_second": 2490.189,
            "eval_steps_per_second": 21.488,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1226,
            "grad_norm": 9.72722339630127,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7325659990310669,
            "eval_matthews_correlation": 0.6135845059453029,
            "eval_runtime": 0.2377,
            "eval_samples_per_second": 4388.738,
            "eval_steps_per_second": 37.87,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1139,
            "grad_norm": 3.73492431640625,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.7715682983398438,
            "eval_matthews_correlation": 0.6031465729998459,
            "eval_runtime": 0.2295,
            "eval_samples_per_second": 4544.68,
            "eval_steps_per_second": 39.216,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1075,
            "grad_norm": 4.595990180969238,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.8273189663887024,
            "eval_matthews_correlation": 0.6085937610714532,
            "eval_runtime": 0.4019,
            "eval_samples_per_second": 2595.113,
            "eval_steps_per_second": 22.393,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0992,
            "grad_norm": 4.398703575134277,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.7926087379455566,
            "eval_matthews_correlation": 0.5981951351808346,
            "eval_runtime": 0.2391,
            "eval_samples_per_second": 4361.87,
            "eval_steps_per_second": 37.638,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0864,
            "grad_norm": 5.673564434051514,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.790012001991272,
            "eval_matthews_correlation": 0.6093514522222457,
            "eval_runtime": 0.3155,
            "eval_samples_per_second": 3305.629,
            "eval_steps_per_second": 28.524,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 409.0043,
            "train_samples_per_second": 2090.687,
            "train_steps_per_second": 16.381,
            "total_flos": 2.552026147848192e+16,
            "train_loss": 0.23439753595987955,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.5893334746360779,
            "eval_matthews_correlation": 0.6185029155864712,
            "eval_runtime": 0.148,
            "eval_samples_per_second": 7047.331,
            "eval_steps_per_second": 60.811,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 409.0043,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616,
            533.807616
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}