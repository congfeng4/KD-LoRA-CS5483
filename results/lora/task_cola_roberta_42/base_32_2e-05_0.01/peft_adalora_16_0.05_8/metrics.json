{
    "eval_loss": 0.42970529198646545,
    "eval_matthews_correlation": 0.5732046470010711,
    "eval_runtime": 0.2039,
    "eval_samples_per_second": 5116.429,
    "eval_steps_per_second": 44.149,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 1.8842,
            "grad_norm": 0.4392821788787842,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5079742670059204,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3336,
            "eval_samples_per_second": 3126.892,
            "eval_steps_per_second": 26.982,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.8528,
            "grad_norm": 0.40549764037132263,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.608073890209198,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3249,
            "eval_samples_per_second": 3210.62,
            "eval_steps_per_second": 27.704,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5915,
            "grad_norm": 0.3959755003452301,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5896949768066406,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3256,
            "eval_samples_per_second": 3203.405,
            "eval_steps_per_second": 27.642,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.526,
            "grad_norm": 0.8019288182258606,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4893200993537903,
            "eval_matthews_correlation": 0.41650989084940443,
            "eval_runtime": 0.3911,
            "eval_samples_per_second": 2667.073,
            "eval_steps_per_second": 23.014,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4651,
            "grad_norm": 0.7351301312446594,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.485578328371048,
            "eval_matthews_correlation": 0.42751732583319796,
            "eval_runtime": 0.3751,
            "eval_samples_per_second": 2780.913,
            "eval_steps_per_second": 23.996,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4382,
            "grad_norm": 0.8221299648284912,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4810451567173004,
            "eval_matthews_correlation": 0.46682909097331426,
            "eval_runtime": 0.5774,
            "eval_samples_per_second": 1806.329,
            "eval_steps_per_second": 15.587,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.421,
            "grad_norm": 0.6879352927207947,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.44143417477607727,
            "eval_matthews_correlation": 0.5259258925916567,
            "eval_runtime": 0.3691,
            "eval_samples_per_second": 2825.584,
            "eval_steps_per_second": 24.382,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4083,
            "grad_norm": 0.981549084186554,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.488406777381897,
            "eval_matthews_correlation": 0.4899667634004927,
            "eval_runtime": 0.2928,
            "eval_samples_per_second": 3562.696,
            "eval_steps_per_second": 30.742,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3968,
            "grad_norm": 1.5302667617797852,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.44109636545181274,
            "eval_matthews_correlation": 0.5390439985632989,
            "eval_runtime": 0.4578,
            "eval_samples_per_second": 2278.205,
            "eval_steps_per_second": 19.659,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3921,
            "grad_norm": 0.9370442032814026,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.44009941816329956,
            "eval_matthews_correlation": 0.5312017201039245,
            "eval_runtime": 0.3807,
            "eval_samples_per_second": 2739.734,
            "eval_steps_per_second": 23.641,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3835,
            "grad_norm": 1.2051335573196411,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4503461420536041,
            "eval_matthews_correlation": 0.557240254761928,
            "eval_runtime": 0.3997,
            "eval_samples_per_second": 2609.268,
            "eval_steps_per_second": 22.515,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3744,
            "grad_norm": 0.6947019696235657,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.47647014260292053,
            "eval_matthews_correlation": 0.5447538747819195,
            "eval_runtime": 0.3403,
            "eval_samples_per_second": 3064.789,
            "eval_steps_per_second": 26.446,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3723,
            "grad_norm": 1.1964269876480103,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.47677740454673767,
            "eval_matthews_correlation": 0.5472187281316763,
            "eval_runtime": 0.3342,
            "eval_samples_per_second": 3120.786,
            "eval_steps_per_second": 26.929,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.3652,
            "grad_norm": 0.9816117286682129,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.47182750701904297,
            "eval_matthews_correlation": 0.5551284044582203,
            "eval_runtime": 0.296,
            "eval_samples_per_second": 3524.08,
            "eval_steps_per_second": 30.409,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3624,
            "grad_norm": 1.7265714406967163,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.4578779637813568,
            "eval_matthews_correlation": 0.5701789905913004,
            "eval_runtime": 0.2907,
            "eval_samples_per_second": 3587.645,
            "eval_steps_per_second": 30.958,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3545,
            "grad_norm": 0.8415456414222717,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4540841281414032,
            "eval_matthews_correlation": 0.5598962230809679,
            "eval_runtime": 0.259,
            "eval_samples_per_second": 4026.437,
            "eval_steps_per_second": 34.744,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.349,
            "grad_norm": 1.4462782144546509,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.493350625038147,
            "eval_matthews_correlation": 0.5499507419176799,
            "eval_runtime": 0.2635,
            "eval_samples_per_second": 3958.215,
            "eval_steps_per_second": 34.155,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3481,
            "grad_norm": 1.139551043510437,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.4789566099643707,
            "eval_matthews_correlation": 0.5601566135203125,
            "eval_runtime": 0.4527,
            "eval_samples_per_second": 2303.725,
            "eval_steps_per_second": 19.879,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3421,
            "grad_norm": 1.4285595417022705,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.42970529198646545,
            "eval_matthews_correlation": 0.5732046470010711,
            "eval_runtime": 0.2807,
            "eval_samples_per_second": 3716.087,
            "eval_steps_per_second": 32.066,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3382,
            "grad_norm": 0.9494062662124634,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.47285622358322144,
            "eval_matthews_correlation": 0.5676145457477023,
            "eval_runtime": 0.3636,
            "eval_samples_per_second": 2868.311,
            "eval_steps_per_second": 24.751,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.338,
            "grad_norm": 0.9818159937858582,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.4798215329647064,
            "eval_matthews_correlation": 0.5627305137323906,
            "eval_runtime": 0.3971,
            "eval_samples_per_second": 2626.746,
            "eval_steps_per_second": 22.666,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3319,
            "grad_norm": 0.8996806740760803,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.47854676842689514,
            "eval_matthews_correlation": 0.5650459791482846,
            "eval_runtime": 0.2653,
            "eval_samples_per_second": 3931.38,
            "eval_steps_per_second": 33.924,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.3326,
            "grad_norm": 1.6867080926895142,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.4835597574710846,
            "eval_matthews_correlation": 0.565579540997454,
            "eval_runtime": 0.351,
            "eval_samples_per_second": 2971.58,
            "eval_steps_per_second": 25.642,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.3257,
            "grad_norm": 1.0748417377471924,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.46824294328689575,
            "eval_matthews_correlation": 0.5675517176765141,
            "eval_runtime": 0.3627,
            "eval_samples_per_second": 2875.627,
            "eval_steps_per_second": 24.814,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 845.3272,
            "train_samples_per_second": 1011.561,
            "train_steps_per_second": 7.926,
            "total_flos": 4.097176535826432e+16,
            "train_loss": 0.4705758682886759,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.42970529198646545,
            "eval_matthews_correlation": 0.5732046470010711,
            "eval_runtime": 0.2039,
            "eval_samples_per_second": 5116.429,
            "eval_steps_per_second": 44.149,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 845.3272,
        "trainable_params_count": 1.182338,
        "memory_allocated": [
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}