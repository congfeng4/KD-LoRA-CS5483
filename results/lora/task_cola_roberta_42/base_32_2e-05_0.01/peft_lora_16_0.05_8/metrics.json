{
    "eval_loss": 0.667490541934967,
    "eval_matthews_correlation": 0.5907675928559818,
    "eval_runtime": 0.2243,
    "eval_samples_per_second": 4650.484,
    "eval_steps_per_second": 40.129,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.6383,
            "grad_norm": 0.5814316272735596,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5704867243766785,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4127,
            "eval_samples_per_second": 2527.457,
            "eval_steps_per_second": 21.809,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.455,
            "grad_norm": 2.0860254764556885,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4640076756477356,
            "eval_matthews_correlation": 0.49162305109049664,
            "eval_runtime": 0.4727,
            "eval_samples_per_second": 2206.603,
            "eval_steps_per_second": 19.041,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3949,
            "grad_norm": 1.210541009902954,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5066285729408264,
            "eval_matthews_correlation": 0.49380076678433954,
            "eval_runtime": 0.2283,
            "eval_samples_per_second": 4568.524,
            "eval_steps_per_second": 39.422,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3547,
            "grad_norm": 1.9123775959014893,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4827764332294464,
            "eval_matthews_correlation": 0.5364128958265776,
            "eval_runtime": 0.4484,
            "eval_samples_per_second": 2326.287,
            "eval_steps_per_second": 20.073,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3299,
            "grad_norm": 1.5923621654510498,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5160432457923889,
            "eval_matthews_correlation": 0.5547291984984687,
            "eval_runtime": 0.3008,
            "eval_samples_per_second": 3467.452,
            "eval_steps_per_second": 29.92,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2935,
            "grad_norm": 3.207361936569214,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4768029451370239,
            "eval_matthews_correlation": 0.5701365244041533,
            "eval_runtime": 0.3704,
            "eval_samples_per_second": 2815.826,
            "eval_steps_per_second": 24.298,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.266,
            "grad_norm": 1.6673622131347656,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4659385085105896,
            "eval_matthews_correlation": 0.5905946226995304,
            "eval_runtime": 0.4062,
            "eval_samples_per_second": 2567.743,
            "eval_steps_per_second": 22.157,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2476,
            "grad_norm": 2.5700795650482178,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5159724950790405,
            "eval_matthews_correlation": 0.5650034395953757,
            "eval_runtime": 0.2341,
            "eval_samples_per_second": 4454.96,
            "eval_steps_per_second": 38.442,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2245,
            "grad_norm": 2.616515636444092,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5628537535667419,
            "eval_matthews_correlation": 0.5803450615832939,
            "eval_runtime": 0.4032,
            "eval_samples_per_second": 2586.925,
            "eval_steps_per_second": 22.322,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2102,
            "grad_norm": 3.001598596572876,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.5535883903503418,
            "eval_matthews_correlation": 0.5881989399089292,
            "eval_runtime": 0.3594,
            "eval_samples_per_second": 2901.959,
            "eval_steps_per_second": 25.041,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1897,
            "grad_norm": 7.625283241271973,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7482255101203918,
            "eval_matthews_correlation": 0.5391901684255385,
            "eval_runtime": 0.3831,
            "eval_samples_per_second": 2722.857,
            "eval_steps_per_second": 23.495,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1788,
            "grad_norm": 2.27418851852417,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.667490541934967,
            "eval_matthews_correlation": 0.5907675928559818,
            "eval_runtime": 0.2092,
            "eval_samples_per_second": 4985.077,
            "eval_steps_per_second": 43.016,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 322.7173,
            "train_samples_per_second": 2649.688,
            "train_steps_per_second": 20.761,
            "total_flos": 2.0416209182785536e+16,
            "train_loss": 0.3152468951543172,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.667490541934967,
            "eval_matthews_correlation": 0.5907675928559818,
            "eval_runtime": 0.2243,
            "eval_samples_per_second": 4650.484,
            "eval_steps_per_second": 40.129,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 322.7173,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184
        ],
        "memory_reserved": [
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176
        ]
    },
    "variant": "lora"
}