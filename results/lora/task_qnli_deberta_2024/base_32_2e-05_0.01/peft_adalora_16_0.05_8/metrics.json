{
    "eval_loss": 0.6931198835372925,
    "eval_accuracy": 0.5824638477027274,
    "eval_runtime": 2.4269,
    "eval_samples_per_second": 2250.997,
    "eval_steps_per_second": 17.718,
    "epoch": 3.907203907203907,
    "log_history": [
        {
            "loss": 2.0762,
            "grad_norm": 0.24447569251060486,
            "learning_rate": 4.8840048840048845e-06,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "eval_loss": 2.0599265098571777,
            "eval_accuracy": 0.4946000366099213,
            "eval_runtime": 2.5532,
            "eval_samples_per_second": 2139.651,
            "eval_steps_per_second": 16.841,
            "epoch": 0.2442002442002442,
            "step": 200
        },
        {
            "loss": 2.025,
            "grad_norm": 0.28274330496788025,
            "learning_rate": 9.768009768009769e-06,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "eval_loss": 1.977630376815796,
            "eval_accuracy": 0.5118066996155958,
            "eval_runtime": 2.5926,
            "eval_samples_per_second": 2107.144,
            "eval_steps_per_second": 16.586,
            "epoch": 0.4884004884004884,
            "step": 400
        },
        {
            "loss": 1.9056,
            "grad_norm": 0.19268274307250977,
            "learning_rate": 1.4652014652014653e-05,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "eval_loss": 1.8135133981704712,
            "eval_accuracy": 0.5248032216730734,
            "eval_runtime": 2.6859,
            "eval_samples_per_second": 2033.928,
            "eval_steps_per_second": 16.009,
            "epoch": 0.7326007326007326,
            "step": 600
        },
        {
            "loss": 1.6794,
            "grad_norm": 0.7727433443069458,
            "learning_rate": 1.9536019536019538e-05,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "eval_loss": 1.5145084857940674,
            "eval_accuracy": 0.5286472634083836,
            "eval_runtime": 2.5959,
            "eval_samples_per_second": 2104.439,
            "eval_steps_per_second": 16.564,
            "epoch": 0.9768009768009768,
            "step": 800
        },
        {
            "loss": 1.2848,
            "grad_norm": 0.31298747658729553,
            "learning_rate": 2.442002442002442e-05,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "eval_loss": 1.0108513832092285,
            "eval_accuracy": 0.5198608822991031,
            "eval_runtime": 2.2411,
            "eval_samples_per_second": 2437.681,
            "eval_steps_per_second": 19.187,
            "epoch": 1.221001221001221,
            "step": 1000
        },
        {
            "loss": 0.7719,
            "grad_norm": 0.4421572983264923,
            "learning_rate": 2.9304029304029305e-05,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "eval_loss": 0.6935475468635559,
            "eval_accuracy": 0.5057660626029654,
            "eval_runtime": 2.0823,
            "eval_samples_per_second": 2623.602,
            "eval_steps_per_second": 20.651,
            "epoch": 1.4652014652014653,
            "step": 1200
        },
        {
            "loss": 0.6937,
            "grad_norm": 0.5230743288993835,
            "learning_rate": 3.418803418803419e-05,
            "epoch": 1.7094017094017095,
            "step": 1400
        },
        {
            "eval_loss": 0.6932269930839539,
            "eval_accuracy": 0.5531759106717921,
            "eval_runtime": 2.0733,
            "eval_samples_per_second": 2634.992,
            "eval_steps_per_second": 20.74,
            "epoch": 1.7094017094017095,
            "step": 1400
        },
        {
            "loss": 0.6942,
            "grad_norm": 0.2509227693080902,
            "learning_rate": 3.9072039072039076e-05,
            "epoch": 1.9536019536019538,
            "step": 1600
        },
        {
            "eval_loss": 0.6934294700622559,
            "eval_accuracy": 0.49478308621636463,
            "eval_runtime": 2.0358,
            "eval_samples_per_second": 2683.444,
            "eval_steps_per_second": 21.122,
            "epoch": 1.9536019536019538,
            "step": 1600
        },
        {
            "loss": 0.694,
            "grad_norm": 0.3664192855358124,
            "learning_rate": 4.3956043956043955e-05,
            "epoch": 2.197802197802198,
            "step": 1800
        },
        {
            "eval_loss": 0.693156898021698,
            "eval_accuracy": 0.5053999633900788,
            "eval_runtime": 2.237,
            "eval_samples_per_second": 2442.149,
            "eval_steps_per_second": 19.222,
            "epoch": 2.197802197802198,
            "step": 1800
        },
        {
            "loss": 0.6937,
            "grad_norm": 0.2207505851984024,
            "learning_rate": 4.884004884004884e-05,
            "epoch": 2.442002442002442,
            "step": 2000
        },
        {
            "eval_loss": 0.6930385828018188,
            "eval_accuracy": 0.5544572579168955,
            "eval_runtime": 2.5055,
            "eval_samples_per_second": 2180.415,
            "eval_steps_per_second": 17.162,
            "epoch": 2.442002442002442,
            "step": 2000
        },
        {
            "loss": 0.6937,
            "grad_norm": 0.31696832180023193,
            "learning_rate": 5.3724053724053725e-05,
            "epoch": 2.6862026862026864,
            "step": 2200
        },
        {
            "eval_loss": 0.6931198835372925,
            "eval_accuracy": 0.5824638477027274,
            "eval_runtime": 2.5745,
            "eval_samples_per_second": 2121.994,
            "eval_steps_per_second": 16.702,
            "epoch": 2.6862026862026864,
            "step": 2200
        },
        {
            "loss": 0.6936,
            "grad_norm": 0.5943665504455566,
            "learning_rate": 5.860805860805861e-05,
            "epoch": 2.9304029304029307,
            "step": 2400
        },
        {
            "eval_loss": 0.6932377815246582,
            "eval_accuracy": 0.49478308621636463,
            "eval_runtime": 2.3437,
            "eval_samples_per_second": 2330.922,
            "eval_steps_per_second": 18.347,
            "epoch": 2.9304029304029307,
            "step": 2400
        },
        {
            "loss": 0.6934,
            "grad_norm": 0.41760385036468506,
            "learning_rate": 6.349206349206349e-05,
            "epoch": 3.1746031746031744,
            "step": 2600
        },
        {
            "eval_loss": 0.6929389834403992,
            "eval_accuracy": 0.49606443346146806,
            "eval_runtime": 2.778,
            "eval_samples_per_second": 1966.519,
            "eval_steps_per_second": 15.479,
            "epoch": 3.1746031746031744,
            "step": 2600
        },
        {
            "loss": 0.6935,
            "grad_norm": 0.36837753653526306,
            "learning_rate": 6.837606837606838e-05,
            "epoch": 3.4188034188034186,
            "step": 2800
        },
        {
            "eval_loss": 0.6928302645683289,
            "eval_accuracy": 0.5053999633900788,
            "eval_runtime": 2.5994,
            "eval_samples_per_second": 2101.665,
            "eval_steps_per_second": 16.542,
            "epoch": 3.4188034188034186,
            "step": 2800
        },
        {
            "loss": 0.6939,
            "grad_norm": 0.39612388610839844,
            "learning_rate": 7.326007326007326e-05,
            "epoch": 3.663003663003663,
            "step": 3000
        },
        {
            "eval_loss": 0.6931247711181641,
            "eval_accuracy": 0.49478308621636463,
            "eval_runtime": 2.6686,
            "eval_samples_per_second": 2047.163,
            "eval_steps_per_second": 16.113,
            "epoch": 3.663003663003663,
            "step": 3000
        },
        {
            "loss": 0.6933,
            "grad_norm": 0.2959808111190796,
            "learning_rate": 7.814407814407815e-05,
            "epoch": 3.907203907203907,
            "step": 3200
        },
        {
            "eval_loss": 0.6929261684417725,
            "eval_accuracy": 0.49478308621636463,
            "eval_runtime": 2.6828,
            "eval_samples_per_second": 2036.301,
            "eval_steps_per_second": 16.028,
            "epoch": 3.907203907203907,
            "step": 3200
        },
        {
            "train_runtime": 869.7551,
            "train_samples_per_second": 12042.815,
            "train_steps_per_second": 94.164,
            "total_flos": 2.7129210317307904e+16,
            "train_loss": 1.0424881982803345,
            "epoch": 3.907203907203907,
            "step": 3200
        },
        {
            "eval_loss": 0.6931198835372925,
            "eval_accuracy": 0.5824638477027274,
            "eval_runtime": 2.4269,
            "eval_samples_per_second": 2250.997,
            "eval_steps_per_second": 17.718,
            "epoch": 3.907203907203907,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "qnli",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 104743
    },
    "train": {
        "train_time": 869.7551,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            767.344128,
            767.344128,
            767.344128,
            767.344128
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}