{
    "eval_loss": 0.5023590326309204,
    "eval_pearson": 0.8892696101973889,
    "eval_spearman": 0.8846683337893804,
    "eval_runtime": 0.5674,
    "eval_samples_per_second": 2643.799,
    "eval_steps_per_second": 21.15,
    "epoch": 44.44444444444444,
    "log_history": [
        {
            "loss": 4.2196,
            "grad_norm": 9.518224716186523,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.5420297384262085,
            "eval_pearson": 0.8717477411281033,
            "eval_spearman": 0.8703199628191458,
            "eval_runtime": 0.6442,
            "eval_samples_per_second": 2328.503,
            "eval_steps_per_second": 18.628,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.5433,
            "grad_norm": 15.441364288330078,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.49081742763519287,
            "eval_pearson": 0.8878323090581424,
            "eval_spearman": 0.8854800221601377,
            "eval_runtime": 0.6372,
            "eval_samples_per_second": 2353.977,
            "eval_steps_per_second": 18.832,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.3969,
            "grad_norm": 3.565300941467285,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.506964921951294,
            "eval_pearson": 0.8845676878387123,
            "eval_spearman": 0.8832747755843713,
            "eval_runtime": 0.5996,
            "eval_samples_per_second": 2501.713,
            "eval_steps_per_second": 20.014,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3145,
            "grad_norm": 6.350852966308594,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5002061724662781,
            "eval_pearson": 0.8875906821684272,
            "eval_spearman": 0.8837917951517157,
            "eval_runtime": 0.5893,
            "eval_samples_per_second": 2545.494,
            "eval_steps_per_second": 20.364,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.2583,
            "grad_norm": 3.666097402572632,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.4764834940433502,
            "eval_pearson": 0.889065794575713,
            "eval_spearman": 0.8867228287108588,
            "eval_runtime": 0.6141,
            "eval_samples_per_second": 2442.488,
            "eval_steps_per_second": 19.54,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.2141,
            "grad_norm": 4.554316520690918,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4911966919898987,
            "eval_pearson": 0.8870972754673612,
            "eval_spearman": 0.8846411264185897,
            "eval_runtime": 0.5616,
            "eval_samples_per_second": 2670.704,
            "eval_steps_per_second": 21.366,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.1889,
            "grad_norm": 3.5392260551452637,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.48532339930534363,
            "eval_pearson": 0.8889981155721454,
            "eval_spearman": 0.8850085195481109,
            "eval_runtime": 0.6298,
            "eval_samples_per_second": 2381.629,
            "eval_steps_per_second": 19.053,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.1659,
            "grad_norm": 4.10325813293457,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5101710557937622,
            "eval_pearson": 0.8885511386122549,
            "eval_spearman": 0.8850187215422111,
            "eval_runtime": 0.5786,
            "eval_samples_per_second": 2592.261,
            "eval_steps_per_second": 20.738,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.1539,
            "grad_norm": 3.4429385662078857,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.511351466178894,
            "eval_pearson": 0.8895837043567514,
            "eval_spearman": 0.8859672163608784,
            "eval_runtime": 0.5874,
            "eval_samples_per_second": 2553.447,
            "eval_steps_per_second": 20.428,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.1411,
            "grad_norm": 3.834294080734253,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.4988201856613159,
            "eval_pearson": 0.8898523988459568,
            "eval_spearman": 0.8847869446755979,
            "eval_runtime": 0.4729,
            "eval_samples_per_second": 3171.688,
            "eval_steps_per_second": 25.374,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "train_runtime": 339.2139,
            "train_samples_per_second": 1694.801,
            "train_steps_per_second": 13.266,
            "total_flos": 1.689711806513152e+16,
            "train_loss": 0.6596505718231201,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5023590326309204,
            "eval_pearson": 0.8892696101973889,
            "eval_spearman": 0.8846683337893804,
            "eval_runtime": 0.5674,
            "eval_samples_per_second": 2643.799,
            "eval_steps_per_second": 21.15,
            "epoch": 44.44444444444444,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 5749
    },
    "train": {
        "train_time": 339.2139,
        "trainable_params_count": 0.295753,
        "memory_allocated": [
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136,
            462.171136
        ],
        "memory_reserved": [
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336
        ]
    },
    "variant": "lora"
}