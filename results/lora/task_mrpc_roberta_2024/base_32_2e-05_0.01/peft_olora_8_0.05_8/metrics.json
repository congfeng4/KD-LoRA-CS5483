{
    "eval_loss": 0.5309698581695557,
    "eval_accuracy": 0.8897058823529411,
    "eval_f1": 0.9225473321858865,
    "eval_runtime": 0.0873,
    "eval_samples_per_second": 4674.698,
    "eval_steps_per_second": 45.83,
    "epoch": 68.96551724137932,
    "log_history": [
        {
            "loss": 0.6237,
            "grad_norm": 1.74496328830719,
            "learning_rate": 0.00013793103448275863,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.513967752456665,
            "eval_accuracy": 0.7279411764705882,
            "eval_f1": 0.8279069767441861,
            "eval_runtime": 0.1559,
            "eval_samples_per_second": 2617.771,
            "eval_steps_per_second": 25.664,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.3799,
            "grad_norm": 1.045870304107666,
            "learning_rate": 0.00019157088122605365,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.3371328115463257,
            "eval_accuracy": 0.8676470588235294,
            "eval_f1": 0.9052631578947367,
            "eval_runtime": 0.2259,
            "eval_samples_per_second": 1806.43,
            "eval_steps_per_second": 17.71,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.2376,
            "grad_norm": 5.915677547454834,
            "learning_rate": 0.00017624521072796937,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.3920166790485382,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9068541300527241,
            "eval_runtime": 0.1518,
            "eval_samples_per_second": 2687.196,
            "eval_steps_per_second": 26.345,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.1696,
            "grad_norm": 3.133977174758911,
            "learning_rate": 0.00016091954022988506,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.3888561427593231,
            "eval_accuracy": 0.8725490196078431,
            "eval_f1": 0.9081272084805654,
            "eval_runtime": 0.2255,
            "eval_samples_per_second": 1809.507,
            "eval_steps_per_second": 17.74,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.1344,
            "grad_norm": 2.5201778411865234,
            "learning_rate": 0.00014559386973180078,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.5309698581695557,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9225473321858865,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 2549.759,
            "eval_steps_per_second": 24.998,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.0893,
            "grad_norm": 3.1511051654815674,
            "learning_rate": 0.00013026819923371647,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.4990600049495697,
            "eval_accuracy": 0.8823529411764706,
            "eval_f1": 0.9139784946236559,
            "eval_runtime": 0.2268,
            "eval_samples_per_second": 1799.218,
            "eval_steps_per_second": 17.639,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.0693,
            "grad_norm": 0.8189265727996826,
            "learning_rate": 0.00011494252873563218,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.5907015204429626,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9217391304347826,
            "eval_runtime": 0.2426,
            "eval_samples_per_second": 1681.797,
            "eval_steps_per_second": 16.488,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.0552,
            "grad_norm": 5.723437309265137,
            "learning_rate": 9.96168582375479e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.5630446076393127,
            "eval_accuracy": 0.8872549019607843,
            "eval_f1": 0.9190140845070423,
            "eval_runtime": 0.1578,
            "eval_samples_per_second": 2584.888,
            "eval_steps_per_second": 25.342,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.0405,
            "grad_norm": 1.9822328090667725,
            "learning_rate": 8.42911877394636e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.6437207460403442,
            "eval_accuracy": 0.8848039215686274,
            "eval_f1": 0.9176882661996497,
            "eval_runtime": 0.2307,
            "eval_samples_per_second": 1768.724,
            "eval_steps_per_second": 17.34,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.0386,
            "grad_norm": 0.944898784160614,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.7878876328468323,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.922279792746114,
            "eval_runtime": 0.2332,
            "eval_samples_per_second": 1749.233,
            "eval_steps_per_second": 17.149,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "train_runtime": 279.2801,
            "train_samples_per_second": 1313.377,
            "train_steps_per_second": 10.384,
            "total_flos": 1.701350765232128e+16,
            "train_loss": 0.18382363843917846,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.5309698581695557,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9225473321858865,
            "eval_runtime": 0.0873,
            "eval_samples_per_second": 4674.698,
            "eval_steps_per_second": 45.83,
            "epoch": 68.96551724137932,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 3668
    },
    "train": {
        "train_time": 279.2801,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904,
            532.75904
        ],
        "memory_reserved": [
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872,
            2067.791872
        ]
    },
    "variant": "lora"
}