{
    "eval_loss": 0.46499526500701904,
    "eval_matthews_correlation": 0.5449141719492956,
    "eval_runtime": 0.3413,
    "eval_samples_per_second": 3055.73,
    "eval_steps_per_second": 26.368,
    "epoch": 80.59701492537313,
    "log_history": [
        {
            "loss": 1.8701,
            "grad_norm": 0.4670509397983551,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.454896330833435,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3532,
            "eval_samples_per_second": 2953.107,
            "eval_steps_per_second": 25.482,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.815,
            "grad_norm": 0.674823522567749,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.608328104019165,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3558,
            "eval_samples_per_second": 2931.124,
            "eval_steps_per_second": 25.293,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5918,
            "grad_norm": 0.39291712641716003,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5984176993370056,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3731,
            "eval_samples_per_second": 2795.322,
            "eval_steps_per_second": 24.121,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5833,
            "grad_norm": 0.7478491067886353,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5891851186752319,
            "eval_matthews_correlation": 0.11382192951310593,
            "eval_runtime": 0.395,
            "eval_samples_per_second": 2640.339,
            "eval_steps_per_second": 22.783,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.5639,
            "grad_norm": 0.6584731936454773,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5681159496307373,
            "eval_matthews_correlation": 0.26535226451661237,
            "eval_runtime": 0.4514,
            "eval_samples_per_second": 2310.716,
            "eval_steps_per_second": 19.939,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.515,
            "grad_norm": 0.6499489545822144,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.49630793929100037,
            "eval_matthews_correlation": 0.4300679389836819,
            "eval_runtime": 0.4979,
            "eval_samples_per_second": 2095.002,
            "eval_steps_per_second": 18.078,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4878,
            "grad_norm": 0.5174208879470825,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.49357661604881287,
            "eval_matthews_correlation": 0.4357053256431942,
            "eval_runtime": 0.289,
            "eval_samples_per_second": 3609.505,
            "eval_steps_per_second": 31.146,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4723,
            "grad_norm": 0.5584637522697449,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.49189847707748413,
            "eval_matthews_correlation": 0.4358463897570972,
            "eval_runtime": 0.3281,
            "eval_samples_per_second": 3178.528,
            "eval_steps_per_second": 27.427,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.457,
            "grad_norm": 0.6643721461296082,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4777272641658783,
            "eval_matthews_correlation": 0.4636597773604369,
            "eval_runtime": 0.3454,
            "eval_samples_per_second": 3019.386,
            "eval_steps_per_second": 26.054,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.4472,
            "grad_norm": 0.8593792915344238,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.4699845314025879,
            "eval_matthews_correlation": 0.4802459822027615,
            "eval_runtime": 0.4305,
            "eval_samples_per_second": 2422.968,
            "eval_steps_per_second": 20.908,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4345,
            "grad_norm": 1.128517746925354,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4501122236251831,
            "eval_matthews_correlation": 0.4938538761601623,
            "eval_runtime": 0.3869,
            "eval_samples_per_second": 2695.967,
            "eval_steps_per_second": 23.263,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.421,
            "grad_norm": 0.6601896286010742,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.4591795802116394,
            "eval_matthews_correlation": 0.4994543232175365,
            "eval_runtime": 0.3158,
            "eval_samples_per_second": 3302.804,
            "eval_steps_per_second": 28.5,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4184,
            "grad_norm": 1.233846664428711,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.47621074318885803,
            "eval_matthews_correlation": 0.518818601771926,
            "eval_runtime": 0.3295,
            "eval_samples_per_second": 3165.029,
            "eval_steps_per_second": 27.311,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.412,
            "grad_norm": 0.9269182682037354,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4675257205963135,
            "eval_matthews_correlation": 0.5158001386531648,
            "eval_runtime": 0.3672,
            "eval_samples_per_second": 2840.782,
            "eval_steps_per_second": 24.513,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4061,
            "grad_norm": 0.4804684817790985,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.4725777506828308,
            "eval_matthews_correlation": 0.5106306596485645,
            "eval_runtime": 0.3288,
            "eval_samples_per_second": 3172.045,
            "eval_steps_per_second": 27.371,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.401,
            "grad_norm": 0.5692979097366333,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4621333181858063,
            "eval_matthews_correlation": 0.5075232924597609,
            "eval_runtime": 0.2952,
            "eval_samples_per_second": 3533.762,
            "eval_steps_per_second": 30.493,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3955,
            "grad_norm": 0.7452698349952698,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.48702773451805115,
            "eval_matthews_correlation": 0.5068375331988826,
            "eval_runtime": 0.3091,
            "eval_samples_per_second": 3374.035,
            "eval_steps_per_second": 29.114,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3879,
            "grad_norm": 0.6487315893173218,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.4555389881134033,
            "eval_matthews_correlation": 0.5206026837066519,
            "eval_runtime": 0.3344,
            "eval_samples_per_second": 3119.142,
            "eval_steps_per_second": 26.915,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3828,
            "grad_norm": 0.6449369788169861,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.43074697256088257,
            "eval_matthews_correlation": 0.5418104520202982,
            "eval_runtime": 0.3318,
            "eval_samples_per_second": 3143.641,
            "eval_steps_per_second": 27.126,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3796,
            "grad_norm": 0.6123638153076172,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.44326457381248474,
            "eval_matthews_correlation": 0.5285368344613508,
            "eval_runtime": 0.3433,
            "eval_samples_per_second": 3038.595,
            "eval_steps_per_second": 26.22,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3772,
            "grad_norm": 0.7601523995399475,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.44844502210617065,
            "eval_matthews_correlation": 0.5338269593815457,
            "eval_runtime": 0.3992,
            "eval_samples_per_second": 2612.576,
            "eval_steps_per_second": 22.544,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3701,
            "grad_norm": 0.5670296549797058,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.46499526500701904,
            "eval_matthews_correlation": 0.5449141719492956,
            "eval_runtime": 0.2931,
            "eval_samples_per_second": 3558.279,
            "eval_steps_per_second": 30.704,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.3709,
            "grad_norm": 1.532541036605835,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.4492762088775635,
            "eval_matthews_correlation": 0.5364214937932232,
            "eval_runtime": 0.3389,
            "eval_samples_per_second": 3077.432,
            "eval_steps_per_second": 26.555,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.3651,
            "grad_norm": 1.1563153266906738,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.45108553767204285,
            "eval_matthews_correlation": 0.5444111532535151,
            "eval_runtime": 0.4925,
            "eval_samples_per_second": 2117.979,
            "eval_steps_per_second": 18.276,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.3627,
            "grad_norm": 0.555937647819519,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4672289490699768,
            "eval_matthews_correlation": 0.5392832081618074,
            "eval_runtime": 0.2979,
            "eval_samples_per_second": 3501.677,
            "eval_steps_per_second": 30.216,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.3574,
            "grad_norm": 1.4375498294830322,
            "learning_rate": 4.975124378109453e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.4491228461265564,
            "eval_matthews_correlation": 0.5365057053910051,
            "eval_runtime": 0.3449,
            "eval_samples_per_second": 3024.043,
            "eval_steps_per_second": 26.094,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.3574,
            "grad_norm": 0.6432867646217346,
            "learning_rate": 4.311774461028192e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 0.45078128576278687,
            "eval_matthews_correlation": 0.5416549448511832,
            "eval_runtime": 0.3455,
            "eval_samples_per_second": 3018.507,
            "eval_steps_per_second": 26.047,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "train_runtime": 720.2193,
            "train_samples_per_second": 1187.277,
            "train_steps_per_second": 9.303,
            "total_flos": 4.577972703775949e+16,
            "train_loss": 0.4964101424040618,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 0.46499526500701904,
            "eval_matthews_correlation": 0.5449141719492956,
            "eval_runtime": 0.3413,
            "eval_samples_per_second": 3055.73,
            "eval_steps_per_second": 26.368,
            "epoch": 80.59701492537313,
            "step": 5400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 720.2193,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}