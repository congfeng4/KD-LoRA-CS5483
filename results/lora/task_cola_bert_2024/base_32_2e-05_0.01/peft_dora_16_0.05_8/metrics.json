{
    "eval_loss": 0.6361843347549438,
    "eval_matthews_correlation": 0.5934998758283692,
    "eval_runtime": 0.354,
    "eval_samples_per_second": 2946.063,
    "eval_steps_per_second": 25.421,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 0.6358,
            "grad_norm": 0.5788900852203369,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5786103010177612,
            "eval_matthews_correlation": 0.09353849894114569,
            "eval_runtime": 0.334,
            "eval_samples_per_second": 3122.889,
            "eval_steps_per_second": 26.947,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4845,
            "grad_norm": 0.8547218441963196,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4742599427700043,
            "eval_matthews_correlation": 0.48860737465469095,
            "eval_runtime": 0.3121,
            "eval_samples_per_second": 3341.975,
            "eval_steps_per_second": 28.838,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.41,
            "grad_norm": 0.7741339802742004,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4586988091468811,
            "eval_matthews_correlation": 0.5339494412838712,
            "eval_runtime": 0.3799,
            "eval_samples_per_second": 2745.251,
            "eval_steps_per_second": 23.689,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.358,
            "grad_norm": 2.3574724197387695,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4384784996509552,
            "eval_matthews_correlation": 0.5755298089385917,
            "eval_runtime": 0.3604,
            "eval_samples_per_second": 2893.727,
            "eval_steps_per_second": 24.97,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3131,
            "grad_norm": 1.1081838607788086,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4590506851673126,
            "eval_matthews_correlation": 0.544301235611677,
            "eval_runtime": 0.4119,
            "eval_samples_per_second": 2532.023,
            "eval_steps_per_second": 21.849,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2762,
            "grad_norm": 1.0774983167648315,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4405977427959442,
            "eval_matthews_correlation": 0.5595884617444483,
            "eval_runtime": 0.3962,
            "eval_samples_per_second": 2632.451,
            "eval_steps_per_second": 22.715,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2425,
            "grad_norm": 2.0240631103515625,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5353850722312927,
            "eval_matthews_correlation": 0.5778482239390005,
            "eval_runtime": 0.2591,
            "eval_samples_per_second": 4025.892,
            "eval_steps_per_second": 34.739,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.224,
            "grad_norm": 2.6489222049713135,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.584526777267456,
            "eval_matthews_correlation": 0.5521390429003941,
            "eval_runtime": 0.4214,
            "eval_samples_per_second": 2474.929,
            "eval_steps_per_second": 21.356,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2011,
            "grad_norm": 2.0596396923065186,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5243391990661621,
            "eval_matthews_correlation": 0.5917933256968625,
            "eval_runtime": 0.3888,
            "eval_samples_per_second": 2682.785,
            "eval_steps_per_second": 23.15,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1872,
            "grad_norm": 1.8717167377471924,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.552738606929779,
            "eval_matthews_correlation": 0.5783323107334525,
            "eval_runtime": 0.3869,
            "eval_samples_per_second": 2695.606,
            "eval_steps_per_second": 23.26,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1709,
            "grad_norm": 3.0289671421051025,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6483109593391418,
            "eval_matthews_correlation": 0.5494767866076017,
            "eval_runtime": 0.4445,
            "eval_samples_per_second": 2346.666,
            "eval_steps_per_second": 20.249,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1484,
            "grad_norm": 1.7645336389541626,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6107915043830872,
            "eval_matthews_correlation": 0.5709406887467645,
            "eval_runtime": 0.2877,
            "eval_samples_per_second": 3624.86,
            "eval_steps_per_second": 31.279,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1428,
            "grad_norm": 3.0707757472991943,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.6361843347549438,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.4054,
            "eval_samples_per_second": 2572.71,
            "eval_steps_per_second": 22.2,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1391,
            "grad_norm": 2.0851943492889404,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.6502938866615295,
            "eval_matthews_correlation": 0.5678267214677118,
            "eval_runtime": 0.4115,
            "eval_samples_per_second": 2534.828,
            "eval_steps_per_second": 21.873,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1211,
            "grad_norm": 1.0543192625045776,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.7146162986755371,
            "eval_matthews_correlation": 0.567550266689718,
            "eval_runtime": 0.3115,
            "eval_samples_per_second": 3348.747,
            "eval_steps_per_second": 28.896,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1199,
            "grad_norm": 3.569070816040039,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.7278174757957458,
            "eval_matthews_correlation": 0.5676145457477023,
            "eval_runtime": 0.3696,
            "eval_samples_per_second": 2821.685,
            "eval_steps_per_second": 24.348,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1122,
            "grad_norm": 1.9519057273864746,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.7392734885215759,
            "eval_matthews_correlation": 0.5677601756676588,
            "eval_runtime": 0.4011,
            "eval_samples_per_second": 2600.125,
            "eval_steps_per_second": 22.436,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1062,
            "grad_norm": 2.4083309173583984,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.7554448843002319,
            "eval_matthews_correlation": 0.5627305137323906,
            "eval_runtime": 0.3514,
            "eval_samples_per_second": 2967.794,
            "eval_steps_per_second": 25.609,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 444.9233,
            "train_samples_per_second": 1921.904,
            "train_steps_per_second": 15.059,
            "total_flos": 3.042182834631475e+16,
            "train_loss": 0.244053332540724,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.6361843347549438,
            "eval_matthews_correlation": 0.5934998758283692,
            "eval_runtime": 0.354,
            "eval_samples_per_second": 2946.063,
            "eval_steps_per_second": 25.421,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 444.9233,
        "trainable_params_count": 0.314882,
        "memory_allocated": [
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744,
            463.071744
        ],
        "memory_reserved": [
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568,
            2325.741568
        ]
    },
    "variant": "lora"
}