{
    "eval_loss": 0.8622751832008362,
    "eval_matthews_correlation": 0.5981951351808346,
    "eval_runtime": 0.4266,
    "eval_samples_per_second": 2444.861,
    "eval_steps_per_second": 21.097,
    "epoch": 56.71641791044776,
    "log_history": [
        {
            "loss": 0.5973,
            "grad_norm": 4.9508867263793945,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.45597440004348755,
            "eval_matthews_correlation": 0.47327984593922173,
            "eval_runtime": 0.4471,
            "eval_samples_per_second": 2332.935,
            "eval_steps_per_second": 20.131,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4249,
            "grad_norm": 5.320578098297119,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.42245200276374817,
            "eval_matthews_correlation": 0.55727640631709,
            "eval_runtime": 0.3613,
            "eval_samples_per_second": 2887.177,
            "eval_steps_per_second": 24.913,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.378,
            "grad_norm": 5.930917263031006,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4308447539806366,
            "eval_matthews_correlation": 0.5647660677080502,
            "eval_runtime": 0.3585,
            "eval_samples_per_second": 2909.271,
            "eval_steps_per_second": 25.104,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3368,
            "grad_norm": 3.7059617042541504,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4598250985145569,
            "eval_matthews_correlation": 0.5807606001872874,
            "eval_runtime": 0.4283,
            "eval_samples_per_second": 2435.157,
            "eval_steps_per_second": 21.013,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2855,
            "grad_norm": 2.562969923019409,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5103946924209595,
            "eval_matthews_correlation": 0.6009835084035468,
            "eval_runtime": 0.3589,
            "eval_samples_per_second": 2905.93,
            "eval_steps_per_second": 25.075,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2425,
            "grad_norm": 3.69625186920166,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5392734408378601,
            "eval_matthews_correlation": 0.5808909972587557,
            "eval_runtime": 0.4015,
            "eval_samples_per_second": 2597.911,
            "eval_steps_per_second": 22.417,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2114,
            "grad_norm": 4.493875980377197,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.684249997138977,
            "eval_matthews_correlation": 0.5850762103185296,
            "eval_runtime": 0.4179,
            "eval_samples_per_second": 2496.045,
            "eval_steps_per_second": 21.538,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1825,
            "grad_norm": 6.7130584716796875,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.7551162838935852,
            "eval_matthews_correlation": 0.5596416792460465,
            "eval_runtime": 0.4282,
            "eval_samples_per_second": 2435.987,
            "eval_steps_per_second": 21.02,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1571,
            "grad_norm": 4.693162441253662,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.7383294105529785,
            "eval_matthews_correlation": 0.5650034395953757,
            "eval_runtime": 0.4333,
            "eval_samples_per_second": 2407.245,
            "eval_steps_per_second": 20.772,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1397,
            "grad_norm": 6.7156147956848145,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6699405312538147,
            "eval_matthews_correlation": 0.606599116735104,
            "eval_runtime": 0.4182,
            "eval_samples_per_second": 2494.06,
            "eval_steps_per_second": 21.521,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1242,
            "grad_norm": 1.8085427284240723,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6857926249504089,
            "eval_matthews_correlation": 0.6006236595789939,
            "eval_runtime": 0.6986,
            "eval_samples_per_second": 1492.887,
            "eval_steps_per_second": 12.882,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1097,
            "grad_norm": 6.422305583953857,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.797989547252655,
            "eval_matthews_correlation": 0.5701181924229938,
            "eval_runtime": 0.387,
            "eval_samples_per_second": 2695.184,
            "eval_steps_per_second": 23.257,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1052,
            "grad_norm": 2.8007218837738037,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.7881895303726196,
            "eval_matthews_correlation": 0.5981451281520205,
            "eval_runtime": 0.3747,
            "eval_samples_per_second": 2783.567,
            "eval_steps_per_second": 24.019,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0956,
            "grad_norm": 8.313631057739258,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.7156595587730408,
            "eval_matthews_correlation": 0.6108743288323454,
            "eval_runtime": 0.4475,
            "eval_samples_per_second": 2330.805,
            "eval_steps_per_second": 20.112,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0805,
            "grad_norm": 6.7795562744140625,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.8135239481925964,
            "eval_matthews_correlation": 0.6061605762137284,
            "eval_runtime": 0.4426,
            "eval_samples_per_second": 2356.692,
            "eval_steps_per_second": 20.336,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.081,
            "grad_norm": 4.911215305328369,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.8600489497184753,
            "eval_matthews_correlation": 0.5931328329100475,
            "eval_runtime": 0.393,
            "eval_samples_per_second": 2654.027,
            "eval_steps_per_second": 22.901,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.07,
            "grad_norm": 3.4320173263549805,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.945665180683136,
            "eval_matthews_correlation": 0.5906042341193154,
            "eval_runtime": 0.4318,
            "eval_samples_per_second": 2415.591,
            "eval_steps_per_second": 20.844,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.069,
            "grad_norm": 6.644456386566162,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.9796305298805237,
            "eval_matthews_correlation": 0.5728803433047456,
            "eval_runtime": 0.4392,
            "eval_samples_per_second": 2375.037,
            "eval_steps_per_second": 20.494,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.0654,
            "grad_norm": 4.036808013916016,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.9159917235374451,
            "eval_matthews_correlation": 0.605839001376474,
            "eval_runtime": 0.4472,
            "eval_samples_per_second": 2332.077,
            "eval_steps_per_second": 20.123,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "train_runtime": 591.4456,
            "train_samples_per_second": 1445.78,
            "train_steps_per_second": 11.328,
            "total_flos": 3.2325718092283904e+16,
            "train_loss": 0.19771714260703638,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.8622751832008362,
            "eval_matthews_correlation": 0.5981951351808346,
            "eval_runtime": 0.4266,
            "eval_samples_per_second": 2444.861,
            "eval_steps_per_second": 21.097,
            "epoch": 56.71641791044776,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 591.4456,
        "trainable_params_count": 0.887114,
        "memory_allocated": [
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856,
            532.41856
        ],
        "memory_reserved": [
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808,
            2839.543808
        ]
    },
    "variant": "lora"
}