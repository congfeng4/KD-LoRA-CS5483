{
    "eval_loss": 0.42937132716178894,
    "eval_matthews_correlation": 0.5495093920893817,
    "eval_runtime": 0.256,
    "eval_samples_per_second": 4073.687,
    "eval_steps_per_second": 35.152,
    "epoch": 77.61194029850746,
    "log_history": [
        {
            "loss": 1.8944,
            "grad_norm": 1.3399326801300049,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4148365259170532,
            "eval_matthews_correlation": 0.018148342420931135,
            "eval_runtime": 0.2508,
            "eval_samples_per_second": 4159.35,
            "eval_steps_per_second": 35.891,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.7899,
            "grad_norm": 0.7769841551780701,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6079047322273254,
            "eval_matthews_correlation": 0.018148342420931135,
            "eval_runtime": 0.3301,
            "eval_samples_per_second": 3159.532,
            "eval_steps_per_second": 27.263,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5947,
            "grad_norm": 0.9468410015106201,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.6003608107566833,
            "eval_matthews_correlation": 0.018148342420931135,
            "eval_runtime": 0.419,
            "eval_samples_per_second": 2489.51,
            "eval_steps_per_second": 21.482,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5843,
            "grad_norm": 0.7122147083282471,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.590168297290802,
            "eval_matthews_correlation": 0.0928457264044978,
            "eval_runtime": 0.3512,
            "eval_samples_per_second": 2970.224,
            "eval_steps_per_second": 25.63,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.5744,
            "grad_norm": 0.7813025712966919,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5588241815567017,
            "eval_matthews_correlation": 0.24479119182687428,
            "eval_runtime": 0.3558,
            "eval_samples_per_second": 2931.818,
            "eval_steps_per_second": 25.299,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.5372,
            "grad_norm": 0.5155726671218872,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5233679413795471,
            "eval_matthews_correlation": 0.393387881425705,
            "eval_runtime": 0.5167,
            "eval_samples_per_second": 2018.727,
            "eval_steps_per_second": 17.42,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.5022,
            "grad_norm": 0.9056650400161743,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5078883171081543,
            "eval_matthews_correlation": 0.4070638887222338,
            "eval_runtime": 0.4092,
            "eval_samples_per_second": 2548.747,
            "eval_steps_per_second": 21.993,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4803,
            "grad_norm": 0.5148188471794128,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.4979911148548126,
            "eval_matthews_correlation": 0.41826917564803634,
            "eval_runtime": 0.3103,
            "eval_samples_per_second": 3361.559,
            "eval_steps_per_second": 29.007,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.4631,
            "grad_norm": 0.382372111082077,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.47966909408569336,
            "eval_matthews_correlation": 0.449682615733785,
            "eval_runtime": 0.412,
            "eval_samples_per_second": 2531.51,
            "eval_steps_per_second": 21.844,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.4513,
            "grad_norm": 0.8200094699859619,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.4892476797103882,
            "eval_matthews_correlation": 0.4673915300903121,
            "eval_runtime": 0.4992,
            "eval_samples_per_second": 2089.249,
            "eval_steps_per_second": 18.028,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4403,
            "grad_norm": 0.48716023564338684,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.47498026490211487,
            "eval_matthews_correlation": 0.48082075308138933,
            "eval_runtime": 0.2997,
            "eval_samples_per_second": 3479.842,
            "eval_steps_per_second": 30.027,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.4327,
            "grad_norm": 0.9236984848976135,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.48443135619163513,
            "eval_matthews_correlation": 0.48239382723457414,
            "eval_runtime": 0.5082,
            "eval_samples_per_second": 2052.16,
            "eval_steps_per_second": 17.708,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4209,
            "grad_norm": 0.7925589680671692,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.4485948383808136,
            "eval_matthews_correlation": 0.5206839744420351,
            "eval_runtime": 0.4772,
            "eval_samples_per_second": 2185.545,
            "eval_steps_per_second": 18.859,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4131,
            "grad_norm": 0.521350622177124,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4597878158092499,
            "eval_matthews_correlation": 0.5181026129120675,
            "eval_runtime": 0.2991,
            "eval_samples_per_second": 3487.107,
            "eval_steps_per_second": 30.09,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4104,
            "grad_norm": 0.7010313272476196,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.45070528984069824,
            "eval_matthews_correlation": 0.5207572018426233,
            "eval_runtime": 0.2543,
            "eval_samples_per_second": 4102.218,
            "eval_steps_per_second": 35.398,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.4001,
            "grad_norm": 0.7698189616203308,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4505595862865448,
            "eval_matthews_correlation": 0.5259770638545269,
            "eval_runtime": 0.3968,
            "eval_samples_per_second": 2628.242,
            "eval_steps_per_second": 22.679,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3931,
            "grad_norm": 0.5982008576393127,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.43631306290626526,
            "eval_matthews_correlation": 0.544301235611677,
            "eval_runtime": 0.3477,
            "eval_samples_per_second": 2999.927,
            "eval_steps_per_second": 25.886,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3928,
            "grad_norm": 0.8826991319656372,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.44271665811538696,
            "eval_matthews_correlation": 0.5311983410233877,
            "eval_runtime": 0.285,
            "eval_samples_per_second": 3659.691,
            "eval_steps_per_second": 31.579,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3831,
            "grad_norm": 1.418584942817688,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.4356326162815094,
            "eval_matthews_correlation": 0.5443411760365089,
            "eval_runtime": 0.3177,
            "eval_samples_per_second": 3282.96,
            "eval_steps_per_second": 28.329,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3821,
            "grad_norm": 0.693096399307251,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.44660571217536926,
            "eval_matthews_correlation": 0.5364214937932232,
            "eval_runtime": 0.2838,
            "eval_samples_per_second": 3674.767,
            "eval_steps_per_second": 31.709,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3758,
            "grad_norm": 0.936559796333313,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.42937132716178894,
            "eval_matthews_correlation": 0.5495093920893817,
            "eval_runtime": 0.4625,
            "eval_samples_per_second": 2255.289,
            "eval_steps_per_second": 19.461,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3717,
            "grad_norm": 0.7160921096801758,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.45965710282325745,
            "eval_matthews_correlation": 0.5367820334111587,
            "eval_runtime": 0.3295,
            "eval_samples_per_second": 3165.801,
            "eval_steps_per_second": 27.318,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.3678,
            "grad_norm": 0.670210063457489,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.4352325201034546,
            "eval_matthews_correlation": 0.5469587051515413,
            "eval_runtime": 0.3727,
            "eval_samples_per_second": 2798.428,
            "eval_steps_per_second": 24.148,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.3616,
            "grad_norm": 1.4274858236312866,
            "learning_rate": 6.301824212271974e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.4564710557460785,
            "eval_matthews_correlation": 0.5365007161029405,
            "eval_runtime": 0.3877,
            "eval_samples_per_second": 2690.105,
            "eval_steps_per_second": 23.213,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.36,
            "grad_norm": 0.6671191453933716,
            "learning_rate": 5.638474295190713e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4425755739212036,
            "eval_matthews_correlation": 0.5468625515611443,
            "eval_runtime": 0.4289,
            "eval_samples_per_second": 2432.023,
            "eval_steps_per_second": 20.986,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.3601,
            "grad_norm": 0.5610065460205078,
            "learning_rate": 4.975124378109453e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.44950395822525024,
            "eval_matthews_correlation": 0.5390693635419077,
            "eval_runtime": 0.3418,
            "eval_samples_per_second": 3051.786,
            "eval_steps_per_second": 26.334,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "train_runtime": 1036.6786,
            "train_samples_per_second": 824.846,
            "train_steps_per_second": 6.463,
            "total_flos": 4.408418159191654e+16,
            "train_loss": 0.5052908633305476,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 0.42937132716178894,
            "eval_matthews_correlation": 0.5495093920893817,
            "eval_runtime": 0.256,
            "eval_samples_per_second": 4073.687,
            "eval_steps_per_second": 35.152,
            "epoch": 77.61194029850746,
            "step": 5200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 1036.6786,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}