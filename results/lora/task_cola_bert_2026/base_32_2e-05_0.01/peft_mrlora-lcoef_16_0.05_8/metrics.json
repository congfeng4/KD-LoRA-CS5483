{
    "eval_loss": 0.639072835445404,
    "eval_matthews_correlation": 0.5685115636716958,
    "eval_runtime": 0.3625,
    "eval_samples_per_second": 2877.264,
    "eval_steps_per_second": 24.828,
    "epoch": 32.83582089552239,
    "log_history": [
        {
            "loss": 0.6688,
            "grad_norm": 0.9836373925209045,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5774641036987305,
            "eval_matthews_correlation": 0.06558874629318973,
            "eval_runtime": 0.4034,
            "eval_samples_per_second": 2585.219,
            "eval_steps_per_second": 22.308,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4693,
            "grad_norm": 2.6539485454559326,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4504031538963318,
            "eval_matthews_correlation": 0.5219521714713824,
            "eval_runtime": 0.3476,
            "eval_samples_per_second": 3000.185,
            "eval_steps_per_second": 25.888,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3874,
            "grad_norm": 2.364112615585327,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.4175461232662201,
            "eval_matthews_correlation": 0.5782372513816034,
            "eval_runtime": 0.5164,
            "eval_samples_per_second": 2019.822,
            "eval_steps_per_second": 17.429,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3282,
            "grad_norm": 2.8232851028442383,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4073222577571869,
            "eval_matthews_correlation": 0.5794528111058918,
            "eval_runtime": 0.4337,
            "eval_samples_per_second": 2404.798,
            "eval_steps_per_second": 20.751,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2631,
            "grad_norm": 1.88295578956604,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.49602895975112915,
            "eval_matthews_correlation": 0.5752957675685068,
            "eval_runtime": 0.4151,
            "eval_samples_per_second": 2512.498,
            "eval_steps_per_second": 21.68,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2141,
            "grad_norm": 2.030693769454956,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.45682060718536377,
            "eval_matthews_correlation": 0.6095582268996396,
            "eval_runtime": 0.403,
            "eval_samples_per_second": 2588.067,
            "eval_steps_per_second": 22.332,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1843,
            "grad_norm": 2.8068323135375977,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5990545749664307,
            "eval_matthews_correlation": 0.5262420102371838,
            "eval_runtime": 0.4171,
            "eval_samples_per_second": 2500.883,
            "eval_steps_per_second": 21.58,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.148,
            "grad_norm": 2.2622153759002686,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.6655480861663818,
            "eval_matthews_correlation": 0.5494767866076017,
            "eval_runtime": 0.381,
            "eval_samples_per_second": 2737.277,
            "eval_steps_per_second": 23.62,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.1305,
            "grad_norm": 2.268702268600464,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.6639494299888611,
            "eval_matthews_correlation": 0.5755298089385917,
            "eval_runtime": 0.4195,
            "eval_samples_per_second": 2486.177,
            "eval_steps_per_second": 21.453,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.1176,
            "grad_norm": 3.2422077655792236,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6969855427742004,
            "eval_matthews_correlation": 0.5604411498024476,
            "eval_runtime": 0.3769,
            "eval_samples_per_second": 2767.565,
            "eval_steps_per_second": 23.881,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1006,
            "grad_norm": 2.6098408699035645,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.7862049341201782,
            "eval_matthews_correlation": 0.5600481335616141,
            "eval_runtime": 0.4503,
            "eval_samples_per_second": 2316.085,
            "eval_steps_per_second": 19.985,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "train_runtime": 353.9714,
            "train_samples_per_second": 2415.732,
            "train_steps_per_second": 18.928,
            "total_flos": 1.858716206052147e+16,
            "train_loss": 0.27380304683338513,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.639072835445404,
            "eval_matthews_correlation": 0.5685115636716958,
            "eval_runtime": 0.3625,
            "eval_samples_per_second": 2877.264,
            "eval_steps_per_second": 24.828,
            "epoch": 32.83582089552239,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 353.9714,
        "trainable_params_count": 0.296522,
        "memory_allocated": [
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496,
            462.186496
        ],
        "memory_reserved": [
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336,
            2764.046336
        ]
    },
    "variant": "lora"
}