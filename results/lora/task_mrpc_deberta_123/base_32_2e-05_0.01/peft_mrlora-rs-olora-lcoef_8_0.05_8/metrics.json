{
    "eval_loss": 0.49604296684265137,
    "eval_accuracy": 0.8529411764705882,
    "eval_f1": 0.8936170212765957,
    "eval_runtime": 0.1514,
    "eval_samples_per_second": 2694.948,
    "eval_steps_per_second": 26.421,
    "epoch": 68.96551724137932,
    "log_history": [
        {
            "loss": 0.6438,
            "grad_norm": 0.5084136128425598,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.6051837205886841,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.2412,
            "eval_samples_per_second": 1691.865,
            "eval_steps_per_second": 16.587,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.5063,
            "grad_norm": 1.1568026542663574,
            "learning_rate": 0.00013793103448275863,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.4228818416595459,
            "eval_accuracy": 0.803921568627451,
            "eval_f1": 0.8581560283687943,
            "eval_runtime": 0.3984,
            "eval_samples_per_second": 1024.181,
            "eval_steps_per_second": 10.041,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.3597,
            "grad_norm": 0.8339086174964905,
            "learning_rate": 0.0001992337164750958,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.40838295221328735,
            "eval_accuracy": 0.8137254901960784,
            "eval_f1": 0.8549618320610688,
            "eval_runtime": 0.3393,
            "eval_samples_per_second": 1202.506,
            "eval_steps_per_second": 11.789,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.2431,
            "grad_norm": 1.9654773473739624,
            "learning_rate": 0.00019157088122605365,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.459501713514328,
            "eval_accuracy": 0.8308823529411765,
            "eval_f1": 0.8729281767955801,
            "eval_runtime": 0.3757,
            "eval_samples_per_second": 1085.941,
            "eval_steps_per_second": 10.646,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.1592,
            "grad_norm": 3.061591863632202,
            "learning_rate": 0.0001839080459770115,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.49604296684265137,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8936170212765957,
            "eval_runtime": 0.214,
            "eval_samples_per_second": 1906.213,
            "eval_steps_per_second": 18.688,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.1012,
            "grad_norm": 0.8354400992393494,
            "learning_rate": 0.00017624521072796937,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.5569291710853577,
            "eval_accuracy": 0.8480392156862745,
            "eval_f1": 0.8888888888888888,
            "eval_runtime": 0.281,
            "eval_samples_per_second": 1451.787,
            "eval_steps_per_second": 14.233,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.0816,
            "grad_norm": 2.235657215118408,
            "learning_rate": 0.0001685823754789272,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.5988643169403076,
            "eval_accuracy": 0.8382352941176471,
            "eval_f1": 0.88,
            "eval_runtime": 0.2284,
            "eval_samples_per_second": 1786.105,
            "eval_steps_per_second": 17.511,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.0556,
            "grad_norm": 1.5129846334457397,
            "learning_rate": 0.00016091954022988506,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.6274783611297607,
            "eval_accuracy": 0.8480392156862745,
            "eval_f1": 0.8888888888888888,
            "eval_runtime": 0.2443,
            "eval_samples_per_second": 1670.158,
            "eval_steps_per_second": 16.374,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.0454,
            "grad_norm": 1.2401407957077026,
            "learning_rate": 0.00015325670498084293,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.6765007972717285,
            "eval_accuracy": 0.8431372549019608,
            "eval_f1": 0.8865248226950355,
            "eval_runtime": 0.3102,
            "eval_samples_per_second": 1315.371,
            "eval_steps_per_second": 12.896,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.0354,
            "grad_norm": 0.2863309681415558,
            "learning_rate": 0.00014559386973180078,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.7266827821731567,
            "eval_accuracy": 0.8480392156862745,
            "eval_f1": 0.8864468864468864,
            "eval_runtime": 0.1684,
            "eval_samples_per_second": 2423.502,
            "eval_steps_per_second": 23.76,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "train_runtime": 561.1849,
            "train_samples_per_second": 1307.234,
            "train_steps_per_second": 10.335,
            "total_flos": 1.689771264966656e+16,
            "train_loss": 0.2231154146194458,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.49604296684265137,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8936170212765957,
            "eval_runtime": 0.1514,
            "eval_samples_per_second": 2694.948,
            "eval_steps_per_second": 26.421,
            "epoch": 68.96551724137932,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 200,
        "peft": "mrlora-rs-olora-lcoef",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "mrpc",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_olora": true,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 561.1849,
        "trainable_params_count": 0.296498,
        "memory_allocated": [
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336,
            761.678336
        ],
        "memory_reserved": [
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176,
            5217.714176
        ]
    },
    "variant": "lora"
}