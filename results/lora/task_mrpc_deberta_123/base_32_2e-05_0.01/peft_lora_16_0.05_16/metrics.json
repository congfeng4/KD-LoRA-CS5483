{
    "eval_loss": 0.35408854484558105,
    "eval_accuracy": 0.8921568627450981,
    "eval_f1": 0.9222614840989399,
    "eval_runtime": 0.2524,
    "eval_samples_per_second": 1616.319,
    "eval_steps_per_second": 15.846,
    "epoch": 62.06896551724138,
    "log_history": [
        {
            "loss": 0.6157,
            "grad_norm": 0.829289972782135,
            "learning_rate": 0.00013793103448275863,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.47554853558540344,
            "eval_accuracy": 0.7965686274509803,
            "eval_f1": 0.8566493955094991,
            "eval_runtime": 0.2388,
            "eval_samples_per_second": 1708.356,
            "eval_steps_per_second": 16.749,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.3561,
            "grad_norm": 0.6203864216804504,
            "learning_rate": 0.00019157088122605365,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.29583480954170227,
            "eval_accuracy": 0.8627450980392157,
            "eval_f1": 0.8955223880597015,
            "eval_runtime": 0.3019,
            "eval_samples_per_second": 1351.631,
            "eval_steps_per_second": 13.251,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.2196,
            "grad_norm": 1.4187310934066772,
            "learning_rate": 0.00017624521072796937,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.32414305210113525,
            "eval_accuracy": 0.8848039215686274,
            "eval_f1": 0.9147005444646098,
            "eval_runtime": 0.2922,
            "eval_samples_per_second": 1396.471,
            "eval_steps_per_second": 13.691,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.1477,
            "grad_norm": 2.0814061164855957,
            "learning_rate": 0.00016091954022988506,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.35408854484558105,
            "eval_accuracy": 0.8921568627450981,
            "eval_f1": 0.9222614840989399,
            "eval_runtime": 0.2366,
            "eval_samples_per_second": 1724.541,
            "eval_steps_per_second": 16.907,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.1054,
            "grad_norm": 0.6254057288169861,
            "learning_rate": 0.00014559386973180078,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.40138328075408936,
            "eval_accuracy": 0.8848039215686274,
            "eval_f1": 0.9176882661996497,
            "eval_runtime": 0.2638,
            "eval_samples_per_second": 1546.821,
            "eval_steps_per_second": 15.165,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.077,
            "grad_norm": 2.0866200923919678,
            "learning_rate": 0.00013026819923371647,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.4417306184768677,
            "eval_accuracy": 0.8823529411764706,
            "eval_f1": 0.9157894736842105,
            "eval_runtime": 0.2852,
            "eval_samples_per_second": 1430.79,
            "eval_steps_per_second": 14.027,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.0665,
            "grad_norm": 1.0838454961776733,
            "learning_rate": 0.00011494252873563218,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.4955369234085083,
            "eval_accuracy": 0.8872549019607843,
            "eval_f1": 0.9192982456140351,
            "eval_runtime": 0.3779,
            "eval_samples_per_second": 1079.589,
            "eval_steps_per_second": 10.584,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.0533,
            "grad_norm": 0.5681325197219849,
            "learning_rate": 9.96168582375479e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.5606531500816345,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9113043478260869,
            "eval_runtime": 0.2611,
            "eval_samples_per_second": 1562.638,
            "eval_steps_per_second": 15.32,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.0461,
            "grad_norm": 2.8435964584350586,
            "learning_rate": 8.42911877394636e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.5103078484535217,
            "eval_accuracy": 0.8848039215686274,
            "eval_f1": 0.917975567190227,
            "eval_runtime": 0.1863,
            "eval_samples_per_second": 2190.487,
            "eval_steps_per_second": 21.475,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "train_runtime": 321.7291,
            "train_samples_per_second": 1140.09,
            "train_steps_per_second": 9.014,
            "total_flos": 1.5260108325912576e+16,
            "train_loss": 0.18749563058217367,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.35408854484558105,
            "eval_accuracy": 0.8921568627450981,
            "eval_f1": 0.9222614840989399,
            "eval_runtime": 0.2524,
            "eval_samples_per_second": 1616.319,
            "eval_steps_per_second": 15.846,
            "epoch": 62.06896551724138,
            "step": 1800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "mrpc",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 3668
    },
    "train": {
        "train_time": 321.7291,
        "trainable_params_count": 0.591362,
        "memory_allocated": [
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312,
            766.349312
        ],
        "memory_reserved": [
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952,
            4773.117952
        ]
    },
    "variant": "lora"
}