{
    "eval_loss": 0.5337975025177002,
    "eval_pearson": 0.8898093083858715,
    "eval_spearman": 0.8861334748833352,
    "eval_runtime": 0.3602,
    "eval_samples_per_second": 4164.621,
    "eval_steps_per_second": 33.317,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 4.1749,
            "grad_norm": 4.3116841316223145,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.226989984512329,
            "eval_pearson": 0.4787162462645936,
            "eval_spearman": 0.6845993853124825,
            "eval_runtime": 0.5862,
            "eval_samples_per_second": 2559.021,
            "eval_steps_per_second": 20.472,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.6985,
            "grad_norm": 2.6709628105163574,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 1.1921650171279907,
            "eval_pearson": 0.698977349017426,
            "eval_spearman": 0.7040298681363698,
            "eval_runtime": 0.4684,
            "eval_samples_per_second": 3202.476,
            "eval_steps_per_second": 25.62,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.0271,
            "grad_norm": 6.649085998535156,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.6978229284286499,
            "eval_pearson": 0.8435257813741124,
            "eval_spearman": 0.8480578468547378,
            "eval_runtime": 0.4569,
            "eval_samples_per_second": 3283.094,
            "eval_steps_per_second": 26.265,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7701,
            "grad_norm": 6.232328414916992,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.5846664905548096,
            "eval_pearson": 0.8681357688653982,
            "eval_spearman": 0.8651532651926651,
            "eval_runtime": 0.7372,
            "eval_samples_per_second": 2034.613,
            "eval_steps_per_second": 16.277,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6609,
            "grad_norm": 1.384517788887024,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5775461792945862,
            "eval_pearson": 0.8766200301875812,
            "eval_spearman": 0.8726259597396965,
            "eval_runtime": 0.5101,
            "eval_samples_per_second": 2940.43,
            "eval_steps_per_second": 23.523,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5989,
            "grad_norm": 5.263182163238525,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5390939712524414,
            "eval_pearson": 0.8820913064840717,
            "eval_spearman": 0.8775324602975973,
            "eval_runtime": 0.3859,
            "eval_samples_per_second": 3886.923,
            "eval_steps_per_second": 31.095,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5529,
            "grad_norm": 5.011144161224365,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.5547093749046326,
            "eval_pearson": 0.883890604253367,
            "eval_spearman": 0.8787947274305298,
            "eval_runtime": 0.5284,
            "eval_samples_per_second": 2838.72,
            "eval_steps_per_second": 22.71,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5282,
            "grad_norm": 3.7372357845306396,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5533139109611511,
            "eval_pearson": 0.8852460632103243,
            "eval_spearman": 0.880855969767122,
            "eval_runtime": 0.4766,
            "eval_samples_per_second": 3147.349,
            "eval_steps_per_second": 25.179,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4918,
            "grad_norm": 3.232168436050415,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5320495367050171,
            "eval_pearson": 0.8871222977666127,
            "eval_spearman": 0.8825304506467475,
            "eval_runtime": 0.4034,
            "eval_samples_per_second": 3718.64,
            "eval_steps_per_second": 29.749,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4681,
            "grad_norm": 3.1082539558410645,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5296797156333923,
            "eval_pearson": 0.8885518218040587,
            "eval_spearman": 0.8846889550213756,
            "eval_runtime": 0.5259,
            "eval_samples_per_second": 2852.326,
            "eval_steps_per_second": 22.819,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4589,
            "grad_norm": 3.2388112545013428,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.5261241793632507,
            "eval_pearson": 0.8885772517047434,
            "eval_spearman": 0.8841592077189412,
            "eval_runtime": 0.6615,
            "eval_samples_per_second": 2267.653,
            "eval_steps_per_second": 18.141,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4378,
            "grad_norm": 1.5773711204528809,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4970458447933197,
            "eval_pearson": 0.8895781231693254,
            "eval_spearman": 0.885780610442588,
            "eval_runtime": 0.4342,
            "eval_samples_per_second": 3454.401,
            "eval_steps_per_second": 27.635,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4285,
            "grad_norm": 8.82576847076416,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.5337975025177002,
            "eval_pearson": 0.8898093083858715,
            "eval_spearman": 0.8861334748833352,
            "eval_runtime": 0.4636,
            "eval_samples_per_second": 3235.317,
            "eval_steps_per_second": 25.883,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.4165,
            "grad_norm": 4.096851348876953,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.5155004858970642,
            "eval_pearson": 0.8889398130463468,
            "eval_spearman": 0.8847431550337592,
            "eval_runtime": 0.5295,
            "eval_samples_per_second": 2832.635,
            "eval_steps_per_second": 22.661,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4063,
            "grad_norm": 3.1392204761505127,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.5012637376785278,
            "eval_pearson": 0.8894527836628559,
            "eval_spearman": 0.8855124956637811,
            "eval_runtime": 0.4536,
            "eval_samples_per_second": 3306.893,
            "eval_steps_per_second": 26.455,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3964,
            "grad_norm": 1.9673446416854858,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.5028883218765259,
            "eval_pearson": 0.8897464445499376,
            "eval_spearman": 0.885926277784234,
            "eval_runtime": 0.469,
            "eval_samples_per_second": 3198.272,
            "eval_steps_per_second": 25.586,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.39,
            "grad_norm": 2.550110340118408,
            "learning_rate": 5.4320987654320986e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.4942941963672638,
            "eval_pearson": 0.8895319195470667,
            "eval_spearman": 0.8856672655331139,
            "eval_runtime": 0.4753,
            "eval_samples_per_second": 3156.001,
            "eval_steps_per_second": 25.248,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 562.2187,
            "train_samples_per_second": 1022.556,
            "train_steps_per_second": 8.004,
            "total_flos": 2.882375919652045e+16,
            "train_loss": 0.8179921475578756,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.5337975025177002,
            "eval_pearson": 0.8898093083858715,
            "eval_spearman": 0.8861334748833352,
            "eval_runtime": 0.3602,
            "eval_samples_per_second": 4164.621,
            "eval_steps_per_second": 33.317,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 5749
    },
    "train": {
        "train_time": 562.2187,
        "trainable_params_count": 0.590977,
        "memory_allocated": [
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728,
            468.041728
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}