{
    "eval_loss": 0.45086556673049927,
    "eval_pearson": 0.9079843187475118,
    "eval_spearman": 0.9104923913513875,
    "eval_runtime": 0.6022,
    "eval_samples_per_second": 2490.71,
    "eval_steps_per_second": 19.926,
    "epoch": 88.88888888888889,
    "log_history": [
        {
            "loss": 9.1913,
            "grad_norm": 19.427032470703125,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 4.697718143463135,
            "eval_pearson": 0.35615526319299085,
            "eval_spearman": 0.36113504168294497,
            "eval_runtime": 0.5289,
            "eval_samples_per_second": 2836.184,
            "eval_steps_per_second": 22.689,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.9277,
            "grad_norm": 1.3280916213989258,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.432246208190918,
            "eval_pearson": 0.591356162801526,
            "eval_spearman": 0.5994435559360711,
            "eval_runtime": 0.7588,
            "eval_samples_per_second": 1976.917,
            "eval_steps_per_second": 15.815,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.8458,
            "grad_norm": 0.9175134301185608,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.9103763103485107,
            "eval_pearson": 0.8556160964608693,
            "eval_spearman": 0.8663249803408732,
            "eval_runtime": 0.8092,
            "eval_samples_per_second": 1853.616,
            "eval_steps_per_second": 14.829,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6757,
            "grad_norm": 0.7244306802749634,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.6864412426948547,
            "eval_pearson": 0.887954817128419,
            "eval_spearman": 0.8944751438557541,
            "eval_runtime": 0.5488,
            "eval_samples_per_second": 2733.091,
            "eval_steps_per_second": 21.865,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5531,
            "grad_norm": 3.82283353805542,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.6450849771499634,
            "eval_pearson": 0.8921075834546166,
            "eval_spearman": 0.8975958430758695,
            "eval_runtime": 0.6218,
            "eval_samples_per_second": 2412.536,
            "eval_steps_per_second": 19.3,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.495,
            "grad_norm": 0.8127011656761169,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5920907258987427,
            "eval_pearson": 0.8945449070180104,
            "eval_spearman": 0.8992568990919046,
            "eval_runtime": 0.6641,
            "eval_samples_per_second": 2258.822,
            "eval_steps_per_second": 18.071,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4612,
            "grad_norm": 0.5815771222114563,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.533637523651123,
            "eval_pearson": 0.8962035489694803,
            "eval_spearman": 0.9005602674954708,
            "eval_runtime": 0.632,
            "eval_samples_per_second": 2373.396,
            "eval_steps_per_second": 18.987,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4349,
            "grad_norm": 0.7199608683586121,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5274332165718079,
            "eval_pearson": 0.9002404202346473,
            "eval_spearman": 0.9042853364437587,
            "eval_runtime": 0.6199,
            "eval_samples_per_second": 2419.848,
            "eval_steps_per_second": 19.359,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4149,
            "grad_norm": 0.6737383008003235,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5052176713943481,
            "eval_pearson": 0.9009150934058113,
            "eval_spearman": 0.9045325807856547,
            "eval_runtime": 0.5348,
            "eval_samples_per_second": 2804.724,
            "eval_steps_per_second": 22.438,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3951,
            "grad_norm": 1.623739242553711,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5387567281723022,
            "eval_pearson": 0.9018834874794633,
            "eval_spearman": 0.9055215577740656,
            "eval_runtime": 0.541,
            "eval_samples_per_second": 2772.453,
            "eval_steps_per_second": 22.18,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3766,
            "grad_norm": 2.12121319770813,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.48553043603897095,
            "eval_pearson": 0.9042637242803179,
            "eval_spearman": 0.9075310282005415,
            "eval_runtime": 0.7384,
            "eval_samples_per_second": 2031.305,
            "eval_steps_per_second": 16.25,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.3656,
            "grad_norm": 0.4523365795612335,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4864833950996399,
            "eval_pearson": 0.9032540704382752,
            "eval_spearman": 0.906729260277481,
            "eval_runtime": 0.6247,
            "eval_samples_per_second": 2401.117,
            "eval_steps_per_second": 19.209,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3538,
            "grad_norm": 0.7072277069091797,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.48842960596084595,
            "eval_pearson": 0.9056174199750853,
            "eval_spearman": 0.9086692091580756,
            "eval_runtime": 0.5807,
            "eval_samples_per_second": 2583.294,
            "eval_steps_per_second": 20.666,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3453,
            "grad_norm": 0.45805853605270386,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.4688171446323395,
            "eval_pearson": 0.9050628954612341,
            "eval_spearman": 0.9081553120651883,
            "eval_runtime": 0.6505,
            "eval_samples_per_second": 2305.921,
            "eval_steps_per_second": 18.447,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.3358,
            "grad_norm": 1.0195775032043457,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.4563920199871063,
            "eval_pearson": 0.9069809878634802,
            "eval_spearman": 0.9097058905641711,
            "eval_runtime": 0.5663,
            "eval_samples_per_second": 2648.95,
            "eval_steps_per_second": 21.192,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3319,
            "grad_norm": 0.9103404879570007,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.45992130041122437,
            "eval_pearson": 0.9060150822066104,
            "eval_spearman": 0.908827493346743,
            "eval_runtime": 0.6131,
            "eval_samples_per_second": 2446.581,
            "eval_steps_per_second": 19.573,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3183,
            "grad_norm": 0.6832314729690552,
            "learning_rate": 5.4320987654320986e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.45404118299484253,
            "eval_pearson": 0.9067374816856858,
            "eval_spearman": 0.909613149691268,
            "eval_runtime": 0.571,
            "eval_samples_per_second": 2627.053,
            "eval_steps_per_second": 21.016,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "loss": 0.3174,
            "grad_norm": 1.3427534103393555,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "eval_loss": 0.46525251865386963,
            "eval_pearson": 0.9065592693762086,
            "eval_spearman": 0.9092794621326026,
            "eval_runtime": 0.5775,
            "eval_samples_per_second": 2597.345,
            "eval_steps_per_second": 20.779,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "loss": 0.3142,
            "grad_norm": 2.635981798171997,
            "learning_rate": 3.45679012345679e-05,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 0.47485485672950745,
            "eval_pearson": 0.9077901885883107,
            "eval_spearman": 0.910334981668422,
            "eval_runtime": 0.5303,
            "eval_samples_per_second": 2828.649,
            "eval_steps_per_second": 22.629,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "loss": 0.3064,
            "grad_norm": 0.5895598530769348,
            "learning_rate": 2.4691358024691357e-05,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "eval_loss": 0.45086556673049927,
            "eval_pearson": 0.9079843187475118,
            "eval_spearman": 0.9104923913513875,
            "eval_runtime": 0.6768,
            "eval_samples_per_second": 2216.28,
            "eval_steps_per_second": 17.73,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "train_runtime": 628.0363,
            "train_samples_per_second": 915.393,
            "train_steps_per_second": 7.165,
            "total_flos": 3.391090891685888e+16,
            "train_loss": 1.0379939794540405,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "eval_loss": 0.45086556673049927,
            "eval_pearson": 0.9079843187475118,
            "eval_spearman": 0.9104923913513875,
            "eval_runtime": 0.6022,
            "eval_samples_per_second": 2490.71,
            "eval_steps_per_second": 19.926,
            "epoch": 88.88888888888889,
            "step": 4000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 628.0363,
        "trainable_params_count": 0.590977,
        "memory_allocated": [
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}