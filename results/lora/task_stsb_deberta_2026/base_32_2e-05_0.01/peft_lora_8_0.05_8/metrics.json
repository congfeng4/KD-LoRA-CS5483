{
    "eval_loss": 0.42815250158309937,
    "eval_pearson": 0.9055674250382527,
    "eval_spearman": 0.9083804974716826,
    "eval_runtime": 0.6748,
    "eval_samples_per_second": 2222.943,
    "eval_steps_per_second": 17.784,
    "epoch": 53.333333333333336,
    "log_history": [
        {
            "loss": 7.333,
            "grad_norm": 3.12813401222229,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.4176268577575684,
            "eval_pearson": 0.12159610290044394,
            "eval_spearman": 0.13576623803711263,
            "eval_runtime": 0.7596,
            "eval_samples_per_second": 1974.665,
            "eval_steps_per_second": 15.797,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.0015,
            "grad_norm": 5.994862079620361,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.7459235191345215,
            "eval_pearson": 0.8441555839507298,
            "eval_spearman": 0.8676558640303665,
            "eval_runtime": 0.7779,
            "eval_samples_per_second": 1928.208,
            "eval_steps_per_second": 15.426,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.4625,
            "grad_norm": 1.338651418685913,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.53107088804245,
            "eval_pearson": 0.8889449002934686,
            "eval_spearman": 0.8968210507512746,
            "eval_runtime": 0.8714,
            "eval_samples_per_second": 1721.334,
            "eval_steps_per_second": 13.771,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3636,
            "grad_norm": 1.9331746101379395,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.4877167046070099,
            "eval_pearson": 0.8994683762419413,
            "eval_spearman": 0.9033965952928791,
            "eval_runtime": 0.6581,
            "eval_samples_per_second": 2279.185,
            "eval_steps_per_second": 18.233,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.3177,
            "grad_norm": 3.7933552265167236,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.4423655569553375,
            "eval_pearson": 0.9054249701005495,
            "eval_spearman": 0.9064697745167419,
            "eval_runtime": 0.8348,
            "eval_samples_per_second": 1796.906,
            "eval_steps_per_second": 14.375,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.284,
            "grad_norm": 1.0739660263061523,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4520370364189148,
            "eval_pearson": 0.9038063404352877,
            "eval_spearman": 0.9072002226815686,
            "eval_runtime": 0.7862,
            "eval_samples_per_second": 1907.971,
            "eval_steps_per_second": 15.264,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.2636,
            "grad_norm": 1.3955827951431274,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.42815250158309937,
            "eval_pearson": 0.9055674250382527,
            "eval_spearman": 0.9083804974716826,
            "eval_runtime": 0.6625,
            "eval_samples_per_second": 2264.308,
            "eval_steps_per_second": 18.114,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.2438,
            "grad_norm": 1.9807723760604858,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.43940269947052,
            "eval_pearson": 0.9063449100431782,
            "eval_spearman": 0.9079571088006936,
            "eval_runtime": 0.7671,
            "eval_samples_per_second": 1955.299,
            "eval_steps_per_second": 15.642,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.2275,
            "grad_norm": 1.0197455883026123,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.44494181871414185,
            "eval_pearson": 0.9042717573176479,
            "eval_spearman": 0.9071819505162113,
            "eval_runtime": 0.9177,
            "eval_samples_per_second": 1634.592,
            "eval_steps_per_second": 13.077,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.2134,
            "grad_norm": 1.3666566610336304,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.42700910568237305,
            "eval_pearson": 0.9069255127382958,
            "eval_spearman": 0.9079882167408843,
            "eval_runtime": 0.8727,
            "eval_samples_per_second": 1718.752,
            "eval_steps_per_second": 13.75,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.2028,
            "grad_norm": 1.8887219429016113,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.43378618359565735,
            "eval_pearson": 0.9048558088581714,
            "eval_spearman": 0.9066579900494717,
            "eval_runtime": 0.7435,
            "eval_samples_per_second": 2017.56,
            "eval_steps_per_second": 16.14,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.1942,
            "grad_norm": 1.2659507989883423,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4312698543071747,
            "eval_pearson": 0.9055407345845142,
            "eval_spearman": 0.9059099349825177,
            "eval_runtime": 0.8759,
            "eval_samples_per_second": 1712.436,
            "eval_steps_per_second": 13.699,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "train_runtime": 426.741,
            "train_samples_per_second": 1347.187,
            "train_steps_per_second": 10.545,
            "total_flos": 2.027687024315597e+16,
            "train_loss": 0.9256427431106568,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.42815250158309937,
            "eval_pearson": 0.9055674250382527,
            "eval_spearman": 0.9083804974716826,
            "eval_runtime": 0.6748,
            "eval_samples_per_second": 2222.943,
            "eval_steps_per_second": 17.784,
            "epoch": 53.333333333333336,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 426.741,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824,
            761.613824
        ],
        "memory_reserved": [
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232,
            4804.575232
        ]
    },
    "variant": "lora"
}