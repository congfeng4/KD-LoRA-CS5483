{
    "eval_loss": 0.48324552178382874,
    "eval_pearson": 0.9020739034158067,
    "eval_spearman": 0.9057856956523288,
    "eval_runtime": 0.5644,
    "eval_samples_per_second": 2657.871,
    "eval_steps_per_second": 21.263,
    "epoch": 88.88888888888889,
    "log_history": [
        {
            "loss": 9.2625,
            "grad_norm": 18.27385902404785,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 4.829907417297363,
            "eval_pearson": 0.040995704279839305,
            "eval_spearman": 0.024069195691416606,
            "eval_runtime": 0.7601,
            "eval_samples_per_second": 1973.323,
            "eval_steps_per_second": 15.787,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.9975,
            "grad_norm": 0.8497484922409058,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.39609694480896,
            "eval_pearson": 0.5084298471087396,
            "eval_spearman": 0.5294058415911742,
            "eval_runtime": 0.7788,
            "eval_samples_per_second": 1926.16,
            "eval_steps_per_second": 15.409,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.4737,
            "grad_norm": 2.5954151153564453,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.8312078714370728,
            "eval_pearson": 0.872029150623149,
            "eval_spearman": 0.8779642055228964,
            "eval_runtime": 0.5589,
            "eval_samples_per_second": 2683.728,
            "eval_steps_per_second": 21.47,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.698,
            "grad_norm": 1.165935754776001,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.6625874638557434,
            "eval_pearson": 0.8772600206660983,
            "eval_spearman": 0.8828955469525187,
            "eval_runtime": 0.6206,
            "eval_samples_per_second": 2416.937,
            "eval_steps_per_second": 19.335,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5867,
            "grad_norm": 0.7964667677879333,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.6201028227806091,
            "eval_pearson": 0.877388374176795,
            "eval_spearman": 0.885454234574122,
            "eval_runtime": 0.59,
            "eval_samples_per_second": 2542.573,
            "eval_steps_per_second": 20.341,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5307,
            "grad_norm": 1.4027732610702515,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5567113161087036,
            "eval_pearson": 0.8835165236857171,
            "eval_spearman": 0.8896834296554993,
            "eval_runtime": 0.5898,
            "eval_samples_per_second": 2543.236,
            "eval_steps_per_second": 20.346,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.482,
            "grad_norm": 1.4779279232025146,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.5686654448509216,
            "eval_pearson": 0.8869832893893649,
            "eval_spearman": 0.8925139002304014,
            "eval_runtime": 0.5799,
            "eval_samples_per_second": 2586.828,
            "eval_steps_per_second": 20.695,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4544,
            "grad_norm": 1.2919849157333374,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5309722423553467,
            "eval_pearson": 0.8890729374733477,
            "eval_spearman": 0.8939577599904621,
            "eval_runtime": 0.8181,
            "eval_samples_per_second": 1833.479,
            "eval_steps_per_second": 14.668,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4269,
            "grad_norm": 0.5870226621627808,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5293777585029602,
            "eval_pearson": 0.8924405540765912,
            "eval_spearman": 0.8962757249278006,
            "eval_runtime": 0.7166,
            "eval_samples_per_second": 2093.207,
            "eval_steps_per_second": 16.746,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4021,
            "grad_norm": 1.107968807220459,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5130714774131775,
            "eval_pearson": 0.8923082241004148,
            "eval_spearman": 0.8969698948633075,
            "eval_runtime": 0.6381,
            "eval_samples_per_second": 2350.605,
            "eval_steps_per_second": 18.805,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3843,
            "grad_norm": 2.115250825881958,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.5169932246208191,
            "eval_pearson": 0.8962374434232702,
            "eval_spearman": 0.9004695405866908,
            "eval_runtime": 0.5822,
            "eval_samples_per_second": 2576.627,
            "eval_steps_per_second": 20.613,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.3698,
            "grad_norm": 1.2275999784469604,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.500484049320221,
            "eval_pearson": 0.8967544497214704,
            "eval_spearman": 0.9011227943768185,
            "eval_runtime": 0.8212,
            "eval_samples_per_second": 1826.508,
            "eval_steps_per_second": 14.612,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3577,
            "grad_norm": 0.6374914646148682,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.49973681569099426,
            "eval_pearson": 0.8986574820650256,
            "eval_spearman": 0.9027470678078663,
            "eval_runtime": 0.644,
            "eval_samples_per_second": 2329.354,
            "eval_steps_per_second": 18.635,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3485,
            "grad_norm": 1.0573726892471313,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.48184940218925476,
            "eval_pearson": 0.8984678669843298,
            "eval_spearman": 0.9027314436398908,
            "eval_runtime": 0.5642,
            "eval_samples_per_second": 2658.65,
            "eval_steps_per_second": 21.269,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.3398,
            "grad_norm": 0.5266804099082947,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.473417729139328,
            "eval_pearson": 0.8997380510091532,
            "eval_spearman": 0.9037578724171775,
            "eval_runtime": 0.5762,
            "eval_samples_per_second": 2603.231,
            "eval_steps_per_second": 20.826,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3304,
            "grad_norm": 0.7222058773040771,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.4863590896129608,
            "eval_pearson": 0.9004665929901764,
            "eval_spearman": 0.9043642310257457,
            "eval_runtime": 0.555,
            "eval_samples_per_second": 2702.859,
            "eval_steps_per_second": 21.623,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3259,
            "grad_norm": 0.5904329419136047,
            "learning_rate": 5.4320987654320986e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.48227110505104065,
            "eval_pearson": 0.9010270310669611,
            "eval_spearman": 0.9047976190316106,
            "eval_runtime": 0.6322,
            "eval_samples_per_second": 2372.519,
            "eval_steps_per_second": 18.98,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "loss": 0.3163,
            "grad_norm": 0.6257704496383667,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "eval_loss": 0.48370370268821716,
            "eval_pearson": 0.9011996218739362,
            "eval_spearman": 0.9051499165470508,
            "eval_runtime": 0.5476,
            "eval_samples_per_second": 2739.031,
            "eval_steps_per_second": 21.912,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "loss": 0.3162,
            "grad_norm": 0.5176530480384827,
            "learning_rate": 3.45679012345679e-05,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 0.491217702627182,
            "eval_pearson": 0.9016024763718155,
            "eval_spearman": 0.9053939232267607,
            "eval_runtime": 0.5461,
            "eval_samples_per_second": 2746.978,
            "eval_steps_per_second": 21.976,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "loss": 0.3138,
            "grad_norm": 0.518581211566925,
            "learning_rate": 2.4691358024691357e-05,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "eval_loss": 0.48324552178382874,
            "eval_pearson": 0.9020739034158067,
            "eval_spearman": 0.9057856956523288,
            "eval_runtime": 0.5757,
            "eval_samples_per_second": 2605.583,
            "eval_steps_per_second": 20.845,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "train_runtime": 782.2666,
            "train_samples_per_second": 734.916,
            "train_steps_per_second": 5.753,
            "total_flos": 3.391090891685888e+16,
            "train_loss": 1.0358643856048584,
            "epoch": 88.88888888888889,
            "step": 4000
        },
        {
            "eval_loss": 0.48324552178382874,
            "eval_pearson": 0.9020739034158067,
            "eval_spearman": 0.9057856956523288,
            "eval_runtime": 0.5644,
            "eval_samples_per_second": 2657.871,
            "eval_steps_per_second": 21.263,
            "epoch": 88.88888888888889,
            "step": 4000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 782.2666,
        "trainable_params_count": 0.590977,
        "memory_allocated": [
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}