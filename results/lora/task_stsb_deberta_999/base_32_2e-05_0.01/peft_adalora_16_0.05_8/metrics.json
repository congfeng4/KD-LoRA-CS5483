{
    "eval_loss": 0.4707573354244232,
    "eval_pearson": 0.9019216123359387,
    "eval_spearman": 0.9057509443218759,
    "eval_runtime": 0.6137,
    "eval_samples_per_second": 2444.384,
    "eval_steps_per_second": 19.555,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 9.5858,
            "grad_norm": 20.875768661499023,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 5.026721954345703,
            "eval_pearson": 0.2270433968018203,
            "eval_spearman": 0.22182584543039108,
            "eval_runtime": 0.6603,
            "eval_samples_per_second": 2271.727,
            "eval_steps_per_second": 18.174,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 3.1095,
            "grad_norm": 1.173816442489624,
            "learning_rate": 0.00017777777777777779,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.3768739700317383,
            "eval_pearson": 0.5296737710727226,
            "eval_spearman": 0.5378899631074305,
            "eval_runtime": 0.7185,
            "eval_samples_per_second": 2087.628,
            "eval_steps_per_second": 16.701,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.6066,
            "grad_norm": 2.3105478286743164,
            "learning_rate": 0.0001925925925925926,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.871880054473877,
            "eval_pearson": 0.869703577582654,
            "eval_spearman": 0.8730897898153933,
            "eval_runtime": 0.5029,
            "eval_samples_per_second": 2982.848,
            "eval_steps_per_second": 23.863,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6866,
            "grad_norm": 0.9603992700576782,
            "learning_rate": 0.00018271604938271605,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.6670516729354858,
            "eval_pearson": 0.8812811824565148,
            "eval_spearman": 0.8830711090337728,
            "eval_runtime": 0.694,
            "eval_samples_per_second": 2161.25,
            "eval_steps_per_second": 17.29,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5531,
            "grad_norm": 0.6041149497032166,
            "learning_rate": 0.0001728395061728395,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5702785849571228,
            "eval_pearson": 0.8850944810445326,
            "eval_spearman": 0.8880457802992995,
            "eval_runtime": 0.6392,
            "eval_samples_per_second": 2346.801,
            "eval_steps_per_second": 18.774,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.4912,
            "grad_norm": 1.3243097066879272,
            "learning_rate": 0.00016296296296296295,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5707510709762573,
            "eval_pearson": 0.8873430348742198,
            "eval_spearman": 0.8916200725495038,
            "eval_runtime": 0.578,
            "eval_samples_per_second": 2595.352,
            "eval_steps_per_second": 20.763,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4468,
            "grad_norm": 0.7953400015830994,
            "learning_rate": 0.0001530864197530864,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.5724424719810486,
            "eval_pearson": 0.8898377322073807,
            "eval_spearman": 0.8946745431144942,
            "eval_runtime": 0.7957,
            "eval_samples_per_second": 1885.142,
            "eval_steps_per_second": 15.081,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4205,
            "grad_norm": 0.9507763981819153,
            "learning_rate": 0.00014320987654320989,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.5404088497161865,
            "eval_pearson": 0.892976030785439,
            "eval_spearman": 0.8972130500553537,
            "eval_runtime": 0.6006,
            "eval_samples_per_second": 2497.683,
            "eval_steps_per_second": 19.981,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.397,
            "grad_norm": 1.3202649354934692,
            "learning_rate": 0.00013333333333333334,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.5449221730232239,
            "eval_pearson": 0.8949080751267534,
            "eval_spearman": 0.899602748840359,
            "eval_runtime": 0.8838,
            "eval_samples_per_second": 1697.291,
            "eval_steps_per_second": 13.578,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3807,
            "grad_norm": 1.0687066316604614,
            "learning_rate": 0.0001234567901234568,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.5101283192634583,
            "eval_pearson": 0.8957527919514097,
            "eval_spearman": 0.9004768789476053,
            "eval_runtime": 0.6072,
            "eval_samples_per_second": 2470.42,
            "eval_steps_per_second": 19.763,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3626,
            "grad_norm": 0.6918172836303711,
            "learning_rate": 0.00011358024691358025,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.5099759101867676,
            "eval_pearson": 0.8980259146482568,
            "eval_spearman": 0.9022417203919024,
            "eval_runtime": 0.666,
            "eval_samples_per_second": 2252.228,
            "eval_steps_per_second": 18.018,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.3534,
            "grad_norm": 0.6186834573745728,
            "learning_rate": 0.0001037037037037037,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.49572932720184326,
            "eval_pearson": 0.8998329476517739,
            "eval_spearman": 0.9041723939845923,
            "eval_runtime": 0.5725,
            "eval_samples_per_second": 2619.875,
            "eval_steps_per_second": 20.959,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3426,
            "grad_norm": 1.1345083713531494,
            "learning_rate": 9.382716049382717e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.4831225275993347,
            "eval_pearson": 0.9000968443372015,
            "eval_spearman": 0.9041504953477603,
            "eval_runtime": 0.7569,
            "eval_samples_per_second": 1981.742,
            "eval_steps_per_second": 15.854,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3343,
            "grad_norm": 0.9297522306442261,
            "learning_rate": 8.395061728395062e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.46250683069229126,
            "eval_pearson": 0.9004306874715675,
            "eval_spearman": 0.9048181999719364,
            "eval_runtime": 0.6421,
            "eval_samples_per_second": 2336.019,
            "eval_steps_per_second": 18.688,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.332,
            "grad_norm": 1.7902686595916748,
            "learning_rate": 7.407407407407407e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.5009934306144714,
            "eval_pearson": 0.9014264614352357,
            "eval_spearman": 0.9053036739155725,
            "eval_runtime": 0.879,
            "eval_samples_per_second": 1706.48,
            "eval_steps_per_second": 13.652,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3166,
            "grad_norm": 0.7960500121116638,
            "learning_rate": 6.419753086419753e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 0.47480908036231995,
            "eval_pearson": 0.9012585070072404,
            "eval_spearman": 0.9051554005471957,
            "eval_runtime": 0.8254,
            "eval_samples_per_second": 1817.213,
            "eval_steps_per_second": 14.538,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3144,
            "grad_norm": 0.7631806135177612,
            "learning_rate": 5.4320987654320986e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.4707573354244232,
            "eval_pearson": 0.9019216123359387,
            "eval_spearman": 0.9057509443218759,
            "eval_runtime": 0.6745,
            "eval_samples_per_second": 2223.753,
            "eval_steps_per_second": 17.79,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 617.7867,
            "train_samples_per_second": 930.58,
            "train_steps_per_second": 7.284,
            "total_flos": 2.882427257933005e+16,
            "train_loss": 1.1784449768066407,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 0.4707573354244232,
            "eval_pearson": 0.9019216123359387,
            "eval_spearman": 0.9057509443218759,
            "eval_runtime": 0.6137,
            "eval_samples_per_second": 2444.384,
            "eval_steps_per_second": 19.555,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 617.7867,
        "trainable_params_count": 0.590977,
        "memory_allocated": [
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984,
            767.337984
        ],
        "memory_reserved": [
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472,
            4794.089472
        ]
    },
    "variant": "lora"
}