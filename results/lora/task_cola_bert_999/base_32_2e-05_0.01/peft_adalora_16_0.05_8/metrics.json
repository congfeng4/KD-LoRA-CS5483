{
    "eval_loss": 0.45246392488479614,
    "eval_matthews_correlation": 0.5390439985632989,
    "eval_runtime": 0.444,
    "eval_samples_per_second": 2349.308,
    "eval_steps_per_second": 20.272,
    "epoch": 68.65671641791045,
    "log_history": [
        {
            "loss": 1.8806,
            "grad_norm": 0.8224519491195679,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.447956919670105,
            "eval_matthews_correlation": -0.02929206145132745,
            "eval_runtime": 0.435,
            "eval_samples_per_second": 2397.808,
            "eval_steps_per_second": 20.691,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.8103,
            "grad_norm": 0.9358693957328796,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6129604578018188,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5932,
            "eval_samples_per_second": 1758.319,
            "eval_steps_per_second": 15.172,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5942,
            "grad_norm": 0.41865110397338867,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.591855525970459,
            "eval_matthews_correlation": 0.0463559874942472,
            "eval_runtime": 0.4415,
            "eval_samples_per_second": 2362.576,
            "eval_steps_per_second": 20.387,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5837,
            "grad_norm": 0.41897979378700256,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5774681568145752,
            "eval_matthews_correlation": 0.1494029403235746,
            "eval_runtime": 0.6163,
            "eval_samples_per_second": 1692.298,
            "eval_steps_per_second": 14.603,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.5677,
            "grad_norm": 0.48364534974098206,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5400487184524536,
            "eval_matthews_correlation": 0.3070751145573488,
            "eval_runtime": 0.4423,
            "eval_samples_per_second": 2358.381,
            "eval_steps_per_second": 20.35,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.5233,
            "grad_norm": 1.3537629842758179,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5402414202690125,
            "eval_matthews_correlation": 0.3500504109815301,
            "eval_runtime": 0.4683,
            "eval_samples_per_second": 2227.365,
            "eval_steps_per_second": 19.22,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4948,
            "grad_norm": 0.41033294796943665,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.515153706073761,
            "eval_matthews_correlation": 0.3976852361564824,
            "eval_runtime": 0.6397,
            "eval_samples_per_second": 1630.407,
            "eval_steps_per_second": 14.069,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4801,
            "grad_norm": 0.5913455486297607,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.49684464931488037,
            "eval_matthews_correlation": 0.415328406505499,
            "eval_runtime": 0.4884,
            "eval_samples_per_second": 2135.349,
            "eval_steps_per_second": 18.426,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.4642,
            "grad_norm": 0.9788576364517212,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.47583621740341187,
            "eval_matthews_correlation": 0.45539810748029474,
            "eval_runtime": 0.5375,
            "eval_samples_per_second": 1940.564,
            "eval_steps_per_second": 16.745,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.4498,
            "grad_norm": 0.785605788230896,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.48545709252357483,
            "eval_matthews_correlation": 0.44985503774934166,
            "eval_runtime": 0.4781,
            "eval_samples_per_second": 2181.63,
            "eval_steps_per_second": 18.825,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4389,
            "grad_norm": 0.6174390912055969,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.4757469892501831,
            "eval_matthews_correlation": 0.47550066760653964,
            "eval_runtime": 0.6185,
            "eval_samples_per_second": 1686.232,
            "eval_steps_per_second": 14.55,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.4306,
            "grad_norm": 0.4945647120475769,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.4737530052661896,
            "eval_matthews_correlation": 0.4837566459939405,
            "eval_runtime": 0.4778,
            "eval_samples_per_second": 2182.947,
            "eval_steps_per_second": 18.837,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4241,
            "grad_norm": 0.6582404971122742,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.45980724692344666,
            "eval_matthews_correlation": 0.4913288678758369,
            "eval_runtime": 0.5498,
            "eval_samples_per_second": 1896.992,
            "eval_steps_per_second": 16.369,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4132,
            "grad_norm": 1.6193817853927612,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.45187830924987793,
            "eval_matthews_correlation": 0.5126523660073969,
            "eval_runtime": 0.4549,
            "eval_samples_per_second": 2292.743,
            "eval_steps_per_second": 19.784,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4048,
            "grad_norm": 0.5535204410552979,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.4345971643924713,
            "eval_matthews_correlation": 0.5287745826239029,
            "eval_runtime": 0.5817,
            "eval_samples_per_second": 1793.027,
            "eval_steps_per_second": 15.472,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.4016,
            "grad_norm": 0.8446986675262451,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.45887693762779236,
            "eval_matthews_correlation": 0.5313214843751437,
            "eval_runtime": 0.3796,
            "eval_samples_per_second": 2747.341,
            "eval_steps_per_second": 23.707,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3993,
            "grad_norm": 1.8503273725509644,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.4577712416648865,
            "eval_matthews_correlation": 0.5233331906511532,
            "eval_runtime": 0.4165,
            "eval_samples_per_second": 2504.429,
            "eval_steps_per_second": 21.611,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3847,
            "grad_norm": 0.5593350529670715,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.45246392488479614,
            "eval_matthews_correlation": 0.5390439985632989,
            "eval_runtime": 0.4654,
            "eval_samples_per_second": 2240.89,
            "eval_steps_per_second": 19.337,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3859,
            "grad_norm": 0.8406007885932922,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.464675635099411,
            "eval_matthews_correlation": 0.5315332344895993,
            "eval_runtime": 0.6097,
            "eval_samples_per_second": 1710.709,
            "eval_steps_per_second": 14.762,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3801,
            "grad_norm": 0.6782349348068237,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.45944252610206604,
            "eval_matthews_correlation": 0.5339494412838712,
            "eval_runtime": 0.5133,
            "eval_samples_per_second": 2031.935,
            "eval_steps_per_second": 17.533,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3787,
            "grad_norm": 1.4619288444519043,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.45113468170166016,
            "eval_matthews_correlation": 0.5364214937932232,
            "eval_runtime": 0.4491,
            "eval_samples_per_second": 2322.651,
            "eval_steps_per_second": 20.042,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3752,
            "grad_norm": 1.4652730226516724,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.45167800784111023,
            "eval_matthews_correlation": 0.5365007161029405,
            "eval_runtime": 0.3833,
            "eval_samples_per_second": 2721.234,
            "eval_steps_per_second": 23.481,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.3669,
            "grad_norm": 2.2692019939422607,
            "learning_rate": 6.965174129353235e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.44587942957878113,
            "eval_matthews_correlation": 0.5365057053910051,
            "eval_runtime": 0.6426,
            "eval_samples_per_second": 1623.119,
            "eval_steps_per_second": 14.006,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "train_runtime": 691.6439,
            "train_samples_per_second": 1236.33,
            "train_steps_per_second": 9.687,
            "total_flos": 3.899754525438771e+16,
            "train_loss": 0.5231658388220746,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.45246392488479614,
            "eval_matthews_correlation": 0.5390439985632989,
            "eval_runtime": 0.444,
            "eval_samples_per_second": 2349.308,
            "eval_steps_per_second": 20.272,
            "epoch": 68.65671641791045,
            "step": 4600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 691.6439,
        "trainable_params_count": 0.591746,
        "memory_allocated": [
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016,
            468.054016
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}