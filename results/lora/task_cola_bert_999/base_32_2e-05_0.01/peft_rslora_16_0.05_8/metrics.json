{
    "eval_loss": 0.40123993158340454,
    "eval_matthews_correlation": 0.5811202551820686,
    "eval_runtime": 0.3213,
    "eval_samples_per_second": 3246.182,
    "eval_steps_per_second": 28.011,
    "epoch": 23.880597014925375,
    "log_history": [
        {
            "loss": 0.6313,
            "grad_norm": 1.361810326576233,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5191842317581177,
            "eval_matthews_correlation": 0.3594552668244613,
            "eval_runtime": 0.4338,
            "eval_samples_per_second": 2404.338,
            "eval_steps_per_second": 20.747,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4555,
            "grad_norm": 1.8884159326553345,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4549907147884369,
            "eval_matthews_correlation": 0.5241981070980204,
            "eval_runtime": 0.3951,
            "eval_samples_per_second": 2639.775,
            "eval_steps_per_second": 22.779,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3835,
            "grad_norm": 1.545353651046753,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.40123993158340454,
            "eval_matthews_correlation": 0.5811202551820686,
            "eval_runtime": 0.466,
            "eval_samples_per_second": 2238.167,
            "eval_steps_per_second": 19.313,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3261,
            "grad_norm": 2.540405035018921,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.43154656887054443,
            "eval_matthews_correlation": 0.5607990478394429,
            "eval_runtime": 0.3053,
            "eval_samples_per_second": 3416.832,
            "eval_steps_per_second": 29.484,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.2676,
            "grad_norm": 2.364473342895508,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5063643455505371,
            "eval_matthews_correlation": 0.5651092792103851,
            "eval_runtime": 0.6215,
            "eval_samples_per_second": 1678.09,
            "eval_steps_per_second": 14.48,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2258,
            "grad_norm": 3.507033348083496,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.5470178723335266,
            "eval_matthews_correlation": 0.5546666671852067,
            "eval_runtime": 0.4865,
            "eval_samples_per_second": 2144.081,
            "eval_steps_per_second": 18.501,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.1845,
            "grad_norm": 2.505333423614502,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5899052023887634,
            "eval_matthews_correlation": 0.5494635525532273,
            "eval_runtime": 0.3981,
            "eval_samples_per_second": 2619.806,
            "eval_steps_per_second": 22.606,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.1568,
            "grad_norm": 3.1255810260772705,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.5890236496925354,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.5072,
            "eval_samples_per_second": 2056.53,
            "eval_steps_per_second": 17.746,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "train_runtime": 182.6537,
            "train_samples_per_second": 4681.537,
            "train_steps_per_second": 36.681,
            "total_flos": 1.3517913495437312e+16,
            "train_loss": 0.3288959288597107,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.40123993158340454,
            "eval_matthews_correlation": 0.5811202551820686,
            "eval_runtime": 0.3213,
            "eval_samples_per_second": 3246.182,
            "eval_steps_per_second": 28.011,
            "epoch": 23.880597014925375,
            "step": 1600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "bert",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 182.6537,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912,
            462.78912
        ],
        "memory_reserved": [
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768,
            2011.168768
        ]
    },
    "variant": "lora"
}