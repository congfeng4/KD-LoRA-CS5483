{
    "eval_loss": 0.6407017111778259,
    "eval_matthews_correlation": 0.6006974680936171,
    "eval_runtime": 0.2371,
    "eval_samples_per_second": 4398.822,
    "eval_steps_per_second": 37.957,
    "epoch": 47.76119402985075,
    "log_history": [
        {
            "loss": 0.6171,
            "grad_norm": 0.3841322660446167,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.5782200694084167,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3462,
            "eval_samples_per_second": 3012.34,
            "eval_steps_per_second": 25.993,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.4587,
            "grad_norm": 2.3771913051605225,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4591878354549408,
            "eval_matthews_correlation": 0.5157664784865402,
            "eval_runtime": 0.2523,
            "eval_samples_per_second": 4133.549,
            "eval_steps_per_second": 35.668,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.3925,
            "grad_norm": 2.062910556793213,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.43004482984542847,
            "eval_matthews_correlation": 0.5727916886351078,
            "eval_runtime": 0.2996,
            "eval_samples_per_second": 3481.071,
            "eval_steps_per_second": 30.038,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.3573,
            "grad_norm": 2.6422526836395264,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4547666311264038,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.2522,
            "eval_samples_per_second": 4136.23,
            "eval_steps_per_second": 35.691,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3195,
            "grad_norm": 1.1686545610427856,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.41545987129211426,
            "eval_matthews_correlation": 0.5815775806078913,
            "eval_runtime": 0.3986,
            "eval_samples_per_second": 2616.428,
            "eval_steps_per_second": 22.577,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.2907,
            "grad_norm": 4.556307315826416,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.43744930624961853,
            "eval_matthews_correlation": 0.5890456886654597,
            "eval_runtime": 0.254,
            "eval_samples_per_second": 4106.007,
            "eval_steps_per_second": 35.431,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.2656,
            "grad_norm": 2.1248676776885986,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5000315308570862,
            "eval_matthews_correlation": 0.5932024506783026,
            "eval_runtime": 0.255,
            "eval_samples_per_second": 4090.045,
            "eval_steps_per_second": 35.293,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.2445,
            "grad_norm": 1.7567578554153442,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.48422080278396606,
            "eval_matthews_correlation": 0.5752574997417079,
            "eval_runtime": 0.2264,
            "eval_samples_per_second": 4606.859,
            "eval_steps_per_second": 39.752,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2219,
            "grad_norm": 2.0227041244506836,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.5242450833320618,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.2586,
            "eval_samples_per_second": 4033.877,
            "eval_steps_per_second": 34.808,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2046,
            "grad_norm": 1.849547266960144,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.6016072034835815,
            "eval_matthews_correlation": 0.5906754216978504,
            "eval_runtime": 0.2906,
            "eval_samples_per_second": 3589.084,
            "eval_steps_per_second": 30.97,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.1928,
            "grad_norm": 3.450099229812622,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.6407017111778259,
            "eval_matthews_correlation": 0.6006974680936171,
            "eval_runtime": 0.3107,
            "eval_samples_per_second": 3356.895,
            "eval_steps_per_second": 28.966,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1786,
            "grad_norm": 2.7964608669281006,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.6358280777931213,
            "eval_matthews_correlation": 0.5754342635449895,
            "eval_runtime": 0.2292,
            "eval_samples_per_second": 4550.684,
            "eval_steps_per_second": 39.268,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1679,
            "grad_norm": 2.4633796215057373,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.6524770259857178,
            "eval_matthews_correlation": 0.5863075494785002,
            "eval_runtime": 0.2485,
            "eval_samples_per_second": 4197.838,
            "eval_steps_per_second": 36.223,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1576,
            "grad_norm": 1.7291849851608276,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.6824689507484436,
            "eval_matthews_correlation": 0.5886507217040784,
            "eval_runtime": 0.2777,
            "eval_samples_per_second": 3756.404,
            "eval_steps_per_second": 32.414,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1474,
            "grad_norm": 4.274307727813721,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.6703028678894043,
            "eval_matthews_correlation": 0.5931328329100475,
            "eval_runtime": 0.233,
            "eval_samples_per_second": 4476.829,
            "eval_steps_per_second": 38.63,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1433,
            "grad_norm": 7.5512566566467285,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.6021687388420105,
            "eval_matthews_correlation": 0.5968831586006677,
            "eval_runtime": 0.4791,
            "eval_samples_per_second": 2176.962,
            "eval_steps_per_second": 18.785,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "train_runtime": 312.0012,
            "train_samples_per_second": 2740.694,
            "train_steps_per_second": 21.474,
            "total_flos": 2.722161224371405e+16,
            "train_loss": 0.27250082790851593,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.6407017111778259,
            "eval_matthews_correlation": 0.6006974680936171,
            "eval_runtime": 0.2371,
            "eval_samples_per_second": 4398.822,
            "eval_steps_per_second": 37.957,
            "epoch": 47.76119402985075,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 312.0012,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184,
            533.021184
        ],
        "memory_reserved": [
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176,
            2071.986176
        ]
    },
    "variant": "lora"
}