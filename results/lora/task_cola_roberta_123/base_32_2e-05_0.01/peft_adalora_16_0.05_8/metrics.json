{
    "eval_loss": 0.4452153146266937,
    "eval_matthews_correlation": 0.5703054933279827,
    "eval_runtime": 0.4966,
    "eval_samples_per_second": 2100.145,
    "eval_steps_per_second": 18.122,
    "epoch": 62.6865671641791,
    "log_history": [
        {
            "loss": 1.8815,
            "grad_norm": 0.3024035692214966,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5745272636413574,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.283,
            "eval_samples_per_second": 3684.957,
            "eval_steps_per_second": 31.797,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.902,
            "grad_norm": 0.6443868279457092,
            "learning_rate": 0.00011940298507462686,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6095489263534546,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2827,
            "eval_samples_per_second": 3689.096,
            "eval_steps_per_second": 31.833,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5909,
            "grad_norm": 1.1895354986190796,
            "learning_rate": 0.0001791044776119403,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5986921787261963,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3261,
            "eval_samples_per_second": 3198.241,
            "eval_steps_per_second": 27.597,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.5212,
            "grad_norm": 0.368843674659729,
            "learning_rate": 0.00019568822553897182,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.5216801762580872,
            "eval_matthews_correlation": 0.3750769421645332,
            "eval_runtime": 0.3852,
            "eval_samples_per_second": 2708.026,
            "eval_steps_per_second": 23.367,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4626,
            "grad_norm": 0.7772372961044312,
            "learning_rate": 0.00018905472636815922,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.4624992609024048,
            "eval_matthews_correlation": 0.4636597773604369,
            "eval_runtime": 0.3124,
            "eval_samples_per_second": 3338.229,
            "eval_steps_per_second": 28.805,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4356,
            "grad_norm": 1.5144381523132324,
            "learning_rate": 0.0001824212271973466,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.44208455085754395,
            "eval_matthews_correlation": 0.5286869837598177,
            "eval_runtime": 0.3875,
            "eval_samples_per_second": 2691.445,
            "eval_steps_per_second": 23.224,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4252,
            "grad_norm": 0.8854694962501526,
            "learning_rate": 0.000175787728026534,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.5018386840820312,
            "eval_matthews_correlation": 0.47899938707563694,
            "eval_runtime": 0.3288,
            "eval_samples_per_second": 3172.066,
            "eval_steps_per_second": 27.372,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.4128,
            "grad_norm": 0.5961371660232544,
            "learning_rate": 0.0001691542288557214,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.46402040123939514,
            "eval_matthews_correlation": 0.5207572018426233,
            "eval_runtime": 0.305,
            "eval_samples_per_second": 3420.104,
            "eval_steps_per_second": 29.512,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3977,
            "grad_norm": 0.5995254516601562,
            "learning_rate": 0.00016252072968490878,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.4483455717563629,
            "eval_matthews_correlation": 0.5468969938757886,
            "eval_runtime": 0.4044,
            "eval_samples_per_second": 2578.94,
            "eval_steps_per_second": 22.254,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3869,
            "grad_norm": 0.7646543979644775,
            "learning_rate": 0.00015588723051409618,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.4779818654060364,
            "eval_matthews_correlation": 0.5417325184178179,
            "eval_runtime": 0.2747,
            "eval_samples_per_second": 3796.801,
            "eval_steps_per_second": 32.762,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3842,
            "grad_norm": 0.8765629529953003,
            "learning_rate": 0.0001492537313432836,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.43813464045524597,
            "eval_matthews_correlation": 0.554912808282685,
            "eval_runtime": 0.2718,
            "eval_samples_per_second": 3837.481,
            "eval_steps_per_second": 33.113,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3732,
            "grad_norm": 0.8127710223197937,
            "learning_rate": 0.000142620232172471,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.4629444479942322,
            "eval_matthews_correlation": 0.5468625515611443,
            "eval_runtime": 0.3619,
            "eval_samples_per_second": 2882.205,
            "eval_steps_per_second": 24.87,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3701,
            "grad_norm": 1.6678632497787476,
            "learning_rate": 0.0001359867330016584,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.47180432081222534,
            "eval_matthews_correlation": 0.5547962503782369,
            "eval_runtime": 0.2602,
            "eval_samples_per_second": 4008.018,
            "eval_steps_per_second": 34.585,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.3662,
            "grad_norm": 0.8914137482643127,
            "learning_rate": 0.0001293532338308458,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4930051267147064,
            "eval_matthews_correlation": 0.540096561588247,
            "eval_runtime": 0.3266,
            "eval_samples_per_second": 3193.97,
            "eval_steps_per_second": 27.561,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3581,
            "grad_norm": 1.1004154682159424,
            "learning_rate": 0.00012271973466003317,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.48683637380599976,
            "eval_matthews_correlation": 0.5524078413415989,
            "eval_runtime": 0.3496,
            "eval_samples_per_second": 2983.826,
            "eval_steps_per_second": 25.747,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3557,
            "grad_norm": 2.6647067070007324,
            "learning_rate": 0.00011608623548922057,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.43213844299316406,
            "eval_matthews_correlation": 0.5702308058201745,
            "eval_runtime": 0.4039,
            "eval_samples_per_second": 2582.352,
            "eval_steps_per_second": 22.283,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.347,
            "grad_norm": 0.945601761341095,
            "learning_rate": 0.00010945273631840796,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.4452153146266937,
            "eval_matthews_correlation": 0.5703054933279827,
            "eval_runtime": 0.4952,
            "eval_samples_per_second": 2106.297,
            "eval_steps_per_second": 18.175,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3438,
            "grad_norm": 0.6564445495605469,
            "learning_rate": 0.00010281923714759536,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.4770394265651703,
            "eval_matthews_correlation": 0.5600481335616141,
            "eval_runtime": 0.4869,
            "eval_samples_per_second": 2142.271,
            "eval_steps_per_second": 18.486,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3415,
            "grad_norm": 1.4372543096542358,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.4828680157661438,
            "eval_matthews_correlation": 0.562537539158554,
            "eval_runtime": 0.347,
            "eval_samples_per_second": 3005.977,
            "eval_steps_per_second": 25.938,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3394,
            "grad_norm": 0.8228603005409241,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.485404908657074,
            "eval_matthews_correlation": 0.5678651899742106,
            "eval_runtime": 0.4369,
            "eval_samples_per_second": 2387.474,
            "eval_steps_per_second": 20.601,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3378,
            "grad_norm": 1.1990727186203003,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.491557240486145,
            "eval_matthews_correlation": 0.5653000167449913,
            "eval_runtime": 0.3914,
            "eval_samples_per_second": 2664.49,
            "eval_steps_per_second": 22.992,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "train_runtime": 465.125,
            "train_samples_per_second": 1838.431,
            "train_steps_per_second": 14.405,
            "total_flos": 3.585029468848128e+16,
            "train_loss": 0.49206501915341333,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.4452153146266937,
            "eval_matthews_correlation": 0.5703054933279827,
            "eval_runtime": 0.4966,
            "eval_samples_per_second": 2100.145,
            "eval_steps_per_second": 18.122,
            "epoch": 62.6865671641791,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 2,
        "model_family": "roberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 465.125,
        "trainable_params_count": 1.182338,
        "memory_allocated": [
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296,
            538.551296
        ],
        "memory_reserved": [
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048,
            2076.18048
        ]
    },
    "variant": "lora"
}