{
    "eval_loss": 0.42395174503326416,
    "eval_pearson": 0.9110226193590013,
    "eval_spearman": 0.9142016499847201,
    "eval_runtime": 0.3223,
    "eval_samples_per_second": 4654.019,
    "eval_steps_per_second": 37.232,
    "epoch": 44.44444444444444,
    "log_history": [
        {
            "loss": 4.3606,
            "grad_norm": 9.839311599731445,
            "learning_rate": 8.888888888888888e-06,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.509691059589386,
            "eval_pearson": 0.8865809944897112,
            "eval_spearman": 0.8910628952322429,
            "eval_runtime": 0.5101,
            "eval_samples_per_second": 2940.455,
            "eval_steps_per_second": 23.524,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.3117,
            "grad_norm": 4.395015239715576,
            "learning_rate": 1.7777777777777777e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.426417738199234,
            "eval_pearson": 0.9100667920648073,
            "eval_spearman": 0.9102725401558655,
            "eval_runtime": 0.5318,
            "eval_samples_per_second": 2820.574,
            "eval_steps_per_second": 22.565,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.1474,
            "grad_norm": 5.0301361083984375,
            "learning_rate": 1.925925925925926e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.5222434997558594,
            "eval_pearson": 0.9110472843419127,
            "eval_spearman": 0.9115987350238197,
            "eval_runtime": 0.4334,
            "eval_samples_per_second": 3460.733,
            "eval_steps_per_second": 27.686,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.0883,
            "grad_norm": 1.4288833141326904,
            "learning_rate": 1.8271604938271607e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.43393757939338684,
            "eval_pearson": 0.9070641542548075,
            "eval_spearman": 0.9105465521606313,
            "eval_runtime": 0.3932,
            "eval_samples_per_second": 3815.302,
            "eval_steps_per_second": 30.522,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.0598,
            "grad_norm": 2.2576634883880615,
            "learning_rate": 1.728395061728395e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.39311307668685913,
            "eval_pearson": 0.9111378586649284,
            "eval_spearman": 0.9131499161324543,
            "eval_runtime": 0.3871,
            "eval_samples_per_second": 3874.569,
            "eval_steps_per_second": 30.997,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.0453,
            "grad_norm": 1.1433824300765991,
            "learning_rate": 1.6296296296296297e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.39883723855018616,
            "eval_pearson": 0.9124755581175858,
            "eval_spearman": 0.9139248283777834,
            "eval_runtime": 0.3988,
            "eval_samples_per_second": 3761.489,
            "eval_steps_per_second": 30.092,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.0381,
            "grad_norm": 1.6601619720458984,
            "learning_rate": 1.5308641975308643e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.41604796051979065,
            "eval_pearson": 0.9091058042714366,
            "eval_spearman": 0.9129348923022571,
            "eval_runtime": 0.3874,
            "eval_samples_per_second": 3871.913,
            "eval_steps_per_second": 30.975,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.0304,
            "grad_norm": 1.7958179712295532,
            "learning_rate": 1.4320987654320988e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.40900272130966187,
            "eval_pearson": 0.9121501341399821,
            "eval_spearman": 0.9135345920966366,
            "eval_runtime": 0.3775,
            "eval_samples_per_second": 3973.243,
            "eval_steps_per_second": 31.786,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.027,
            "grad_norm": 1.115781307220459,
            "learning_rate": 1.3333333333333333e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.40243765711784363,
            "eval_pearson": 0.9127851194094229,
            "eval_spearman": 0.9140995401516127,
            "eval_runtime": 0.4178,
            "eval_samples_per_second": 3590.399,
            "eval_steps_per_second": 28.723,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.0244,
            "grad_norm": 1.0301071405410767,
            "learning_rate": 1.234567901234568e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.42395174503326416,
            "eval_pearson": 0.9110226193590013,
            "eval_spearman": 0.9142016499847201,
            "eval_runtime": 0.3955,
            "eval_samples_per_second": 3792.625,
            "eval_steps_per_second": 30.341,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "train_runtime": 672.6278,
            "train_samples_per_second": 854.708,
            "train_steps_per_second": 6.69,
            "total_flos": 1.6839258144768e+16,
            "train_loss": 0.5133034970760345,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.42395174503326416,
            "eval_pearson": 0.9110226193590013,
            "eval_spearman": 0.9142016499847201,
            "eval_runtime": 0.3223,
            "eval_samples_per_second": 4654.019,
            "eval_steps_per_second": 37.232,
            "epoch": 44.44444444444444,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 672.6278,
        "trainable_params_count": 184.422913,
        "memory_allocated": [
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112,
            3029.70112
        ],
        "memory_reserved": [
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688,
            8480.882688
        ]
    },
    "variant": "fft"
}