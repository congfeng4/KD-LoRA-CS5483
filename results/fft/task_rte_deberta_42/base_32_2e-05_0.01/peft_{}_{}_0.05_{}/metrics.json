{
    "eval_loss": 1.34990656375885,
    "eval_accuracy": 0.8447653429602888,
    "eval_runtime": 0.0988,
    "eval_samples_per_second": 2804.627,
    "eval_steps_per_second": 30.375,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 0.5608,
            "grad_norm": 11.044471740722656,
            "learning_rate": 1.54e-05,
            "epoch": 7.7,
            "step": 154
        },
        {
            "eval_loss": 0.665887176990509,
            "eval_accuracy": 0.7870036101083032,
            "eval_runtime": 0.1141,
            "eval_samples_per_second": 2428.127,
            "eval_steps_per_second": 26.297,
            "epoch": 7.7,
            "step": 154
        },
        {
            "loss": 0.0631,
            "grad_norm": 13.148272514343262,
            "learning_rate": 1.88e-05,
            "epoch": 15.4,
            "step": 308
        },
        {
            "eval_loss": 1.5088986158370972,
            "eval_accuracy": 0.7436823104693141,
            "eval_runtime": 0.1031,
            "eval_samples_per_second": 2686.828,
            "eval_steps_per_second": 29.099,
            "epoch": 15.4,
            "step": 308
        },
        {
            "loss": 0.0164,
            "grad_norm": 0.07609833031892776,
            "learning_rate": 1.708888888888889e-05,
            "epoch": 23.1,
            "step": 462
        },
        {
            "eval_loss": 1.3457754850387573,
            "eval_accuracy": 0.7833935018050542,
            "eval_runtime": 0.102,
            "eval_samples_per_second": 2715.731,
            "eval_steps_per_second": 29.412,
            "epoch": 23.1,
            "step": 462
        },
        {
            "loss": 0.0108,
            "grad_norm": 0.8167062401771545,
            "learning_rate": 1.537777777777778e-05,
            "epoch": 30.8,
            "step": 616
        },
        {
            "eval_loss": 1.371833324432373,
            "eval_accuracy": 0.8050541516245487,
            "eval_runtime": 0.1047,
            "eval_samples_per_second": 2645.459,
            "eval_steps_per_second": 28.651,
            "epoch": 30.8,
            "step": 616
        },
        {
            "loss": 0.0045,
            "grad_norm": 0.005774569232016802,
            "learning_rate": 1.3666666666666667e-05,
            "epoch": 38.5,
            "step": 770
        },
        {
            "eval_loss": 1.3237963914871216,
            "eval_accuracy": 0.8231046931407943,
            "eval_runtime": 0.1097,
            "eval_samples_per_second": 2525.865,
            "eval_steps_per_second": 27.356,
            "epoch": 38.5,
            "step": 770
        },
        {
            "loss": 0.0064,
            "grad_norm": 3.2689740657806396,
            "learning_rate": 1.1955555555555556e-05,
            "epoch": 46.2,
            "step": 924
        },
        {
            "eval_loss": 1.34990656375885,
            "eval_accuracy": 0.8447653429602888,
            "eval_runtime": 0.109,
            "eval_samples_per_second": 2541.307,
            "eval_steps_per_second": 27.523,
            "epoch": 46.2,
            "step": 924
        },
        {
            "loss": 0.0026,
            "grad_norm": 0.002537396503612399,
            "learning_rate": 1.0244444444444445e-05,
            "epoch": 53.9,
            "step": 1078
        },
        {
            "eval_loss": 1.580615520477295,
            "eval_accuracy": 0.7870036101083032,
            "eval_runtime": 0.1023,
            "eval_samples_per_second": 2707.51,
            "eval_steps_per_second": 29.323,
            "epoch": 53.9,
            "step": 1078
        },
        {
            "loss": 0.002,
            "grad_norm": 0.002514610532671213,
            "learning_rate": 8.533333333333335e-06,
            "epoch": 61.6,
            "step": 1232
        },
        {
            "eval_loss": 1.663110613822937,
            "eval_accuracy": 0.7978339350180506,
            "eval_runtime": 0.1031,
            "eval_samples_per_second": 2687.201,
            "eval_steps_per_second": 29.103,
            "epoch": 61.6,
            "step": 1232
        },
        {
            "loss": 0.001,
            "grad_norm": 0.0015385071747004986,
            "learning_rate": 6.8222222222222225e-06,
            "epoch": 69.3,
            "step": 1386
        },
        {
            "eval_loss": 1.877732515335083,
            "eval_accuracy": 0.7725631768953068,
            "eval_runtime": 0.1019,
            "eval_samples_per_second": 2719.519,
            "eval_steps_per_second": 29.453,
            "epoch": 69.3,
            "step": 1386
        },
        {
            "loss": 0.0005,
            "grad_norm": 0.052624695003032684,
            "learning_rate": 5.1111111111111115e-06,
            "epoch": 77.0,
            "step": 1540
        },
        {
            "eval_loss": 1.7789701223373413,
            "eval_accuracy": 0.7870036101083032,
            "eval_runtime": 0.1102,
            "eval_samples_per_second": 2514.152,
            "eval_steps_per_second": 27.229,
            "epoch": 77.0,
            "step": 1540
        },
        {
            "loss": 0.0003,
            "grad_norm": 0.0011944067664444447,
            "learning_rate": 3.4000000000000005e-06,
            "epoch": 84.7,
            "step": 1694
        },
        {
            "eval_loss": 1.7261404991149902,
            "eval_accuracy": 0.8050541516245487,
            "eval_runtime": 0.1123,
            "eval_samples_per_second": 2465.881,
            "eval_steps_per_second": 26.706,
            "epoch": 84.7,
            "step": 1694
        },
        {
            "loss": 0.0004,
            "grad_norm": 0.000955255061853677,
            "learning_rate": 1.688888888888889e-06,
            "epoch": 92.4,
            "step": 1848
        },
        {
            "eval_loss": 1.7546640634536743,
            "eval_accuracy": 0.8014440433212996,
            "eval_runtime": 0.1134,
            "eval_samples_per_second": 2442.168,
            "eval_steps_per_second": 26.449,
            "epoch": 92.4,
            "step": 1848
        },
        {
            "train_runtime": 606.5908,
            "train_samples_per_second": 410.491,
            "train_steps_per_second": 3.297,
            "total_flos": 1.6839409408147456e+16,
            "train_loss": 0.051504775212146345,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 1.34990656375885,
            "eval_accuracy": 0.8447653429602888,
            "eval_runtime": 0.0988,
            "eval_samples_per_second": 2804.627,
            "eval_steps_per_second": 30.375,
            "epoch": 100.0,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "type": 0,
        "model_family": "deberta",
        "task": "rte",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 2490
    },
    "train": {
        "train_time": 606.5908,
        "trainable_params_count": 184.423682,
        "memory_allocated": [
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712,
            3017.9712
        ],
        "memory_reserved": [
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976,
            8136.94976
        ]
    },
    "variant": "fft"
}