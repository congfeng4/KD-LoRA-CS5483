{
    "eval_loss": 0.4777486026287079,
    "eval_pearson": 0.8934128157713738,
    "eval_spearman": 0.8902296038793986,
    "eval_runtime": 0.1926,
    "eval_samples_per_second": 7788.962,
    "eval_steps_per_second": 62.312,
    "epoch": 57.77777777777778,
    "log_history": [
        {
            "loss": 5.9619,
            "grad_norm": 7.714468955993652,
            "learning_rate": 8.888888888888888e-06,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.6034348011016846,
            "eval_pearson": 0.8579499675829648,
            "eval_spearman": 0.8584257432014338,
            "eval_runtime": 0.2355,
            "eval_samples_per_second": 6368.56,
            "eval_steps_per_second": 50.948,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.3996,
            "grad_norm": 5.9875969886779785,
            "learning_rate": 1.7777777777777777e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.6133912801742554,
            "eval_pearson": 0.8770029028729459,
            "eval_spearman": 0.8749493896087374,
            "eval_runtime": 0.229,
            "eval_samples_per_second": 6550.666,
            "eval_steps_per_second": 52.405,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.1873,
            "grad_norm": 5.009919166564941,
            "learning_rate": 1.925925925925926e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.5646315813064575,
            "eval_pearson": 0.8850035458405088,
            "eval_spearman": 0.8810930576826908,
            "eval_runtime": 0.2029,
            "eval_samples_per_second": 7393.78,
            "eval_steps_per_second": 59.15,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.11,
            "grad_norm": 5.854249000549316,
            "learning_rate": 1.8271604938271607e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.48501741886138916,
            "eval_pearson": 0.8882964870681781,
            "eval_spearman": 0.8843202502545188,
            "eval_runtime": 0.2301,
            "eval_samples_per_second": 6520.022,
            "eval_steps_per_second": 52.16,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.0741,
            "grad_norm": 3.6795010566711426,
            "learning_rate": 1.728395061728395e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.48726555705070496,
            "eval_pearson": 0.889826181537053,
            "eval_spearman": 0.8867872928241529,
            "eval_runtime": 0.2287,
            "eval_samples_per_second": 6558.758,
            "eval_steps_per_second": 52.47,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.0582,
            "grad_norm": 1.3602286577224731,
            "learning_rate": 1.6296296296296297e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4657368063926697,
            "eval_pearson": 0.8922651830963251,
            "eval_spearman": 0.8882728215818317,
            "eval_runtime": 0.2353,
            "eval_samples_per_second": 6373.838,
            "eval_steps_per_second": 50.991,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.0489,
            "grad_norm": 1.4219954013824463,
            "learning_rate": 1.5308641975308643e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.47269076108932495,
            "eval_pearson": 0.8923441947691663,
            "eval_spearman": 0.8884798951489333,
            "eval_runtime": 0.1877,
            "eval_samples_per_second": 7992.023,
            "eval_steps_per_second": 63.936,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.0404,
            "grad_norm": 1.4827351570129395,
            "learning_rate": 1.4320987654320988e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.4777486026287079,
            "eval_pearson": 0.8934128157713738,
            "eval_spearman": 0.8902296038793986,
            "eval_runtime": 0.1883,
            "eval_samples_per_second": 7964.171,
            "eval_steps_per_second": 63.713,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.0344,
            "grad_norm": 1.3076411485671997,
            "learning_rate": 1.3333333333333333e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.47194674611091614,
            "eval_pearson": 0.8919388102173017,
            "eval_spearman": 0.8883415808811148,
            "eval_runtime": 0.2352,
            "eval_samples_per_second": 6377.624,
            "eval_steps_per_second": 51.021,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.0306,
            "grad_norm": 2.1679940223693848,
            "learning_rate": 1.234567901234568e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.46244221925735474,
            "eval_pearson": 0.892069957945688,
            "eval_spearman": 0.8893862021145101,
            "eval_runtime": 0.2436,
            "eval_samples_per_second": 6157.921,
            "eval_steps_per_second": 49.263,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.0281,
            "grad_norm": 1.4592933654785156,
            "learning_rate": 1.1358024691358025e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.46877214312553406,
            "eval_pearson": 0.8928061719945851,
            "eval_spearman": 0.8892359555964492,
            "eval_runtime": 0.1918,
            "eval_samples_per_second": 7822.052,
            "eval_steps_per_second": 62.576,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.0245,
            "grad_norm": 0.9190128445625305,
            "learning_rate": 1.037037037037037e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4599941670894623,
            "eval_pearson": 0.893458948448566,
            "eval_spearman": 0.8899002500879301,
            "eval_runtime": 0.1971,
            "eval_samples_per_second": 7612.176,
            "eval_steps_per_second": 60.897,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.0232,
            "grad_norm": 2.4891130924224854,
            "learning_rate": 9.382716049382717e-06,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.4744753837585449,
            "eval_pearson": 0.8925563231285596,
            "eval_spearman": 0.8890131173687535,
            "eval_runtime": 0.2372,
            "eval_samples_per_second": 6323.319,
            "eval_steps_per_second": 50.587,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "train_runtime": 367.5139,
            "train_samples_per_second": 1564.295,
            "train_steps_per_second": 12.244,
            "total_flos": 2.1890643001344e+16,
            "train_loss": 0.5400863086260282,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.4777486026287079,
            "eval_pearson": 0.8934128157713738,
            "eval_spearman": 0.8902296038793986,
            "eval_runtime": 0.1926,
            "eval_samples_per_second": 7788.962,
            "eval_steps_per_second": 62.312,
            "epoch": 57.77777777777778,
            "step": 2600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "bert",
        "task": "stsb",
        "seed": 123,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 5749
    },
    "train": {
        "train_time": 367.5139,
        "trainable_params_count": 109.483009,
        "memory_allocated": [
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952,
            1807.869952
        ],
        "memory_reserved": [
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968
        ]
    },
    "variant": "fft"
}