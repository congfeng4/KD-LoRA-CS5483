{
    "eval_loss": 1.6347382068634033,
    "eval_accuracy": 0.8158844765342961,
    "eval_runtime": 0.0755,
    "eval_samples_per_second": 3670.809,
    "eval_steps_per_second": 39.756,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 0.5012,
            "grad_norm": 15.960935592651367,
            "learning_rate": 2e-05,
            "epoch": 10.0,
            "step": 200
        },
        {
            "eval_loss": 0.9624506235122681,
            "eval_accuracy": 0.7256317689530686,
            "eval_runtime": 0.075,
            "eval_samples_per_second": 3693.906,
            "eval_steps_per_second": 40.006,
            "epoch": 10.0,
            "step": 200
        },
        {
            "loss": 0.0504,
            "grad_norm": 1.2030208110809326,
            "learning_rate": 1.7777777777777777e-05,
            "epoch": 20.0,
            "step": 400
        },
        {
            "eval_loss": 1.6890300512313843,
            "eval_accuracy": 0.7148014440433214,
            "eval_runtime": 0.0769,
            "eval_samples_per_second": 3601.567,
            "eval_steps_per_second": 39.006,
            "epoch": 20.0,
            "step": 400
        },
        {
            "loss": 0.0163,
            "grad_norm": 0.013354373164474964,
            "learning_rate": 1.555555555555556e-05,
            "epoch": 30.0,
            "step": 600
        },
        {
            "eval_loss": 1.5926705598831177,
            "eval_accuracy": 0.779783393501805,
            "eval_runtime": 0.0738,
            "eval_samples_per_second": 3753.25,
            "eval_steps_per_second": 40.649,
            "epoch": 30.0,
            "step": 600
        },
        {
            "loss": 0.0055,
            "grad_norm": 0.005888747982680798,
            "learning_rate": 1.3333333333333333e-05,
            "epoch": 40.0,
            "step": 800
        },
        {
            "eval_loss": 1.716721773147583,
            "eval_accuracy": 0.7689530685920578,
            "eval_runtime": 0.0956,
            "eval_samples_per_second": 2895.998,
            "eval_steps_per_second": 31.365,
            "epoch": 40.0,
            "step": 800
        },
        {
            "loss": 0.0032,
            "grad_norm": 0.002780207898467779,
            "learning_rate": 1.1111111111111113e-05,
            "epoch": 50.0,
            "step": 1000
        },
        {
            "eval_loss": 1.8593961000442505,
            "eval_accuracy": 0.7689530685920578,
            "eval_runtime": 0.0958,
            "eval_samples_per_second": 2890.493,
            "eval_steps_per_second": 31.305,
            "epoch": 50.0,
            "step": 1000
        },
        {
            "loss": 0.0026,
            "grad_norm": 0.0038111116737127304,
            "learning_rate": 8.888888888888888e-06,
            "epoch": 60.0,
            "step": 1200
        },
        {
            "eval_loss": 1.6347382068634033,
            "eval_accuracy": 0.8158844765342961,
            "eval_runtime": 0.0791,
            "eval_samples_per_second": 3502.461,
            "eval_steps_per_second": 37.933,
            "epoch": 60.0,
            "step": 1200
        },
        {
            "loss": 0.0007,
            "grad_norm": 0.0013005624059587717,
            "learning_rate": 6.666666666666667e-06,
            "epoch": 70.0,
            "step": 1400
        },
        {
            "eval_loss": 1.883741021156311,
            "eval_accuracy": 0.8050541516245487,
            "eval_runtime": 0.0951,
            "eval_samples_per_second": 2913.953,
            "eval_steps_per_second": 31.559,
            "epoch": 70.0,
            "step": 1400
        },
        {
            "loss": 0.0004,
            "grad_norm": 0.006054833065718412,
            "learning_rate": 4.444444444444444e-06,
            "epoch": 80.0,
            "step": 1600
        },
        {
            "eval_loss": 1.9980219602584839,
            "eval_accuracy": 0.7906137184115524,
            "eval_runtime": 0.0867,
            "eval_samples_per_second": 3195.375,
            "eval_steps_per_second": 34.607,
            "epoch": 80.0,
            "step": 1600
        },
        {
            "loss": 0.001,
            "grad_norm": 0.0008858644287101924,
            "learning_rate": 2.222222222222222e-06,
            "epoch": 90.0,
            "step": 1800
        },
        {
            "eval_loss": 2.038426637649536,
            "eval_accuracy": 0.7906137184115524,
            "eval_runtime": 0.1121,
            "eval_samples_per_second": 2470.117,
            "eval_steps_per_second": 26.752,
            "epoch": 90.0,
            "step": 1800
        },
        {
            "loss": 0.0003,
            "grad_norm": 0.0015129350358620286,
            "learning_rate": 0.0,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 1.9422492980957031,
            "eval_accuracy": 0.8122743682310469,
            "eval_runtime": 0.0951,
            "eval_samples_per_second": 2912.828,
            "eval_steps_per_second": 31.547,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "train_runtime": 543.3554,
            "train_samples_per_second": 458.264,
            "train_steps_per_second": 3.681,
            "total_flos": 1.683940981080064e+16,
            "train_loss": 0.05817436179146171,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 1.6347382068634033,
            "eval_accuracy": 0.8158844765342961,
            "eval_runtime": 0.0755,
            "eval_samples_per_second": 3670.809,
            "eval_steps_per_second": 39.756,
            "epoch": 100.0,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "deberta",
        "task": "rte",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 2490
    },
    "train": {
        "train_time": 543.3554,
        "trainable_params_count": 184.423682,
        "memory_allocated": [
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472,
            3015.977472
        ],
        "memory_reserved": [
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456
        ]
    },
    "variant": "fft"
}