{
    "eval_loss": 1.4607850313186646,
    "eval_accuracy": 0.7906137184115524,
    "eval_runtime": 0.0623,
    "eval_samples_per_second": 4442.949,
    "eval_steps_per_second": 48.119,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 0.644,
            "grad_norm": 8.474457740783691,
            "learning_rate": 1.54e-05,
            "epoch": 7.7,
            "step": 154
        },
        {
            "eval_loss": 0.553235650062561,
            "eval_accuracy": 0.7436823104693141,
            "eval_runtime": 0.0667,
            "eval_samples_per_second": 4151.678,
            "eval_steps_per_second": 44.964,
            "epoch": 7.7,
            "step": 154
        },
        {
            "loss": 0.192,
            "grad_norm": 31.01483154296875,
            "learning_rate": 1.88e-05,
            "epoch": 15.4,
            "step": 308
        },
        {
            "eval_loss": 1.3782893419265747,
            "eval_accuracy": 0.7184115523465704,
            "eval_runtime": 0.0704,
            "eval_samples_per_second": 3933.873,
            "eval_steps_per_second": 42.605,
            "epoch": 15.4,
            "step": 308
        },
        {
            "loss": 0.0513,
            "grad_norm": 14.392065048217773,
            "learning_rate": 1.708888888888889e-05,
            "epoch": 23.1,
            "step": 462
        },
        {
            "eval_loss": 1.5091603994369507,
            "eval_accuracy": 0.7689530685920578,
            "eval_runtime": 0.0648,
            "eval_samples_per_second": 4276.625,
            "eval_steps_per_second": 46.317,
            "epoch": 23.1,
            "step": 462
        },
        {
            "loss": 0.0186,
            "grad_norm": 0.08132299780845642,
            "learning_rate": 1.537777777777778e-05,
            "epoch": 30.8,
            "step": 616
        },
        {
            "eval_loss": 1.4607850313186646,
            "eval_accuracy": 0.7906137184115524,
            "eval_runtime": 0.0629,
            "eval_samples_per_second": 4401.042,
            "eval_steps_per_second": 47.665,
            "epoch": 30.8,
            "step": 616
        },
        {
            "loss": 0.0104,
            "grad_norm": 0.017371617257595062,
            "learning_rate": 1.3666666666666667e-05,
            "epoch": 38.5,
            "step": 770
        },
        {
            "eval_loss": 1.7669522762298584,
            "eval_accuracy": 0.7725631768953068,
            "eval_runtime": 0.0649,
            "eval_samples_per_second": 4270.102,
            "eval_steps_per_second": 46.247,
            "epoch": 38.5,
            "step": 770
        },
        {
            "loss": 0.008,
            "grad_norm": 0.10050445050001144,
            "learning_rate": 1.1955555555555556e-05,
            "epoch": 46.2,
            "step": 924
        },
        {
            "eval_loss": 2.0322725772857666,
            "eval_accuracy": 0.7509025270758123,
            "eval_runtime": 0.0599,
            "eval_samples_per_second": 4625.199,
            "eval_steps_per_second": 50.092,
            "epoch": 46.2,
            "step": 924
        },
        {
            "loss": 0.005,
            "grad_norm": 0.002643102314323187,
            "learning_rate": 1.0244444444444445e-05,
            "epoch": 53.9,
            "step": 1078
        },
        {
            "eval_loss": 1.9055362939834595,
            "eval_accuracy": 0.779783393501805,
            "eval_runtime": 0.0724,
            "eval_samples_per_second": 3824.854,
            "eval_steps_per_second": 41.424,
            "epoch": 53.9,
            "step": 1078
        },
        {
            "loss": 0.0031,
            "grad_norm": 0.0029114193748682737,
            "learning_rate": 8.533333333333335e-06,
            "epoch": 61.6,
            "step": 1232
        },
        {
            "eval_loss": 2.0583133697509766,
            "eval_accuracy": 0.7617328519855595,
            "eval_runtime": 0.0608,
            "eval_samples_per_second": 4558.185,
            "eval_steps_per_second": 49.367,
            "epoch": 61.6,
            "step": 1232
        },
        {
            "loss": 0.0036,
            "grad_norm": 0.0027881257701665163,
            "learning_rate": 6.8222222222222225e-06,
            "epoch": 69.3,
            "step": 1386
        },
        {
            "eval_loss": 1.853883147239685,
            "eval_accuracy": 0.776173285198556,
            "eval_runtime": 0.0722,
            "eval_samples_per_second": 3835.815,
            "eval_steps_per_second": 41.543,
            "epoch": 69.3,
            "step": 1386
        },
        {
            "loss": 0.0041,
            "grad_norm": 0.0019346652552485466,
            "learning_rate": 5.1111111111111115e-06,
            "epoch": 77.0,
            "step": 1540
        },
        {
            "eval_loss": 2.0339913368225098,
            "eval_accuracy": 0.7833935018050542,
            "eval_runtime": 0.0704,
            "eval_samples_per_second": 3935.832,
            "eval_steps_per_second": 42.626,
            "epoch": 77.0,
            "step": 1540
        },
        {
            "loss": 0.0027,
            "grad_norm": 0.0014522073324769735,
            "learning_rate": 3.4000000000000005e-06,
            "epoch": 84.7,
            "step": 1694
        },
        {
            "eval_loss": 2.053945302963257,
            "eval_accuracy": 0.7870036101083032,
            "eval_runtime": 0.062,
            "eval_samples_per_second": 4465.747,
            "eval_steps_per_second": 48.365,
            "epoch": 84.7,
            "step": 1694
        },
        {
            "loss": 0.0013,
            "grad_norm": 0.0017559031257405877,
            "learning_rate": 1.688888888888889e-06,
            "epoch": 92.4,
            "step": 1848
        },
        {
            "eval_loss": 2.0268359184265137,
            "eval_accuracy": 0.7833935018050542,
            "eval_runtime": 0.0753,
            "eval_samples_per_second": 3679.89,
            "eval_steps_per_second": 39.854,
            "epoch": 92.4,
            "step": 1848
        },
        {
            "train_runtime": 355.5571,
            "train_samples_per_second": 700.309,
            "train_steps_per_second": 5.625,
            "total_flos": 1.683910782091264e+16,
            "train_loss": 0.07269297136180103,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 1.4607850313186646,
            "eval_accuracy": 0.7906137184115524,
            "eval_runtime": 0.0623,
            "eval_samples_per_second": 4442.949,
            "eval_steps_per_second": 48.119,
            "epoch": 100.0,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "type": 0,
        "model_family": "roberta",
        "task": "rte",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 2490
    },
    "train": {
        "train_time": 355.5571,
        "trainable_params_count": 124.64717,
        "memory_allocated": [
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232,
            2028.319232
        ],
        "memory_reserved": [
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712,
            4259.315712
        ]
    },
    "variant": "fft"
}