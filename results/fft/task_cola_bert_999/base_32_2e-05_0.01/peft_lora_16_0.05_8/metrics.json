{
    "eval_loss": 1.1627991199493408,
    "eval_matthews_correlation": 0.6008301887604578,
    "eval_runtime": 0.1825,
    "eval_samples_per_second": 5714.326,
    "eval_steps_per_second": 49.309,
    "epoch": 47.76119402985075,
    "log_history": [
        {
            "loss": 0.6104,
            "grad_norm": 2.7600855827331543,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.4696165919303894,
            "eval_matthews_correlation": 0.45532057993228,
            "eval_runtime": 0.178,
            "eval_samples_per_second": 5860.007,
            "eval_steps_per_second": 50.566,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3376,
            "grad_norm": 4.490810871124268,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4924103915691376,
            "eval_matthews_correlation": 0.547116568580723,
            "eval_runtime": 0.1777,
            "eval_samples_per_second": 5869.41,
            "eval_steps_per_second": 50.647,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.1714,
            "grad_norm": 4.777901649475098,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.495807021856308,
            "eval_matthews_correlation": 0.5850764491793297,
            "eval_runtime": 0.174,
            "eval_samples_per_second": 5995.345,
            "eval_steps_per_second": 51.734,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.0938,
            "grad_norm": 8.414019584655762,
            "learning_rate": 1.9568822553897184e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.7041252851486206,
            "eval_matthews_correlation": 0.5547962503782369,
            "eval_runtime": 0.1744,
            "eval_samples_per_second": 5978.908,
            "eval_steps_per_second": 51.592,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.06,
            "grad_norm": 4.333278179168701,
            "learning_rate": 1.890547263681592e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.700453519821167,
            "eval_matthews_correlation": 0.5756649957099432,
            "eval_runtime": 0.178,
            "eval_samples_per_second": 5861.177,
            "eval_steps_per_second": 50.576,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.039,
            "grad_norm": 0.41482222080230713,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.9179237484931946,
            "eval_matthews_correlation": 0.562419829892001,
            "eval_runtime": 0.1429,
            "eval_samples_per_second": 7297.313,
            "eval_steps_per_second": 62.968,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.03,
            "grad_norm": 0.804897665977478,
            "learning_rate": 1.75787728026534e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.9033740162849426,
            "eval_matthews_correlation": 0.5884972789253764,
            "eval_runtime": 0.1749,
            "eval_samples_per_second": 5962.942,
            "eval_steps_per_second": 51.454,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.0224,
            "grad_norm": 5.829154968261719,
            "learning_rate": 1.691542288557214e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.1201403141021729,
            "eval_matthews_correlation": 0.5472224847569017,
            "eval_runtime": 0.1437,
            "eval_samples_per_second": 7257.4,
            "eval_steps_per_second": 62.624,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0169,
            "grad_norm": 9.098240852355957,
            "learning_rate": 1.625207296849088e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.1299508810043335,
            "eval_matthews_correlation": 0.5757702121003263,
            "eval_runtime": 0.1777,
            "eval_samples_per_second": 5869.733,
            "eval_steps_per_second": 50.65,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0141,
            "grad_norm": 0.2522661089897156,
            "learning_rate": 1.558872305140962e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.1479370594024658,
            "eval_matthews_correlation": 0.5696227147853862,
            "eval_runtime": 0.1767,
            "eval_samples_per_second": 5901.86,
            "eval_steps_per_second": 50.927,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0125,
            "grad_norm": 8.028603553771973,
            "learning_rate": 1.492537313432836e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.1627991199493408,
            "eval_matthews_correlation": 0.6008301887604578,
            "eval_runtime": 0.1457,
            "eval_samples_per_second": 7157.082,
            "eval_steps_per_second": 61.758,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0103,
            "grad_norm": 0.0603579618036747,
            "learning_rate": 1.4262023217247098e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.232181429862976,
            "eval_matthews_correlation": 0.5722385869866928,
            "eval_runtime": 0.1778,
            "eval_samples_per_second": 5866.128,
            "eval_steps_per_second": 50.619,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0072,
            "grad_norm": 0.3664569556713104,
            "learning_rate": 1.3598673300165839e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.2902625799179077,
            "eval_matthews_correlation": 0.570213836374093,
            "eval_runtime": 0.1762,
            "eval_samples_per_second": 5918.011,
            "eval_steps_per_second": 51.066,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0081,
            "grad_norm": 16.56276512145996,
            "learning_rate": 1.293532338308458e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.3022443056106567,
            "eval_matthews_correlation": 0.5805514135255713,
            "eval_runtime": 0.1441,
            "eval_samples_per_second": 7238.091,
            "eval_steps_per_second": 62.457,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0079,
            "grad_norm": 0.01000797189772129,
            "learning_rate": 1.2271973466003317e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.2701259851455688,
            "eval_matthews_correlation": 0.5833729687013477,
            "eval_runtime": 0.1745,
            "eval_samples_per_second": 5976.939,
            "eval_steps_per_second": 51.575,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0066,
            "grad_norm": 4.66395902633667,
            "learning_rate": 1.1608623548922058e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.38189697265625,
            "eval_matthews_correlation": 0.5788207437251082,
            "eval_runtime": 0.1802,
            "eval_samples_per_second": 5788.5,
            "eval_steps_per_second": 49.949,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "train_runtime": 454.2484,
            "train_samples_per_second": 1882.45,
            "train_steps_per_second": 14.75,
            "total_flos": 2.6942572513460224e+16,
            "train_loss": 0.09050049770623446,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.1627991199493408,
            "eval_matthews_correlation": 0.6008301887604578,
            "eval_runtime": 0.1825,
            "eval_samples_per_second": 5714.326,
            "eval_steps_per_second": 49.309,
            "epoch": 47.76119402985075,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "bert",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 454.2484,
        "trainable_params_count": 109.483778,
        "memory_allocated": [
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168,
            1807.879168
        ],
        "memory_reserved": [
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968,
            3858.75968
        ]
    },
    "variant": "fft"
}