{
    "eval_loss": 0.41757291555404663,
    "eval_pearson": 0.9098611878723196,
    "eval_spearman": 0.9133420216418286,
    "eval_runtime": 0.3013,
    "eval_samples_per_second": 4978.064,
    "eval_steps_per_second": 39.825,
    "epoch": 53.333333333333336,
    "log_history": [
        {
            "loss": 4.2785,
            "grad_norm": 20.510875701904297,
            "learning_rate": 8.888888888888888e-06,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 0.7034052610397339,
            "eval_pearson": 0.8762627337687641,
            "eval_spearman": 0.88555422411304,
            "eval_runtime": 0.3759,
            "eval_samples_per_second": 3990.595,
            "eval_steps_per_second": 31.925,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.3218,
            "grad_norm": 3.3540704250335693,
            "learning_rate": 1.7777777777777777e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 0.5141036510467529,
            "eval_pearson": 0.9046624293857738,
            "eval_spearman": 0.90733586424483,
            "eval_runtime": 0.3978,
            "eval_samples_per_second": 3770.812,
            "eval_steps_per_second": 30.166,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.142,
            "grad_norm": 5.879222869873047,
            "learning_rate": 1.925925925925926e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.4122980237007141,
            "eval_pearson": 0.9048802574476029,
            "eval_spearman": 0.908524740251327,
            "eval_runtime": 0.4683,
            "eval_samples_per_second": 3202.797,
            "eval_steps_per_second": 25.622,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.0808,
            "grad_norm": 3.5444908142089844,
            "learning_rate": 1.8271604938271607e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.41772404313087463,
            "eval_pearson": 0.905896314014596,
            "eval_spearman": 0.9087025969250231,
            "eval_runtime": 0.3768,
            "eval_samples_per_second": 3981.09,
            "eval_steps_per_second": 31.849,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.0596,
            "grad_norm": 2.689633846282959,
            "learning_rate": 1.728395061728395e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.4478718340396881,
            "eval_pearson": 0.9080530088402736,
            "eval_spearman": 0.910171182352064,
            "eval_runtime": 0.4141,
            "eval_samples_per_second": 3622.12,
            "eval_steps_per_second": 28.977,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.044,
            "grad_norm": 1.5133609771728516,
            "learning_rate": 1.6296296296296297e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.4102969467639923,
            "eval_pearson": 0.9069180101592178,
            "eval_spearman": 0.9096551205154297,
            "eval_runtime": 0.4293,
            "eval_samples_per_second": 3493.883,
            "eval_steps_per_second": 27.951,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.0371,
            "grad_norm": 1.6396535634994507,
            "learning_rate": 1.5308641975308643e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.41218557953834534,
            "eval_pearson": 0.91030670858795,
            "eval_spearman": 0.9118232206576418,
            "eval_runtime": 0.3752,
            "eval_samples_per_second": 3997.697,
            "eval_steps_per_second": 31.982,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.0318,
            "grad_norm": 1.1532498598098755,
            "learning_rate": 1.4320987654320988e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.42041271924972534,
            "eval_pearson": 0.9092264026432293,
            "eval_spearman": 0.9127426138399982,
            "eval_runtime": 0.4711,
            "eval_samples_per_second": 3184.182,
            "eval_steps_per_second": 25.473,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.0269,
            "grad_norm": 0.6097552180290222,
            "learning_rate": 1.3333333333333333e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.41757291555404663,
            "eval_pearson": 0.9098611878723196,
            "eval_spearman": 0.9133420216418286,
            "eval_runtime": 0.3834,
            "eval_samples_per_second": 3912.697,
            "eval_steps_per_second": 31.302,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.0241,
            "grad_norm": 0.5961892604827881,
            "learning_rate": 1.234567901234568e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.40621861815452576,
            "eval_pearson": 0.9109486557918355,
            "eval_spearman": 0.9132912400666992,
            "eval_runtime": 0.4157,
            "eval_samples_per_second": 3608.771,
            "eval_steps_per_second": 28.87,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.0225,
            "grad_norm": 0.9808897972106934,
            "learning_rate": 1.1358024691358025e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.41540729999542236,
            "eval_pearson": 0.910181064139681,
            "eval_spearman": 0.9121815080263496,
            "eval_runtime": 0.4231,
            "eval_samples_per_second": 3545.501,
            "eval_steps_per_second": 28.364,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.0206,
            "grad_norm": 0.568740725517273,
            "learning_rate": 1.037037037037037e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4133583903312683,
            "eval_pearson": 0.910071521123131,
            "eval_spearman": 0.9119710057179105,
            "eval_runtime": 0.4166,
            "eval_samples_per_second": 3600.595,
            "eval_steps_per_second": 28.805,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "train_runtime": 706.7974,
            "train_samples_per_second": 813.387,
            "train_steps_per_second": 6.367,
            "total_flos": 2.02071097737216e+16,
            "train_loss": 0.4241424653927485,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.41757291555404663,
            "eval_pearson": 0.9098611878723196,
            "eval_spearman": 0.9133420216418286,
            "eval_runtime": 0.3013,
            "eval_samples_per_second": 4978.064,
            "eval_steps_per_second": 39.825,
            "epoch": 53.333333333333336,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "type": 0,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 706.7974,
        "trainable_params_count": 184.422913,
        "memory_allocated": [
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048,
            3021.186048
        ],
        "memory_reserved": [
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456
        ]
    },
    "variant": "fft"
}