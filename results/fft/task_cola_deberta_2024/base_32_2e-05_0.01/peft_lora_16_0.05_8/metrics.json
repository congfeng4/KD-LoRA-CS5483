{
    "eval_loss": 0.9085730910301208,
    "eval_matthews_correlation": 0.7126253011889259,
    "eval_runtime": 0.2205,
    "eval_samples_per_second": 4729.1,
    "eval_steps_per_second": 40.807,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.5655,
            "grad_norm": 2.8524463176727295,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.40726152062416077,
            "eval_matthews_correlation": 0.6107938612917774,
            "eval_runtime": 0.2544,
            "eval_samples_per_second": 4100.219,
            "eval_steps_per_second": 35.381,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.2566,
            "grad_norm": 4.04873514175415,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4580155313014984,
            "eval_matthews_correlation": 0.6631704044482196,
            "eval_runtime": 0.2205,
            "eval_samples_per_second": 4730.021,
            "eval_steps_per_second": 40.815,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.1376,
            "grad_norm": 7.939414024353027,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5939345955848694,
            "eval_matthews_correlation": 0.6393763818577548,
            "eval_runtime": 0.2419,
            "eval_samples_per_second": 4312.392,
            "eval_steps_per_second": 37.211,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.0835,
            "grad_norm": 3.693220853805542,
            "learning_rate": 1.9568822553897184e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.6051913499832153,
            "eval_matthews_correlation": 0.6454933691830679,
            "eval_runtime": 0.2228,
            "eval_samples_per_second": 4681.98,
            "eval_steps_per_second": 40.401,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.0501,
            "grad_norm": 1.436268925666809,
            "learning_rate": 1.890547263681592e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5568369030952454,
            "eval_matthews_correlation": 0.6870441525925487,
            "eval_runtime": 0.2196,
            "eval_samples_per_second": 4748.525,
            "eval_steps_per_second": 40.975,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.0354,
            "grad_norm": 1.7726290225982666,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.680618166923523,
            "eval_matthews_correlation": 0.6792126156603279,
            "eval_runtime": 0.285,
            "eval_samples_per_second": 3659.761,
            "eval_steps_per_second": 31.58,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.0237,
            "grad_norm": 1.2374814748764038,
            "learning_rate": 1.75787728026534e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.8158522844314575,
            "eval_matthews_correlation": 0.66271185211871,
            "eval_runtime": 0.2385,
            "eval_samples_per_second": 4373.456,
            "eval_steps_per_second": 37.738,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.0169,
            "grad_norm": 5.9884748458862305,
            "learning_rate": 1.691542288557214e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.7166747450828552,
            "eval_matthews_correlation": 0.6910467213104741,
            "eval_runtime": 0.2171,
            "eval_samples_per_second": 4804.124,
            "eval_steps_per_second": 41.455,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0127,
            "grad_norm": 1.721171498298645,
            "learning_rate": 1.625207296849088e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.9213765859603882,
            "eval_matthews_correlation": 0.6804570666176275,
            "eval_runtime": 0.2828,
            "eval_samples_per_second": 3687.939,
            "eval_steps_per_second": 31.823,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0109,
            "grad_norm": 0.6722486019134521,
            "learning_rate": 1.558872305140962e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.8737423419952393,
            "eval_matthews_correlation": 0.7043983963543379,
            "eval_runtime": 0.2881,
            "eval_samples_per_second": 3620.885,
            "eval_steps_per_second": 31.244,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0104,
            "grad_norm": 0.013891207054257393,
            "learning_rate": 1.492537313432836e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.9736048579216003,
            "eval_matthews_correlation": 0.6826253049219981,
            "eval_runtime": 0.2244,
            "eval_samples_per_second": 4647.184,
            "eval_steps_per_second": 40.1,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0084,
            "grad_norm": 5.9031081199646,
            "learning_rate": 1.4262023217247098e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.9085730910301208,
            "eval_matthews_correlation": 0.7126253011889259,
            "eval_runtime": 0.2209,
            "eval_samples_per_second": 4722.372,
            "eval_steps_per_second": 40.749,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.01,
            "grad_norm": 0.02486952394247055,
            "learning_rate": 1.3598673300165839e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.0244108438491821,
            "eval_matthews_correlation": 0.6749454683036585,
            "eval_runtime": 0.2793,
            "eval_samples_per_second": 3733.855,
            "eval_steps_per_second": 32.219,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.007,
            "grad_norm": 0.09784659743309021,
            "learning_rate": 1.293532338308458e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.0898594856262207,
            "eval_matthews_correlation": 0.6870284696189455,
            "eval_runtime": 0.2182,
            "eval_samples_per_second": 4779.23,
            "eval_steps_per_second": 41.24,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.006,
            "grad_norm": 0.17005707323551178,
            "learning_rate": 1.2271973466003317e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.0822076797485352,
            "eval_matthews_correlation": 0.6943594960345291,
            "eval_runtime": 0.2994,
            "eval_samples_per_second": 3483.206,
            "eval_steps_per_second": 30.056,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.006,
            "grad_norm": 0.007011183071881533,
            "learning_rate": 1.1608623548922058e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.073599100112915,
            "eval_matthews_correlation": 0.697422297549312,
            "eval_runtime": 0.2255,
            "eval_samples_per_second": 4624.336,
            "eval_steps_per_second": 39.903,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.007,
            "grad_norm": 0.017626207321882248,
            "learning_rate": 1.0945273631840796e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.0729819536209106,
            "eval_matthews_correlation": 0.7068649074843276,
            "eval_runtime": 0.2875,
            "eval_samples_per_second": 3628.255,
            "eval_steps_per_second": 31.308,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 921.8621,
            "train_samples_per_second": 927.579,
            "train_steps_per_second": 7.268,
            "total_flos": 2.862699667836109e+16,
            "train_loss": 0.07339831264579998,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.9085730910301208,
            "eval_matthews_correlation": 0.7126253011889259,
            "eval_runtime": 0.2205,
            "eval_samples_per_second": 4729.1,
            "eval_steps_per_second": 40.807,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 921.8621,
        "trainable_params_count": 184.423682,
        "memory_allocated": [
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264
        ],
        "memory_reserved": [
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456
        ]
    },
    "variant": "fft"
}