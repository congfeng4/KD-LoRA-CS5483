{
    "eval_loss": 1.0477206707000732,
    "eval_matthews_correlation": 0.6502092478742336,
    "eval_runtime": 0.1291,
    "eval_samples_per_second": 8081.57,
    "eval_steps_per_second": 69.736,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 0.5882,
            "grad_norm": 6.662522315979004,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.4752197563648224,
            "eval_matthews_correlation": 0.4205186520108999,
            "eval_runtime": 0.1271,
            "eval_samples_per_second": 8208.463,
            "eval_steps_per_second": 70.83,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.3677,
            "grad_norm": 12.975311279296875,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.4645959734916687,
            "eval_matthews_correlation": 0.5491920151313351,
            "eval_runtime": 0.1575,
            "eval_samples_per_second": 6621.199,
            "eval_steps_per_second": 57.134,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.2143,
            "grad_norm": 9.514493942260742,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.511481523513794,
            "eval_matthews_correlation": 0.5924834238001306,
            "eval_runtime": 0.1572,
            "eval_samples_per_second": 6636.708,
            "eval_steps_per_second": 57.268,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.1274,
            "grad_norm": 19.695222854614258,
            "learning_rate": 1.9568822553897184e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.633585512638092,
            "eval_matthews_correlation": 0.6019614846840845,
            "eval_runtime": 0.1554,
            "eval_samples_per_second": 6711.37,
            "eval_steps_per_second": 57.912,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.0766,
            "grad_norm": 5.370508670806885,
            "learning_rate": 1.890547263681592e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.7550264596939087,
            "eval_matthews_correlation": 0.5943397045380183,
            "eval_runtime": 0.1508,
            "eval_samples_per_second": 6915.44,
            "eval_steps_per_second": 59.673,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.0605,
            "grad_norm": 10.693775177001953,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.7353861927986145,
            "eval_matthews_correlation": 0.6015805476045657,
            "eval_runtime": 0.1528,
            "eval_samples_per_second": 6827.319,
            "eval_steps_per_second": 58.913,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.0421,
            "grad_norm": 5.7805585861206055,
            "learning_rate": 1.75787728026534e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.8223282694816589,
            "eval_matthews_correlation": 0.605839001376474,
            "eval_runtime": 0.1587,
            "eval_samples_per_second": 6573.522,
            "eval_steps_per_second": 56.723,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.0341,
            "grad_norm": 6.2126359939575195,
            "learning_rate": 1.691542288557214e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.9374956488609314,
            "eval_matthews_correlation": 0.6210093223610296,
            "eval_runtime": 0.1563,
            "eval_samples_per_second": 6671.525,
            "eval_steps_per_second": 57.568,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0258,
            "grad_norm": 14.769539833068848,
            "learning_rate": 1.625207296849088e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.0197147130966187,
            "eval_matthews_correlation": 0.6093514522222457,
            "eval_runtime": 0.1268,
            "eval_samples_per_second": 8224.033,
            "eval_steps_per_second": 70.965,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0228,
            "grad_norm": 17.993452072143555,
            "learning_rate": 1.558872305140962e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.050333023071289,
            "eval_matthews_correlation": 0.6135933777663026,
            "eval_runtime": 0.1537,
            "eval_samples_per_second": 6787.289,
            "eval_steps_per_second": 58.567,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0209,
            "grad_norm": 19.29344367980957,
            "learning_rate": 1.492537313432836e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.269627571105957,
            "eval_matthews_correlation": 0.5948268419780214,
            "eval_runtime": 0.1296,
            "eval_samples_per_second": 8047.244,
            "eval_steps_per_second": 69.439,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0175,
            "grad_norm": 18.684066772460938,
            "learning_rate": 1.4262023217247098e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.0477206707000732,
            "eval_matthews_correlation": 0.6502092478742336,
            "eval_runtime": 0.1298,
            "eval_samples_per_second": 8035.006,
            "eval_steps_per_second": 69.334,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.0131,
            "grad_norm": 0.03270913287997246,
            "learning_rate": 1.3598673300165839e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.2412270307540894,
            "eval_matthews_correlation": 0.6035113508865858,
            "eval_runtime": 0.1553,
            "eval_samples_per_second": 6717.471,
            "eval_steps_per_second": 57.965,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.0137,
            "grad_norm": 17.47587776184082,
            "learning_rate": 1.293532338308458e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.266818642616272,
            "eval_matthews_correlation": 0.6159937744560633,
            "eval_runtime": 0.1529,
            "eval_samples_per_second": 6821.751,
            "eval_steps_per_second": 58.865,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.0125,
            "grad_norm": 25.64174461364746,
            "learning_rate": 1.2271973466003317e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.3325648307800293,
            "eval_matthews_correlation": 0.6331818186325034,
            "eval_runtime": 0.1271,
            "eval_samples_per_second": 8206.923,
            "eval_steps_per_second": 70.817,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.0102,
            "grad_norm": 1.6410176753997803,
            "learning_rate": 1.1608623548922058e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.1848565340042114,
            "eval_matthews_correlation": 0.6390928214337828,
            "eval_runtime": 0.1279,
            "eval_samples_per_second": 8154.937,
            "eval_steps_per_second": 70.369,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.0077,
            "grad_norm": 0.07473596185445786,
            "learning_rate": 1.0945273631840796e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.3929582834243774,
            "eval_matthews_correlation": 0.6107938612917774,
            "eval_runtime": 0.1518,
            "eval_samples_per_second": 6868.998,
            "eval_steps_per_second": 59.272,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 527.63,
            "train_samples_per_second": 1620.643,
            "train_steps_per_second": 12.698,
            "total_flos": 2.862648329555149e+16,
            "train_loss": 0.09735875087625841,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.0477206707000732,
            "eval_matthews_correlation": 0.6502092478742336,
            "eval_runtime": 0.1291,
            "eval_samples_per_second": 8081.57,
            "eval_steps_per_second": 69.736,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "roberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 527.63,
        "trainable_params_count": 124.64717,
        "memory_allocated": [
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352,
            2034.468352
        ],
        "memory_reserved": [
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496,
            4414.50496
        ]
    },
    "variant": "fft"
}