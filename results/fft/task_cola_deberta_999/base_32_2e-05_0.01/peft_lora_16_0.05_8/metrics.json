{
    "eval_loss": 0.8070260286331177,
    "eval_matthews_correlation": 0.7006291426503737,
    "eval_runtime": 0.22,
    "eval_samples_per_second": 4740.698,
    "eval_steps_per_second": 40.907,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 0.5597,
            "grad_norm": 3.52941632270813,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.3784850239753723,
            "eval_matthews_correlation": 0.6340992349486394,
            "eval_runtime": 0.2315,
            "eval_samples_per_second": 4505.063,
            "eval_steps_per_second": 38.874,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.2508,
            "grad_norm": 3.3881516456604004,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.37372225522994995,
            "eval_matthews_correlation": 0.695519139087268,
            "eval_runtime": 0.2787,
            "eval_samples_per_second": 3741.942,
            "eval_steps_per_second": 32.289,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.1315,
            "grad_norm": 5.904128551483154,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.520378053188324,
            "eval_matthews_correlation": 0.6773214607424106,
            "eval_runtime": 0.2778,
            "eval_samples_per_second": 3754.595,
            "eval_steps_per_second": 32.398,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.0761,
            "grad_norm": 5.007238388061523,
            "learning_rate": 1.9568822553897184e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.6042611598968506,
            "eval_matthews_correlation": 0.6553462265049138,
            "eval_runtime": 0.2176,
            "eval_samples_per_second": 4792.54,
            "eval_steps_per_second": 41.355,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.0499,
            "grad_norm": 0.6972964406013489,
            "learning_rate": 1.890547263681592e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.5780965089797974,
            "eval_matthews_correlation": 0.6986534818270481,
            "eval_runtime": 0.2793,
            "eval_samples_per_second": 3734.818,
            "eval_steps_per_second": 32.228,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.0339,
            "grad_norm": 5.353068828582764,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.6312570571899414,
            "eval_matthews_correlation": 0.6880706584062217,
            "eval_runtime": 0.2159,
            "eval_samples_per_second": 4831.758,
            "eval_steps_per_second": 41.693,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.0225,
            "grad_norm": 0.5537048578262329,
            "learning_rate": 1.75787728026534e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.8070260286331177,
            "eval_matthews_correlation": 0.7006291426503737,
            "eval_runtime": 0.281,
            "eval_samples_per_second": 3712.092,
            "eval_steps_per_second": 32.031,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.0172,
            "grad_norm": 3.7032289505004883,
            "learning_rate": 1.691542288557214e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.8485715985298157,
            "eval_matthews_correlation": 0.6899565609421873,
            "eval_runtime": 0.2807,
            "eval_samples_per_second": 3715.635,
            "eval_steps_per_second": 32.062,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.0154,
            "grad_norm": 0.4091344177722931,
            "learning_rate": 1.625207296849088e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.8095502257347107,
            "eval_matthews_correlation": 0.6849514557852503,
            "eval_runtime": 0.2136,
            "eval_samples_per_second": 4882.339,
            "eval_steps_per_second": 42.129,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.0137,
            "grad_norm": 4.29864501953125,
            "learning_rate": 1.558872305140962e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.79477858543396,
            "eval_matthews_correlation": 0.6893389355857963,
            "eval_runtime": 0.2134,
            "eval_samples_per_second": 4887.33,
            "eval_steps_per_second": 42.173,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.0105,
            "grad_norm": 2.298457622528076,
            "learning_rate": 1.492537313432836e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.0757426023483276,
            "eval_matthews_correlation": 0.6651338996433138,
            "eval_runtime": 0.2184,
            "eval_samples_per_second": 4775.636,
            "eval_steps_per_second": 41.209,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.0097,
            "grad_norm": 0.00865962728857994,
            "learning_rate": 1.4262023217247098e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.9818719029426575,
            "eval_matthews_correlation": 0.6873926435877296,
            "eval_runtime": 0.2193,
            "eval_samples_per_second": 4756.533,
            "eval_steps_per_second": 41.044,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 652.7614,
            "train_samples_per_second": 1309.973,
            "train_steps_per_second": 10.264,
            "total_flos": 2.020729177296077e+16,
            "train_loss": 0.09923377950986226,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.8070260286331177,
            "eval_matthews_correlation": 0.7006291426503737,
            "eval_runtime": 0.22,
            "eval_samples_per_second": 4740.698,
            "eval_steps_per_second": 40.907,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 0,
        "model_family": "deberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 652.7614,
        "trainable_params_count": 184.423682,
        "memory_allocated": [
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264,
            3021.195264
        ],
        "memory_reserved": [
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456,
            8132.755456
        ]
    },
    "variant": "fft"
}