{
    "eval_loss": 2.973621368408203,
    "eval_pearson": 0.8858881320568097,
    "eval_spearman": 0.884592993229385,
    "eval_runtime": 0.3013,
    "eval_samples_per_second": 4978.832,
    "eval_steps_per_second": 39.831,
    "epoch": 57.77777777777778,
    "log_history": [
        {
            "loss": 9.5952,
            "grad_norm": 35.607051849365234,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 3.6866848468780518,
            "eval_pearson": -0.04207948301341043,
            "eval_spearman": -0.013566579344455893,
            "eval_runtime": 0.3102,
            "eval_samples_per_second": 4835.668,
            "eval_steps_per_second": 38.685,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.8788,
            "grad_norm": 5.940557479858398,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 3.031942129135132,
            "eval_pearson": 0.8360978861448546,
            "eval_spearman": 0.8409275881699575,
            "eval_runtime": 0.3218,
            "eval_samples_per_second": 4661.93,
            "eval_steps_per_second": 37.295,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.7678,
            "grad_norm": 2.8920340538024902,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.979222059249878,
            "eval_pearson": 0.8612952369548894,
            "eval_spearman": 0.8614736513263613,
            "eval_runtime": 0.307,
            "eval_samples_per_second": 4885.263,
            "eval_steps_per_second": 39.082,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6295,
            "grad_norm": 1.8263598680496216,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.019045352935791,
            "eval_pearson": 0.8699252051632849,
            "eval_spearman": 0.8700806429045895,
            "eval_runtime": 0.2991,
            "eval_samples_per_second": 5015.11,
            "eval_steps_per_second": 40.121,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5543,
            "grad_norm": 5.149243354797363,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 3.1440253257751465,
            "eval_pearson": 0.8716803235623016,
            "eval_spearman": 0.8730096960285199,
            "eval_runtime": 0.3538,
            "eval_samples_per_second": 4239.64,
            "eval_steps_per_second": 33.917,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.4959,
            "grad_norm": 1.5822464227676392,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.9627010822296143,
            "eval_pearson": 0.8803663544256695,
            "eval_spearman": 0.8800480788015895,
            "eval_runtime": 0.3028,
            "eval_samples_per_second": 4954.398,
            "eval_steps_per_second": 39.635,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4531,
            "grad_norm": 4.672150135040283,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 3.1147050857543945,
            "eval_pearson": 0.8812336101678794,
            "eval_spearman": 0.8817755905139801,
            "eval_runtime": 0.3056,
            "eval_samples_per_second": 4907.643,
            "eval_steps_per_second": 39.261,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4263,
            "grad_norm": 1.8932863473892212,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.980179786682129,
            "eval_pearson": 0.8835210855958063,
            "eval_spearman": 0.8829679146000369,
            "eval_runtime": 0.3019,
            "eval_samples_per_second": 4968.876,
            "eval_steps_per_second": 39.751,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4024,
            "grad_norm": 1.6689419746398926,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.9913783073425293,
            "eval_pearson": 0.8843253882190559,
            "eval_spearman": 0.8835476825922712,
            "eval_runtime": 0.3077,
            "eval_samples_per_second": 4875.371,
            "eval_steps_per_second": 39.003,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3876,
            "grad_norm": 3.7410624027252197,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.9753737449645996,
            "eval_pearson": 0.8846084676230099,
            "eval_spearman": 0.8838854356537998,
            "eval_runtime": 0.301,
            "eval_samples_per_second": 4983.158,
            "eval_steps_per_second": 39.865,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3643,
            "grad_norm": 5.355433464050293,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.0744755268096924,
            "eval_pearson": 0.8814543222713314,
            "eval_spearman": 0.8806120273728638,
            "eval_runtime": 0.3099,
            "eval_samples_per_second": 4840.758,
            "eval_steps_per_second": 38.726,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.3538,
            "grad_norm": 1.2607076168060303,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.945737838745117,
            "eval_pearson": 0.8843663234251637,
            "eval_spearman": 0.8832819720386441,
            "eval_runtime": 0.3141,
            "eval_samples_per_second": 4775.36,
            "eval_steps_per_second": 38.203,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3374,
            "grad_norm": 4.116634368896484,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.973621368408203,
            "eval_pearson": 0.8858881320568097,
            "eval_spearman": 0.884592993229385,
            "eval_runtime": 0.3067,
            "eval_samples_per_second": 4890.967,
            "eval_steps_per_second": 39.128,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "train_runtime": 161.3189,
            "train_samples_per_second": 3563.748,
            "train_steps_per_second": 27.895,
            "total_flos": 1.1172433868357632e+16,
            "train_loss": 1.2804887272761418,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.973621368408203,
            "eval_pearson": 0.8858881320568097,
            "eval_spearman": 0.884592993229385,
            "eval_runtime": 0.3013,
            "eval_samples_per_second": 4978.832,
            "eval_steps_per_second": 39.831,
            "epoch": 57.77777777777778,
            "step": 2600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 161.3189,
        "trainable_params_count": 0.590593,
        "memory_allocated": [
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336,
            596.622336
        ],
        "memory_reserved": [
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584
        ]
    },
    "variant": "kd-lora"
}