{
    "eval_loss": 2.918086290359497,
    "eval_pearson": 0.8918513097844093,
    "eval_spearman": 0.8907434094530539,
    "eval_runtime": 0.3825,
    "eval_samples_per_second": 3921.951,
    "eval_steps_per_second": 31.376,
    "epoch": 84.44444444444444,
    "log_history": [
        {
            "loss": 9.8508,
            "grad_norm": 43.9903678894043,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 5.756239414215088,
            "eval_pearson": 0.09914886103451152,
            "eval_spearman": 0.09604143610509368,
            "eval_runtime": 0.3709,
            "eval_samples_per_second": 4044.501,
            "eval_steps_per_second": 32.356,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 3.1638,
            "grad_norm": 16.2237606048584,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.838400363922119,
            "eval_pearson": 0.8134219151510742,
            "eval_spearman": 0.8203533402556057,
            "eval_runtime": 0.3701,
            "eval_samples_per_second": 4052.773,
            "eval_steps_per_second": 32.422,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.934,
            "grad_norm": 2.645439624786377,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.950208902359009,
            "eval_pearson": 0.8531947750342865,
            "eval_spearman": 0.8547741426716982,
            "eval_runtime": 0.3659,
            "eval_samples_per_second": 4099.798,
            "eval_steps_per_second": 32.798,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7471,
            "grad_norm": 1.8158963918685913,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.0101914405822754,
            "eval_pearson": 0.8634219677987882,
            "eval_spearman": 0.8642549166097518,
            "eval_runtime": 0.3711,
            "eval_samples_per_second": 4041.685,
            "eval_steps_per_second": 32.333,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6597,
            "grad_norm": 1.9969922304153442,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.965756416320801,
            "eval_pearson": 0.8683982492294385,
            "eval_spearman": 0.8688576322674048,
            "eval_runtime": 0.3828,
            "eval_samples_per_second": 3918.602,
            "eval_steps_per_second": 31.349,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5982,
            "grad_norm": 1.7018015384674072,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 3.0333821773529053,
            "eval_pearson": 0.8743376793641976,
            "eval_spearman": 0.8753108976992573,
            "eval_runtime": 0.3743,
            "eval_samples_per_second": 4007.976,
            "eval_steps_per_second": 32.064,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5569,
            "grad_norm": 1.6698635816574097,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 3.016542434692383,
            "eval_pearson": 0.8788990357240773,
            "eval_spearman": 0.8793727141184617,
            "eval_runtime": 0.3719,
            "eval_samples_per_second": 4033.104,
            "eval_steps_per_second": 32.265,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5239,
            "grad_norm": 3.7105977535247803,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.931844472885132,
            "eval_pearson": 0.8826278625037243,
            "eval_spearman": 0.8828276946578234,
            "eval_runtime": 0.3778,
            "eval_samples_per_second": 3970.039,
            "eval_steps_per_second": 31.76,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.5021,
            "grad_norm": 2.6774280071258545,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.99961519241333,
            "eval_pearson": 0.8864220884663313,
            "eval_spearman": 0.8863328691946261,
            "eval_runtime": 0.4462,
            "eval_samples_per_second": 3361.799,
            "eval_steps_per_second": 26.894,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4855,
            "grad_norm": 2.3538818359375,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.9888932704925537,
            "eval_pearson": 0.8871375321812548,
            "eval_spearman": 0.8866488300815923,
            "eval_runtime": 0.372,
            "eval_samples_per_second": 4031.734,
            "eval_steps_per_second": 32.254,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4656,
            "grad_norm": 3.523562431335449,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.004220724105835,
            "eval_pearson": 0.8877002746885194,
            "eval_spearman": 0.8872020859122194,
            "eval_runtime": 0.373,
            "eval_samples_per_second": 4021.109,
            "eval_steps_per_second": 32.169,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4563,
            "grad_norm": 1.9838811159133911,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.9410336017608643,
            "eval_pearson": 0.8879998737658843,
            "eval_spearman": 0.8875977738931655,
            "eval_runtime": 0.3773,
            "eval_samples_per_second": 3975.317,
            "eval_steps_per_second": 31.803,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4405,
            "grad_norm": 5.672056674957275,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.9436168670654297,
            "eval_pearson": 0.8894488392640835,
            "eval_spearman": 0.888366121373684,
            "eval_runtime": 0.3787,
            "eval_samples_per_second": 3960.724,
            "eval_steps_per_second": 31.686,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.4332,
            "grad_norm": 1.8563727140426636,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.94614839553833,
            "eval_pearson": 0.8906145161255544,
            "eval_spearman": 0.8898389479452581,
            "eval_runtime": 0.3784,
            "eval_samples_per_second": 3963.784,
            "eval_steps_per_second": 31.71,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4274,
            "grad_norm": 1.9098273515701294,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.943638563156128,
            "eval_pearson": 0.8895174834004287,
            "eval_spearman": 0.8884993758042703,
            "eval_runtime": 0.378,
            "eval_samples_per_second": 3968.592,
            "eval_steps_per_second": 31.749,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.4182,
            "grad_norm": 1.4947181940078735,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.9111905097961426,
            "eval_pearson": 0.8913381345707712,
            "eval_spearman": 0.8902943625418114,
            "eval_runtime": 0.3763,
            "eval_samples_per_second": 3986.279,
            "eval_steps_per_second": 31.89,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.4117,
            "grad_norm": 1.7521533966064453,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.8915605545043945,
            "eval_pearson": 0.8916358865921078,
            "eval_spearman": 0.8906198700205997,
            "eval_runtime": 0.3734,
            "eval_samples_per_second": 4017.12,
            "eval_steps_per_second": 32.137,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "loss": 0.4098,
            "grad_norm": 1.5706714391708374,
            "learning_rate": 2.2222222222222223e-05,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "eval_loss": 2.918086290359497,
            "eval_pearson": 0.8918513097844093,
            "eval_spearman": 0.8907434094530539,
            "eval_runtime": 0.3804,
            "eval_samples_per_second": 3943.295,
            "eval_steps_per_second": 31.546,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "loss": 0.404,
            "grad_norm": 1.8288036584854126,
            "learning_rate": 1.728395061728395e-05,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 2.8884079456329346,
            "eval_pearson": 0.8912087841896599,
            "eval_spearman": 0.8900592769543163,
            "eval_runtime": 0.3812,
            "eval_samples_per_second": 3934.462,
            "eval_steps_per_second": 31.476,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "train_runtime": 263.5872,
            "train_samples_per_second": 2181.062,
            "train_steps_per_second": 17.072,
            "total_flos": 1.6167135625609216e+16,
            "train_loss": 1.1520335629111842,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 2.918086290359497,
            "eval_pearson": 0.8918513097844093,
            "eval_spearman": 0.8907434094530539,
            "eval_runtime": 0.3825,
            "eval_samples_per_second": 3921.951,
            "eval_steps_per_second": 31.376,
            "epoch": 84.44444444444444,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 263.5872,
        "trainable_params_count": 0.157441,
        "memory_allocated": [
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184
        ],
        "memory_reserved": [
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288
        ]
    },
    "variant": "kd-lora"
}