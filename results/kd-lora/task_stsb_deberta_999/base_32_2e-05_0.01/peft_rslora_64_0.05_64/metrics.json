{
    "eval_loss": 2.974475145339966,
    "eval_pearson": 0.887529271914375,
    "eval_spearman": 0.8843498336233622,
    "eval_runtime": 0.3457,
    "eval_samples_per_second": 4338.899,
    "eval_steps_per_second": 34.711,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 6.5704,
            "grad_norm": 40.39368438720703,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.5561044216156006,
            "eval_pearson": 0.8102691173591712,
            "eval_spearman": 0.8215772419507177,
            "eval_runtime": 0.2957,
            "eval_samples_per_second": 5072.045,
            "eval_steps_per_second": 40.576,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 0.7681,
            "grad_norm": 4.808217525482178,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.912431001663208,
            "eval_pearson": 0.8700285419796819,
            "eval_spearman": 0.8692520376096772,
            "eval_runtime": 0.3014,
            "eval_samples_per_second": 4977.083,
            "eval_steps_per_second": 39.817,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.4974,
            "grad_norm": 12.593111038208008,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.156235694885254,
            "eval_pearson": 0.8797963571950069,
            "eval_spearman": 0.8798837070494279,
            "eval_runtime": 0.3391,
            "eval_samples_per_second": 4423.951,
            "eval_steps_per_second": 35.392,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.3541,
            "grad_norm": 7.213044166564941,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.152556896209717,
            "eval_pearson": 0.8764900112301734,
            "eval_spearman": 0.8794186715054573,
            "eval_runtime": 0.3499,
            "eval_samples_per_second": 4286.37,
            "eval_steps_per_second": 34.291,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.2632,
            "grad_norm": 2.905733346939087,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.946934938430786,
            "eval_pearson": 0.8789807507091741,
            "eval_spearman": 0.878167832364295,
            "eval_runtime": 0.3018,
            "eval_samples_per_second": 4969.539,
            "eval_steps_per_second": 39.756,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.214,
            "grad_norm": 3.135143518447876,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.9268860816955566,
            "eval_pearson": 0.8804351751108569,
            "eval_spearman": 0.8785794410157071,
            "eval_runtime": 0.2999,
            "eval_samples_per_second": 5001.996,
            "eval_steps_per_second": 40.016,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.1769,
            "grad_norm": 3.7430214881896973,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.9755449295043945,
            "eval_pearson": 0.8852406137398684,
            "eval_spearman": 0.8813106720471011,
            "eval_runtime": 0.3445,
            "eval_samples_per_second": 4354.449,
            "eval_steps_per_second": 34.836,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.154,
            "grad_norm": 3.8665688037872314,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.9682793617248535,
            "eval_pearson": 0.8817703162245973,
            "eval_spearman": 0.8799929435785727,
            "eval_runtime": 0.3488,
            "eval_samples_per_second": 4300.189,
            "eval_steps_per_second": 34.402,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.1394,
            "grad_norm": 5.433259963989258,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.933748722076416,
            "eval_pearson": 0.8809172346209908,
            "eval_spearman": 0.8781519120483003,
            "eval_runtime": 0.3376,
            "eval_samples_per_second": 4443.401,
            "eval_steps_per_second": 35.547,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.1266,
            "grad_norm": 2.251490831375122,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 3.1037333011627197,
            "eval_pearson": 0.8815728199827669,
            "eval_spearman": 0.8779882535191027,
            "eval_runtime": 0.299,
            "eval_samples_per_second": 5016.522,
            "eval_steps_per_second": 40.132,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.115,
            "grad_norm": 1.6183112859725952,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.0234456062316895,
            "eval_pearson": 0.8830704662798798,
            "eval_spearman": 0.8798007535249849,
            "eval_runtime": 0.292,
            "eval_samples_per_second": 5136.49,
            "eval_steps_per_second": 41.092,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.1056,
            "grad_norm": 2.431220531463623,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.974475145339966,
            "eval_pearson": 0.887529271914375,
            "eval_spearman": 0.8843498336233622,
            "eval_runtime": 0.3377,
            "eval_samples_per_second": 4441.826,
            "eval_steps_per_second": 35.535,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.099,
            "grad_norm": 2.780764102935791,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.8948705196380615,
            "eval_pearson": 0.883217282216831,
            "eval_spearman": 0.8795748766700753,
            "eval_runtime": 0.3385,
            "eval_samples_per_second": 4431.289,
            "eval_steps_per_second": 35.45,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.0915,
            "grad_norm": 1.3586257696151733,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.0142083168029785,
            "eval_pearson": 0.8831170326252195,
            "eval_spearman": 0.8797016365540019,
            "eval_runtime": 0.3005,
            "eval_samples_per_second": 4991.124,
            "eval_steps_per_second": 39.929,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.0877,
            "grad_norm": 2.669891357421875,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 3.054138660430908,
            "eval_pearson": 0.8824815142305623,
            "eval_spearman": 0.8786894165232391,
            "eval_runtime": 0.3035,
            "eval_samples_per_second": 4942.053,
            "eval_steps_per_second": 39.536,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.0846,
            "grad_norm": 1.670149564743042,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.894730567932129,
            "eval_pearson": 0.8860401558731203,
            "eval_spearman": 0.8830846266457354,
            "eval_runtime": 0.2996,
            "eval_samples_per_second": 5006.172,
            "eval_steps_per_second": 40.049,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.0816,
            "grad_norm": 1.2838151454925537,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.906794309616089,
            "eval_pearson": 0.8836608535634008,
            "eval_spearman": 0.8807164680158389,
            "eval_runtime": 0.3474,
            "eval_samples_per_second": 4317.683,
            "eval_steps_per_second": 34.541,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 211.7674,
            "train_samples_per_second": 2714.772,
            "train_steps_per_second": 21.25,
            "total_flos": 1.4807244826738688e+16,
            "train_loss": 0.5840705753775204,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.974475145339966,
            "eval_pearson": 0.887529271914375,
            "eval_spearman": 0.8843498336233622,
            "eval_runtime": 0.3457,
            "eval_samples_per_second": 4338.899,
            "eval_steps_per_second": 34.711,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 64,
        "lora_alpha": 64,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 211.7674,
        "trainable_params_count": 1.180417,
        "memory_allocated": [
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456
        ],
        "memory_reserved": [
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584
        ]
    },
    "variant": "kd-lora"
}