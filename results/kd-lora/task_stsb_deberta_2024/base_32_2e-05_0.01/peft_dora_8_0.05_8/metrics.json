{
    "eval_loss": 2.7563729286193848,
    "eval_pearson": 0.883755886014593,
    "eval_spearman": 0.8825464786489305,
    "eval_runtime": 0.3827,
    "eval_samples_per_second": 3919.827,
    "eval_steps_per_second": 31.359,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 9.3766,
            "grad_norm": 42.87153244018555,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 5.685179233551025,
            "eval_pearson": 0.0035592215455580345,
            "eval_spearman": 0.006793808725607429,
            "eval_runtime": 0.38,
            "eval_samples_per_second": 3947.432,
            "eval_steps_per_second": 31.579,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 3.3658,
            "grad_norm": 5.135931015014648,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.6494624614715576,
            "eval_pearson": 0.6297388643394094,
            "eval_spearman": 0.6325418702957004,
            "eval_runtime": 0.4133,
            "eval_samples_per_second": 3629.488,
            "eval_steps_per_second": 29.036,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.0283,
            "grad_norm": 4.119112968444824,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.9945333003997803,
            "eval_pearson": 0.842146632030307,
            "eval_spearman": 0.8445617434845202,
            "eval_runtime": 0.3763,
            "eval_samples_per_second": 3986.428,
            "eval_steps_per_second": 31.891,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7541,
            "grad_norm": 2.2595653533935547,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.9138476848602295,
            "eval_pearson": 0.8584828676689178,
            "eval_spearman": 0.8585458786558845,
            "eval_runtime": 0.3812,
            "eval_samples_per_second": 3935.276,
            "eval_steps_per_second": 31.482,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6732,
            "grad_norm": 2.525944948196411,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.9021711349487305,
            "eval_pearson": 0.8677714345435616,
            "eval_spearman": 0.8666657299133449,
            "eval_runtime": 0.3733,
            "eval_samples_per_second": 4018.033,
            "eval_steps_per_second": 32.144,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.608,
            "grad_norm": 4.136333465576172,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.9011387825012207,
            "eval_pearson": 0.8703106932137475,
            "eval_spearman": 0.869341399858645,
            "eval_runtime": 0.4133,
            "eval_samples_per_second": 3628.975,
            "eval_steps_per_second": 29.032,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5714,
            "grad_norm": 2.4898502826690674,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.836256504058838,
            "eval_pearson": 0.8747377970588336,
            "eval_spearman": 0.873257414847886,
            "eval_runtime": 0.3711,
            "eval_samples_per_second": 4041.516,
            "eval_steps_per_second": 32.332,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5457,
            "grad_norm": 5.309934139251709,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.8123955726623535,
            "eval_pearson": 0.8752617413267344,
            "eval_spearman": 0.8740038406852422,
            "eval_runtime": 0.3811,
            "eval_samples_per_second": 3936.239,
            "eval_steps_per_second": 31.49,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.5249,
            "grad_norm": 1.5074512958526611,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.8400449752807617,
            "eval_pearson": 0.8788096592092465,
            "eval_spearman": 0.8773701119244529,
            "eval_runtime": 0.378,
            "eval_samples_per_second": 3968.602,
            "eval_steps_per_second": 31.749,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4971,
            "grad_norm": 4.493513107299805,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.8166236877441406,
            "eval_pearson": 0.8804541751597463,
            "eval_spearman": 0.8792105836100497,
            "eval_runtime": 0.3789,
            "eval_samples_per_second": 3959.069,
            "eval_steps_per_second": 31.673,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4865,
            "grad_norm": 3.7751758098602295,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.788173198699951,
            "eval_pearson": 0.8799850770247362,
            "eval_spearman": 0.8788479241546288,
            "eval_runtime": 0.3777,
            "eval_samples_per_second": 3971.613,
            "eval_steps_per_second": 31.773,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4726,
            "grad_norm": 3.2046921253204346,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.7980005741119385,
            "eval_pearson": 0.8824826770886796,
            "eval_spearman": 0.8812420625639543,
            "eval_runtime": 0.377,
            "eval_samples_per_second": 3978.261,
            "eval_steps_per_second": 31.826,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4575,
            "grad_norm": 1.8065435886383057,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.7962486743927,
            "eval_pearson": 0.883460939609981,
            "eval_spearman": 0.8820970318397662,
            "eval_runtime": 0.4588,
            "eval_samples_per_second": 3269.461,
            "eval_steps_per_second": 26.156,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.4421,
            "grad_norm": 1.2730700969696045,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.781675100326538,
            "eval_pearson": 0.8836877910845449,
            "eval_spearman": 0.8825083882563182,
            "eval_runtime": 0.3802,
            "eval_samples_per_second": 3945.548,
            "eval_steps_per_second": 31.564,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4381,
            "grad_norm": 2.0799684524536133,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.823012590408325,
            "eval_pearson": 0.8836717777625377,
            "eval_spearman": 0.8823699291043103,
            "eval_runtime": 0.3771,
            "eval_samples_per_second": 3978.052,
            "eval_steps_per_second": 31.824,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.435,
            "grad_norm": 2.103545904159546,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.7688112258911133,
            "eval_pearson": 0.8838515270348442,
            "eval_spearman": 0.8825180568236217,
            "eval_runtime": 0.3873,
            "eval_samples_per_second": 3873.193,
            "eval_steps_per_second": 30.986,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.426,
            "grad_norm": 3.585146188735962,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.7563729286193848,
            "eval_pearson": 0.883755886014593,
            "eval_spearman": 0.8825464786489305,
            "eval_runtime": 0.389,
            "eval_samples_per_second": 3855.879,
            "eval_steps_per_second": 30.847,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 239.2001,
            "train_samples_per_second": 2403.427,
            "train_steps_per_second": 18.813,
            "total_flos": 1.4465331875545088e+16,
            "train_loss": 1.2413317915972542,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.7563729286193848,
            "eval_pearson": 0.883755886014593,
            "eval_spearman": 0.8825464786489305,
            "eval_runtime": 0.3827,
            "eval_samples_per_second": 3919.827,
            "eval_steps_per_second": 31.359,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 239.2001,
        "trainable_params_count": 0.157441,
        "memory_allocated": [
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184,
            588.253184
        ],
        "memory_reserved": [
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944,
            2820.66944
        ]
    },
    "variant": "kd-lora"
}