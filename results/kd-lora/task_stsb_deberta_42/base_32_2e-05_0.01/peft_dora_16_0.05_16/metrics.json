{
    "eval_loss": 2.8006153106689453,
    "eval_pearson": 0.8848553808172422,
    "eval_spearman": 0.8841032406071415,
    "eval_runtime": 0.3837,
    "eval_samples_per_second": 3909.597,
    "eval_steps_per_second": 31.277,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 9.1371,
            "grad_norm": 31.25210952758789,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 5.22785758972168,
            "eval_pearson": 0.0012125052577913673,
            "eval_spearman": -0.01246741941101966,
            "eval_runtime": 0.3782,
            "eval_samples_per_second": 3966.598,
            "eval_steps_per_second": 31.733,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.6365,
            "grad_norm": 12.209013938903809,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.4960739612579346,
            "eval_pearson": 0.7835453658468174,
            "eval_spearman": 0.8223208117392938,
            "eval_runtime": 0.3752,
            "eval_samples_per_second": 3998.343,
            "eval_steps_per_second": 31.987,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.8846,
            "grad_norm": 3.2997517585754395,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.8493499755859375,
            "eval_pearson": 0.8554455120117849,
            "eval_spearman": 0.8588784022876753,
            "eval_runtime": 0.3728,
            "eval_samples_per_second": 4023.457,
            "eval_steps_per_second": 32.188,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6885,
            "grad_norm": 1.5163869857788086,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.885972738265991,
            "eval_pearson": 0.8669798107325744,
            "eval_spearman": 0.8667039469609351,
            "eval_runtime": 0.375,
            "eval_samples_per_second": 3999.969,
            "eval_steps_per_second": 32.0,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5951,
            "grad_norm": 1.890582799911499,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.9227142333984375,
            "eval_pearson": 0.8711887540683707,
            "eval_spearman": 0.8704246341004901,
            "eval_runtime": 0.3802,
            "eval_samples_per_second": 3944.942,
            "eval_steps_per_second": 31.56,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5519,
            "grad_norm": 4.459407806396484,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.8720545768737793,
            "eval_pearson": 0.8752881326126623,
            "eval_spearman": 0.8746255201041406,
            "eval_runtime": 0.3802,
            "eval_samples_per_second": 3945.189,
            "eval_steps_per_second": 31.562,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5114,
            "grad_norm": 2.2484307289123535,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.903125762939453,
            "eval_pearson": 0.8758356352595515,
            "eval_spearman": 0.8768359812889404,
            "eval_runtime": 0.3875,
            "eval_samples_per_second": 3870.836,
            "eval_steps_per_second": 30.967,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4854,
            "grad_norm": 2.5679638385772705,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.7528483867645264,
            "eval_pearson": 0.8790263064051308,
            "eval_spearman": 0.8785797997949474,
            "eval_runtime": 0.3816,
            "eval_samples_per_second": 3930.367,
            "eval_steps_per_second": 31.443,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4662,
            "grad_norm": 3.7303194999694824,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.8971641063690186,
            "eval_pearson": 0.881610935174353,
            "eval_spearman": 0.880164666735843,
            "eval_runtime": 0.39,
            "eval_samples_per_second": 3846.59,
            "eval_steps_per_second": 30.773,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4407,
            "grad_norm": 1.5460096597671509,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.8079497814178467,
            "eval_pearson": 0.8822443640823263,
            "eval_spearman": 0.8819429654077969,
            "eval_runtime": 0.3811,
            "eval_samples_per_second": 3936.224,
            "eval_steps_per_second": 31.49,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4273,
            "grad_norm": 1.6913632154464722,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.8287229537963867,
            "eval_pearson": 0.8828873304080764,
            "eval_spearman": 0.8818676345360678,
            "eval_runtime": 0.3042,
            "eval_samples_per_second": 4930.318,
            "eval_steps_per_second": 39.443,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4088,
            "grad_norm": 1.8671839237213135,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.8137717247009277,
            "eval_pearson": 0.8840739166062725,
            "eval_spearman": 0.8833594921169601,
            "eval_runtime": 0.3749,
            "eval_samples_per_second": 4001.516,
            "eval_steps_per_second": 32.012,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4014,
            "grad_norm": 1.6924878358840942,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.8006153106689453,
            "eval_pearson": 0.8848553808172422,
            "eval_spearman": 0.8841032406071415,
            "eval_runtime": 0.3785,
            "eval_samples_per_second": 3962.84,
            "eval_steps_per_second": 31.703,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.3931,
            "grad_norm": 3.2834980487823486,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.8230392932891846,
            "eval_pearson": 0.8847747763516234,
            "eval_spearman": 0.8832704980524688,
            "eval_runtime": 0.3646,
            "eval_samples_per_second": 4114.217,
            "eval_steps_per_second": 32.914,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.3808,
            "grad_norm": 1.8526033163070679,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.813603401184082,
            "eval_pearson": 0.8845243953908621,
            "eval_spearman": 0.883881096492584,
            "eval_runtime": 0.3792,
            "eval_samples_per_second": 3956.127,
            "eval_steps_per_second": 31.649,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3778,
            "grad_norm": 1.774194359779358,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.8785390853881836,
            "eval_pearson": 0.884561279290487,
            "eval_spearman": 0.8831393362127351,
            "eval_runtime": 0.393,
            "eval_samples_per_second": 3816.737,
            "eval_steps_per_second": 30.534,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3692,
            "grad_norm": 3.2974138259887695,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.800750732421875,
            "eval_pearson": 0.8843726477286176,
            "eval_spearman": 0.8827951687650998,
            "eval_runtime": 0.3729,
            "eval_samples_per_second": 4022.271,
            "eval_steps_per_second": 32.178,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 238.0107,
            "train_samples_per_second": 2415.437,
            "train_steps_per_second": 18.907,
            "total_flos": 1.4514616625266688e+16,
            "train_loss": 1.126799592410817,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.8006153106689453,
            "eval_pearson": 0.8848553808172422,
            "eval_spearman": 0.8841032406071415,
            "eval_runtime": 0.3837,
            "eval_samples_per_second": 3909.597,
            "eval_steps_per_second": 31.277,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 238.0107,
        "trainable_params_count": 0.304897,
        "memory_allocated": [
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648,
            591.515648
        ],
        "memory_reserved": [
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568,
            2850.029568
        ]
    },
    "variant": "kd-lora"
}