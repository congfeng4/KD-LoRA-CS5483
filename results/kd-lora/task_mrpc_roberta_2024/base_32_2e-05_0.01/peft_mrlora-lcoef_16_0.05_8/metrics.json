{
    "eval_loss": 2.7821640968322754,
    "eval_accuracy": 0.8553921568627451,
    "eval_f1": 0.8987993138936535,
    "eval_runtime": 0.0833,
    "eval_samples_per_second": 4898.261,
    "eval_steps_per_second": 48.022,
    "epoch": 75.86206896551724,
    "log_history": [
        {
            "loss": 1.2264,
            "grad_norm": 4.428812026977539,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 1.2844080924987793,
            "eval_accuracy": 0.7181372549019608,
            "eval_f1": 0.8244274809160306,
            "eval_runtime": 0.0845,
            "eval_samples_per_second": 4825.689,
            "eval_steps_per_second": 47.311,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.8289,
            "grad_norm": 9.014019012451172,
            "learning_rate": 9.578544061302682e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 1.7891277074813843,
            "eval_accuracy": 0.8382352941176471,
            "eval_f1": 0.8914473684210527,
            "eval_runtime": 0.0833,
            "eval_samples_per_second": 4900.0,
            "eval_steps_per_second": 48.039,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.5917,
            "grad_norm": 9.226665496826172,
            "learning_rate": 8.812260536398468e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 2.024636745452881,
            "eval_accuracy": 0.8382352941176471,
            "eval_f1": 0.8888888888888888,
            "eval_runtime": 0.0835,
            "eval_samples_per_second": 4883.43,
            "eval_steps_per_second": 47.877,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.4737,
            "grad_norm": 20.20862579345703,
            "learning_rate": 8.045977011494253e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 2.2372241020202637,
            "eval_accuracy": 0.8308823529411765,
            "eval_f1": 0.883248730964467,
            "eval_runtime": 0.0813,
            "eval_samples_per_second": 5020.245,
            "eval_steps_per_second": 49.218,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.3876,
            "grad_norm": 11.372486114501953,
            "learning_rate": 7.279693486590039e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 2.438432216644287,
            "eval_accuracy": 0.8308823529411765,
            "eval_f1": 0.8840336134453781,
            "eval_runtime": 0.0825,
            "eval_samples_per_second": 4945.599,
            "eval_steps_per_second": 48.486,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.319,
            "grad_norm": 7.644038677215576,
            "learning_rate": 6.513409961685824e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 2.544990062713623,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.9003436426116839,
            "eval_runtime": 0.0904,
            "eval_samples_per_second": 4514.192,
            "eval_steps_per_second": 44.257,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.2739,
            "grad_norm": 21.334182739257812,
            "learning_rate": 5.747126436781609e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 2.555581569671631,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.9008695652173914,
            "eval_runtime": 0.0822,
            "eval_samples_per_second": 4963.875,
            "eval_steps_per_second": 48.665,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.2308,
            "grad_norm": 12.214409828186035,
            "learning_rate": 4.980842911877395e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 2.702042579650879,
            "eval_accuracy": 0.8504901960784313,
            "eval_f1": 0.8942807625649914,
            "eval_runtime": 0.0615,
            "eval_samples_per_second": 6638.694,
            "eval_steps_per_second": 65.085,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.2073,
            "grad_norm": 6.028311252593994,
            "learning_rate": 4.21455938697318e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 2.7499988079071045,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8958333333333334,
            "eval_runtime": 0.084,
            "eval_samples_per_second": 4855.207,
            "eval_steps_per_second": 47.6,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.1819,
            "grad_norm": 10.271414756774902,
            "learning_rate": 3.4482758620689657e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 2.7420499324798584,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.9015544041450777,
            "eval_runtime": 0.0826,
            "eval_samples_per_second": 4942.313,
            "eval_steps_per_second": 48.454,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "loss": 0.1751,
            "grad_norm": 12.45401668548584,
            "learning_rate": 2.681992337164751e-05,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "eval_loss": 2.766666889190674,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.9006849315068494,
            "eval_runtime": 0.0835,
            "eval_samples_per_second": 4885.089,
            "eval_steps_per_second": 47.893,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "train_runtime": 122.9019,
            "train_samples_per_second": 2984.493,
            "train_steps_per_second": 23.596,
            "total_flos": 9485669617369088.0,
            "train_loss": 0.4451318428733132,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "eval_loss": 2.7821640968322754,
            "eval_accuracy": 0.8553921568627451,
            "eval_f1": 0.8987993138936535,
            "eval_runtime": 0.0833,
            "eval_samples_per_second": 4898.261,
            "eval_steps_per_second": 48.022,
            "epoch": 75.86206896551724,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 122.9019,
        "trainable_params_count": 0.739622,
        "memory_allocated": [
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312
        ],
        "memory_reserved": [
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392
        ]
    },
    "variant": "kd-lora"
}