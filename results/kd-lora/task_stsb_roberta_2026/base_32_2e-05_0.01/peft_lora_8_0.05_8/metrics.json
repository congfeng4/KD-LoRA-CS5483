{
    "eval_loss": 2.7272863388061523,
    "eval_pearson": 0.8666170422792472,
    "eval_spearman": 0.8645466223348571,
    "eval_runtime": 0.2136,
    "eval_samples_per_second": 7023.11,
    "eval_steps_per_second": 56.185,
    "epoch": 48.888888888888886,
    "log_history": [
        {
            "loss": 4.6804,
            "grad_norm": 6.451460838317871,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.843419313430786,
            "eval_pearson": 0.20051735513646235,
            "eval_spearman": 0.19561756864629612,
            "eval_runtime": 0.2157,
            "eval_samples_per_second": 6952.915,
            "eval_steps_per_second": 55.623,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.7492,
            "grad_norm": 3.355132818222046,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.6427533626556396,
            "eval_pearson": 0.8220742430156134,
            "eval_spearman": 0.8186125881714678,
            "eval_runtime": 0.221,
            "eval_samples_per_second": 6788.225,
            "eval_steps_per_second": 54.306,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.9024,
            "grad_norm": 5.3583760261535645,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.7365760803222656,
            "eval_pearson": 0.8531481362699014,
            "eval_spearman": 0.8496562883140254,
            "eval_runtime": 0.2108,
            "eval_samples_per_second": 7114.593,
            "eval_steps_per_second": 56.917,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7516,
            "grad_norm": 11.132054328918457,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.6817643642425537,
            "eval_pearson": 0.8587548569715705,
            "eval_spearman": 0.8554149786963476,
            "eval_runtime": 0.2115,
            "eval_samples_per_second": 7093.208,
            "eval_steps_per_second": 56.746,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6866,
            "grad_norm": 16.004104614257812,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.7562336921691895,
            "eval_pearson": 0.8593236562782051,
            "eval_spearman": 0.8563274492260926,
            "eval_runtime": 0.2109,
            "eval_samples_per_second": 7113.853,
            "eval_steps_per_second": 56.911,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.6411,
            "grad_norm": 2.570430278778076,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.7773239612579346,
            "eval_pearson": 0.8655182458859699,
            "eval_spearman": 0.8631551112089632,
            "eval_runtime": 0.2132,
            "eval_samples_per_second": 7035.959,
            "eval_steps_per_second": 56.288,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.6149,
            "grad_norm": 2.244781017303467,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.7378697395324707,
            "eval_pearson": 0.8629863940372624,
            "eval_spearman": 0.8604774251308742,
            "eval_runtime": 0.2139,
            "eval_samples_per_second": 7011.979,
            "eval_steps_per_second": 56.096,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5822,
            "grad_norm": 3.4334568977355957,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.6944997310638428,
            "eval_pearson": 0.8643911982579877,
            "eval_spearman": 0.861931187778545,
            "eval_runtime": 0.2147,
            "eval_samples_per_second": 6987.719,
            "eval_steps_per_second": 55.902,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.5687,
            "grad_norm": 3.9399373531341553,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.748037099838257,
            "eval_pearson": 0.8660594960252733,
            "eval_spearman": 0.8632855541832911,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 7109.713,
            "eval_steps_per_second": 56.878,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.5514,
            "grad_norm": 4.9282546043396,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.731231212615967,
            "eval_pearson": 0.8664194849733896,
            "eval_spearman": 0.8641000971081189,
            "eval_runtime": 0.2116,
            "eval_samples_per_second": 7089.324,
            "eval_steps_per_second": 56.715,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.5365,
            "grad_norm": 3.8215999603271484,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.7272863388061523,
            "eval_pearson": 0.8666170422792472,
            "eval_spearman": 0.8645466223348571,
            "eval_runtime": 0.2121,
            "eval_samples_per_second": 7071.721,
            "eval_steps_per_second": 56.574,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "train_runtime": 101.0064,
            "train_samples_per_second": 5691.72,
            "train_steps_per_second": 44.552,
            "total_flos": 9485321926344704.0,
            "train_loss": 1.115003908330744,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.7272863388061523,
            "eval_pearson": 0.8666170422792472,
            "eval_spearman": 0.8645466223348571,
            "eval_runtime": 0.2136,
            "eval_samples_per_second": 7023.11,
            "eval_steps_per_second": 56.185,
            "epoch": 48.888888888888886,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 101.0064,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}