{
    "eval_loss": 2.323435068130493,
    "eval_matthews_correlation": 0.5858661515147512,
    "eval_runtime": 0.3925,
    "eval_samples_per_second": 2657.425,
    "eval_steps_per_second": 22.931,
    "epoch": 59.701492537313435,
    "log_history": [
        {
            "loss": 1.5544,
            "grad_norm": 0.49044209718704224,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4516783952713013,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3421,
            "eval_samples_per_second": 3048.864,
            "eval_steps_per_second": 26.309,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4041,
            "grad_norm": 0.4058242440223694,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.459731936454773,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3669,
            "eval_samples_per_second": 2842.7,
            "eval_steps_per_second": 24.53,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.3872,
            "grad_norm": 0.5784556269645691,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.4407464265823364,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3579,
            "eval_samples_per_second": 2914.483,
            "eval_steps_per_second": 25.149,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.1107,
            "grad_norm": 0.6049429178237915,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.7560571432113647,
            "eval_matthews_correlation": 0.47776696465916185,
            "eval_runtime": 0.3472,
            "eval_samples_per_second": 3003.963,
            "eval_steps_per_second": 25.921,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9918,
            "grad_norm": 1.4440077543258667,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.8361200094223022,
            "eval_matthews_correlation": 0.5181917740456299,
            "eval_runtime": 0.3551,
            "eval_samples_per_second": 2937.555,
            "eval_steps_per_second": 25.348,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9577,
            "grad_norm": 2.356877565383911,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.8819565773010254,
            "eval_matthews_correlation": 0.5422671648885407,
            "eval_runtime": 0.3461,
            "eval_samples_per_second": 3013.627,
            "eval_steps_per_second": 26.004,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.9286,
            "grad_norm": 0.7495911121368408,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.9846230745315552,
            "eval_matthews_correlation": 0.536662198889055,
            "eval_runtime": 0.3224,
            "eval_samples_per_second": 3235.096,
            "eval_steps_per_second": 27.916,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.9015,
            "grad_norm": 0.6300283670425415,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.025662660598755,
            "eval_matthews_correlation": 0.5325068699355778,
            "eval_runtime": 0.3603,
            "eval_samples_per_second": 2895.118,
            "eval_steps_per_second": 24.982,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.8739,
            "grad_norm": 0.8424713015556335,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.1180522441864014,
            "eval_matthews_correlation": 0.547116568580723,
            "eval_runtime": 0.3647,
            "eval_samples_per_second": 2860.118,
            "eval_steps_per_second": 24.68,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.8583,
            "grad_norm": 0.7512689232826233,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.1297802925109863,
            "eval_matthews_correlation": 0.5625821583056989,
            "eval_runtime": 0.3354,
            "eval_samples_per_second": 3110.072,
            "eval_steps_per_second": 26.837,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.8416,
            "grad_norm": 1.1611809730529785,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.1908795833587646,
            "eval_matthews_correlation": 0.5729657494988228,
            "eval_runtime": 0.4009,
            "eval_samples_per_second": 2601.559,
            "eval_steps_per_second": 22.449,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.8184,
            "grad_norm": 0.8576909303665161,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.2543983459472656,
            "eval_matthews_correlation": 0.5752615459764325,
            "eval_runtime": 0.3521,
            "eval_samples_per_second": 2962.286,
            "eval_steps_per_second": 25.561,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.8019,
            "grad_norm": 0.9017148017883301,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.255826234817505,
            "eval_matthews_correlation": 0.5806473000395166,
            "eval_runtime": 0.3544,
            "eval_samples_per_second": 2942.845,
            "eval_steps_per_second": 25.394,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.7803,
            "grad_norm": 1.230808138847351,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.2898082733154297,
            "eval_matthews_correlation": 0.5780903072486336,
            "eval_runtime": 0.3415,
            "eval_samples_per_second": 3053.893,
            "eval_steps_per_second": 26.352,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.7719,
            "grad_norm": 0.7820855975151062,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.323435068130493,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.3515,
            "eval_samples_per_second": 2967.349,
            "eval_steps_per_second": 25.605,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.7699,
            "grad_norm": 0.7454469203948975,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.3525969982147217,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.3856,
            "eval_samples_per_second": 2704.617,
            "eval_steps_per_second": 23.338,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.7577,
            "grad_norm": 2.7845940589904785,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.38871693611145,
            "eval_matthews_correlation": 0.5834463254140851,
            "eval_runtime": 0.4051,
            "eval_samples_per_second": 2574.553,
            "eval_steps_per_second": 22.216,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.7404,
            "grad_norm": 0.8345386981964111,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.4564049243927,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.4008,
            "eval_samples_per_second": 2602.295,
            "eval_steps_per_second": 22.455,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.7361,
            "grad_norm": 0.7792029976844788,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 2.4316799640655518,
            "eval_matthews_correlation": 0.5786416039440073,
            "eval_runtime": 0.3622,
            "eval_samples_per_second": 2879.922,
            "eval_steps_per_second": 24.851,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.7381,
            "grad_norm": 0.8762468695640564,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.427466630935669,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.3819,
            "eval_samples_per_second": 2731.216,
            "eval_steps_per_second": 23.568,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "train_runtime": 336.3416,
            "train_samples_per_second": 2542.356,
            "train_steps_per_second": 19.92,
            "total_flos": 1.707308019089408e+16,
            "train_loss": 0.9362255859375,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.323435068130493,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.3925,
            "eval_samples_per_second": 2657.425,
            "eval_steps_per_second": 22.931,
            "epoch": 59.701492537313435,
            "step": 4000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 336.3416,
        "trainable_params_count": 0.296642,
        "memory_allocated": [
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184,
            591.65184
        ],
        "memory_reserved": [
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688,
            2673.8688
        ]
    },
    "variant": "kd-lora"
}