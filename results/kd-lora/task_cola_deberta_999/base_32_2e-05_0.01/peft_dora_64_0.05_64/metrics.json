{
    "eval_loss": 3.4824092388153076,
    "eval_matthews_correlation": 0.608093390893245,
    "eval_runtime": 0.2817,
    "eval_samples_per_second": 3702.964,
    "eval_steps_per_second": 31.953,
    "epoch": 68.65671641791045,
    "log_history": [
        {
            "loss": 1.5435,
            "grad_norm": 0.5992312431335449,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4480235576629639,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2038,
            "eval_samples_per_second": 5117.614,
            "eval_steps_per_second": 44.16,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.1876,
            "grad_norm": 1.7292402982711792,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.847204327583313,
            "eval_matthews_correlation": 0.4968948635850979,
            "eval_runtime": 0.2889,
            "eval_samples_per_second": 3610.754,
            "eval_steps_per_second": 31.157,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.9352,
            "grad_norm": 1.7501957416534424,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.8972806930541992,
            "eval_matthews_correlation": 0.5549749054428225,
            "eval_runtime": 0.2734,
            "eval_samples_per_second": 3814.769,
            "eval_steps_per_second": 32.917,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.8339,
            "grad_norm": 1.9459463357925415,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.2727105617523193,
            "eval_matthews_correlation": 0.5630684232854489,
            "eval_runtime": 0.2876,
            "eval_samples_per_second": 3627.042,
            "eval_steps_per_second": 31.298,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.7535,
            "grad_norm": 2.168210029602051,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.3185343742370605,
            "eval_matthews_correlation": 0.5865803156957233,
            "eval_runtime": 0.2764,
            "eval_samples_per_second": 3772.91,
            "eval_steps_per_second": 32.556,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6797,
            "grad_norm": 2.546786069869995,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.6182873249053955,
            "eval_matthews_correlation": 0.5786416039440073,
            "eval_runtime": 0.2825,
            "eval_samples_per_second": 3692.281,
            "eval_steps_per_second": 31.861,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6202,
            "grad_norm": 2.604340076446533,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.615283966064453,
            "eval_matthews_correlation": 0.5803192651231377,
            "eval_runtime": 0.2819,
            "eval_samples_per_second": 3699.256,
            "eval_steps_per_second": 31.921,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.57,
            "grad_norm": 3.5031511783599854,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.7359142303466797,
            "eval_matthews_correlation": 0.5861472777603488,
            "eval_runtime": 0.2846,
            "eval_samples_per_second": 3664.571,
            "eval_steps_per_second": 31.621,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5207,
            "grad_norm": 3.7258694171905518,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.8495938777923584,
            "eval_matthews_correlation": 0.5840154203141334,
            "eval_runtime": 0.2826,
            "eval_samples_per_second": 3690.92,
            "eval_steps_per_second": 31.849,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.4926,
            "grad_norm": 3.1238205432891846,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.9354288578033447,
            "eval_matthews_correlation": 0.5907527969578087,
            "eval_runtime": 0.285,
            "eval_samples_per_second": 3659.192,
            "eval_steps_per_second": 31.575,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4506,
            "grad_norm": 2.93146014213562,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 3.0594024658203125,
            "eval_matthews_correlation": 0.5924834238001306,
            "eval_runtime": 0.2769,
            "eval_samples_per_second": 3766.144,
            "eval_steps_per_second": 32.498,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.4173,
            "grad_norm": 2.825083017349243,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 3.1980862617492676,
            "eval_matthews_correlation": 0.5817890663339899,
            "eval_runtime": 0.284,
            "eval_samples_per_second": 3672.111,
            "eval_steps_per_second": 31.686,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3937,
            "grad_norm": 3.4538321495056152,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 3.2593114376068115,
            "eval_matthews_correlation": 0.5892524852490167,
            "eval_runtime": 0.2814,
            "eval_samples_per_second": 3706.917,
            "eval_steps_per_second": 31.987,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.3664,
            "grad_norm": 4.517183780670166,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 3.2692251205444336,
            "eval_matthews_correlation": 0.6012291127184685,
            "eval_runtime": 0.2855,
            "eval_samples_per_second": 3653.813,
            "eval_steps_per_second": 31.529,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3482,
            "grad_norm": 2.304882764816284,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 3.350489854812622,
            "eval_matthews_correlation": 0.5770529432203132,
            "eval_runtime": 0.2785,
            "eval_samples_per_second": 3744.632,
            "eval_steps_per_second": 32.312,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3393,
            "grad_norm": 3.4334006309509277,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.4538159370422363,
            "eval_matthews_correlation": 0.5922529130736769,
            "eval_runtime": 0.2755,
            "eval_samples_per_second": 3786.449,
            "eval_steps_per_second": 32.673,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3187,
            "grad_norm": 3.5293331146240234,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.4572274684906006,
            "eval_matthews_correlation": 0.6048093844194747,
            "eval_runtime": 0.2817,
            "eval_samples_per_second": 3702.108,
            "eval_steps_per_second": 31.945,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3032,
            "grad_norm": 2.938241481781006,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.4137516021728516,
            "eval_matthews_correlation": 0.6073548306804695,
            "eval_runtime": 0.2977,
            "eval_samples_per_second": 3503.794,
            "eval_steps_per_second": 30.234,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.2907,
            "grad_norm": 3.5755441188812256,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 3.4824092388153076,
            "eval_matthews_correlation": 0.608093390893245,
            "eval_runtime": 0.2794,
            "eval_samples_per_second": 3733.613,
            "eval_steps_per_second": 32.217,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.278,
            "grad_norm": 4.532932758331299,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 3.594193935394287,
            "eval_matthews_correlation": 0.5958590286908729,
            "eval_runtime": 0.2765,
            "eval_samples_per_second": 3771.755,
            "eval_steps_per_second": 32.546,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.2644,
            "grad_norm": 1.617988109588623,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 3.579571008682251,
            "eval_matthews_correlation": 0.5948184421509001,
            "eval_runtime": 0.281,
            "eval_samples_per_second": 3712.403,
            "eval_steps_per_second": 32.034,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.2577,
            "grad_norm": 5.362834930419922,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.577226161956787,
            "eval_matthews_correlation": 0.5819672098044298,
            "eval_runtime": 0.283,
            "eval_samples_per_second": 3685.267,
            "eval_steps_per_second": 31.8,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.2433,
            "grad_norm": 5.559266090393066,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.6630053520202637,
            "eval_matthews_correlation": 0.5866829545434369,
            "eval_runtime": 0.2859,
            "eval_samples_per_second": 3647.714,
            "eval_steps_per_second": 31.476,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "train_runtime": 315.8348,
            "train_samples_per_second": 2707.428,
            "train_steps_per_second": 21.214,
            "total_flos": 2.003819327337267e+16,
            "train_loss": 0.5395081387395444,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.4824092388153076,
            "eval_matthews_correlation": 0.608093390893245,
            "eval_runtime": 0.2817,
            "eval_samples_per_second": 3702.964,
            "eval_steps_per_second": 31.953,
            "epoch": 68.65671641791045,
            "step": 4600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 64,
        "lora_alpha": 64,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 315.8348,
        "trainable_params_count": 1.190402,
        "memory_allocated": [
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712,
            604.99712
        ],
        "memory_reserved": [
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672
        ]
    },
    "variant": "kd-lora"
}