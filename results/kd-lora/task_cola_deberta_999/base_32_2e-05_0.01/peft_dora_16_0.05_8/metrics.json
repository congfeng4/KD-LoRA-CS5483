{
    "eval_loss": 2.7609126567840576,
    "eval_matthews_correlation": 0.6063017263508896,
    "eval_runtime": 0.4101,
    "eval_samples_per_second": 2543.451,
    "eval_steps_per_second": 21.947,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 1.5517,
            "grad_norm": 0.4484297037124634,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4499518871307373,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.402,
            "eval_samples_per_second": 2594.431,
            "eval_steps_per_second": 22.387,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3421,
            "grad_norm": 1.521575689315796,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.590662956237793,
            "eval_matthews_correlation": 0.42401740759429074,
            "eval_runtime": 0.4067,
            "eval_samples_per_second": 2564.791,
            "eval_steps_per_second": 22.131,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0105,
            "grad_norm": 1.6873635053634644,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.797678828239441,
            "eval_matthews_correlation": 0.5221760895479017,
            "eval_runtime": 0.4143,
            "eval_samples_per_second": 2517.498,
            "eval_steps_per_second": 21.723,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9187,
            "grad_norm": 2.981553316116333,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.9321045875549316,
            "eval_matthews_correlation": 0.5526838482765232,
            "eval_runtime": 0.4014,
            "eval_samples_per_second": 2598.36,
            "eval_steps_per_second": 22.421,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8706,
            "grad_norm": 2.200376272201538,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.0562033653259277,
            "eval_matthews_correlation": 0.5722385869866928,
            "eval_runtime": 0.4257,
            "eval_samples_per_second": 2449.804,
            "eval_steps_per_second": 21.139,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8236,
            "grad_norm": 3.556962251663208,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.2669765949249268,
            "eval_matthews_correlation": 0.5779181076197502,
            "eval_runtime": 0.4039,
            "eval_samples_per_second": 2582.07,
            "eval_steps_per_second": 22.281,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.784,
            "grad_norm": 2.477485179901123,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.243858814239502,
            "eval_matthews_correlation": 0.5845760203069087,
            "eval_runtime": 0.382,
            "eval_samples_per_second": 2730.387,
            "eval_steps_per_second": 23.56,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7511,
            "grad_norm": 2.8300905227661133,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.3979179859161377,
            "eval_matthews_correlation": 0.5806473000395166,
            "eval_runtime": 0.4469,
            "eval_samples_per_second": 2333.846,
            "eval_steps_per_second": 20.139,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7199,
            "grad_norm": 3.979339361190796,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.5117170810699463,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.3798,
            "eval_samples_per_second": 2746.382,
            "eval_steps_per_second": 23.698,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7039,
            "grad_norm": 3.736555814743042,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.4979560375213623,
            "eval_matthews_correlation": 0.5885471185335819,
            "eval_runtime": 0.4257,
            "eval_samples_per_second": 2450.281,
            "eval_steps_per_second": 21.143,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6823,
            "grad_norm": 4.7940144538879395,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.6560885906219482,
            "eval_matthews_correlation": 0.5829638006957694,
            "eval_runtime": 0.4251,
            "eval_samples_per_second": 2453.309,
            "eval_steps_per_second": 21.169,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6559,
            "grad_norm": 3.5180962085723877,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.6796443462371826,
            "eval_matthews_correlation": 0.5908413057707468,
            "eval_runtime": 0.3856,
            "eval_samples_per_second": 2704.928,
            "eval_steps_per_second": 23.341,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.637,
            "grad_norm": 3.7347664833068848,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.6470048427581787,
            "eval_matthews_correlation": 0.6061605762137284,
            "eval_runtime": 0.396,
            "eval_samples_per_second": 2633.928,
            "eval_steps_per_second": 22.728,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6107,
            "grad_norm": 4.096693515777588,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.711331367492676,
            "eval_matthews_correlation": 0.6033168402681877,
            "eval_runtime": 0.4074,
            "eval_samples_per_second": 2560.041,
            "eval_steps_per_second": 22.09,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.608,
            "grad_norm": 3.6210148334503174,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.7609126567840576,
            "eval_matthews_correlation": 0.6063017263508896,
            "eval_runtime": 0.361,
            "eval_samples_per_second": 2889.171,
            "eval_steps_per_second": 24.931,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.5977,
            "grad_norm": 4.176619052886963,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.796229839324951,
            "eval_matthews_correlation": 0.5994237360829193,
            "eval_runtime": 0.4469,
            "eval_samples_per_second": 2333.929,
            "eval_steps_per_second": 20.139,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.584,
            "grad_norm": 8.504915237426758,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.837751626968384,
            "eval_matthews_correlation": 0.5963273779713936,
            "eval_runtime": 0.4152,
            "eval_samples_per_second": 2512.181,
            "eval_steps_per_second": 21.677,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5667,
            "grad_norm": 3.8435041904449463,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.8755764961242676,
            "eval_matthews_correlation": 0.6031932328167873,
            "eval_runtime": 0.3999,
            "eval_samples_per_second": 2607.984,
            "eval_steps_per_second": 22.504,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 332.7119,
            "train_samples_per_second": 2570.091,
            "train_steps_per_second": 20.138,
            "total_flos": 1.5316777332375552e+16,
            "train_loss": 0.801016239590115,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.7609126567840576,
            "eval_matthews_correlation": 0.6063017263508896,
            "eval_runtime": 0.4101,
            "eval_samples_per_second": 2543.451,
            "eval_steps_per_second": 21.947,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 332.7119,
        "trainable_params_count": 0.15821,
        "memory_allocated": [
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832
        ],
        "memory_reserved": [
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048,
            2829.058048
        ]
    },
    "variant": "kd-lora"
}