{
    "eval_loss": 2.867008924484253,
    "eval_matthews_correlation": 0.5914107788502262,
    "eval_runtime": 0.172,
    "eval_samples_per_second": 6064.242,
    "eval_steps_per_second": 52.328,
    "epoch": 68.65671641791045,
    "log_history": [
        {
            "loss": 1.4767,
            "grad_norm": 0.7729995250701904,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4986308813095093,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1683,
            "eval_samples_per_second": 6198.666,
            "eval_steps_per_second": 53.488,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3516,
            "grad_norm": 3.4688167572021484,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.7347867488861084,
            "eval_matthews_correlation": 0.36482611663159664,
            "eval_runtime": 0.1641,
            "eval_samples_per_second": 6355.791,
            "eval_steps_per_second": 54.844,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1307,
            "grad_norm": 2.1215243339538574,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.007359743118286,
            "eval_matthews_correlation": 0.4209578417145201,
            "eval_runtime": 0.1721,
            "eval_samples_per_second": 6060.352,
            "eval_steps_per_second": 52.295,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0623,
            "grad_norm": 2.293729543685913,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.1644792556762695,
            "eval_matthews_correlation": 0.4636216536931484,
            "eval_runtime": 0.1699,
            "eval_samples_per_second": 6139.881,
            "eval_steps_per_second": 52.981,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 1.0133,
            "grad_norm": 2.1927974224090576,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.0576889514923096,
            "eval_matthews_correlation": 0.5134084664186066,
            "eval_runtime": 0.1694,
            "eval_samples_per_second": 6155.536,
            "eval_steps_per_second": 53.116,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9624,
            "grad_norm": 4.426174163818359,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.2497200965881348,
            "eval_matthews_correlation": 0.51643905902784,
            "eval_runtime": 0.1677,
            "eval_samples_per_second": 6220.791,
            "eval_steps_per_second": 53.679,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.9381,
            "grad_norm": 2.0364480018615723,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.3955399990081787,
            "eval_matthews_correlation": 0.5287745826239029,
            "eval_runtime": 0.1616,
            "eval_samples_per_second": 6453.337,
            "eval_steps_per_second": 55.686,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.9051,
            "grad_norm": 2.8581435680389404,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.3158435821533203,
            "eval_matthews_correlation": 0.5577353353156735,
            "eval_runtime": 0.1671,
            "eval_samples_per_second": 6241.773,
            "eval_steps_per_second": 53.86,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.8753,
            "grad_norm": 2.8456296920776367,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.358931064605713,
            "eval_matthews_correlation": 0.5473459132428302,
            "eval_runtime": 0.1655,
            "eval_samples_per_second": 6300.212,
            "eval_steps_per_second": 54.364,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.8472,
            "grad_norm": 2.803173780441284,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.468855142593384,
            "eval_matthews_correlation": 0.5640063794282216,
            "eval_runtime": 0.172,
            "eval_samples_per_second": 6063.2,
            "eval_steps_per_second": 52.319,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.8349,
            "grad_norm": 8.444395065307617,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.665599822998047,
            "eval_matthews_correlation": 0.5342661861783563,
            "eval_runtime": 0.1671,
            "eval_samples_per_second": 6240.429,
            "eval_steps_per_second": 53.848,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.806,
            "grad_norm": 3.034496545791626,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.5856666564941406,
            "eval_matthews_correlation": 0.56217893832047,
            "eval_runtime": 0.1716,
            "eval_samples_per_second": 6078.87,
            "eval_steps_per_second": 52.454,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.7908,
            "grad_norm": 2.992119312286377,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.5604562759399414,
            "eval_matthews_correlation": 0.5633840892174439,
            "eval_runtime": 0.1694,
            "eval_samples_per_second": 6158.621,
            "eval_steps_per_second": 53.142,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.7748,
            "grad_norm": 2.993983507156372,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.8851261138916016,
            "eval_matthews_correlation": 0.5285348624455609,
            "eval_runtime": 0.1677,
            "eval_samples_per_second": 6218.863,
            "eval_steps_per_second": 53.662,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.7607,
            "grad_norm": 3.302116870880127,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.7063300609588623,
            "eval_matthews_correlation": 0.5713110471171509,
            "eval_runtime": 0.1683,
            "eval_samples_per_second": 6198.754,
            "eval_steps_per_second": 53.489,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.7518,
            "grad_norm": 8.141010284423828,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.7437667846679688,
            "eval_matthews_correlation": 0.5764508680057442,
            "eval_runtime": 0.174,
            "eval_samples_per_second": 5994.211,
            "eval_steps_per_second": 51.724,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.7325,
            "grad_norm": 3.236551523208618,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.8101325035095215,
            "eval_matthews_correlation": 0.5679361809424823,
            "eval_runtime": 0.1671,
            "eval_samples_per_second": 6243.528,
            "eval_steps_per_second": 53.875,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.7105,
            "grad_norm": 3.4845082759857178,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.807103395462036,
            "eval_matthews_correlation": 0.5907527969578087,
            "eval_runtime": 0.1757,
            "eval_samples_per_second": 5937.691,
            "eval_steps_per_second": 51.236,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.7135,
            "grad_norm": 3.2112925052642822,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 2.8234355449676514,
            "eval_matthews_correlation": 0.5786416039440073,
            "eval_runtime": 0.1679,
            "eval_samples_per_second": 6213.519,
            "eval_steps_per_second": 53.616,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.6936,
            "grad_norm": 2.850191593170166,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.917451858520508,
            "eval_matthews_correlation": 0.5804732682978748,
            "eval_runtime": 0.167,
            "eval_samples_per_second": 6245.284,
            "eval_steps_per_second": 53.89,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.6902,
            "grad_norm": 2.490180492401123,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 2.9409537315368652,
            "eval_matthews_correlation": 0.5834463254140851,
            "eval_runtime": 0.173,
            "eval_samples_per_second": 6027.976,
            "eval_steps_per_second": 52.015,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.6816,
            "grad_norm": 6.226171016693115,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 2.9010281562805176,
            "eval_matthews_correlation": 0.5855730181125508,
            "eval_runtime": 0.167,
            "eval_samples_per_second": 6246.301,
            "eval_steps_per_second": 53.899,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.6753,
            "grad_norm": 5.410260200500488,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 2.867008924484253,
            "eval_matthews_correlation": 0.5914107788502262,
            "eval_runtime": 0.1683,
            "eval_samples_per_second": 6197.542,
            "eval_steps_per_second": 53.478,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "train_runtime": 222.1781,
            "train_samples_per_second": 3848.715,
            "train_steps_per_second": 30.156,
            "total_flos": 1.983364042273587e+16,
            "train_loss": 0.8773425127112348,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 2.867008924484253,
            "eval_matthews_correlation": 0.5914107788502262,
            "eval_runtime": 0.172,
            "eval_samples_per_second": 6064.242,
            "eval_steps_per_second": 52.328,
            "epoch": 68.65671641791045,
            "step": 4600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 222.1781,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}