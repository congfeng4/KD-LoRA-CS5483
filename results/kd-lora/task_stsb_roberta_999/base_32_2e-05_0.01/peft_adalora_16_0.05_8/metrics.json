{
    "eval_loss": 2.7955143451690674,
    "eval_pearson": 0.861441595030255,
    "eval_spearman": 0.8605572512360247,
    "eval_runtime": 0.2214,
    "eval_samples_per_second": 6776.424,
    "eval_steps_per_second": 54.211,
    "epoch": 84.44444444444444,
    "log_history": [
        {
            "loss": 6.2825,
            "grad_norm": 2.1656877994537354,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.784574270248413,
            "eval_pearson": -0.028534487549453886,
            "eval_spearman": -0.016272618378793707,
            "eval_runtime": 0.2221,
            "eval_samples_per_second": 6752.272,
            "eval_steps_per_second": 54.018,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.4729,
            "grad_norm": 2.022205352783203,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.8434927463531494,
            "eval_pearson": 0.33436009921141957,
            "eval_spearman": 0.29870593216333646,
            "eval_runtime": 0.2206,
            "eval_samples_per_second": 6799.303,
            "eval_steps_per_second": 54.394,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.4038,
            "grad_norm": 8.93858528137207,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.591904878616333,
            "eval_pearson": 0.8118792101570785,
            "eval_spearman": 0.811370957831706,
            "eval_runtime": 0.219,
            "eval_samples_per_second": 6850.766,
            "eval_steps_per_second": 54.806,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 1.0122,
            "grad_norm": 1.8127180337905884,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.655829668045044,
            "eval_pearson": 0.8315461283156402,
            "eval_spearman": 0.8322160771158797,
            "eval_runtime": 0.1914,
            "eval_samples_per_second": 7837.428,
            "eval_steps_per_second": 62.699,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.9104,
            "grad_norm": 3.966329574584961,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.7431745529174805,
            "eval_pearson": 0.8415630620256009,
            "eval_spearman": 0.8416115973058177,
            "eval_runtime": 0.2181,
            "eval_samples_per_second": 6876.84,
            "eval_steps_per_second": 55.015,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.8539,
            "grad_norm": 9.018362045288086,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.721951723098755,
            "eval_pearson": 0.8449551260110313,
            "eval_spearman": 0.845650354225891,
            "eval_runtime": 0.1917,
            "eval_samples_per_second": 7824.571,
            "eval_steps_per_second": 62.597,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.8095,
            "grad_norm": 2.081859827041626,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.8394088745117188,
            "eval_pearson": 0.8499884808070175,
            "eval_spearman": 0.8499467146340148,
            "eval_runtime": 0.2167,
            "eval_samples_per_second": 6921.446,
            "eval_steps_per_second": 55.372,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.7748,
            "grad_norm": 1.0146006345748901,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.762754440307617,
            "eval_pearson": 0.8526083390409026,
            "eval_spearman": 0.8518160421281922,
            "eval_runtime": 0.2198,
            "eval_samples_per_second": 6823.165,
            "eval_steps_per_second": 54.585,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.7469,
            "grad_norm": 5.044854164123535,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.8560521602630615,
            "eval_pearson": 0.853764017834119,
            "eval_spearman": 0.8530796693566364,
            "eval_runtime": 0.2202,
            "eval_samples_per_second": 6812.754,
            "eval_steps_per_second": 54.502,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.7293,
            "grad_norm": 4.886348247528076,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.847841739654541,
            "eval_pearson": 0.8556879111669822,
            "eval_spearman": 0.8549005528131786,
            "eval_runtime": 0.1911,
            "eval_samples_per_second": 7849.808,
            "eval_steps_per_second": 62.798,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.7182,
            "grad_norm": 3.507098436355591,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.8540396690368652,
            "eval_pearson": 0.856980504793206,
            "eval_spearman": 0.8562172751434715,
            "eval_runtime": 0.192,
            "eval_samples_per_second": 7811.718,
            "eval_steps_per_second": 62.494,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.6952,
            "grad_norm": 2.5776374340057373,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.8377578258514404,
            "eval_pearson": 0.8571174029687809,
            "eval_spearman": 0.8565484724969381,
            "eval_runtime": 0.1915,
            "eval_samples_per_second": 7831.253,
            "eval_steps_per_second": 62.65,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.693,
            "grad_norm": 2.4376256465911865,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.8266665935516357,
            "eval_pearson": 0.8583071142094301,
            "eval_spearman": 0.8573789522401938,
            "eval_runtime": 0.1911,
            "eval_samples_per_second": 7848.163,
            "eval_steps_per_second": 62.785,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.6818,
            "grad_norm": 4.559829235076904,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.822733163833618,
            "eval_pearson": 0.8597352713730256,
            "eval_spearman": 0.8588070775315528,
            "eval_runtime": 0.1918,
            "eval_samples_per_second": 7822.382,
            "eval_steps_per_second": 62.579,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.6721,
            "grad_norm": 2.5793070793151855,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.8406457901000977,
            "eval_pearson": 0.8601271563343388,
            "eval_spearman": 0.8591635299851931,
            "eval_runtime": 0.2223,
            "eval_samples_per_second": 6749.012,
            "eval_steps_per_second": 53.992,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.6611,
            "grad_norm": 1.8231486082077026,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.851534843444824,
            "eval_pearson": 0.8607786295106326,
            "eval_spearman": 0.8597222541154856,
            "eval_runtime": 0.2239,
            "eval_samples_per_second": 6699.317,
            "eval_steps_per_second": 53.595,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.6519,
            "grad_norm": 4.49041748046875,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.804579973220825,
            "eval_pearson": 0.8615177761872952,
            "eval_spearman": 0.8603296941751527,
            "eval_runtime": 0.1903,
            "eval_samples_per_second": 7882.766,
            "eval_steps_per_second": 63.062,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "loss": 0.6506,
            "grad_norm": 1.8112547397613525,
            "learning_rate": 2.2222222222222223e-05,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "eval_loss": 2.808943271636963,
            "eval_pearson": 0.8610928990028164,
            "eval_spearman": 0.8599945686926429,
            "eval_runtime": 0.221,
            "eval_samples_per_second": 6787.485,
            "eval_steps_per_second": 54.3,
            "epoch": 80.0,
            "step": 3600
        },
        {
            "loss": 0.6454,
            "grad_norm": 1.4200960397720337,
            "learning_rate": 1.728395061728395e-05,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 2.7955143451690674,
            "eval_pearson": 0.861441595030255,
            "eval_spearman": 0.8605572512360247,
            "eval_runtime": 0.2218,
            "eval_samples_per_second": 6763.836,
            "eval_steps_per_second": 54.111,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "train_runtime": 177.384,
            "train_samples_per_second": 3240.992,
            "train_steps_per_second": 25.369,
            "total_flos": 1.643889605738496e+16,
            "train_loss": 1.1613399063913445,
            "epoch": 84.44444444444444,
            "step": 3800
        },
        {
            "eval_loss": 2.7955143451690674,
            "eval_pearson": 0.861441595030255,
            "eval_spearman": 0.8605572512360247,
            "eval_runtime": 0.2214,
            "eval_samples_per_second": 6776.424,
            "eval_steps_per_second": 54.211,
            "epoch": 84.44444444444444,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "adalora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 177.384,
        "trainable_params_count": 0.886465,
        "memory_allocated": [
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688,
            361.586688
        ],
        "memory_reserved": [
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424
        ]
    },
    "variant": "kd-lora"
}