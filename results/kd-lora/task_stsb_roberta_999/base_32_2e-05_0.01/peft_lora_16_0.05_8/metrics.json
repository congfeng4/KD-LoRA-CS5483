{
    "eval_loss": 2.948521375656128,
    "eval_pearson": 0.8699578276632052,
    "eval_spearman": 0.8678363868269521,
    "eval_runtime": 0.2128,
    "eval_samples_per_second": 7050.499,
    "eval_steps_per_second": 56.404,
    "epoch": 66.66666666666667,
    "log_history": [
        {
            "loss": 5.916,
            "grad_norm": 4.998249053955078,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.8037097454071045,
            "eval_pearson": 0.23242956481336643,
            "eval_spearman": 0.20426211916538647,
            "eval_runtime": 0.2107,
            "eval_samples_per_second": 7119.045,
            "eval_steps_per_second": 56.952,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.6015,
            "grad_norm": 12.070123672485352,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.803515911102295,
            "eval_pearson": 0.8374037939730626,
            "eval_spearman": 0.8322044654589358,
            "eval_runtime": 0.2092,
            "eval_samples_per_second": 7171.508,
            "eval_steps_per_second": 57.372,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.8729,
            "grad_norm": 7.3413262367248535,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.9343974590301514,
            "eval_pearson": 0.8605651810764898,
            "eval_spearman": 0.8567114788363215,
            "eval_runtime": 0.2094,
            "eval_samples_per_second": 7162.616,
            "eval_steps_per_second": 57.301,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.7483,
            "grad_norm": 3.2820820808410645,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.7942919731140137,
            "eval_pearson": 0.8620069148938314,
            "eval_spearman": 0.8595098635023107,
            "eval_runtime": 0.2166,
            "eval_samples_per_second": 6926.269,
            "eval_steps_per_second": 55.41,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6794,
            "grad_norm": 4.4425530433654785,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.9079296588897705,
            "eval_pearson": 0.8644903638308522,
            "eval_spearman": 0.8614055184131331,
            "eval_runtime": 0.2118,
            "eval_samples_per_second": 7081.121,
            "eval_steps_per_second": 56.649,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.6385,
            "grad_norm": 7.243739128112793,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.907263994216919,
            "eval_pearson": 0.8645923946054414,
            "eval_spearman": 0.8620851326921963,
            "eval_runtime": 0.1854,
            "eval_samples_per_second": 8091.738,
            "eval_steps_per_second": 64.734,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.6032,
            "grad_norm": 3.9351305961608887,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.8958516120910645,
            "eval_pearson": 0.8659108785571131,
            "eval_spearman": 0.8641331247480634,
            "eval_runtime": 0.2114,
            "eval_samples_per_second": 7096.273,
            "eval_steps_per_second": 56.77,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5755,
            "grad_norm": 3.722869634628296,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.8837311267852783,
            "eval_pearson": 0.866247350724814,
            "eval_spearman": 0.8636207557244263,
            "eval_runtime": 0.2128,
            "eval_samples_per_second": 7049.535,
            "eval_steps_per_second": 56.396,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.5512,
            "grad_norm": 3.8626205921173096,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.793440818786621,
            "eval_pearson": 0.8658415363007061,
            "eval_spearman": 0.8644619957936523,
            "eval_runtime": 0.2429,
            "eval_samples_per_second": 6174.699,
            "eval_steps_per_second": 49.398,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.537,
            "grad_norm": 8.443583488464355,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.8298144340515137,
            "eval_pearson": 0.868402456313849,
            "eval_spearman": 0.8665078609161678,
            "eval_runtime": 0.2115,
            "eval_samples_per_second": 7091.25,
            "eval_steps_per_second": 56.73,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.5269,
            "grad_norm": 9.057890892028809,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.980842351913452,
            "eval_pearson": 0.8679039543322772,
            "eval_spearman": 0.8663496231297925,
            "eval_runtime": 0.2126,
            "eval_samples_per_second": 7057.039,
            "eval_steps_per_second": 56.456,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.5095,
            "grad_norm": 8.16806411743164,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.918325901031494,
            "eval_pearson": 0.8685207902750907,
            "eval_spearman": 0.8669377999245567,
            "eval_runtime": 0.212,
            "eval_samples_per_second": 7076.995,
            "eval_steps_per_second": 56.616,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.5,
            "grad_norm": 7.7784743309021,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.948521375656128,
            "eval_pearson": 0.8699578276632052,
            "eval_spearman": 0.8678363868269521,
            "eval_runtime": 0.2134,
            "eval_samples_per_second": 7028.264,
            "eval_steps_per_second": 56.226,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.486,
            "grad_norm": 5.121006488800049,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.911318063735962,
            "eval_pearson": 0.8692073176834814,
            "eval_spearman": 0.8669302471125602,
            "eval_runtime": 0.2171,
            "eval_samples_per_second": 6908.89,
            "eval_steps_per_second": 55.271,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4742,
            "grad_norm": 4.91516637802124,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.931480884552002,
            "eval_pearson": 0.8684238633704969,
            "eval_spearman": 0.8662423174976642,
            "eval_runtime": 0.2116,
            "eval_samples_per_second": 7089.867,
            "eval_steps_per_second": 56.719,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "train_runtime": 134.4869,
            "train_samples_per_second": 4274.765,
            "train_steps_per_second": 33.461,
            "total_flos": 1.293452989956096e+16,
            "train_loss": 1.0146694208780924,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.948521375656128,
            "eval_pearson": 0.8699578276632052,
            "eval_spearman": 0.8678363868269521,
            "eval_runtime": 0.2128,
            "eval_samples_per_second": 7050.499,
            "eval_steps_per_second": 56.404,
            "epoch": 66.66666666666667,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 999,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 134.4869,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296,
            358.711296
        ],
        "memory_reserved": [
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424,
            1178.599424
        ]
    },
    "variant": "kd-lora"
}