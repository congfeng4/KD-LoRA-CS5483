{
    "eval_loss": 1.1087247133255005,
    "eval_matthews_correlation": 0.544509467622167,
    "eval_runtime": 0.2094,
    "eval_samples_per_second": 4979.986,
    "eval_steps_per_second": 42.972,
    "epoch": 62.6865671641791,
    "log_history": [
        {
            "loss": 0.8384,
            "grad_norm": 0.7043594717979431,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.7515673041343689,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.209,
            "eval_samples_per_second": 4989.699,
            "eval_steps_per_second": 43.056,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.6178,
            "grad_norm": 1.9350712299346924,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.9626220464706421,
            "eval_matthews_correlation": 0.39521791340818474,
            "eval_runtime": 0.2103,
            "eval_samples_per_second": 4960.027,
            "eval_steps_per_second": 42.8,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4903,
            "grad_norm": 1.2783703804016113,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.0045310258865356,
            "eval_matthews_correlation": 0.4472920787771666,
            "eval_runtime": 0.208,
            "eval_samples_per_second": 5013.844,
            "eval_steps_per_second": 43.264,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.4563,
            "grad_norm": 1.5584360361099243,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.9679000377655029,
            "eval_matthews_correlation": 0.4774618517292431,
            "eval_runtime": 0.2144,
            "eval_samples_per_second": 4864.905,
            "eval_steps_per_second": 41.979,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4335,
            "grad_norm": 1.7691032886505127,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.0760830640792847,
            "eval_matthews_correlation": 0.47194522204020767,
            "eval_runtime": 0.2098,
            "eval_samples_per_second": 4971.582,
            "eval_steps_per_second": 42.9,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.4171,
            "grad_norm": 1.8657312393188477,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.0009527206420898,
            "eval_matthews_correlation": 0.5024061937657525,
            "eval_runtime": 0.2059,
            "eval_samples_per_second": 5064.529,
            "eval_steps_per_second": 43.702,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4048,
            "grad_norm": 1.2896716594696045,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.037105679512024,
            "eval_matthews_correlation": 0.5181917740456299,
            "eval_runtime": 0.2097,
            "eval_samples_per_second": 4973.34,
            "eval_steps_per_second": 42.915,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.395,
            "grad_norm": 1.5797865390777588,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.1181447505950928,
            "eval_matthews_correlation": 0.4774992729117021,
            "eval_runtime": 0.2085,
            "eval_samples_per_second": 5002.166,
            "eval_steps_per_second": 43.163,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3773,
            "grad_norm": 1.2084271907806396,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.0742037296295166,
            "eval_matthews_correlation": 0.5100410597431988,
            "eval_runtime": 0.2075,
            "eval_samples_per_second": 5027.044,
            "eval_steps_per_second": 43.378,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3699,
            "grad_norm": 3.539818048477173,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.1204975843429565,
            "eval_matthews_correlation": 0.49652146303644756,
            "eval_runtime": 0.2096,
            "eval_samples_per_second": 4976.955,
            "eval_steps_per_second": 42.946,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3614,
            "grad_norm": 1.5830477476119995,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.0735752582550049,
            "eval_matthews_correlation": 0.5154446997281555,
            "eval_runtime": 0.2072,
            "eval_samples_per_second": 5034.339,
            "eval_steps_per_second": 43.441,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.356,
            "grad_norm": 1.093602180480957,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.1197985410690308,
            "eval_matthews_correlation": 0.5261360919387726,
            "eval_runtime": 0.2103,
            "eval_samples_per_second": 4958.683,
            "eval_steps_per_second": 42.788,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3473,
            "grad_norm": 2.770115852355957,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.1147403717041016,
            "eval_matthews_correlation": 0.5258867890805083,
            "eval_runtime": 0.2279,
            "eval_samples_per_second": 4575.951,
            "eval_steps_per_second": 39.486,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.344,
            "grad_norm": 1.3185502290725708,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.12467622756958,
            "eval_matthews_correlation": 0.5259790835948196,
            "eval_runtime": 0.1793,
            "eval_samples_per_second": 5815.827,
            "eval_steps_per_second": 50.185,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3382,
            "grad_norm": 2.2649049758911133,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.1218791007995605,
            "eval_matthews_correlation": 0.5373623427702773,
            "eval_runtime": 0.2076,
            "eval_samples_per_second": 5025.132,
            "eval_steps_per_second": 43.362,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3366,
            "grad_norm": 1.3693681955337524,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.1087247133255005,
            "eval_matthews_correlation": 0.544509467622167,
            "eval_runtime": 0.2106,
            "eval_samples_per_second": 4952.592,
            "eval_steps_per_second": 42.736,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3296,
            "grad_norm": 2.31834077835083,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.113978385925293,
            "eval_matthews_correlation": 0.5416469931221344,
            "eval_runtime": 0.2133,
            "eval_samples_per_second": 4890.401,
            "eval_steps_per_second": 42.199,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3199,
            "grad_norm": 2.4661760330200195,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.1243332624435425,
            "eval_matthews_correlation": 0.5418980827011334,
            "eval_runtime": 0.2065,
            "eval_samples_per_second": 5051.744,
            "eval_steps_per_second": 43.591,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3212,
            "grad_norm": 1.3413649797439575,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.1195210218429565,
            "eval_matthews_correlation": 0.5298746530730193,
            "eval_runtime": 0.2072,
            "eval_samples_per_second": 5033.157,
            "eval_steps_per_second": 43.431,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3182,
            "grad_norm": 1.7555925846099854,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.122991681098938,
            "eval_matthews_correlation": 0.5442645975519255,
            "eval_runtime": 0.217,
            "eval_samples_per_second": 4805.913,
            "eval_steps_per_second": 41.47,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3141,
            "grad_norm": 1.289847731590271,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.1271604299545288,
            "eval_matthews_correlation": 0.5390439985632989,
            "eval_runtime": 0.2104,
            "eval_samples_per_second": 4956.935,
            "eval_steps_per_second": 42.773,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "train_runtime": 234.3074,
            "train_samples_per_second": 3649.479,
            "train_steps_per_second": 28.595,
            "total_flos": 1.8112781110738944e+16,
            "train_loss": 0.40413466953095933,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.1087247133255005,
            "eval_matthews_correlation": 0.544509467622167,
            "eval_runtime": 0.2094,
            "eval_samples_per_second": 4979.986,
            "eval_steps_per_second": 42.972,
            "epoch": 62.6865671641791,
            "step": 4200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 234.3074,
        "trainable_params_count": 0.748802,
        "memory_allocated": [
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112
        ],
        "memory_reserved": [
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128
        ]
    },
    "variant": "kd-lora"
}