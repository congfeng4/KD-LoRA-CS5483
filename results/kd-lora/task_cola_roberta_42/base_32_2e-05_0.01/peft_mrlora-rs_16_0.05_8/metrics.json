{
    "eval_loss": 0.6736274361610413,
    "eval_matthews_correlation": 0.5235990316279782,
    "eval_runtime": 0.1809,
    "eval_samples_per_second": 5764.147,
    "eval_steps_per_second": 49.739,
    "epoch": 20.0,
    "log_history": [
        {
            "loss": 0.5476,
            "grad_norm": 2.138232469558716,
            "learning_rate": 7.910447761194029e-05,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "eval_loss": 0.7036967277526855,
            "eval_matthews_correlation": 0.33476181390509474,
            "eval_runtime": 0.1828,
            "eval_samples_per_second": 5704.252,
            "eval_steps_per_second": 49.222,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "loss": 0.3496,
            "grad_norm": 1.9940619468688965,
            "learning_rate": 9.353233830845772e-05,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "eval_loss": 0.5904144048690796,
            "eval_matthews_correlation": 0.4657800904528511,
            "eval_runtime": 0.1824,
            "eval_samples_per_second": 5717.97,
            "eval_steps_per_second": 49.34,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "loss": 0.3234,
            "grad_norm": 3.436634063720703,
            "learning_rate": 8.474295190713102e-05,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "eval_loss": 0.6559337377548218,
            "eval_matthews_correlation": 0.48652176899433314,
            "eval_runtime": 0.2397,
            "eval_samples_per_second": 4351.102,
            "eval_steps_per_second": 37.545,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "loss": 0.3035,
            "grad_norm": 3.2267239093780518,
            "learning_rate": 7.595356550580432e-05,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "eval_loss": 0.6939088702201843,
            "eval_matthews_correlation": 0.4829189832085035,
            "eval_runtime": 0.1925,
            "eval_samples_per_second": 5416.79,
            "eval_steps_per_second": 46.741,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "loss": 0.2941,
            "grad_norm": 2.184401035308838,
            "learning_rate": 6.716417910447762e-05,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "eval_loss": 0.6725366115570068,
            "eval_matthews_correlation": 0.4885661202102094,
            "eval_runtime": 0.1842,
            "eval_samples_per_second": 5661.406,
            "eval_steps_per_second": 48.852,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "loss": 0.2824,
            "grad_norm": 2.0336732864379883,
            "learning_rate": 5.837479270315092e-05,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "eval_loss": 0.6879261136054993,
            "eval_matthews_correlation": 0.4832216996895926,
            "eval_runtime": 0.1816,
            "eval_samples_per_second": 5743.397,
            "eval_steps_per_second": 49.56,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "loss": 0.2743,
            "grad_norm": 2.3075790405273438,
            "learning_rate": 4.958540630182422e-05,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "eval_loss": 0.6891375780105591,
            "eval_matthews_correlation": 0.49652146303644756,
            "eval_runtime": 0.1958,
            "eval_samples_per_second": 5327.946,
            "eval_steps_per_second": 45.975,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "loss": 0.2707,
            "grad_norm": 2.6263325214385986,
            "learning_rate": 4.079601990049751e-05,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "eval_loss": 0.6391561627388,
            "eval_matthews_correlation": 0.5298746530730193,
            "eval_runtime": 0.1835,
            "eval_samples_per_second": 5682.77,
            "eval_steps_per_second": 49.036,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "loss": 0.2646,
            "grad_norm": 1.6576993465423584,
            "learning_rate": 3.200663349917081e-05,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "eval_loss": 0.649290144443512,
            "eval_matthews_correlation": 0.5315139457578117,
            "eval_runtime": 0.1837,
            "eval_samples_per_second": 5678.109,
            "eval_steps_per_second": 48.996,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "loss": 0.2579,
            "grad_norm": 2.038098096847534,
            "learning_rate": 2.3217247097844114e-05,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "eval_loss": 0.6934853196144104,
            "eval_matthews_correlation": 0.5045859154729114,
            "eval_runtime": 0.179,
            "eval_samples_per_second": 5826.819,
            "eval_steps_per_second": 50.279,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "loss": 0.2549,
            "grad_norm": 2.030454158782959,
            "learning_rate": 1.4427860696517415e-05,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "eval_loss": 0.6928120851516724,
            "eval_matthews_correlation": 0.5287745826239029,
            "eval_runtime": 0.192,
            "eval_samples_per_second": 5433.536,
            "eval_steps_per_second": 46.886,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "loss": 0.2561,
            "grad_norm": 1.9100022315979004,
            "learning_rate": 5.638474295190714e-06,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "eval_loss": 0.676457941532135,
            "eval_matthews_correlation": 0.5287745826239029,
            "eval_runtime": 0.1832,
            "eval_samples_per_second": 5692.731,
            "eval_steps_per_second": 49.122,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "train_runtime": 85.1871,
            "train_samples_per_second": 2007.58,
            "train_steps_per_second": 15.73,
            "total_flos": 5775202340306944.0,
            "train_loss": 0.30374615655016546,
            "epoch": 20.0,
            "step": 1340
        },
        {
            "eval_loss": 0.6736274361610413,
            "eval_matthews_correlation": 0.5235990316279782,
            "eval_runtime": 0.1809,
            "eval_samples_per_second": 5764.147,
            "eval_steps_per_second": 49.739,
            "epoch": 20.0,
            "step": 1340
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "roberta",
        "task": "cola",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 85.1871,
        "trainable_params_count": 0.72119,
        "memory_allocated": [
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832,
            358.456832
        ],
        "memory_reserved": [
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392
        ]
    },
    "variant": "kd-lora"
}