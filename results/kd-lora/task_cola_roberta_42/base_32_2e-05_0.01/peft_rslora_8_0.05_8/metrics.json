{
    "eval_loss": 1.154264211654663,
    "eval_matthews_correlation": 0.5812018675459495,
    "eval_runtime": 0.1608,
    "eval_samples_per_second": 6487.137,
    "eval_steps_per_second": 55.977,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 0.8319,
            "grad_norm": 0.8360666632652283,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.7550133466720581,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1629,
            "eval_samples_per_second": 6401.465,
            "eval_steps_per_second": 55.238,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.5536,
            "grad_norm": 3.7003698348999023,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.008777141571045,
            "eval_matthews_correlation": 0.433128798177375,
            "eval_runtime": 0.1619,
            "eval_samples_per_second": 6443.774,
            "eval_steps_per_second": 55.603,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.4734,
            "grad_norm": 2.5067012310028076,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.0037225484848022,
            "eval_matthews_correlation": 0.44960521225224076,
            "eval_runtime": 0.1606,
            "eval_samples_per_second": 6494.687,
            "eval_steps_per_second": 56.042,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.4387,
            "grad_norm": 2.173724889755249,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.020625114440918,
            "eval_matthews_correlation": 0.47471355759396977,
            "eval_runtime": 0.1594,
            "eval_samples_per_second": 6542.652,
            "eval_steps_per_second": 56.456,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.4108,
            "grad_norm": 2.623507499694824,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.1126831769943237,
            "eval_matthews_correlation": 0.47745692156806036,
            "eval_runtime": 0.1633,
            "eval_samples_per_second": 6387.082,
            "eval_steps_per_second": 55.114,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.3905,
            "grad_norm": 3.381760835647583,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.0291252136230469,
            "eval_matthews_correlation": 0.5185657415144317,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 6520.223,
            "eval_steps_per_second": 56.263,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3763,
            "grad_norm": 3.2601518630981445,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.084611415863037,
            "eval_matthews_correlation": 0.5073042789739086,
            "eval_runtime": 0.1597,
            "eval_samples_per_second": 6532.14,
            "eval_steps_per_second": 56.366,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3606,
            "grad_norm": 2.4602348804473877,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.1334397792816162,
            "eval_matthews_correlation": 0.5048397535049444,
            "eval_runtime": 0.1595,
            "eval_samples_per_second": 6541.116,
            "eval_steps_per_second": 56.443,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3395,
            "grad_norm": 2.5831551551818848,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.1118000745773315,
            "eval_matthews_correlation": 0.5258978858175564,
            "eval_runtime": 0.1587,
            "eval_samples_per_second": 6571.626,
            "eval_steps_per_second": 56.706,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3314,
            "grad_norm": 5.622949600219727,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.124437689781189,
            "eval_matthews_correlation": 0.5153742778418894,
            "eval_runtime": 0.1639,
            "eval_samples_per_second": 6363.057,
            "eval_steps_per_second": 54.907,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.3196,
            "grad_norm": 2.675577402114868,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.1573283672332764,
            "eval_matthews_correlation": 0.5152794748216469,
            "eval_runtime": 0.1617,
            "eval_samples_per_second": 6451.348,
            "eval_steps_per_second": 55.668,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.3111,
            "grad_norm": 1.8830236196517944,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.1612634658813477,
            "eval_matthews_correlation": 0.5521069582827846,
            "eval_runtime": 0.1621,
            "eval_samples_per_second": 6432.546,
            "eval_steps_per_second": 55.506,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.3019,
            "grad_norm": 4.143425941467285,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.1357452869415283,
            "eval_matthews_correlation": 0.5520738806744706,
            "eval_runtime": 0.162,
            "eval_samples_per_second": 6436.872,
            "eval_steps_per_second": 55.543,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.2952,
            "grad_norm": 2.104182720184326,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.1029185056686401,
            "eval_matthews_correlation": 0.5657894359264041,
            "eval_runtime": 0.1581,
            "eval_samples_per_second": 6597.861,
            "eval_steps_per_second": 56.933,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.2904,
            "grad_norm": 4.474519729614258,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.1537120342254639,
            "eval_matthews_correlation": 0.57368884664922,
            "eval_runtime": 0.1588,
            "eval_samples_per_second": 6567.61,
            "eval_steps_per_second": 56.672,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.2851,
            "grad_norm": 2.2846405506134033,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.1612540483474731,
            "eval_matthews_correlation": 0.5705082043516121,
            "eval_runtime": 0.1618,
            "eval_samples_per_second": 6447.573,
            "eval_steps_per_second": 55.636,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.2793,
            "grad_norm": 3.5259571075439453,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.1551806926727295,
            "eval_matthews_correlation": 0.5495609631481372,
            "eval_runtime": 0.1581,
            "eval_samples_per_second": 6598.1,
            "eval_steps_per_second": 56.935,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.2686,
            "grad_norm": 3.4809470176696777,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.1523133516311646,
            "eval_matthews_correlation": 0.5728724145437311,
            "eval_runtime": 0.159,
            "eval_samples_per_second": 6558.857,
            "eval_steps_per_second": 56.596,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.2692,
            "grad_norm": 2.1794025897979736,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.154264211654663,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6525.797,
            "eval_steps_per_second": 56.311,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.2641,
            "grad_norm": 3.5590453147888184,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.18595552444458,
            "eval_matthews_correlation": 0.5521589562965672,
            "eval_runtime": 0.1588,
            "eval_samples_per_second": 6568.567,
            "eval_steps_per_second": 56.68,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.2615,
            "grad_norm": 2.048711061477661,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.1482763290405273,
            "eval_matthews_correlation": 0.5572552114140278,
            "eval_runtime": 0.1612,
            "eval_samples_per_second": 6472.203,
            "eval_steps_per_second": 55.848,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.2564,
            "grad_norm": 2.919973611831665,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.1668896675109863,
            "eval_matthews_correlation": 0.5598743897878832,
            "eval_runtime": 0.1582,
            "eval_samples_per_second": 6594.45,
            "eval_steps_per_second": 56.903,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.2535,
            "grad_norm": 4.358067989349365,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.1625179052352905,
            "eval_matthews_correlation": 0.5804732682978748,
            "eval_runtime": 0.1595,
            "eval_samples_per_second": 6537.187,
            "eval_steps_per_second": 56.409,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.2494,
            "grad_norm": 2.821357488632202,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.185420036315918,
            "eval_matthews_correlation": 0.5624553233571645,
            "eval_runtime": 0.1627,
            "eval_samples_per_second": 6410.649,
            "eval_steps_per_second": 55.317,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 220.9129,
            "train_samples_per_second": 3870.756,
            "train_steps_per_second": 30.329,
            "total_flos": 2.0695972615028736e+16,
            "train_loss": 0.3505055578549703,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.154264211654663,
            "eval_matthews_correlation": 0.5812018675459495,
            "eval_runtime": 0.1608,
            "eval_samples_per_second": 6487.137,
            "eval_steps_per_second": 55.977,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 220.9129,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}