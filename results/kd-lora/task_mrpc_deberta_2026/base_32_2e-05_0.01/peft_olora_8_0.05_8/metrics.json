{
    "eval_loss": 2.518052577972412,
    "eval_accuracy": 0.8946078431372549,
    "eval_f1": 0.9225225225225226,
    "eval_runtime": 0.1059,
    "eval_samples_per_second": 3853.097,
    "eval_steps_per_second": 37.775,
    "epoch": 68.96551724137932,
    "log_history": [
        {
            "loss": 1.4877,
            "grad_norm": 1.5608304738998413,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 1.4121016263961792,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.1219,
            "eval_samples_per_second": 3346.009,
            "eval_steps_per_second": 32.804,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 1.2431,
            "grad_norm": 6.230564117431641,
            "learning_rate": 9.578544061302682e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 1.8034452199935913,
            "eval_accuracy": 0.8259803921568627,
            "eval_f1": 0.8790459965928449,
            "eval_runtime": 0.1037,
            "eval_samples_per_second": 3934.954,
            "eval_steps_per_second": 38.578,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.8406,
            "grad_norm": 2.2243504524230957,
            "learning_rate": 8.812260536398468e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 2.027268409729004,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9023941068139963,
            "eval_runtime": 0.1029,
            "eval_samples_per_second": 3964.72,
            "eval_steps_per_second": 38.87,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.7056,
            "grad_norm": 3.2621943950653076,
            "learning_rate": 8.045977011494253e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 2.408763885498047,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9109947643979057,
            "eval_runtime": 0.1046,
            "eval_samples_per_second": 3901.171,
            "eval_steps_per_second": 38.247,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.6067,
            "grad_norm": 4.633942604064941,
            "learning_rate": 7.279693486590039e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 2.518052577972412,
            "eval_accuracy": 0.8946078431372549,
            "eval_f1": 0.9225225225225226,
            "eval_runtime": 0.1185,
            "eval_samples_per_second": 3443.883,
            "eval_steps_per_second": 33.764,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.5425,
            "grad_norm": 5.7044901847839355,
            "learning_rate": 6.513409961685824e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 2.580556869506836,
            "eval_accuracy": 0.8872549019607843,
            "eval_f1": 0.9184397163120569,
            "eval_runtime": 0.1046,
            "eval_samples_per_second": 3899.296,
            "eval_steps_per_second": 38.228,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.4869,
            "grad_norm": 5.178585052490234,
            "learning_rate": 5.747126436781609e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 2.7069671154022217,
            "eval_accuracy": 0.8946078431372549,
            "eval_f1": 0.9222423146473779,
            "eval_runtime": 0.1031,
            "eval_samples_per_second": 3956.973,
            "eval_steps_per_second": 38.794,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.455,
            "grad_norm": 2.2723615169525146,
            "learning_rate": 4.980842911877395e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 2.802919387817383,
            "eval_accuracy": 0.8872549019607843,
            "eval_f1": 0.9175627240143369,
            "eval_runtime": 0.1027,
            "eval_samples_per_second": 3971.169,
            "eval_steps_per_second": 38.933,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.4164,
            "grad_norm": 3.6542911529541016,
            "learning_rate": 4.21455938697318e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 2.9347054958343506,
            "eval_accuracy": 0.8848039215686274,
            "eval_f1": 0.9162210338680927,
            "eval_runtime": 0.1252,
            "eval_samples_per_second": 3258.369,
            "eval_steps_per_second": 31.945,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.3807,
            "grad_norm": 2.816509962081909,
            "learning_rate": 3.4482758620689657e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 3.051772117614746,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9200710479573712,
            "eval_runtime": 0.1033,
            "eval_samples_per_second": 3950.259,
            "eval_steps_per_second": 38.728,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "train_runtime": 123.5254,
            "train_samples_per_second": 2969.43,
            "train_steps_per_second": 23.477,
            "total_flos": 8507508800880640.0,
            "train_loss": 0.7165339469909668,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 2.518052577972412,
            "eval_accuracy": 0.8946078431372549,
            "eval_f1": 0.9225225225225226,
            "eval_runtime": 0.1059,
            "eval_samples_per_second": 3853.097,
            "eval_steps_per_second": 37.775,
            "epoch": 68.96551724137932,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "mrpc",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 3668
    },
    "train": {
        "train_time": 123.5254,
        "trainable_params_count": 0.148994,
        "memory_allocated": [
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088
        ],
        "memory_reserved": [
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672
        ]
    },
    "variant": "kd-lora"
}