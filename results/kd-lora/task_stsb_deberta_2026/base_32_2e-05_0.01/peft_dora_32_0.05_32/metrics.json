{
    "eval_loss": 2.9756429195404053,
    "eval_pearson": 0.8897348884668458,
    "eval_spearman": 0.8875316418223268,
    "eval_runtime": 0.3754,
    "eval_samples_per_second": 3995.849,
    "eval_steps_per_second": 31.967,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 9.8941,
            "grad_norm": 31.369945526123047,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 4.074165344238281,
            "eval_pearson": -0.05373421456196641,
            "eval_spearman": -0.01255650046973291,
            "eval_runtime": 0.3777,
            "eval_samples_per_second": 3971.763,
            "eval_steps_per_second": 31.774,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.9318,
            "grad_norm": 17.64935874938965,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 3.232386350631714,
            "eval_pearson": 0.8417654842138019,
            "eval_spearman": 0.8468418863100075,
            "eval_runtime": 0.3752,
            "eval_samples_per_second": 3997.405,
            "eval_steps_per_second": 31.979,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.849,
            "grad_norm": 3.6089823246002197,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.120241641998291,
            "eval_pearson": 0.8588426351668089,
            "eval_spearman": 0.8589024838823854,
            "eval_runtime": 0.3732,
            "eval_samples_per_second": 4019.065,
            "eval_steps_per_second": 32.153,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6803,
            "grad_norm": 12.462764739990234,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.983879566192627,
            "eval_pearson": 0.8697474785531052,
            "eval_spearman": 0.8692150165331478,
            "eval_runtime": 0.3741,
            "eval_samples_per_second": 4009.869,
            "eval_steps_per_second": 32.079,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.596,
            "grad_norm": 4.512688159942627,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 3.0364346504211426,
            "eval_pearson": 0.8753410421452955,
            "eval_spearman": 0.8743712923056703,
            "eval_runtime": 0.3669,
            "eval_samples_per_second": 4087.785,
            "eval_steps_per_second": 32.702,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5315,
            "grad_norm": 1.9801487922668457,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 3.0961830615997314,
            "eval_pearson": 0.8800399346871711,
            "eval_spearman": 0.8790245243240464,
            "eval_runtime": 0.3903,
            "eval_samples_per_second": 3843.07,
            "eval_steps_per_second": 30.745,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4924,
            "grad_norm": 2.1137423515319824,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 3.0536255836486816,
            "eval_pearson": 0.8826666100238969,
            "eval_spearman": 0.8819025876881932,
            "eval_runtime": 0.3748,
            "eval_samples_per_second": 4002.552,
            "eval_steps_per_second": 32.02,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.4603,
            "grad_norm": 3.243382215499878,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 3.043971300125122,
            "eval_pearson": 0.8840855182398186,
            "eval_spearman": 0.8821977750842377,
            "eval_runtime": 0.3721,
            "eval_samples_per_second": 4030.902,
            "eval_steps_per_second": 32.247,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4342,
            "grad_norm": 1.453291893005371,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 3.0220210552215576,
            "eval_pearson": 0.886897254162375,
            "eval_spearman": 0.8850954382336378,
            "eval_runtime": 0.3759,
            "eval_samples_per_second": 3990.109,
            "eval_steps_per_second": 31.921,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4203,
            "grad_norm": 1.5848817825317383,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 3.1024160385131836,
            "eval_pearson": 0.8867850656045339,
            "eval_spearman": 0.884745904069978,
            "eval_runtime": 0.3724,
            "eval_samples_per_second": 4027.439,
            "eval_steps_per_second": 32.22,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4061,
            "grad_norm": 5.112513542175293,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.030697822570801,
            "eval_pearson": 0.8873911812113477,
            "eval_spearman": 0.8852508569567823,
            "eval_runtime": 0.3745,
            "eval_samples_per_second": 4004.96,
            "eval_steps_per_second": 32.04,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.3852,
            "grad_norm": 3.096277952194214,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.9756429195404053,
            "eval_pearson": 0.8897348884668458,
            "eval_spearman": 0.8875316418223268,
            "eval_runtime": 0.3706,
            "eval_samples_per_second": 4047.553,
            "eval_steps_per_second": 32.38,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.3753,
            "grad_norm": 1.288661241531372,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 3.068915367126465,
            "eval_pearson": 0.8872173521616753,
            "eval_spearman": 0.8851425847941036,
            "eval_runtime": 0.3301,
            "eval_samples_per_second": 4543.535,
            "eval_steps_per_second": 36.348,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.367,
            "grad_norm": 1.4090282917022705,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.021195888519287,
            "eval_pearson": 0.8887870424786193,
            "eval_spearman": 0.8867029524184185,
            "eval_runtime": 0.3714,
            "eval_samples_per_second": 4038.322,
            "eval_steps_per_second": 32.307,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.356,
            "grad_norm": 1.7475347518920898,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 3.0368385314941406,
            "eval_pearson": 0.8876553689112396,
            "eval_spearman": 0.8853864174654138,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 5310.855,
            "eval_steps_per_second": 42.487,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.3478,
            "grad_norm": 2.71175217628479,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.969050884246826,
            "eval_pearson": 0.8885687701267897,
            "eval_spearman": 0.8863414772106495,
            "eval_runtime": 0.3752,
            "eval_samples_per_second": 3997.964,
            "eval_steps_per_second": 31.984,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.3398,
            "grad_norm": 1.7747442722320557,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.996711015701294,
            "eval_pearson": 0.8881535641142092,
            "eval_spearman": 0.8855796936470915,
            "eval_runtime": 0.3645,
            "eval_samples_per_second": 4115.393,
            "eval_steps_per_second": 32.923,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 232.238,
            "train_samples_per_second": 2475.477,
            "train_steps_per_second": 19.377,
            "total_flos": 1.4613186124709888e+16,
            "train_loss": 1.1098253496955424,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 2.9756429195404053,
            "eval_pearson": 0.8897348884668458,
            "eval_spearman": 0.8875316418223268,
            "eval_runtime": 0.3754,
            "eval_samples_per_second": 3995.849,
            "eval_steps_per_second": 31.967,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 232.238,
        "trainable_params_count": 0.599809,
        "memory_allocated": [
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064,
            596.696064
        ],
        "memory_reserved": [
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552
        ]
    },
    "variant": "kd-lora"
}