{
    "eval_loss": 3.012969493865967,
    "eval_pearson": 0.8845309121364608,
    "eval_spearman": 0.8855147619886408,
    "eval_runtime": 0.2966,
    "eval_samples_per_second": 5058.075,
    "eval_steps_per_second": 40.465,
    "epoch": 62.22222222222222,
    "log_history": [
        {
            "loss": 9.0533,
            "grad_norm": 6.052888870239258,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.9235081672668457,
            "eval_pearson": 0.43560793483779175,
            "eval_spearman": 0.44978960855225,
            "eval_runtime": 0.3045,
            "eval_samples_per_second": 4926.111,
            "eval_steps_per_second": 39.409,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.0945,
            "grad_norm": 3.986755609512329,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 3.2842965126037598,
            "eval_pearson": 0.8624985408673363,
            "eval_spearman": 0.8642098359579665,
            "eval_runtime": 0.2974,
            "eval_samples_per_second": 5043.672,
            "eval_steps_per_second": 40.349,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.614,
            "grad_norm": 2.13869571685791,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.0586230754852295,
            "eval_pearson": 0.8759802112539558,
            "eval_spearman": 0.8761621029231575,
            "eval_runtime": 0.2955,
            "eval_samples_per_second": 5076.445,
            "eval_steps_per_second": 40.612,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.465,
            "grad_norm": 4.4249043464660645,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.0289368629455566,
            "eval_pearson": 0.8800798750383653,
            "eval_spearman": 0.8794568017756684,
            "eval_runtime": 0.2962,
            "eval_samples_per_second": 5063.868,
            "eval_steps_per_second": 40.511,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.3752,
            "grad_norm": 5.852890491485596,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.9569883346557617,
            "eval_pearson": 0.8765773731187482,
            "eval_spearman": 0.8760242865855815,
            "eval_runtime": 0.3372,
            "eval_samples_per_second": 4448.541,
            "eval_steps_per_second": 35.588,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.3216,
            "grad_norm": 1.9467240571975708,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.9608964920043945,
            "eval_pearson": 0.880101631548602,
            "eval_spearman": 0.8802781141812903,
            "eval_runtime": 0.2951,
            "eval_samples_per_second": 5083.524,
            "eval_steps_per_second": 40.668,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.281,
            "grad_norm": 2.4497649669647217,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.9757909774780273,
            "eval_pearson": 0.8820380433461511,
            "eval_spearman": 0.8821568271714015,
            "eval_runtime": 0.3358,
            "eval_samples_per_second": 4466.406,
            "eval_steps_per_second": 35.731,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.2519,
            "grad_norm": 1.6445029973983765,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 3.0609846115112305,
            "eval_pearson": 0.883264830612349,
            "eval_spearman": 0.8823236867727235,
            "eval_runtime": 0.3011,
            "eval_samples_per_second": 4981.126,
            "eval_steps_per_second": 39.849,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.2286,
            "grad_norm": 1.4028762578964233,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 3.04195237159729,
            "eval_pearson": 0.885285166649366,
            "eval_spearman": 0.8854596197924584,
            "eval_runtime": 0.3035,
            "eval_samples_per_second": 4942.923,
            "eval_steps_per_second": 39.543,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.2077,
            "grad_norm": 1.502605676651001,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 3.0608460903167725,
            "eval_pearson": 0.8838789944058778,
            "eval_spearman": 0.88235138421586,
            "eval_runtime": 0.3387,
            "eval_samples_per_second": 4428.788,
            "eval_steps_per_second": 35.43,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.1986,
            "grad_norm": 1.8199504613876343,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.9618258476257324,
            "eval_pearson": 0.8830457803440789,
            "eval_spearman": 0.881038311589271,
            "eval_runtime": 0.2944,
            "eval_samples_per_second": 5094.329,
            "eval_steps_per_second": 40.755,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.1831,
            "grad_norm": 1.7620131969451904,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 3.012969493865967,
            "eval_pearson": 0.8845309121364608,
            "eval_spearman": 0.8855147619886408,
            "eval_runtime": 0.3429,
            "eval_samples_per_second": 4374.939,
            "eval_steps_per_second": 35.0,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.1732,
            "grad_norm": 1.4337079524993896,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 3.0503311157226562,
            "eval_pearson": 0.8814503683992507,
            "eval_spearman": 0.8818746993003016,
            "eval_runtime": 0.3377,
            "eval_samples_per_second": 4442.312,
            "eval_steps_per_second": 35.538,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.1672,
            "grad_norm": 1.5462197065353394,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.0205440521240234,
            "eval_pearson": 0.8817046132275853,
            "eval_spearman": 0.8820395326773693,
            "eval_runtime": 0.2957,
            "eval_samples_per_second": 5072.434,
            "eval_steps_per_second": 40.579,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "train_runtime": 172.2985,
            "train_samples_per_second": 3336.651,
            "train_steps_per_second": 26.117,
            "total_flos": 1.2194201622020096e+16,
            "train_loss": 0.972494673047747,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.012969493865967,
            "eval_pearson": 0.8845309121364608,
            "eval_spearman": 0.8855147619886408,
            "eval_runtime": 0.2966,
            "eval_samples_per_second": 5058.075,
            "eval_steps_per_second": 40.465,
            "epoch": 62.22222222222222,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 64,
        "lora_alpha": 64,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 172.2985,
        "trainable_params_count": 1.180417,
        "memory_allocated": [
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456,
            604.883456
        ],
        "memory_reserved": [
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584
        ]
    },
    "variant": "kd-lora"
}