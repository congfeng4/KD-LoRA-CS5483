{
    "eval_loss": 2.9401309490203857,
    "eval_pearson": 0.8757528719839919,
    "eval_spearman": 0.8736453399593261,
    "eval_runtime": 0.3029,
    "eval_samples_per_second": 4952.697,
    "eval_steps_per_second": 39.622,
    "epoch": 71.11111111111111,
    "log_history": [
        {
            "loss": 10.1317,
            "grad_norm": 40.19688034057617,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 6.120794296264648,
            "eval_pearson": 0.2320351337658847,
            "eval_spearman": 0.223270905407835,
            "eval_runtime": 0.2974,
            "eval_samples_per_second": 5043.328,
            "eval_steps_per_second": 40.347,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 3.5654,
            "grad_norm": 3.417219877243042,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.7025630474090576,
            "eval_pearson": 0.7002173269713755,
            "eval_spearman": 0.6980998647377145,
            "eval_runtime": 0.2971,
            "eval_samples_per_second": 5049.047,
            "eval_steps_per_second": 40.392,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.171,
            "grad_norm": 7.322301864624023,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.2134785652160645,
            "eval_pearson": 0.8440388830621904,
            "eval_spearman": 0.849449654527244,
            "eval_runtime": 0.2964,
            "eval_samples_per_second": 5060.854,
            "eval_steps_per_second": 40.487,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.864,
            "grad_norm": 9.470748901367188,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.2256839275360107,
            "eval_pearson": 0.8566809235351284,
            "eval_spearman": 0.8558519669255998,
            "eval_runtime": 0.3003,
            "eval_samples_per_second": 4995.396,
            "eval_steps_per_second": 39.963,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.7589,
            "grad_norm": 3.9850194454193115,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 3.117344379425049,
            "eval_pearson": 0.8619218437864188,
            "eval_spearman": 0.8604192506638777,
            "eval_runtime": 0.3494,
            "eval_samples_per_second": 4293.129,
            "eval_steps_per_second": 34.345,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.698,
            "grad_norm": 4.518920421600342,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 3.1803395748138428,
            "eval_pearson": 0.8638948179823416,
            "eval_spearman": 0.862460675423344,
            "eval_runtime": 0.2998,
            "eval_samples_per_second": 5004.153,
            "eval_steps_per_second": 40.033,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.6571,
            "grad_norm": 1.98519766330719,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 3.1950631141662598,
            "eval_pearson": 0.8656025424324482,
            "eval_spearman": 0.8643680152746946,
            "eval_runtime": 0.3011,
            "eval_samples_per_second": 4982.4,
            "eval_steps_per_second": 39.859,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.6229,
            "grad_norm": 2.6512811183929443,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 3.019928455352783,
            "eval_pearson": 0.8680439958097207,
            "eval_spearman": 0.8662503113031054,
            "eval_runtime": 0.2995,
            "eval_samples_per_second": 5007.702,
            "eval_steps_per_second": 40.062,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.597,
            "grad_norm": 1.8403550386428833,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 3.0286293029785156,
            "eval_pearson": 0.8718570549732485,
            "eval_spearman": 0.8696445512708473,
            "eval_runtime": 0.2994,
            "eval_samples_per_second": 5009.249,
            "eval_steps_per_second": 40.074,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.5724,
            "grad_norm": 1.7917046546936035,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 3.1435015201568604,
            "eval_pearson": 0.8725055285750432,
            "eval_spearman": 0.8704891833627059,
            "eval_runtime": 0.2996,
            "eval_samples_per_second": 5007.215,
            "eval_steps_per_second": 40.058,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.5655,
            "grad_norm": 4.45823335647583,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.0674169063568115,
            "eval_pearson": 0.8740343825994539,
            "eval_spearman": 0.8718434504804002,
            "eval_runtime": 0.3145,
            "eval_samples_per_second": 4769.803,
            "eval_steps_per_second": 38.158,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.5408,
            "grad_norm": 1.88498055934906,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 3.0130960941314697,
            "eval_pearson": 0.8744743031277372,
            "eval_spearman": 0.8722199041794992,
            "eval_runtime": 0.3535,
            "eval_samples_per_second": 4243.294,
            "eval_steps_per_second": 33.946,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.5283,
            "grad_norm": 2.2905728816986084,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 3.118699312210083,
            "eval_pearson": 0.8749209832462492,
            "eval_spearman": 0.8728688215690974,
            "eval_runtime": 0.3433,
            "eval_samples_per_second": 4369.343,
            "eval_steps_per_second": 34.955,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.5267,
            "grad_norm": 2.709047317504883,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.1392641067504883,
            "eval_pearson": 0.8754849273559703,
            "eval_spearman": 0.8733401803441962,
            "eval_runtime": 0.2989,
            "eval_samples_per_second": 5017.57,
            "eval_steps_per_second": 40.141,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.5067,
            "grad_norm": 2.0893115997314453,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 3.079594135284424,
            "eval_pearson": 0.8758391205877878,
            "eval_spearman": 0.8736112683798192,
            "eval_runtime": 0.3441,
            "eval_samples_per_second": 4359.675,
            "eval_steps_per_second": 34.877,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.5003,
            "grad_norm": 3.0394980907440186,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.9401309490203857,
            "eval_pearson": 0.8757528719839919,
            "eval_spearman": 0.8736453399593261,
            "eval_runtime": 0.307,
            "eval_samples_per_second": 4886.2,
            "eval_steps_per_second": 39.09,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "train_runtime": 194.1154,
            "train_samples_per_second": 2961.64,
            "train_steps_per_second": 23.182,
            "total_flos": 1.3611530897588224e+16,
            "train_loss": 1.4254233717918396,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.9401309490203857,
            "eval_pearson": 0.8757528719839919,
            "eval_spearman": 0.8736453399593261,
            "eval_runtime": 0.3029,
            "eval_samples_per_second": 4952.697,
            "eval_steps_per_second": 39.622,
            "epoch": 71.11111111111111,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 194.1154,
        "trainable_params_count": 0.148225,
        "memory_allocated": [
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728,
            588.105728
        ],
        "memory_reserved": [
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672
        ]
    },
    "variant": "kd-lora"
}