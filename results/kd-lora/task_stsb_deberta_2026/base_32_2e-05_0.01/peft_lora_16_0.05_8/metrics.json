{
    "eval_loss": 3.0895345211029053,
    "eval_pearson": 0.8838647826106847,
    "eval_spearman": 0.8814898645015378,
    "eval_runtime": 0.3818,
    "eval_samples_per_second": 3928.448,
    "eval_steps_per_second": 31.428,
    "epoch": 75.55555555555556,
    "log_history": [
        {
            "loss": 10.0733,
            "grad_norm": 39.191162109375,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 5.826446056365967,
            "eval_pearson": 0.16713785659948818,
            "eval_spearman": 0.1638371519801692,
            "eval_runtime": 0.4716,
            "eval_samples_per_second": 3180.516,
            "eval_steps_per_second": 25.444,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 2.8049,
            "grad_norm": 23.1060791015625,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 3.061983823776245,
            "eval_pearson": 0.8008417290287754,
            "eval_spearman": 0.8092003234904435,
            "eval_runtime": 0.5238,
            "eval_samples_per_second": 2863.729,
            "eval_steps_per_second": 22.91,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.9775,
            "grad_norm": 6.73505973815918,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.0222856998443604,
            "eval_pearson": 0.8582311975849459,
            "eval_spearman": 0.8581533350059513,
            "eval_runtime": 0.5077,
            "eval_samples_per_second": 2954.588,
            "eval_steps_per_second": 23.637,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.759,
            "grad_norm": 12.947327613830566,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 3.071364164352417,
            "eval_pearson": 0.8657604264419074,
            "eval_spearman": 0.8644138448501024,
            "eval_runtime": 0.4731,
            "eval_samples_per_second": 3170.576,
            "eval_steps_per_second": 25.365,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6704,
            "grad_norm": 8.891087532043457,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 3.0609636306762695,
            "eval_pearson": 0.8685043694789292,
            "eval_spearman": 0.8672317312442716,
            "eval_runtime": 0.5195,
            "eval_samples_per_second": 2887.504,
            "eval_steps_per_second": 23.1,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.6172,
            "grad_norm": 2.460524797439575,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 3.202319622039795,
            "eval_pearson": 0.8715203049444531,
            "eval_spearman": 0.8706521648511031,
            "eval_runtime": 0.524,
            "eval_samples_per_second": 2862.532,
            "eval_steps_per_second": 22.9,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5768,
            "grad_norm": 2.5050547122955322,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 3.067774772644043,
            "eval_pearson": 0.8750196251033652,
            "eval_spearman": 0.8738884404894824,
            "eval_runtime": 0.5471,
            "eval_samples_per_second": 2741.505,
            "eval_steps_per_second": 21.932,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5452,
            "grad_norm": 3.8996427059173584,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 3.049095630645752,
            "eval_pearson": 0.8775585619889239,
            "eval_spearman": 0.8759637898075879,
            "eval_runtime": 0.5033,
            "eval_samples_per_second": 2980.406,
            "eval_steps_per_second": 23.843,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.5183,
            "grad_norm": 4.622824668884277,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 3.0628886222839355,
            "eval_pearson": 0.879297896366844,
            "eval_spearman": 0.8777175396787451,
            "eval_runtime": 0.4919,
            "eval_samples_per_second": 3049.197,
            "eval_steps_per_second": 24.394,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4989,
            "grad_norm": 3.219348669052124,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 3.1408183574676514,
            "eval_pearson": 0.8810800454159408,
            "eval_spearman": 0.8793731145858379,
            "eval_runtime": 0.5517,
            "eval_samples_per_second": 2719.07,
            "eval_steps_per_second": 21.753,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4889,
            "grad_norm": 3.8793792724609375,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 3.099944591522217,
            "eval_pearson": 0.8798090774620949,
            "eval_spearman": 0.8784053241148652,
            "eval_runtime": 0.4885,
            "eval_samples_per_second": 3070.817,
            "eval_steps_per_second": 24.567,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4678,
            "grad_norm": 3.249453067779541,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 3.0659990310668945,
            "eval_pearson": 0.8832963776133862,
            "eval_spearman": 0.8813208239299648,
            "eval_runtime": 0.3288,
            "eval_samples_per_second": 4561.892,
            "eval_steps_per_second": 36.495,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4547,
            "grad_norm": 1.9823143482208252,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 3.187857151031494,
            "eval_pearson": 0.8814458735539241,
            "eval_spearman": 0.8794725088090639,
            "eval_runtime": 0.3141,
            "eval_samples_per_second": 4775.596,
            "eval_steps_per_second": 38.205,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.4506,
            "grad_norm": 3.4579267501831055,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 3.129056692123413,
            "eval_pearson": 0.8829672726468099,
            "eval_spearman": 0.8804071714027657,
            "eval_runtime": 0.3709,
            "eval_samples_per_second": 4044.361,
            "eval_steps_per_second": 32.355,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4334,
            "grad_norm": 2.0444259643554688,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 3.096754789352417,
            "eval_pearson": 0.8825775466414192,
            "eval_spearman": 0.8803658690393558,
            "eval_runtime": 0.3664,
            "eval_samples_per_second": 4094.273,
            "eval_steps_per_second": 32.754,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.4311,
            "grad_norm": 2.903587579727173,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.9833755493164062,
            "eval_pearson": 0.8821980222139855,
            "eval_spearman": 0.8797822936680711,
            "eval_runtime": 0.3664,
            "eval_samples_per_second": 4094.185,
            "eval_steps_per_second": 32.753,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "loss": 0.4208,
            "grad_norm": 3.399334192276001,
            "learning_rate": 2.7160493827160493e-05,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 3.0895345211029053,
            "eval_pearson": 0.8838647826106847,
            "eval_spearman": 0.8814898645015378,
            "eval_runtime": 0.3705,
            "eval_samples_per_second": 4048.884,
            "eval_steps_per_second": 32.391,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "train_runtime": 270.7024,
            "train_samples_per_second": 2123.735,
            "train_steps_per_second": 16.623,
            "total_flos": 1.4462251578687488e+16,
            "train_loss": 1.2463937916475183,
            "epoch": 75.55555555555556,
            "step": 3400
        },
        {
            "eval_loss": 3.0895345211029053,
            "eval_pearson": 0.8838647826106847,
            "eval_spearman": 0.8814898645015378,
            "eval_runtime": 0.3818,
            "eval_samples_per_second": 3928.448,
            "eval_steps_per_second": 31.428,
            "epoch": 75.55555555555556,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 270.7024,
        "trainable_params_count": 0.148225,
        "memory_allocated": [
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448,
            589.416448
        ],
        "memory_reserved": [
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824,
            2646.605824
        ]
    },
    "variant": "kd-lora"
}