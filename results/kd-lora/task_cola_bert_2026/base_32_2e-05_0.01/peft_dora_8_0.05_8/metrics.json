{
    "eval_loss": 2.9447548389434814,
    "eval_matthews_correlation": 0.5327637463001902,
    "eval_runtime": 0.2023,
    "eval_samples_per_second": 5154.9,
    "eval_steps_per_second": 44.481,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 1.464,
            "grad_norm": 0.7284834384918213,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4998183250427246,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2012,
            "eval_samples_per_second": 5184.744,
            "eval_steps_per_second": 44.739,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3017,
            "grad_norm": 1.0055372714996338,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.683042049407959,
            "eval_matthews_correlation": 0.386267165755511,
            "eval_runtime": 0.1777,
            "eval_samples_per_second": 5870.599,
            "eval_steps_per_second": 50.657,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1541,
            "grad_norm": 2.061868190765381,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.8329273462295532,
            "eval_matthews_correlation": 0.41228689861294754,
            "eval_runtime": 0.1755,
            "eval_samples_per_second": 5942.159,
            "eval_steps_per_second": 51.275,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0735,
            "grad_norm": 1.9100887775421143,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.9467507600784302,
            "eval_matthews_correlation": 0.45003782776384227,
            "eval_runtime": 0.2025,
            "eval_samples_per_second": 5150.051,
            "eval_steps_per_second": 44.44,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 1.004,
            "grad_norm": 2.5862879753112793,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.912599802017212,
            "eval_matthews_correlation": 0.4837384262663906,
            "eval_runtime": 0.1998,
            "eval_samples_per_second": 5219.03,
            "eval_steps_per_second": 45.035,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9524,
            "grad_norm": 1.9106535911560059,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.0097670555114746,
            "eval_matthews_correlation": 0.4854632779262472,
            "eval_runtime": 0.224,
            "eval_samples_per_second": 4656.83,
            "eval_steps_per_second": 40.184,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.9079,
            "grad_norm": 2.092878580093384,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.1878089904785156,
            "eval_matthews_correlation": 0.47184352166873134,
            "eval_runtime": 0.2009,
            "eval_samples_per_second": 5192.665,
            "eval_steps_per_second": 44.807,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.8522,
            "grad_norm": 2.5567026138305664,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.2219364643096924,
            "eval_matthews_correlation": 0.4694118952751528,
            "eval_runtime": 0.202,
            "eval_samples_per_second": 5162.826,
            "eval_steps_per_second": 44.55,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.8187,
            "grad_norm": 2.650230646133423,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.2509164810180664,
            "eval_matthews_correlation": 0.4905937147239641,
            "eval_runtime": 0.262,
            "eval_samples_per_second": 3980.871,
            "eval_steps_per_second": 34.351,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7768,
            "grad_norm": 2.567061185836792,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.325021505355835,
            "eval_matthews_correlation": 0.4870956322514055,
            "eval_runtime": 0.1748,
            "eval_samples_per_second": 5966.236,
            "eval_steps_per_second": 51.482,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.7538,
            "grad_norm": 3.6416561603546143,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.26869797706604,
            "eval_matthews_correlation": 0.4992436500882773,
            "eval_runtime": 0.1739,
            "eval_samples_per_second": 5996.75,
            "eval_steps_per_second": 51.746,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.7185,
            "grad_norm": 2.20381760597229,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.4267666339874268,
            "eval_matthews_correlation": 0.4657800904528511,
            "eval_runtime": 0.1733,
            "eval_samples_per_second": 6019.731,
            "eval_steps_per_second": 51.944,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6903,
            "grad_norm": 2.198436975479126,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.421555757522583,
            "eval_matthews_correlation": 0.5033485542799104,
            "eval_runtime": 0.1993,
            "eval_samples_per_second": 5233.666,
            "eval_steps_per_second": 45.161,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6607,
            "grad_norm": 5.6422224044799805,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.5662596225738525,
            "eval_matthews_correlation": 0.5020753041155603,
            "eval_runtime": 0.202,
            "eval_samples_per_second": 5163.442,
            "eval_steps_per_second": 44.555,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.6371,
            "grad_norm": 2.4769833087921143,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.5374062061309814,
            "eval_matthews_correlation": 0.50782859379038,
            "eval_runtime": 0.1992,
            "eval_samples_per_second": 5235.814,
            "eval_steps_per_second": 45.18,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.6214,
            "grad_norm": 3.7158660888671875,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.629606008529663,
            "eval_matthews_correlation": 0.5051600900029769,
            "eval_runtime": 0.2025,
            "eval_samples_per_second": 5151.142,
            "eval_steps_per_second": 44.449,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.6097,
            "grad_norm": 3.068058729171753,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.548525810241699,
            "eval_matthews_correlation": 0.5105414995361648,
            "eval_runtime": 0.2039,
            "eval_samples_per_second": 5114.754,
            "eval_steps_per_second": 44.135,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5885,
            "grad_norm": 3.190824031829834,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.6247942447662354,
            "eval_matthews_correlation": 0.5127451929115474,
            "eval_runtime": 0.202,
            "eval_samples_per_second": 5162.741,
            "eval_steps_per_second": 44.549,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5812,
            "grad_norm": 2.8171653747558594,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 2.6122078895568848,
            "eval_matthews_correlation": 0.5024875124748389,
            "eval_runtime": 0.2055,
            "eval_samples_per_second": 5075.688,
            "eval_steps_per_second": 43.798,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5514,
            "grad_norm": 3.465033769607544,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.6852402687072754,
            "eval_matthews_correlation": 0.5188823116947865,
            "eval_runtime": 0.2008,
            "eval_samples_per_second": 5194.28,
            "eval_steps_per_second": 44.821,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5523,
            "grad_norm": 2.8777151107788086,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 2.661912202835083,
            "eval_matthews_correlation": 0.5037970015010991,
            "eval_runtime": 0.2028,
            "eval_samples_per_second": 5141.879,
            "eval_steps_per_second": 44.369,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5257,
            "grad_norm": 3.878821849822998,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 2.813119411468506,
            "eval_matthews_correlation": 0.5089318947112005,
            "eval_runtime": 0.2009,
            "eval_samples_per_second": 5192.338,
            "eval_steps_per_second": 44.804,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.5218,
            "grad_norm": 4.017810821533203,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 2.8066985607147217,
            "eval_matthews_correlation": 0.5093030018169853,
            "eval_runtime": 0.1789,
            "eval_samples_per_second": 5829.008,
            "eval_steps_per_second": 50.298,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5087,
            "grad_norm": 6.107426643371582,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 2.784289598464966,
            "eval_matthews_correlation": 0.5070207143299597,
            "eval_runtime": 0.2066,
            "eval_samples_per_second": 5048.241,
            "eval_steps_per_second": 43.561,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.4973,
            "grad_norm": 3.0339272022247314,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 2.8751938343048096,
            "eval_matthews_correlation": 0.5203121591830998,
            "eval_runtime": 0.2051,
            "eval_samples_per_second": 5086.298,
            "eval_steps_per_second": 43.889,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.4903,
            "grad_norm": 2.9156925678253174,
            "learning_rate": 2.4875621890547266e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 2.820390462875366,
            "eval_matthews_correlation": 0.5263989868108533,
            "eval_runtime": 0.2144,
            "eval_samples_per_second": 4864.44,
            "eval_steps_per_second": 41.975,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.4784,
            "grad_norm": 4.306128025054932,
            "learning_rate": 2.155887230514096e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 2.932143211364746,
            "eval_matthews_correlation": 0.5138995234247261,
            "eval_runtime": 0.2011,
            "eval_samples_per_second": 5186.834,
            "eval_steps_per_second": 44.757,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "loss": 0.475,
            "grad_norm": 3.1617534160614014,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 2.884018898010254,
            "eval_matthews_correlation": 0.5199312393606881,
            "eval_runtime": 0.1975,
            "eval_samples_per_second": 5281.899,
            "eval_steps_per_second": 45.577,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "loss": 0.4645,
            "grad_norm": 3.5279500484466553,
            "learning_rate": 1.4925373134328357e-05,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "eval_loss": 2.9261314868927,
            "eval_matthews_correlation": 0.5304969997797532,
            "eval_runtime": 0.2045,
            "eval_samples_per_second": 5101.334,
            "eval_steps_per_second": 44.019,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "loss": 0.4659,
            "grad_norm": 5.996208190917969,
            "learning_rate": 1.1608623548922057e-05,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "eval_loss": 2.9138705730438232,
            "eval_matthews_correlation": 0.5304969997797532,
            "eval_runtime": 0.2014,
            "eval_samples_per_second": 5178.656,
            "eval_steps_per_second": 44.686,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "loss": 0.4676,
            "grad_norm": 4.795107841491699,
            "learning_rate": 8.291873963515755e-06,
            "epoch": 92.53731343283582,
            "step": 6200
        },
        {
            "eval_loss": 2.92398738861084,
            "eval_matthews_correlation": 0.5248549558132585,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 4943.0,
            "eval_steps_per_second": 42.653,
            "epoch": 92.53731343283582,
            "step": 6200
        },
        {
            "loss": 0.461,
            "grad_norm": 4.573452472686768,
            "learning_rate": 4.975124378109453e-06,
            "epoch": 95.5223880597015,
            "step": 6400
        },
        {
            "eval_loss": 2.9419105052948,
            "eval_matthews_correlation": 0.5301312348234369,
            "eval_runtime": 0.2019,
            "eval_samples_per_second": 5166.9,
            "eval_steps_per_second": 44.585,
            "epoch": 95.5223880597015,
            "step": 6400
        },
        {
            "loss": 0.4439,
            "grad_norm": 2.6710989475250244,
            "learning_rate": 1.6583747927031512e-06,
            "epoch": 98.50746268656717,
            "step": 6600
        },
        {
            "eval_loss": 2.9447548389434814,
            "eval_matthews_correlation": 0.5327637463001902,
            "eval_runtime": 0.2037,
            "eval_samples_per_second": 5120.441,
            "eval_steps_per_second": 44.184,
            "epoch": 98.50746268656717,
            "step": 6600
        },
        {
            "train_runtime": 355.1251,
            "train_samples_per_second": 2407.884,
            "train_steps_per_second": 18.867,
            "total_flos": 2.8894198438559744e+16,
            "train_loss": 0.695301367916278,
            "epoch": 100.0,
            "step": 6700
        },
        {
            "eval_loss": 2.9447548389434814,
            "eval_matthews_correlation": 0.5327637463001902,
            "eval_runtime": 0.2023,
            "eval_samples_per_second": 5154.9,
            "eval_steps_per_second": 44.481,
            "epoch": 100.0,
            "step": 6700
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 355.1251,
        "trainable_params_count": 0.748802,
        "memory_allocated": [
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064
        ],
        "memory_reserved": [
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912
        ]
    },
    "variant": "kd-lora"
}