{
    "eval_loss": 0.6585142016410828,
    "eval_matthews_correlation": 0.5011003042513985,
    "eval_runtime": 0.1873,
    "eval_samples_per_second": 5568.778,
    "eval_steps_per_second": 48.053,
    "epoch": 20.0,
    "log_history": [
        {
            "loss": 0.5306,
            "grad_norm": 0.9240173697471619,
            "learning_rate": 7.910447761194029e-05,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "eval_loss": 0.5310419201850891,
            "eval_matthews_correlation": 0.1830077398660012,
            "eval_runtime": 0.1979,
            "eval_samples_per_second": 5269.943,
            "eval_steps_per_second": 45.474,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "loss": 0.3761,
            "grad_norm": 1.5496814250946045,
            "learning_rate": 9.353233830845772e-05,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "eval_loss": 0.5744732618331909,
            "eval_matthews_correlation": 0.42289687557672184,
            "eval_runtime": 0.2098,
            "eval_samples_per_second": 4972.396,
            "eval_steps_per_second": 42.907,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "loss": 0.3341,
            "grad_norm": 2.1626038551330566,
            "learning_rate": 8.474295190713102e-05,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "eval_loss": 0.5974723696708679,
            "eval_matthews_correlation": 0.4491534084057902,
            "eval_runtime": 0.1857,
            "eval_samples_per_second": 5617.395,
            "eval_steps_per_second": 48.472,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "loss": 0.3074,
            "grad_norm": 1.489869236946106,
            "learning_rate": 7.595356550580432e-05,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "eval_loss": 0.6478794813156128,
            "eval_matthews_correlation": 0.46924526844967124,
            "eval_runtime": 0.1846,
            "eval_samples_per_second": 5649.883,
            "eval_steps_per_second": 48.753,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "loss": 0.2911,
            "grad_norm": 1.8581644296646118,
            "learning_rate": 6.716417910447762e-05,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "eval_loss": 0.6541271209716797,
            "eval_matthews_correlation": 0.48584699342231225,
            "eval_runtime": 0.203,
            "eval_samples_per_second": 5138.786,
            "eval_steps_per_second": 44.342,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "loss": 0.2773,
            "grad_norm": 1.7503303289413452,
            "learning_rate": 5.837479270315092e-05,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "eval_loss": 0.6323152780532837,
            "eval_matthews_correlation": 0.4830497789593027,
            "eval_runtime": 0.1813,
            "eval_samples_per_second": 5751.499,
            "eval_steps_per_second": 49.629,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "loss": 0.2595,
            "grad_norm": 2.2205021381378174,
            "learning_rate": 4.958540630182422e-05,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "eval_loss": 0.646742045879364,
            "eval_matthews_correlation": 0.4849110175375249,
            "eval_runtime": 0.1823,
            "eval_samples_per_second": 5721.829,
            "eval_steps_per_second": 49.373,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "loss": 0.2544,
            "grad_norm": 2.08882212638855,
            "learning_rate": 4.079601990049751e-05,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "eval_loss": 0.6428093910217285,
            "eval_matthews_correlation": 0.509946898813958,
            "eval_runtime": 0.2096,
            "eval_samples_per_second": 4977.165,
            "eval_steps_per_second": 42.948,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "loss": 0.2466,
            "grad_norm": 1.9809231758117676,
            "learning_rate": 3.200663349917081e-05,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "eval_loss": 0.6485963463783264,
            "eval_matthews_correlation": 0.5075813582663956,
            "eval_runtime": 0.1834,
            "eval_samples_per_second": 5685.924,
            "eval_steps_per_second": 49.064,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "loss": 0.2393,
            "grad_norm": 2.263136863708496,
            "learning_rate": 2.3217247097844114e-05,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "eval_loss": 0.6534317135810852,
            "eval_matthews_correlation": 0.5120519207329847,
            "eval_runtime": 0.184,
            "eval_samples_per_second": 5669.55,
            "eval_steps_per_second": 48.922,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "loss": 0.2342,
            "grad_norm": 2.532813549041748,
            "learning_rate": 1.4427860696517415e-05,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "eval_loss": 0.6693686246871948,
            "eval_matthews_correlation": 0.508446504598424,
            "eval_runtime": 0.1777,
            "eval_samples_per_second": 5868.835,
            "eval_steps_per_second": 50.642,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "loss": 0.2319,
            "grad_norm": 1.756967544555664,
            "learning_rate": 5.638474295190714e-06,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "eval_loss": 0.6547856330871582,
            "eval_matthews_correlation": 0.5035363418469242,
            "eval_runtime": 0.1904,
            "eval_samples_per_second": 5478.919,
            "eval_steps_per_second": 47.277,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "train_runtime": 85.4289,
            "train_samples_per_second": 2001.898,
            "train_steps_per_second": 15.686,
            "total_flos": 5775202340306944.0,
            "train_loss": 0.29516640350000184,
            "epoch": 20.0,
            "step": 1340
        },
        {
            "eval_loss": 0.6585142016410828,
            "eval_matthews_correlation": 0.5011003042513985,
            "eval_runtime": 0.1873,
            "eval_samples_per_second": 5568.778,
            "eval_steps_per_second": 48.053,
            "epoch": 20.0,
            "step": 1340
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "bert",
        "task": "cola",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 85.4289,
        "trainable_params_count": 0.72119,
        "memory_allocated": [
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072,
            297.63072
        ],
        "memory_reserved": [
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792,
            1488.97792
        ]
    },
    "variant": "kd-lora"
}