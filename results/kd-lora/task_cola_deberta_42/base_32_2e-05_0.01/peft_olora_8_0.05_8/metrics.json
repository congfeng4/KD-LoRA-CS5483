{
    "eval_loss": 2.69393253326416,
    "eval_matthews_correlation": 0.6380746914814548,
    "eval_runtime": 0.2597,
    "eval_samples_per_second": 4016.548,
    "eval_steps_per_second": 34.659,
    "epoch": 41.791044776119406,
    "log_history": [
        {
            "loss": 1.5699,
            "grad_norm": 1.690962553024292,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4631179571151733,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2252,
            "eval_samples_per_second": 4632.019,
            "eval_steps_per_second": 39.969,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4011,
            "grad_norm": 1.004414677619934,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.443678855895996,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.224,
            "eval_samples_per_second": 4656.602,
            "eval_steps_per_second": 40.182,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0555,
            "grad_norm": 1.5074760913848877,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.8880356550216675,
            "eval_matthews_correlation": 0.5445029137697658,
            "eval_runtime": 0.2249,
            "eval_samples_per_second": 4637.189,
            "eval_steps_per_second": 40.014,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.8935,
            "grad_norm": 1.5938082933425903,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.1323153972625732,
            "eval_matthews_correlation": 0.5728803433047456,
            "eval_runtime": 0.2253,
            "eval_samples_per_second": 4630.317,
            "eval_steps_per_second": 39.955,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8231,
            "grad_norm": 1.9193146228790283,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.3311963081359863,
            "eval_matthews_correlation": 0.5906042341193154,
            "eval_runtime": 0.265,
            "eval_samples_per_second": 3935.883,
            "eval_steps_per_second": 33.963,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.7734,
            "grad_norm": 1.8608862161636353,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.3746390342712402,
            "eval_matthews_correlation": 0.605712540622093,
            "eval_runtime": 0.2255,
            "eval_samples_per_second": 4625.03,
            "eval_steps_per_second": 39.909,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.7395,
            "grad_norm": 2.2359867095947266,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.500977039337158,
            "eval_matthews_correlation": 0.6082315244746964,
            "eval_runtime": 0.2298,
            "eval_samples_per_second": 4538.73,
            "eval_steps_per_second": 39.164,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7094,
            "grad_norm": 1.998907446861267,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.615079879760742,
            "eval_matthews_correlation": 0.6157901886148166,
            "eval_runtime": 0.2233,
            "eval_samples_per_second": 4670.727,
            "eval_steps_per_second": 40.303,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.6774,
            "grad_norm": 2.1065123081207275,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.69393253326416,
            "eval_matthews_correlation": 0.6380746914814548,
            "eval_runtime": 0.2235,
            "eval_samples_per_second": 4667.134,
            "eval_steps_per_second": 40.272,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.6409,
            "grad_norm": 3.668691396713257,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.7180018424987793,
            "eval_matthews_correlation": 0.6309028031172018,
            "eval_runtime": 0.2511,
            "eval_samples_per_second": 4154.472,
            "eval_steps_per_second": 35.849,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6313,
            "grad_norm": 2.366734743118286,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.7818968296051025,
            "eval_matthews_correlation": 0.6192420072395528,
            "eval_runtime": 0.2217,
            "eval_samples_per_second": 4705.073,
            "eval_steps_per_second": 40.6,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6088,
            "grad_norm": 2.775503396987915,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.810682535171509,
            "eval_matthews_correlation": 0.6239164540479953,
            "eval_runtime": 0.2571,
            "eval_samples_per_second": 4056.03,
            "eval_steps_per_second": 34.999,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5937,
            "grad_norm": 1.8353573083877563,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.850987672805786,
            "eval_matthews_correlation": 0.6287714546565786,
            "eval_runtime": 0.2231,
            "eval_samples_per_second": 4674.106,
            "eval_steps_per_second": 40.333,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.5726,
            "grad_norm": 2.9214184284210205,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.9671401977539062,
            "eval_matthews_correlation": 0.6257105594755433,
            "eval_runtime": 0.2579,
            "eval_samples_per_second": 4044.644,
            "eval_steps_per_second": 34.901,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "train_runtime": 170.4657,
            "train_samples_per_second": 5016.258,
            "train_steps_per_second": 39.304,
            "total_flos": 1.1910512321232896e+16,
            "train_loss": 0.8350116811479841,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.69393253326416,
            "eval_matthews_correlation": 0.6380746914814548,
            "eval_runtime": 0.2597,
            "eval_samples_per_second": 4016.548,
            "eval_steps_per_second": 34.659,
            "epoch": 41.791044776119406,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 170.4657,
        "trainable_params_count": 0.148994,
        "memory_allocated": [
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088,
            588.121088
        ],
        "memory_reserved": [
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672,
            2644.508672
        ]
    },
    "variant": "kd-lora"
}