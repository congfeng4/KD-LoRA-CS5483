{
    "eval_loss": 3.1629996299743652,
    "eval_matthews_correlation": 0.6538328050901304,
    "eval_runtime": 0.2304,
    "eval_samples_per_second": 4527.887,
    "eval_steps_per_second": 39.071,
    "epoch": 53.73134328358209,
    "log_history": [
        {
            "loss": 1.5674,
            "grad_norm": 1.5938422679901123,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4608755111694336,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2305,
            "eval_samples_per_second": 4524.123,
            "eval_steps_per_second": 39.038,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.2966,
            "grad_norm": 2.112523078918457,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6620821952819824,
            "eval_matthews_correlation": 0.5000765695969273,
            "eval_runtime": 0.2327,
            "eval_samples_per_second": 4481.636,
            "eval_steps_per_second": 38.672,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.9201,
            "grad_norm": 1.6602860689163208,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.0064659118652344,
            "eval_matthews_correlation": 0.5778482239390005,
            "eval_runtime": 0.2267,
            "eval_samples_per_second": 4601.785,
            "eval_steps_per_second": 39.709,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.8023,
            "grad_norm": 2.20054292678833,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.2105166912078857,
            "eval_matthews_correlation": 0.6007221525351318,
            "eval_runtime": 0.2606,
            "eval_samples_per_second": 4001.671,
            "eval_steps_per_second": 34.53,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.7273,
            "grad_norm": 2.126664638519287,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.4377663135528564,
            "eval_matthews_correlation": 0.6107991646384716,
            "eval_runtime": 0.2269,
            "eval_samples_per_second": 4595.805,
            "eval_steps_per_second": 39.657,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6663,
            "grad_norm": 2.482989549636841,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.56205677986145,
            "eval_matthews_correlation": 0.6314267706887338,
            "eval_runtime": 0.2273,
            "eval_samples_per_second": 4589.638,
            "eval_steps_per_second": 39.604,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6218,
            "grad_norm": 2.4527618885040283,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.6854915618896484,
            "eval_matthews_correlation": 0.6231769752814784,
            "eval_runtime": 0.2271,
            "eval_samples_per_second": 4592.509,
            "eval_steps_per_second": 39.629,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.5858,
            "grad_norm": 2.5747594833374023,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.8161303997039795,
            "eval_matthews_correlation": 0.640717737606528,
            "eval_runtime": 0.2294,
            "eval_samples_per_second": 4547.567,
            "eval_steps_per_second": 39.241,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5427,
            "grad_norm": 2.7736780643463135,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.97969126701355,
            "eval_matthews_correlation": 0.6430274487762421,
            "eval_runtime": 0.227,
            "eval_samples_per_second": 4594.941,
            "eval_steps_per_second": 39.65,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.5068,
            "grad_norm": 4.305135250091553,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.943894624710083,
            "eval_matthews_correlation": 0.6389155058365095,
            "eval_runtime": 0.2265,
            "eval_samples_per_second": 4604.235,
            "eval_steps_per_second": 39.73,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4827,
            "grad_norm": 2.5225250720977783,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 3.076320171356201,
            "eval_matthews_correlation": 0.6458160430668494,
            "eval_runtime": 0.2258,
            "eval_samples_per_second": 4619.814,
            "eval_steps_per_second": 39.864,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.4594,
            "grad_norm": 3.288769245147705,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 3.121168613433838,
            "eval_matthews_correlation": 0.6386095679193793,
            "eval_runtime": 0.2254,
            "eval_samples_per_second": 4626.84,
            "eval_steps_per_second": 39.925,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4395,
            "grad_norm": 2.3591625690460205,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 3.1629996299743652,
            "eval_matthews_correlation": 0.6538328050901304,
            "eval_runtime": 0.23,
            "eval_samples_per_second": 4535.586,
            "eval_steps_per_second": 39.137,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4103,
            "grad_norm": 2.5503287315368652,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 3.3138959407806396,
            "eval_matthews_correlation": 0.6454933691830679,
            "eval_runtime": 0.2266,
            "eval_samples_per_second": 4603.296,
            "eval_steps_per_second": 39.722,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.3992,
            "grad_norm": 4.357949256896973,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 3.2957983016967773,
            "eval_matthews_correlation": 0.643896576182995,
            "eval_runtime": 0.2262,
            "eval_samples_per_second": 4610.996,
            "eval_steps_per_second": 39.788,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3694,
            "grad_norm": 3.0539894104003906,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.4065518379211426,
            "eval_matthews_correlation": 0.6530464576994947,
            "eval_runtime": 0.227,
            "eval_samples_per_second": 4595.404,
            "eval_steps_per_second": 39.654,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3687,
            "grad_norm": 2.0408437252044678,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.3588876724243164,
            "eval_matthews_correlation": 0.6482933482592925,
            "eval_runtime": 0.227,
            "eval_samples_per_second": 4594.477,
            "eval_steps_per_second": 39.646,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3442,
            "grad_norm": 1.926142930984497,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.4351961612701416,
            "eval_matthews_correlation": 0.6528865280950995,
            "eval_runtime": 0.2262,
            "eval_samples_per_second": 4611.399,
            "eval_steps_per_second": 39.792,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "train_runtime": 216.9163,
            "train_samples_per_second": 3942.073,
            "train_steps_per_second": 30.887,
            "total_flos": 1.5365699694231552e+16,
            "train_loss": 0.6394855478074816,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.1629996299743652,
            "eval_matthews_correlation": 0.6538328050901304,
            "eval_runtime": 0.2304,
            "eval_samples_per_second": 4527.887,
            "eval_steps_per_second": 39.071,
            "epoch": 53.73134328358209,
            "step": 3600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 216.9163,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512
        ],
        "memory_reserved": [
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216
        ]
    },
    "variant": "kd-lora"
}