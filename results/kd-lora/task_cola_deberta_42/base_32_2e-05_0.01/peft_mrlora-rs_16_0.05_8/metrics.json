{
    "eval_loss": 0.6874268651008606,
    "eval_matthews_correlation": 0.6292829640607693,
    "eval_runtime": 0.294,
    "eval_samples_per_second": 3547.916,
    "eval_steps_per_second": 30.615,
    "epoch": 20.0,
    "log_history": [
        {
            "loss": 0.6017,
            "grad_norm": 0.8698168396949768,
            "learning_rate": 7.910447761194029e-05,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "eval_loss": 0.5096475481987,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3047,
            "eval_samples_per_second": 3423.463,
            "eval_steps_per_second": 29.541,
            "epoch": 1.582089552238806,
            "step": 106
        },
        {
            "loss": 0.3696,
            "grad_norm": 1.9990010261535645,
            "learning_rate": 9.353233830845772e-05,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "eval_loss": 0.6066473722457886,
            "eval_matthews_correlation": 0.5520661099098646,
            "eval_runtime": 0.2992,
            "eval_samples_per_second": 3485.487,
            "eval_steps_per_second": 30.076,
            "epoch": 3.1641791044776117,
            "step": 212
        },
        {
            "loss": 0.2825,
            "grad_norm": 2.2118237018585205,
            "learning_rate": 8.474295190713102e-05,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "eval_loss": 0.6385350823402405,
            "eval_matthews_correlation": 0.5855730181125508,
            "eval_runtime": 0.2862,
            "eval_samples_per_second": 3643.94,
            "eval_steps_per_second": 31.443,
            "epoch": 4.746268656716418,
            "step": 318
        },
        {
            "loss": 0.2554,
            "grad_norm": 1.7450361251831055,
            "learning_rate": 7.595356550580432e-05,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "eval_loss": 0.674938440322876,
            "eval_matthews_correlation": 0.5829638006957694,
            "eval_runtime": 0.2912,
            "eval_samples_per_second": 3581.653,
            "eval_steps_per_second": 30.906,
            "epoch": 6.3283582089552235,
            "step": 424
        },
        {
            "loss": 0.2399,
            "grad_norm": 1.1710208654403687,
            "learning_rate": 6.716417910447762e-05,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "eval_loss": 0.6950144171714783,
            "eval_matthews_correlation": 0.5955827154899263,
            "eval_runtime": 0.2839,
            "eval_samples_per_second": 3673.819,
            "eval_steps_per_second": 31.701,
            "epoch": 7.91044776119403,
            "step": 530
        },
        {
            "loss": 0.2302,
            "grad_norm": 1.6140294075012207,
            "learning_rate": 5.837479270315092e-05,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "eval_loss": 0.6731910705566406,
            "eval_matthews_correlation": 0.6061605762137284,
            "eval_runtime": 0.2902,
            "eval_samples_per_second": 3594.309,
            "eval_steps_per_second": 31.015,
            "epoch": 9.492537313432836,
            "step": 636
        },
        {
            "loss": 0.2202,
            "grad_norm": 1.3086215257644653,
            "learning_rate": 4.958540630182422e-05,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "eval_loss": 0.6726148128509521,
            "eval_matthews_correlation": 0.6165463827085729,
            "eval_runtime": 0.2897,
            "eval_samples_per_second": 3599.689,
            "eval_steps_per_second": 31.062,
            "epoch": 11.074626865671641,
            "step": 742
        },
        {
            "loss": 0.215,
            "grad_norm": 1.9304299354553223,
            "learning_rate": 4.079601990049751e-05,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "eval_loss": 0.6723360419273376,
            "eval_matthews_correlation": 0.6212374648619859,
            "eval_runtime": 0.3009,
            "eval_samples_per_second": 3465.969,
            "eval_steps_per_second": 29.908,
            "epoch": 12.656716417910447,
            "step": 848
        },
        {
            "loss": 0.2107,
            "grad_norm": 1.782735824584961,
            "learning_rate": 3.200663349917081e-05,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "eval_loss": 0.6900607943534851,
            "eval_matthews_correlation": 0.616383370327138,
            "eval_runtime": 0.2935,
            "eval_samples_per_second": 3553.571,
            "eval_steps_per_second": 30.664,
            "epoch": 14.238805970149254,
            "step": 954
        },
        {
            "loss": 0.2046,
            "grad_norm": 1.5610274076461792,
            "learning_rate": 2.3217247097844114e-05,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "eval_loss": 0.6857225298881531,
            "eval_matthews_correlation": 0.6394949291150869,
            "eval_runtime": 0.2839,
            "eval_samples_per_second": 3673.98,
            "eval_steps_per_second": 31.703,
            "epoch": 15.82089552238806,
            "step": 1060
        },
        {
            "loss": 0.2003,
            "grad_norm": 1.5151759386062622,
            "learning_rate": 1.4427860696517415e-05,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "eval_loss": 0.6882338523864746,
            "eval_matthews_correlation": 0.6322105347010745,
            "eval_runtime": 0.3336,
            "eval_samples_per_second": 3126.266,
            "eval_steps_per_second": 26.976,
            "epoch": 17.402985074626866,
            "step": 1166
        },
        {
            "loss": 0.2005,
            "grad_norm": 1.626028060913086,
            "learning_rate": 5.638474295190714e-06,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "eval_loss": 0.6844967007637024,
            "eval_matthews_correlation": 0.6342890666845706,
            "eval_runtime": 0.3011,
            "eval_samples_per_second": 3463.853,
            "eval_steps_per_second": 29.889,
            "epoch": 18.98507462686567,
            "step": 1272
        },
        {
            "train_runtime": 122.6179,
            "train_samples_per_second": 1394.739,
            "train_steps_per_second": 10.928,
            "total_flos": 5697607749861376.0,
            "train_loss": 0.2654524297856573,
            "epoch": 20.0,
            "step": 1340
        },
        {
            "eval_loss": 0.6874268651008606,
            "eval_matthews_correlation": 0.6292829640607693,
            "eval_runtime": 0.294,
            "eval_samples_per_second": 3547.916,
            "eval_steps_per_second": 30.615,
            "epoch": 20.0,
            "step": 1340
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "cola",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "lora_alpha": 16,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 122.6179,
        "trainable_params_count": 0.130598,
        "memory_allocated": [
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472,
            589.161472
        ],
        "memory_reserved": [
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224,
            3066.036224
        ]
    },
    "variant": "kd-lora"
}