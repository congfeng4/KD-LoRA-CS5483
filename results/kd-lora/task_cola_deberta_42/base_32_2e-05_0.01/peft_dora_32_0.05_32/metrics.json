{
    "eval_loss": 2.5485291481018066,
    "eval_matthews_correlation": 0.6569300311970928,
    "eval_runtime": 0.2817,
    "eval_samples_per_second": 3702.484,
    "eval_steps_per_second": 31.949,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 1.5658,
            "grad_norm": 1.4081288576126099,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4591245651245117,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.274,
            "eval_samples_per_second": 3805.944,
            "eval_steps_per_second": 32.841,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.2454,
            "grad_norm": 2.687530517578125,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.7732923030853271,
            "eval_matthews_correlation": 0.5232849512779736,
            "eval_runtime": 0.2835,
            "eval_samples_per_second": 3679.211,
            "eval_steps_per_second": 31.748,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.9434,
            "grad_norm": 1.7450438737869263,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.0318825244903564,
            "eval_matthews_correlation": 0.5778590180299453,
            "eval_runtime": 0.2808,
            "eval_samples_per_second": 3714.752,
            "eval_steps_per_second": 32.054,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.8418,
            "grad_norm": 2.031067371368408,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.2098162174224854,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.276,
            "eval_samples_per_second": 3779.253,
            "eval_steps_per_second": 32.611,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.7723,
            "grad_norm": 2.8411459922790527,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.392892837524414,
            "eval_matthews_correlation": 0.6427153093486515,
            "eval_runtime": 0.2735,
            "eval_samples_per_second": 3813.579,
            "eval_steps_per_second": 32.907,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.7131,
            "grad_norm": 2.576133966445923,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.440300226211548,
            "eval_matthews_correlation": 0.6549305528417414,
            "eval_runtime": 0.2759,
            "eval_samples_per_second": 3780.18,
            "eval_steps_per_second": 32.619,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6713,
            "grad_norm": 2.420555591583252,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.5485291481018066,
            "eval_matthews_correlation": 0.6569300311970928,
            "eval_runtime": 0.2791,
            "eval_samples_per_second": 3736.888,
            "eval_steps_per_second": 32.245,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.6307,
            "grad_norm": 2.631260871887207,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.6669204235076904,
            "eval_matthews_correlation": 0.6406194503745494,
            "eval_runtime": 0.2082,
            "eval_samples_per_second": 5010.766,
            "eval_steps_per_second": 43.238,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5871,
            "grad_norm": 2.7025623321533203,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.822547435760498,
            "eval_matthews_correlation": 0.6417812098009434,
            "eval_runtime": 0.2101,
            "eval_samples_per_second": 4964.406,
            "eval_steps_per_second": 42.838,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.5583,
            "grad_norm": 3.2099008560180664,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.7981643676757812,
            "eval_matthews_correlation": 0.6394949291150869,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 3693.706,
            "eval_steps_per_second": 31.873,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.5376,
            "grad_norm": 2.5880801677703857,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.921107769012451,
            "eval_matthews_correlation": 0.6463838109387049,
            "eval_runtime": 0.2835,
            "eval_samples_per_second": 3679.322,
            "eval_steps_per_second": 31.749,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.5182,
            "grad_norm": 3.4647457599639893,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.963634729385376,
            "eval_matthews_correlation": 0.6561372224507469,
            "eval_runtime": 0.2846,
            "eval_samples_per_second": 3665.311,
            "eval_steps_per_second": 31.628,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 165.3271,
            "train_samples_per_second": 5172.171,
            "train_steps_per_second": 40.526,
            "total_flos": 1.0315552593543168e+16,
            "train_loss": 0.7987505149841309,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.5485291481018066,
            "eval_matthews_correlation": 0.6569300311970928,
            "eval_runtime": 0.2817,
            "eval_samples_per_second": 3702.484,
            "eval_steps_per_second": 31.949,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 165.3271,
        "trainable_params_count": 0.600578,
        "memory_allocated": [
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208
        ],
        "memory_reserved": [
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552
        ]
    },
    "variant": "kd-lora"
}