{
    "eval_loss": 2.7046403884887695,
    "eval_matthews_correlation": 0.6467651157966614,
    "eval_runtime": 0.3695,
    "eval_samples_per_second": 2823.086,
    "eval_steps_per_second": 24.36,
    "epoch": 65.67164179104478,
    "log_history": [
        {
            "loss": 1.6112,
            "grad_norm": 3.0679826736450195,
            "learning_rate": 1.4925373134328357e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5181268453598022,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3825,
            "eval_samples_per_second": 2726.934,
            "eval_steps_per_second": 23.531,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4455,
            "grad_norm": 0.8946720361709595,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.4684733152389526,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.397,
            "eval_samples_per_second": 2626.88,
            "eval_steps_per_second": 22.667,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.4088,
            "grad_norm": 1.2332285642623901,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.4608349800109863,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3456,
            "eval_samples_per_second": 3017.537,
            "eval_steps_per_second": 26.038,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.2511,
            "grad_norm": 2.3940670490264893,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.5726455450057983,
            "eval_matthews_correlation": 0.47745692156806036,
            "eval_runtime": 0.3827,
            "eval_samples_per_second": 2725.658,
            "eval_steps_per_second": 23.52,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9942,
            "grad_norm": 1.4389985799789429,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.7914714813232422,
            "eval_matthews_correlation": 0.5142305590961299,
            "eval_runtime": 0.3633,
            "eval_samples_per_second": 2870.816,
            "eval_steps_per_second": 24.772,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9093,
            "grad_norm": 1.2642782926559448,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.9331583976745605,
            "eval_matthews_correlation": 0.5615726454989121,
            "eval_runtime": 0.4494,
            "eval_samples_per_second": 2321.029,
            "eval_steps_per_second": 20.028,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.857,
            "grad_norm": 1.9052133560180664,
            "learning_rate": 9.950248756218906e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.080199956893921,
            "eval_matthews_correlation": 0.5644375055893357,
            "eval_runtime": 0.3802,
            "eval_samples_per_second": 2743.319,
            "eval_steps_per_second": 23.672,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.8089,
            "grad_norm": 1.4185503721237183,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.1589207649230957,
            "eval_matthews_correlation": 0.5842220918189158,
            "eval_runtime": 0.3293,
            "eval_samples_per_second": 3167.454,
            "eval_steps_per_second": 27.332,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.77,
            "grad_norm": 1.3356034755706787,
            "learning_rate": 9.618573797678275e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.3001821041107178,
            "eval_matthews_correlation": 0.5936945766996267,
            "eval_runtime": 0.4339,
            "eval_samples_per_second": 2403.71,
            "eval_steps_per_second": 20.742,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7274,
            "grad_norm": 2.584101438522339,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.2906622886657715,
            "eval_matthews_correlation": 0.6182836522279034,
            "eval_runtime": 0.3728,
            "eval_samples_per_second": 2797.724,
            "eval_steps_per_second": 24.141,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.7043,
            "grad_norm": 1.4806545972824097,
            "learning_rate": 9.286898839137645e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.3648874759674072,
            "eval_matthews_correlation": 0.6158642432257276,
            "eval_runtime": 0.3884,
            "eval_samples_per_second": 2685.044,
            "eval_steps_per_second": 23.169,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.682,
            "grad_norm": 2.5811057090759277,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.433418035507202,
            "eval_matthews_correlation": 0.6132022979495473,
            "eval_runtime": 0.3638,
            "eval_samples_per_second": 2866.813,
            "eval_steps_per_second": 24.738,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.657,
            "grad_norm": 2.0063040256500244,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.5171430110931396,
            "eval_matthews_correlation": 0.6206942584175241,
            "eval_runtime": 0.3742,
            "eval_samples_per_second": 2787.568,
            "eval_steps_per_second": 24.054,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6286,
            "grad_norm": 1.7926093339920044,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.663722515106201,
            "eval_matthews_correlation": 0.620844043646687,
            "eval_runtime": 0.4515,
            "eval_samples_per_second": 2310.279,
            "eval_steps_per_second": 19.935,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.6125,
            "grad_norm": 3.762369155883789,
            "learning_rate": 8.623548922056384e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.6971194744110107,
            "eval_matthews_correlation": 0.6192420072395528,
            "eval_runtime": 0.4208,
            "eval_samples_per_second": 2478.4,
            "eval_steps_per_second": 21.386,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.585,
            "grad_norm": 2.84708309173584,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.7158172130584717,
            "eval_matthews_correlation": 0.6336264552651618,
            "eval_runtime": 0.4032,
            "eval_samples_per_second": 2586.75,
            "eval_steps_per_second": 22.321,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5729,
            "grad_norm": 1.8697481155395508,
            "learning_rate": 8.291873963515754e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.7046403884887695,
            "eval_matthews_correlation": 0.6467651157966614,
            "eval_runtime": 0.3979,
            "eval_samples_per_second": 2621.479,
            "eval_steps_per_second": 22.621,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5553,
            "grad_norm": 1.7294871807098389,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.7719974517822266,
            "eval_matthews_correlation": 0.6258269726983982,
            "eval_runtime": 0.4044,
            "eval_samples_per_second": 2578.951,
            "eval_steps_per_second": 22.254,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5394,
            "grad_norm": 1.5732942819595337,
            "learning_rate": 7.960199004975125e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 2.796325922012329,
            "eval_matthews_correlation": 0.6467651157966614,
            "eval_runtime": 0.3537,
            "eval_samples_per_second": 2948.998,
            "eval_steps_per_second": 25.447,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5255,
            "grad_norm": 3.9912633895874023,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.9094996452331543,
            "eval_matthews_correlation": 0.6284086224320302,
            "eval_runtime": 0.391,
            "eval_samples_per_second": 2667.338,
            "eval_steps_per_second": 23.016,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5182,
            "grad_norm": 2.002086639404297,
            "learning_rate": 7.628524046434495e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 2.8745951652526855,
            "eval_matthews_correlation": 0.6434514580893359,
            "eval_runtime": 0.3781,
            "eval_samples_per_second": 2758.466,
            "eval_steps_per_second": 23.803,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.4964,
            "grad_norm": 4.566651821136475,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 2.928194046020508,
            "eval_matthews_correlation": 0.6444865955961476,
            "eval_runtime": 0.4122,
            "eval_samples_per_second": 2530.122,
            "eval_steps_per_second": 21.832,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "train_runtime": 443.5483,
            "train_samples_per_second": 3855.724,
            "train_steps_per_second": 30.211,
            "total_flos": 1.871654003146752e+16,
            "train_loss": 0.8118543451482599,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 2.7046403884887695,
            "eval_matthews_correlation": 0.6467651157966614,
            "eval_runtime": 0.3695,
            "eval_samples_per_second": 2823.086,
            "eval_steps_per_second": 24.36,
            "epoch": 65.67164179104478,
            "step": 4400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": true,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 200,
        "peft": "mrlora-rs-olora-lcoef",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 42,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_olora": true,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 443.5483,
        "trainable_params_count": 0.149018,
        "memory_allocated": [
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664,
            588.145664
        ],
        "memory_reserved": [
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112,
            2843.738112
        ]
    },
    "variant": "kd-lora"
}