{
    "eval_loss": 2.7061800956726074,
    "eval_pearson": 0.8702060246795359,
    "eval_spearman": 0.8685231805520526,
    "eval_runtime": 0.2117,
    "eval_samples_per_second": 7084.797,
    "eval_steps_per_second": 56.678,
    "epoch": 71.11111111111111,
    "log_history": [
        {
            "loss": 4.7979,
            "grad_norm": 3.7825803756713867,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.6437745094299316,
            "eval_pearson": 0.2504340857093069,
            "eval_spearman": 0.2211105625515155,
            "eval_runtime": 0.1864,
            "eval_samples_per_second": 8049.334,
            "eval_steps_per_second": 64.395,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.4576,
            "grad_norm": 19.34113311767578,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.546478509902954,
            "eval_pearson": 0.8380333924148634,
            "eval_spearman": 0.8338759798057271,
            "eval_runtime": 0.1934,
            "eval_samples_per_second": 7754.803,
            "eval_steps_per_second": 62.038,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.8027,
            "grad_norm": 15.549530029296875,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.742053747177124,
            "eval_pearson": 0.8607495367539738,
            "eval_spearman": 0.8571304966128274,
            "eval_runtime": 0.2113,
            "eval_samples_per_second": 7098.539,
            "eval_steps_per_second": 56.788,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6819,
            "grad_norm": 5.6043829917907715,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.63893723487854,
            "eval_pearson": 0.8608929256641752,
            "eval_spearman": 0.8597658537557911,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 7110.34,
            "eval_steps_per_second": 56.883,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6052,
            "grad_norm": 12.97765064239502,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.7050676345825195,
            "eval_pearson": 0.8642627080617707,
            "eval_spearman": 0.862506126900604,
            "eval_runtime": 0.2117,
            "eval_samples_per_second": 7084.319,
            "eval_steps_per_second": 56.675,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.563,
            "grad_norm": 9.17186164855957,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.6877682209014893,
            "eval_pearson": 0.8662600678660303,
            "eval_spearman": 0.8644027206177781,
            "eval_runtime": 0.2142,
            "eval_samples_per_second": 7003.167,
            "eval_steps_per_second": 56.025,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.532,
            "grad_norm": 6.828350067138672,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.7131714820861816,
            "eval_pearson": 0.8662895672545411,
            "eval_spearman": 0.8639727391396171,
            "eval_runtime": 0.2118,
            "eval_samples_per_second": 7082.819,
            "eval_steps_per_second": 56.663,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5076,
            "grad_norm": 3.728548765182495,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.7756431102752686,
            "eval_pearson": 0.8678501435462485,
            "eval_spearman": 0.8651309812428526,
            "eval_runtime": 0.2162,
            "eval_samples_per_second": 6939.494,
            "eval_steps_per_second": 55.516,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4878,
            "grad_norm": 4.417252063751221,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.7334649562835693,
            "eval_pearson": 0.8679563916683284,
            "eval_spearman": 0.8651865580152872,
            "eval_runtime": 0.2172,
            "eval_samples_per_second": 6906.645,
            "eval_steps_per_second": 55.253,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4633,
            "grad_norm": 6.680878162384033,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.637650489807129,
            "eval_pearson": 0.8645720788480032,
            "eval_spearman": 0.8621805724490685,
            "eval_runtime": 0.2132,
            "eval_samples_per_second": 7034.897,
            "eval_steps_per_second": 56.279,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4568,
            "grad_norm": 3.6953482627868652,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.7095422744750977,
            "eval_pearson": 0.868727020897598,
            "eval_spearman": 0.866697702851461,
            "eval_runtime": 0.2162,
            "eval_samples_per_second": 6938.468,
            "eval_steps_per_second": 55.508,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4425,
            "grad_norm": 3.9105989933013916,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.7564382553100586,
            "eval_pearson": 0.8683543121210747,
            "eval_spearman": 0.8659559978096919,
            "eval_runtime": 0.2184,
            "eval_samples_per_second": 6866.805,
            "eval_steps_per_second": 54.934,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.4259,
            "grad_norm": 3.6559298038482666,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.7068064212799072,
            "eval_pearson": 0.8699431075421628,
            "eval_spearman": 0.8674736236130383,
            "eval_runtime": 0.2196,
            "eval_samples_per_second": 6829.609,
            "eval_steps_per_second": 54.637,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.4144,
            "grad_norm": 8.157698631286621,
            "learning_rate": 4.197530864197531e-05,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 2.7465736865997314,
            "eval_pearson": 0.8690731880483747,
            "eval_spearman": 0.8679811598041665,
            "eval_runtime": 0.2154,
            "eval_samples_per_second": 6963.496,
            "eval_steps_per_second": 55.708,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.4046,
            "grad_norm": 5.179877281188965,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 2.7061800956726074,
            "eval_pearson": 0.8702060246795359,
            "eval_spearman": 0.8685231805520526,
            "eval_runtime": 0.2124,
            "eval_samples_per_second": 7061.649,
            "eval_steps_per_second": 56.493,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "loss": 0.4032,
            "grad_norm": 8.964875221252441,
            "learning_rate": 3.209876543209876e-05,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.7356083393096924,
            "eval_pearson": 0.869884812201213,
            "eval_spearman": 0.8676636478789223,
            "eval_runtime": 0.2151,
            "eval_samples_per_second": 6972.966,
            "eval_steps_per_second": 55.784,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "train_runtime": 146.9616,
            "train_samples_per_second": 3911.907,
            "train_steps_per_second": 30.62,
            "total_flos": 1.3796831892865024e+16,
            "train_loss": 0.8404013228416443,
            "epoch": 71.11111111111111,
            "step": 3200
        },
        {
            "eval_loss": 2.7061800956726074,
            "eval_pearson": 0.8702060246795359,
            "eval_spearman": 0.8685231805520526,
            "eval_runtime": 0.2117,
            "eval_samples_per_second": 7084.797,
            "eval_steps_per_second": 56.678,
            "epoch": 71.11111111111111,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "stsb",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 146.9616,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728,
            359.497728
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}