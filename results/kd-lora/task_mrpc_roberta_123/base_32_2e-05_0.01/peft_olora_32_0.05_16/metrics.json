{
    "eval_loss": 3.346681594848633,
    "eval_accuracy": 0.8602941176470589,
    "eval_f1": 0.8998242530755711,
    "eval_runtime": 0.0762,
    "eval_samples_per_second": 5350.915,
    "eval_steps_per_second": 52.46,
    "epoch": 55.172413793103445,
    "log_history": [
        {
            "loss": 1.4881,
            "grad_norm": 4.047893047332764,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 1.6323740482330322,
            "eval_accuracy": 0.7352941176470589,
            "eval_f1": 0.8296529968454259,
            "eval_runtime": 0.0756,
            "eval_samples_per_second": 5399.386,
            "eval_steps_per_second": 52.935,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.965,
            "grad_norm": 4.526236057281494,
            "learning_rate": 9.578544061302682e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 2.524803638458252,
            "eval_accuracy": 0.8235294117647058,
            "eval_f1": 0.8727915194346291,
            "eval_runtime": 0.0767,
            "eval_samples_per_second": 5319.924,
            "eval_steps_per_second": 52.156,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.6276,
            "grad_norm": 8.031861305236816,
            "learning_rate": 8.812260536398468e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 3.346681594848633,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8998242530755711,
            "eval_runtime": 0.0756,
            "eval_samples_per_second": 5398.347,
            "eval_steps_per_second": 52.925,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.4347,
            "grad_norm": 9.366023063659668,
            "learning_rate": 8.045977011494253e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 3.7056894302368164,
            "eval_accuracy": 0.8455882352941176,
            "eval_f1": 0.8934010152284263,
            "eval_runtime": 0.0751,
            "eval_samples_per_second": 5432.916,
            "eval_steps_per_second": 53.264,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.3149,
            "grad_norm": 6.468634605407715,
            "learning_rate": 7.279693486590039e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 4.059921741485596,
            "eval_accuracy": 0.8455882352941176,
            "eval_f1": 0.8934010152284263,
            "eval_runtime": 0.0753,
            "eval_samples_per_second": 5418.877,
            "eval_steps_per_second": 53.126,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.2311,
            "grad_norm": 8.648209571838379,
            "learning_rate": 6.513409961685824e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 4.343980312347412,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8976109215017065,
            "eval_runtime": 0.0745,
            "eval_samples_per_second": 5478.292,
            "eval_steps_per_second": 53.709,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.1826,
            "grad_norm": 6.4087605476379395,
            "learning_rate": 5.747126436781609e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 4.501012325286865,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8951048951048952,
            "eval_runtime": 0.0745,
            "eval_samples_per_second": 5478.573,
            "eval_steps_per_second": 53.711,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.1456,
            "grad_norm": 11.43565559387207,
            "learning_rate": 4.980842911877395e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 4.591252326965332,
            "eval_accuracy": 0.8357843137254902,
            "eval_f1": 0.8854700854700854,
            "eval_runtime": 0.0761,
            "eval_samples_per_second": 5359.092,
            "eval_steps_per_second": 52.54,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "train_runtime": 71.2776,
            "train_samples_per_second": 5146.079,
            "train_steps_per_second": 40.686,
            "total_flos": 6921850361741312.0,
            "train_loss": 0.5486934554576873,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 3.346681594848633,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8998242530755711,
            "eval_runtime": 0.0762,
            "eval_samples_per_second": 5350.915,
            "eval_steps_per_second": 52.46,
            "epoch": 55.172413793103445,
            "step": 1600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 16,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 3668
    },
    "train": {
        "train_time": 71.2776,
        "trainable_params_count": 0.887042,
        "memory_allocated": [
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472,
            361.577472
        ],
        "memory_reserved": [
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032,
            1186.988032
        ]
    },
    "variant": "kd-lora"
}