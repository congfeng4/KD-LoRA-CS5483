{
    "eval_loss": 4.120874881744385,
    "eval_accuracy": 0.8651960784313726,
    "eval_f1": 0.9050086355785838,
    "eval_runtime": 0.0834,
    "eval_samples_per_second": 4894.086,
    "eval_steps_per_second": 47.981,
    "epoch": 82.75862068965517,
    "log_history": [
        {
            "loss": 1.4845,
            "grad_norm": 2.9203648567199707,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 1.6022170782089233,
            "eval_accuracy": 0.75,
            "eval_f1": 0.8370607028753992,
            "eval_runtime": 0.0842,
            "eval_samples_per_second": 4845.79,
            "eval_steps_per_second": 47.508,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 1.0555,
            "grad_norm": 7.0594868659973145,
            "learning_rate": 9.578544061302682e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 2.293898105621338,
            "eval_accuracy": 0.8406862745098039,
            "eval_f1": 0.888888888888889,
            "eval_runtime": 0.0828,
            "eval_samples_per_second": 4929.571,
            "eval_steps_per_second": 48.329,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.7983,
            "grad_norm": 13.337689399719238,
            "learning_rate": 8.812260536398468e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 2.765305995941162,
            "eval_accuracy": 0.8651960784313726,
            "eval_f1": 0.9029982363315697,
            "eval_runtime": 0.0832,
            "eval_samples_per_second": 4906.027,
            "eval_steps_per_second": 48.098,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.6546,
            "grad_norm": 22.49637222290039,
            "learning_rate": 8.045977011494253e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 3.04962158203125,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.9008695652173914,
            "eval_runtime": 0.0837,
            "eval_samples_per_second": 4876.834,
            "eval_steps_per_second": 47.812,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.5533,
            "grad_norm": 9.896448135375977,
            "learning_rate": 7.279693486590039e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 3.304786443710327,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8954703832752613,
            "eval_runtime": 0.0817,
            "eval_samples_per_second": 4993.642,
            "eval_steps_per_second": 48.957,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.449,
            "grad_norm": 16.26717758178711,
            "learning_rate": 6.513409961685824e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 3.7907986640930176,
            "eval_accuracy": 0.8553921568627451,
            "eval_f1": 0.8977469670710572,
            "eval_runtime": 0.0819,
            "eval_samples_per_second": 4978.779,
            "eval_steps_per_second": 48.812,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.3752,
            "grad_norm": 16.467998504638672,
            "learning_rate": 5.747126436781609e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 4.098880767822266,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9087656529516995,
            "eval_runtime": 0.0851,
            "eval_samples_per_second": 4796.89,
            "eval_steps_per_second": 47.028,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.3217,
            "grad_norm": 10.874345779418945,
            "learning_rate": 4.980842911877395e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 4.254181861877441,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.9015544041450777,
            "eval_runtime": 0.0827,
            "eval_samples_per_second": 4930.551,
            "eval_steps_per_second": 48.339,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.2894,
            "grad_norm": 29.885164260864258,
            "learning_rate": 4.21455938697318e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 4.285956382751465,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9068541300527241,
            "eval_runtime": 0.0826,
            "eval_samples_per_second": 4940.558,
            "eval_steps_per_second": 48.437,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.2453,
            "grad_norm": 23.51036262512207,
            "learning_rate": 3.4482758620689657e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 4.373732089996338,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.8993055555555555,
            "eval_runtime": 0.0823,
            "eval_samples_per_second": 4955.265,
            "eval_steps_per_second": 48.581,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "loss": 0.2284,
            "grad_norm": 24.001201629638672,
            "learning_rate": 2.681992337164751e-05,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "eval_loss": 4.627511024475098,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.9003436426116839,
            "eval_runtime": 0.0818,
            "eval_samples_per_second": 4985.451,
            "eval_steps_per_second": 48.877,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "loss": 0.21,
            "grad_norm": 24.841365814208984,
            "learning_rate": 1.9157088122605367e-05,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "eval_loss": 4.593324184417725,
            "eval_accuracy": 0.8676470588235294,
            "eval_f1": 0.9059233449477352,
            "eval_runtime": 0.0833,
            "eval_samples_per_second": 4896.635,
            "eval_steps_per_second": 48.006,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "train_runtime": 138.0562,
            "train_samples_per_second": 2656.888,
            "train_steps_per_second": 21.006,
            "total_flos": 1.0348003218948096e+16,
            "train_loss": 0.55542289574941,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "eval_loss": 4.120874881744385,
            "eval_accuracy": 0.8651960784313726,
            "eval_f1": 0.9050086355785838,
            "eval_runtime": 0.0834,
            "eval_samples_per_second": 4894.086,
            "eval_steps_per_second": 47.981,
            "epoch": 82.75862068965517,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 123,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 138.0562,
        "trainable_params_count": 0.739622,
        "memory_allocated": [
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312,
            357.965312
        ],
        "memory_reserved": [
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392,
            1564.475392
        ]
    },
    "variant": "kd-lora"
}