{
    "eval_loss": 2.5659914016723633,
    "eval_matthews_correlation": 0.5219614412677479,
    "eval_runtime": 0.1572,
    "eval_samples_per_second": 6632.844,
    "eval_steps_per_second": 57.235,
    "epoch": 44.776119402985074,
    "log_history": [
        {
            "loss": 1.4842,
            "grad_norm": 0.5651872158050537,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4991919994354248,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1672,
            "eval_samples_per_second": 6237.955,
            "eval_steps_per_second": 53.827,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.2586,
            "grad_norm": 1.9791667461395264,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.7612335681915283,
            "eval_matthews_correlation": 0.3791399403306623,
            "eval_runtime": 0.1609,
            "eval_samples_per_second": 6483.656,
            "eval_steps_per_second": 55.947,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.112,
            "grad_norm": 4.087164878845215,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9708805084228516,
            "eval_matthews_correlation": 0.42096010214901264,
            "eval_runtime": 0.1621,
            "eval_samples_per_second": 6435.328,
            "eval_steps_per_second": 55.53,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0346,
            "grad_norm": 3.030021905899048,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.0710597038269043,
            "eval_matthews_correlation": 0.45844098248595105,
            "eval_runtime": 0.1631,
            "eval_samples_per_second": 6393.859,
            "eval_steps_per_second": 55.172,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9552,
            "grad_norm": 2.9419639110565186,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.9820139408111572,
            "eval_matthews_correlation": 0.48906137985709797,
            "eval_runtime": 0.1611,
            "eval_samples_per_second": 6473.659,
            "eval_steps_per_second": 55.861,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8826,
            "grad_norm": 3.140021800994873,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.0796778202056885,
            "eval_matthews_correlation": 0.4881621973057103,
            "eval_runtime": 0.1646,
            "eval_samples_per_second": 6337.202,
            "eval_steps_per_second": 54.683,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8291,
            "grad_norm": 3.6856894493103027,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.3521969318389893,
            "eval_matthews_correlation": 0.4810794261012942,
            "eval_runtime": 0.1649,
            "eval_samples_per_second": 6326.561,
            "eval_steps_per_second": 54.592,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.776,
            "grad_norm": 4.353007793426514,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.297250986099243,
            "eval_matthews_correlation": 0.5140072587631689,
            "eval_runtime": 0.1652,
            "eval_samples_per_second": 6311.984,
            "eval_steps_per_second": 54.466,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7223,
            "grad_norm": 5.2716217041015625,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.427422285079956,
            "eval_matthews_correlation": 0.5059047788828706,
            "eval_runtime": 0.1634,
            "eval_samples_per_second": 6383.335,
            "eval_steps_per_second": 55.082,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.6823,
            "grad_norm": 5.733809471130371,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.5659914016723633,
            "eval_matthews_correlation": 0.5219614412677479,
            "eval_runtime": 0.1631,
            "eval_samples_per_second": 6394.336,
            "eval_steps_per_second": 55.176,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6604,
            "grad_norm": 6.942563056945801,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.691474676132202,
            "eval_matthews_correlation": 0.5082293777336861,
            "eval_runtime": 0.1635,
            "eval_samples_per_second": 6379.211,
            "eval_steps_per_second": 55.046,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6244,
            "grad_norm": 4.955994129180908,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.781952142715454,
            "eval_matthews_correlation": 0.5064665464580312,
            "eval_runtime": 0.1626,
            "eval_samples_per_second": 6415.773,
            "eval_steps_per_second": 55.361,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5855,
            "grad_norm": 5.103522777557373,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.8225526809692383,
            "eval_matthews_correlation": 0.4908744677337709,
            "eval_runtime": 0.1712,
            "eval_samples_per_second": 6091.016,
            "eval_steps_per_second": 52.559,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.5562,
            "grad_norm": 6.116322040557861,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.807359218597412,
            "eval_matthews_correlation": 0.4913323507188424,
            "eval_runtime": 0.1576,
            "eval_samples_per_second": 6619.906,
            "eval_steps_per_second": 57.123,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.5392,
            "grad_norm": 5.157985687255859,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.8442466259002686,
            "eval_matthews_correlation": 0.4918210201113668,
            "eval_runtime": 0.1587,
            "eval_samples_per_second": 6570.422,
            "eval_steps_per_second": 56.696,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "train_runtime": 141.5358,
            "train_samples_per_second": 6041.582,
            "train_steps_per_second": 47.338,
            "total_flos": 1.293498288439296e+16,
            "train_loss": 0.8468481369018555,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.5659914016723633,
            "eval_matthews_correlation": 0.5219614412677479,
            "eval_runtime": 0.1572,
            "eval_samples_per_second": 6632.844,
            "eval_steps_per_second": 57.235,
            "epoch": 44.776119402985074,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 141.5358,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016
        ],
        "memory_reserved": [
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344
        ]
    },
    "variant": "kd-lora"
}