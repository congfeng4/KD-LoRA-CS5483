{
    "eval_loss": 2.215541124343872,
    "eval_matthews_correlation": 0.5132274753696389,
    "eval_runtime": 0.2116,
    "eval_samples_per_second": 4929.871,
    "eval_steps_per_second": 42.54,
    "epoch": 41.791044776119406,
    "log_history": [
        {
            "loss": 1.4887,
            "grad_norm": 0.4956830143928528,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.493776798248291,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2367,
            "eval_samples_per_second": 4406.341,
            "eval_steps_per_second": 38.022,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3124,
            "grad_norm": 1.0334807634353638,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6971638202667236,
            "eval_matthews_correlation": 0.3551488292952868,
            "eval_runtime": 0.2269,
            "eval_samples_per_second": 4597.094,
            "eval_steps_per_second": 39.668,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1557,
            "grad_norm": 1.9640055894851685,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9035406112670898,
            "eval_matthews_correlation": 0.41222715814310473,
            "eval_runtime": 0.2292,
            "eval_samples_per_second": 4551.536,
            "eval_steps_per_second": 39.275,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0778,
            "grad_norm": 1.344879150390625,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.9824949502944946,
            "eval_matthews_correlation": 0.43846185615604477,
            "eval_runtime": 0.2356,
            "eval_samples_per_second": 4426.838,
            "eval_steps_per_second": 38.199,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 1.01,
            "grad_norm": 1.7019718885421753,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.9001359939575195,
            "eval_matthews_correlation": 0.4782596897918875,
            "eval_runtime": 0.2212,
            "eval_samples_per_second": 4715.439,
            "eval_steps_per_second": 40.689,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9489,
            "grad_norm": 2.1681957244873047,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.0162696838378906,
            "eval_matthews_correlation": 0.4903279207078663,
            "eval_runtime": 0.2103,
            "eval_samples_per_second": 4960.117,
            "eval_steps_per_second": 42.801,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.9052,
            "grad_norm": 2.5069098472595215,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.123352527618408,
            "eval_matthews_correlation": 0.48170038113970914,
            "eval_runtime": 0.2365,
            "eval_samples_per_second": 4410.699,
            "eval_steps_per_second": 38.06,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.8565,
            "grad_norm": 2.6412808895111084,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.1792705059051514,
            "eval_matthews_correlation": 0.47761066068613917,
            "eval_runtime": 0.2113,
            "eval_samples_per_second": 4935.962,
            "eval_steps_per_second": 42.592,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.8055,
            "grad_norm": 2.8149805068969727,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.215541124343872,
            "eval_matthews_correlation": 0.5132274753696389,
            "eval_runtime": 0.2211,
            "eval_samples_per_second": 4716.792,
            "eval_steps_per_second": 40.701,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7689,
            "grad_norm": 2.5198726654052734,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.39386248588562,
            "eval_matthews_correlation": 0.5012885291628268,
            "eval_runtime": 0.2071,
            "eval_samples_per_second": 5035.666,
            "eval_steps_per_second": 43.453,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.7467,
            "grad_norm": 4.08405065536499,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.4184367656707764,
            "eval_matthews_correlation": 0.4968656675106091,
            "eval_runtime": 0.2155,
            "eval_samples_per_second": 4838.796,
            "eval_steps_per_second": 41.754,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.7123,
            "grad_norm": 2.74780011177063,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.5153629779815674,
            "eval_matthews_correlation": 0.4989966372841492,
            "eval_runtime": 0.2237,
            "eval_samples_per_second": 4662.548,
            "eval_steps_per_second": 40.233,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6722,
            "grad_norm": 2.670140504837036,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.5617141723632812,
            "eval_matthews_correlation": 0.4864009329913555,
            "eval_runtime": 0.2145,
            "eval_samples_per_second": 4862.202,
            "eval_steps_per_second": 41.956,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6441,
            "grad_norm": 3.395437240600586,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.5546388626098633,
            "eval_matthews_correlation": 0.5093030018169853,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 4943.659,
            "eval_steps_per_second": 42.659,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "train_runtime": 166.5252,
            "train_samples_per_second": 5134.957,
            "train_steps_per_second": 40.234,
            "total_flos": 1.2075187407159296e+16,
            "train_loss": 0.9360531997680664,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.215541124343872,
            "eval_matthews_correlation": 0.5132274753696389,
            "eval_runtime": 0.2116,
            "eval_samples_per_second": 4929.871,
            "eval_steps_per_second": 42.54,
            "epoch": 41.791044776119406,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 166.5252,
        "trainable_params_count": 0.748802,
        "memory_allocated": [
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064
        ],
        "memory_reserved": [
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912
        ]
    },
    "variant": "kd-lora"
}