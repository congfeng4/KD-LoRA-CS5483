{
    "eval_loss": 2.6957461833953857,
    "eval_matthews_correlation": 0.4982331824617808,
    "eval_runtime": 0.1815,
    "eval_samples_per_second": 5745.584,
    "eval_steps_per_second": 49.578,
    "epoch": 32.83582089552239,
    "log_history": [
        {
            "loss": 1.4777,
            "grad_norm": 0.9833692312240601,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5030956268310547,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1756,
            "eval_samples_per_second": 5939.376,
            "eval_steps_per_second": 51.251,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.222,
            "grad_norm": 4.5842390060424805,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.7774713039398193,
            "eval_matthews_correlation": 0.40640794008878706,
            "eval_runtime": 0.1728,
            "eval_samples_per_second": 6036.552,
            "eval_steps_per_second": 52.089,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0863,
            "grad_norm": 9.099382400512695,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.0160164833068848,
            "eval_matthews_correlation": 0.4383073763444572,
            "eval_runtime": 0.1759,
            "eval_samples_per_second": 5929.707,
            "eval_steps_per_second": 51.167,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9979,
            "grad_norm": 6.17680549621582,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.0953240394592285,
            "eval_matthews_correlation": 0.45808021085661066,
            "eval_runtime": 0.1722,
            "eval_samples_per_second": 6055.554,
            "eval_steps_per_second": 52.253,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9039,
            "grad_norm": 6.599422454833984,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.0886759757995605,
            "eval_matthews_correlation": 0.4908549322620884,
            "eval_runtime": 0.1747,
            "eval_samples_per_second": 5969.859,
            "eval_steps_per_second": 51.514,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8221,
            "grad_norm": 7.52280330657959,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.1826658248901367,
            "eval_matthews_correlation": 0.5141951979542654,
            "eval_runtime": 0.1707,
            "eval_samples_per_second": 6109.876,
            "eval_steps_per_second": 52.722,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.7614,
            "grad_norm": 8.846086502075195,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.499047040939331,
            "eval_matthews_correlation": 0.4821946236605807,
            "eval_runtime": 0.1712,
            "eval_samples_per_second": 6090.812,
            "eval_steps_per_second": 52.557,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.701,
            "grad_norm": 9.090785026550293,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.4682676792144775,
            "eval_matthews_correlation": 0.4928616186320675,
            "eval_runtime": 0.1658,
            "eval_samples_per_second": 6290.989,
            "eval_steps_per_second": 54.285,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.6486,
            "grad_norm": 7.962603569030762,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.6192357540130615,
            "eval_matthews_correlation": 0.5146251651052666,
            "eval_runtime": 0.1737,
            "eval_samples_per_second": 6003.539,
            "eval_steps_per_second": 51.804,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.5999,
            "grad_norm": 9.2579984664917,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.82716703414917,
            "eval_matthews_correlation": 0.506019094116684,
            "eval_runtime": 0.171,
            "eval_samples_per_second": 6097.689,
            "eval_steps_per_second": 52.617,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.578,
            "grad_norm": 9.895415306091309,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.9369311332702637,
            "eval_matthews_correlation": 0.497129893901161,
            "eval_runtime": 0.1673,
            "eval_samples_per_second": 6234.79,
            "eval_steps_per_second": 53.8,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "train_runtime": 121.2878,
            "train_samples_per_second": 7050.175,
            "train_steps_per_second": 55.241,
            "total_flos": 9485669617369088.0,
            "train_loss": 0.890822771245783,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.6957461833953857,
            "eval_matthews_correlation": 0.4982331824617808,
            "eval_runtime": 0.1815,
            "eval_samples_per_second": 5745.584,
            "eval_steps_per_second": 49.578,
            "epoch": 32.83582089552239,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 121.2878,
        "trainable_params_count": 0.739622,
        "memory_allocated": [
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832,
            296.952832
        ],
        "memory_reserved": [
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792,
            1459.617792
        ]
    },
    "variant": "kd-lora"
}