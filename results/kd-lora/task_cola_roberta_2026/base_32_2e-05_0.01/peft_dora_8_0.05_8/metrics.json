{
    "eval_loss": 1.7388869524002075,
    "eval_matthews_correlation": 0.5730766020227869,
    "eval_runtime": 0.2071,
    "eval_samples_per_second": 5036.866,
    "eval_steps_per_second": 43.463,
    "epoch": 74.6268656716418,
    "log_history": [
        {
            "loss": 1.1098,
            "grad_norm": 1.2183114290237427,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.0802056789398193,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1849,
            "eval_samples_per_second": 5641.555,
            "eval_steps_per_second": 48.681,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.9513,
            "grad_norm": 1.089107632637024,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.3130687475204468,
            "eval_matthews_correlation": 0.39150252536899116,
            "eval_runtime": 0.2063,
            "eval_samples_per_second": 5054.932,
            "eval_steps_per_second": 43.619,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.7913,
            "grad_norm": 1.8082908391952515,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.385982871055603,
            "eval_matthews_correlation": 0.4446196636082168,
            "eval_runtime": 0.2069,
            "eval_samples_per_second": 5040.9,
            "eval_steps_per_second": 43.498,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.74,
            "grad_norm": 2.088009834289551,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.4159220457077026,
            "eval_matthews_correlation": 0.48334022151161765,
            "eval_runtime": 0.2126,
            "eval_samples_per_second": 4904.843,
            "eval_steps_per_second": 42.324,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.7144,
            "grad_norm": 3.7668628692626953,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.452808141708374,
            "eval_matthews_correlation": 0.5072784045554821,
            "eval_runtime": 0.2072,
            "eval_samples_per_second": 5034.709,
            "eval_steps_per_second": 43.444,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6942,
            "grad_norm": 1.4419231414794922,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.469916582107544,
            "eval_matthews_correlation": 0.5303353676557755,
            "eval_runtime": 0.1766,
            "eval_samples_per_second": 5906.402,
            "eval_steps_per_second": 50.966,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6697,
            "grad_norm": 2.0196003913879395,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.5537948608398438,
            "eval_matthews_correlation": 0.510581671760424,
            "eval_runtime": 0.1791,
            "eval_samples_per_second": 5823.049,
            "eval_steps_per_second": 50.247,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.6472,
            "grad_norm": 2.0350162982940674,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.6428205966949463,
            "eval_matthews_correlation": 0.5126228485857701,
            "eval_runtime": 0.2031,
            "eval_samples_per_second": 5134.42,
            "eval_steps_per_second": 44.305,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.6356,
            "grad_norm": 2.014824628829956,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.579106330871582,
            "eval_matthews_correlation": 0.5367676459034164,
            "eval_runtime": 0.1772,
            "eval_samples_per_second": 5884.806,
            "eval_steps_per_second": 50.78,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.6194,
            "grad_norm": 1.9823758602142334,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.530758023262024,
            "eval_matthews_correlation": 0.5448788961504227,
            "eval_runtime": 0.1781,
            "eval_samples_per_second": 5856.476,
            "eval_steps_per_second": 50.535,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6112,
            "grad_norm": 2.743624210357666,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.5983505249023438,
            "eval_matthews_correlation": 0.5473459132428302,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 4944.011,
            "eval_steps_per_second": 42.662,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.5953,
            "grad_norm": 1.762853741645813,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.711202621459961,
            "eval_matthews_correlation": 0.5391948418977317,
            "eval_runtime": 0.1792,
            "eval_samples_per_second": 5820.206,
            "eval_steps_per_second": 50.222,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5778,
            "grad_norm": 1.9850807189941406,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.7362428903579712,
            "eval_matthews_correlation": 0.544509467622167,
            "eval_runtime": 0.1764,
            "eval_samples_per_second": 5914.187,
            "eval_steps_per_second": 51.033,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.578,
            "grad_norm": 2.0534965991973877,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.7333126068115234,
            "eval_matthews_correlation": 0.5526896422396544,
            "eval_runtime": 0.1766,
            "eval_samples_per_second": 5904.831,
            "eval_steps_per_second": 50.953,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.5653,
            "grad_norm": 2.809070348739624,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.710159182548523,
            "eval_matthews_correlation": 0.550090073200501,
            "eval_runtime": 0.176,
            "eval_samples_per_second": 5925.819,
            "eval_steps_per_second": 51.134,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.5589,
            "grad_norm": 2.9373562335968018,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.7769397497177124,
            "eval_matthews_correlation": 0.5395109128667314,
            "eval_runtime": 0.2149,
            "eval_samples_per_second": 4853.506,
            "eval_steps_per_second": 41.881,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5481,
            "grad_norm": 2.4719078540802,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.683401346206665,
            "eval_matthews_correlation": 0.5611975320184954,
            "eval_runtime": 0.2111,
            "eval_samples_per_second": 4940.84,
            "eval_steps_per_second": 42.634,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5381,
            "grad_norm": 3.3921587467193604,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.72672700881958,
            "eval_matthews_correlation": 0.5654865997646326,
            "eval_runtime": 0.211,
            "eval_samples_per_second": 4942.827,
            "eval_steps_per_second": 42.651,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5349,
            "grad_norm": 2.5240256786346436,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.7476146221160889,
            "eval_matthews_correlation": 0.5550196600183235,
            "eval_runtime": 0.1785,
            "eval_samples_per_second": 5842.078,
            "eval_steps_per_second": 50.411,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5266,
            "grad_norm": 2.6831419467926025,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.7388869524002075,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.2145,
            "eval_samples_per_second": 4862.602,
            "eval_steps_per_second": 41.959,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5174,
            "grad_norm": 5.173256874084473,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.7509591579437256,
            "eval_matthews_correlation": 0.5551439282323715,
            "eval_runtime": 0.2045,
            "eval_samples_per_second": 5100.008,
            "eval_steps_per_second": 44.008,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5209,
            "grad_norm": 2.2334165573120117,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.814714789390564,
            "eval_matthews_correlation": 0.5418980827011334,
            "eval_runtime": 0.2135,
            "eval_samples_per_second": 4886.168,
            "eval_steps_per_second": 42.163,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.5143,
            "grad_norm": 3.8452348709106445,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.7667787075042725,
            "eval_matthews_correlation": 0.5703054933279827,
            "eval_runtime": 0.2064,
            "eval_samples_per_second": 5054.312,
            "eval_steps_per_second": 43.613,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5166,
            "grad_norm": 2.971658945083618,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.8175345659255981,
            "eval_matthews_correlation": 0.5601977832642419,
            "eval_runtime": 0.1784,
            "eval_samples_per_second": 5846.747,
            "eval_steps_per_second": 50.451,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.4986,
            "grad_norm": 2.5533900260925293,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 1.7999130487442017,
            "eval_matthews_correlation": 0.5707798240133651,
            "eval_runtime": 0.2044,
            "eval_samples_per_second": 5103.054,
            "eval_steps_per_second": 44.034,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "train_runtime": 264.3244,
            "train_samples_per_second": 3235.04,
            "train_steps_per_second": 25.348,
            "total_flos": 2.15628346556416e+16,
            "train_loss": 0.6309910064697266,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 1.7388869524002075,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.2071,
            "eval_samples_per_second": 5036.866,
            "eval_steps_per_second": 43.463,
            "epoch": 74.6268656716418,
            "step": 5000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 264.3244,
        "trainable_params_count": 0.748802,
        "memory_allocated": [
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112,
            358.874112
        ],
        "memory_reserved": [
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128,
            1340.080128
        ]
    },
    "variant": "kd-lora"
}