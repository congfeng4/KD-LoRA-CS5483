{
    "eval_loss": 1.951189637184143,
    "eval_matthews_correlation": 0.5981951351808346,
    "eval_runtime": 0.1589,
    "eval_samples_per_second": 6565.757,
    "eval_steps_per_second": 56.656,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 1.1089,
            "grad_norm": 1.2467139959335327,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.0783389806747437,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1644,
            "eval_samples_per_second": 6345.116,
            "eval_steps_per_second": 54.752,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.9147,
            "grad_norm": 2.0519425868988037,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.35089111328125,
            "eval_matthews_correlation": 0.39738998737159736,
            "eval_runtime": 0.1605,
            "eval_samples_per_second": 6497.002,
            "eval_steps_per_second": 56.062,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.7644,
            "grad_norm": 3.9120702743530273,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.4760620594024658,
            "eval_matthews_correlation": 0.45539810748029474,
            "eval_runtime": 0.1614,
            "eval_samples_per_second": 6461.258,
            "eval_steps_per_second": 55.754,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.6923,
            "grad_norm": 3.63936448097229,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.557646632194519,
            "eval_matthews_correlation": 0.4892344546051281,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 6517.814,
            "eval_steps_per_second": 56.242,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.6526,
            "grad_norm": 4.867619037628174,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.5585790872573853,
            "eval_matthews_correlation": 0.5142153328951897,
            "eval_runtime": 0.1582,
            "eval_samples_per_second": 6592.482,
            "eval_steps_per_second": 56.886,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6087,
            "grad_norm": 2.547697067260742,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.624132513999939,
            "eval_matthews_correlation": 0.5319354120310512,
            "eval_runtime": 0.1594,
            "eval_samples_per_second": 6543.425,
            "eval_steps_per_second": 56.463,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.575,
            "grad_norm": 4.200062274932861,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.6467525959014893,
            "eval_matthews_correlation": 0.5582103540932131,
            "eval_runtime": 0.1648,
            "eval_samples_per_second": 6329.069,
            "eval_steps_per_second": 54.613,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.5351,
            "grad_norm": 3.7574522495269775,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.7853151559829712,
            "eval_matthews_correlation": 0.5550196600183235,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6525.242,
            "eval_steps_per_second": 56.306,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5165,
            "grad_norm": 4.607379913330078,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.7876535654067993,
            "eval_matthews_correlation": 0.5730766020227869,
            "eval_runtime": 0.1592,
            "eval_samples_per_second": 6553.119,
            "eval_steps_per_second": 56.547,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.4918,
            "grad_norm": 4.062307357788086,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.7165882587432861,
            "eval_matthews_correlation": 0.5779953180551635,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6526.614,
            "eval_steps_per_second": 56.318,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4778,
            "grad_norm": 4.593901634216309,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.7830535173416138,
            "eval_matthews_correlation": 0.5715199776370171,
            "eval_runtime": 0.1591,
            "eval_samples_per_second": 6557.205,
            "eval_steps_per_second": 56.582,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.454,
            "grad_norm": 4.200273036956787,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.9209568500518799,
            "eval_matthews_correlation": 0.5573424050983508,
            "eval_runtime": 0.1595,
            "eval_samples_per_second": 6538.115,
            "eval_steps_per_second": 56.417,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4405,
            "grad_norm": 3.881253480911255,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.9656974077224731,
            "eval_matthews_correlation": 0.5573424050983508,
            "eval_runtime": 0.1609,
            "eval_samples_per_second": 6484.098,
            "eval_steps_per_second": 55.951,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4291,
            "grad_norm": 3.837156295776367,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.8585491180419922,
            "eval_matthews_correlation": 0.5884139541276108,
            "eval_runtime": 0.1629,
            "eval_samples_per_second": 6401.297,
            "eval_steps_per_second": 55.237,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.406,
            "grad_norm": 4.861401081085205,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.913132667541504,
            "eval_matthews_correlation": 0.5706355604450147,
            "eval_runtime": 0.1617,
            "eval_samples_per_second": 6451.519,
            "eval_steps_per_second": 55.67,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.3942,
            "grad_norm": 6.481387138366699,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.9830996990203857,
            "eval_matthews_correlation": 0.5779181076197502,
            "eval_runtime": 0.1574,
            "eval_samples_per_second": 6624.598,
            "eval_steps_per_second": 57.163,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.3855,
            "grad_norm": 4.201971054077148,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.8930598497390747,
            "eval_matthews_correlation": 0.5941395545037332,
            "eval_runtime": 0.1601,
            "eval_samples_per_second": 6513.457,
            "eval_steps_per_second": 56.204,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.3814,
            "grad_norm": 3.5408122539520264,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.893632173538208,
            "eval_matthews_correlation": 0.5936351080219947,
            "eval_runtime": 0.1403,
            "eval_samples_per_second": 7434.485,
            "eval_steps_per_second": 64.152,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.3644,
            "grad_norm": 4.312115669250488,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.951189637184143,
            "eval_matthews_correlation": 0.5981951351808346,
            "eval_runtime": 0.1591,
            "eval_samples_per_second": 6556.871,
            "eval_steps_per_second": 56.579,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.3653,
            "grad_norm": 5.60118293762207,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.924986481666565,
            "eval_matthews_correlation": 0.593197037544882,
            "eval_runtime": 0.157,
            "eval_samples_per_second": 6642.17,
            "eval_steps_per_second": 57.315,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.3487,
            "grad_norm": 8.81831169128418,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 2.014586925506592,
            "eval_matthews_correlation": 0.5933815828411364,
            "eval_runtime": 0.159,
            "eval_samples_per_second": 6561.808,
            "eval_steps_per_second": 56.622,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.3497,
            "grad_norm": 3.489692211151123,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.9901187419891357,
            "eval_matthews_correlation": 0.5957317644481708,
            "eval_runtime": 0.1593,
            "eval_samples_per_second": 6549.146,
            "eval_steps_per_second": 56.512,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.3448,
            "grad_norm": 4.755664825439453,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.9824258089065552,
            "eval_matthews_correlation": 0.583024886611504,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6528.747,
            "eval_steps_per_second": 56.336,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.3452,
            "grad_norm": 5.8611626625061035,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 2.0010175704956055,
            "eval_matthews_correlation": 0.5829211024374039,
            "eval_runtime": 0.161,
            "eval_samples_per_second": 6479.508,
            "eval_steps_per_second": 55.911,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 215.8739,
            "train_samples_per_second": 3961.109,
            "train_steps_per_second": 31.037,
            "total_flos": 2.0695972615028736e+16,
            "train_loss": 0.5144393507639567,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.951189637184143,
            "eval_matthews_correlation": 0.5981951351808346,
            "eval_runtime": 0.1589,
            "eval_samples_per_second": 6565.757,
            "eval_steps_per_second": 56.656,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 215.8739,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}