{
    "eval_loss": 1.889599084854126,
    "eval_matthews_correlation": 0.5839395532441031,
    "eval_runtime": 0.1609,
    "eval_samples_per_second": 6483.82,
    "eval_steps_per_second": 55.949,
    "epoch": 74.6268656716418,
    "log_history": [
        {
            "loss": 1.106,
            "grad_norm": 1.3334689140319824,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.0794373750686646,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1626,
            "eval_samples_per_second": 6412.942,
            "eval_steps_per_second": 55.337,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.8733,
            "grad_norm": 2.3631014823913574,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.3582854270935059,
            "eval_matthews_correlation": 0.4467807407096838,
            "eval_runtime": 0.1597,
            "eval_samples_per_second": 6532.774,
            "eval_steps_per_second": 56.371,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.7698,
            "grad_norm": 2.8161654472351074,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.370039463043213,
            "eval_matthews_correlation": 0.4509257189091659,
            "eval_runtime": 0.1632,
            "eval_samples_per_second": 6391.113,
            "eval_steps_per_second": 55.149,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.717,
            "grad_norm": 3.413025379180908,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.4093146324157715,
            "eval_matthews_correlation": 0.5202921584818164,
            "eval_runtime": 0.1636,
            "eval_samples_per_second": 6375.177,
            "eval_steps_per_second": 55.011,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.6817,
            "grad_norm": 5.680644512176514,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.4984664916992188,
            "eval_matthews_correlation": 0.5377587696044389,
            "eval_runtime": 0.1587,
            "eval_samples_per_second": 6573.611,
            "eval_steps_per_second": 56.723,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6562,
            "grad_norm": 4.711909294128418,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.463465690612793,
            "eval_matthews_correlation": 0.5578317381927368,
            "eval_runtime": 0.1586,
            "eval_samples_per_second": 6576.585,
            "eval_steps_per_second": 56.749,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6238,
            "grad_norm": 3.0198891162872314,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.649989128112793,
            "eval_matthews_correlation": 0.5494767866076017,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 6520.408,
            "eval_steps_per_second": 56.264,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.5919,
            "grad_norm": 4.645884990692139,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.7303179502487183,
            "eval_matthews_correlation": 0.5153691855191354,
            "eval_runtime": 0.1604,
            "eval_samples_per_second": 6502.575,
            "eval_steps_per_second": 56.11,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5791,
            "grad_norm": 3.7089555263519287,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.7078983783721924,
            "eval_matthews_correlation": 0.5495093920893817,
            "eval_runtime": 0.1572,
            "eval_samples_per_second": 6635.228,
            "eval_steps_per_second": 57.255,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.5569,
            "grad_norm": 3.9885385036468506,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.6348178386688232,
            "eval_matthews_correlation": 0.5627810283916928,
            "eval_runtime": 0.1566,
            "eval_samples_per_second": 6661.447,
            "eval_steps_per_second": 57.481,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.5403,
            "grad_norm": 5.073540687561035,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.7484729290008545,
            "eval_matthews_correlation": 0.5651604238862242,
            "eval_runtime": 0.1624,
            "eval_samples_per_second": 6422.018,
            "eval_steps_per_second": 55.415,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.5249,
            "grad_norm": 3.1737353801727295,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.8127222061157227,
            "eval_matthews_correlation": 0.5627810283916928,
            "eval_runtime": 0.1577,
            "eval_samples_per_second": 6612.312,
            "eval_steps_per_second": 57.057,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5002,
            "grad_norm": 3.6668055057525635,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.832383394241333,
            "eval_matthews_correlation": 0.5551439282323715,
            "eval_runtime": 0.1601,
            "eval_samples_per_second": 6515.746,
            "eval_steps_per_second": 56.224,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4995,
            "grad_norm": 3.8783631324768066,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.8274693489074707,
            "eval_matthews_correlation": 0.5738826222928127,
            "eval_runtime": 0.1579,
            "eval_samples_per_second": 6605.742,
            "eval_steps_per_second": 57.001,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4817,
            "grad_norm": 4.055394172668457,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.8507112264633179,
            "eval_matthews_correlation": 0.5656296906477638,
            "eval_runtime": 0.1585,
            "eval_samples_per_second": 6579.315,
            "eval_steps_per_second": 56.773,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.4745,
            "grad_norm": 4.518909454345703,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.9062886238098145,
            "eval_matthews_correlation": 0.5554433905906734,
            "eval_runtime": 0.1605,
            "eval_samples_per_second": 6497.292,
            "eval_steps_per_second": 56.065,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.4574,
            "grad_norm": 4.471468925476074,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.7913144826889038,
            "eval_matthews_correlation": 0.5827865839334545,
            "eval_runtime": 0.1614,
            "eval_samples_per_second": 6462.069,
            "eval_steps_per_second": 55.761,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.4461,
            "grad_norm": 7.968841552734375,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.8896868228912354,
            "eval_matthews_correlation": 0.5606238208505129,
            "eval_runtime": 0.1576,
            "eval_samples_per_second": 6618.164,
            "eval_steps_per_second": 57.108,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.4419,
            "grad_norm": 4.103618144989014,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.8947761058807373,
            "eval_matthews_correlation": 0.5784786967005595,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 6519.456,
            "eval_steps_per_second": 56.256,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.4334,
            "grad_norm": 4.820352077484131,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.889599084854126,
            "eval_matthews_correlation": 0.5839395532441031,
            "eval_runtime": 0.1575,
            "eval_samples_per_second": 6623.324,
            "eval_steps_per_second": 57.152,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.4254,
            "grad_norm": 10.298043251037598,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.920912742614746,
            "eval_matthews_correlation": 0.5813817583744711,
            "eval_runtime": 0.1601,
            "eval_samples_per_second": 6514.388,
            "eval_steps_per_second": 56.212,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.4281,
            "grad_norm": 3.772016763687134,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.942442774772644,
            "eval_matthews_correlation": 0.5626727648075698,
            "eval_runtime": 0.1616,
            "eval_samples_per_second": 6454.375,
            "eval_steps_per_second": 55.695,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.4175,
            "grad_norm": 4.733699321746826,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.9368953704833984,
            "eval_matthews_correlation": 0.5834463254140851,
            "eval_runtime": 0.1573,
            "eval_samples_per_second": 6630.743,
            "eval_steps_per_second": 57.216,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.4166,
            "grad_norm": 5.55374002456665,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.9644975662231445,
            "eval_matthews_correlation": 0.5735110679870338,
            "eval_runtime": 0.158,
            "eval_samples_per_second": 6603.179,
            "eval_steps_per_second": 56.979,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.4031,
            "grad_norm": 9.282369613647461,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 1.974497675895691,
            "eval_matthews_correlation": 0.5834463254140851,
            "eval_runtime": 0.1647,
            "eval_samples_per_second": 6331.286,
            "eval_steps_per_second": 54.632,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "train_runtime": 227.6213,
            "train_samples_per_second": 3756.678,
            "train_steps_per_second": 29.435,
            "total_flos": 2.15583048073216e+16,
            "train_loss": 0.5618455123901367,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 1.889599084854126,
            "eval_matthews_correlation": 0.5839395532441031,
            "eval_runtime": 0.1609,
            "eval_samples_per_second": 6483.82,
            "eval_steps_per_second": 55.949,
            "epoch": 74.6268656716418,
            "step": 5000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 227.6213,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088,
            359.513088
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}