{
    "eval_loss": 3.3221852779388428,
    "eval_matthews_correlation": 0.6606471098852346,
    "eval_runtime": 0.2802,
    "eval_samples_per_second": 3721.895,
    "eval_steps_per_second": 32.116,
    "epoch": 80.59701492537313,
    "log_history": [
        {
            "loss": 1.5837,
            "grad_norm": 0.8150269985198975,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5270209312438965,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2888,
            "eval_samples_per_second": 3611.52,
            "eval_steps_per_second": 31.164,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4274,
            "grad_norm": 1.8170334100723267,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6306519508361816,
            "eval_matthews_correlation": 0.39950616612594125,
            "eval_runtime": 0.333,
            "eval_samples_per_second": 3131.695,
            "eval_steps_per_second": 27.023,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0768,
            "grad_norm": 2.623420238494873,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9881609678268433,
            "eval_matthews_correlation": 0.5029926075993093,
            "eval_runtime": 0.2776,
            "eval_samples_per_second": 3757.456,
            "eval_steps_per_second": 32.423,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.97,
            "grad_norm": 1.6194067001342773,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.176002025604248,
            "eval_matthews_correlation": 0.5367820334111587,
            "eval_runtime": 0.2808,
            "eval_samples_per_second": 3714.49,
            "eval_steps_per_second": 32.052,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9022,
            "grad_norm": 2.0824954509735107,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.2056429386138916,
            "eval_matthews_correlation": 0.5727969336224868,
            "eval_runtime": 0.2736,
            "eval_samples_per_second": 3812.821,
            "eval_steps_per_second": 32.901,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8418,
            "grad_norm": 2.193272829055786,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.432673454284668,
            "eval_matthews_correlation": 0.5829638006957694,
            "eval_runtime": 0.2837,
            "eval_samples_per_second": 3676.4,
            "eval_steps_per_second": 31.723,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8061,
            "grad_norm": 2.6802613735198975,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.713148593902588,
            "eval_matthews_correlation": 0.6009540363352786,
            "eval_runtime": 0.2888,
            "eval_samples_per_second": 3612.089,
            "eval_steps_per_second": 31.169,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.784,
            "grad_norm": 2.7741057872772217,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.5317885875701904,
            "eval_matthews_correlation": 0.6115083173955205,
            "eval_runtime": 0.2825,
            "eval_samples_per_second": 3692.01,
            "eval_steps_per_second": 31.858,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7468,
            "grad_norm": 2.1467576026916504,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.5563178062438965,
            "eval_matthews_correlation": 0.60819133045274,
            "eval_runtime": 0.3296,
            "eval_samples_per_second": 3164.033,
            "eval_steps_per_second": 27.302,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7061,
            "grad_norm": 2.514240264892578,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.7701430320739746,
            "eval_matthews_correlation": 0.6209103735772308,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 3693.023,
            "eval_steps_per_second": 31.867,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6913,
            "grad_norm": 2.214211940765381,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.8409736156463623,
            "eval_matthews_correlation": 0.6146094301507191,
            "eval_runtime": 0.2834,
            "eval_samples_per_second": 3680.619,
            "eval_steps_per_second": 31.76,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6637,
            "grad_norm": 2.573352813720703,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.96939754486084,
            "eval_matthews_correlation": 0.6158979909555603,
            "eval_runtime": 0.2785,
            "eval_samples_per_second": 3744.53,
            "eval_steps_per_second": 32.311,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6565,
            "grad_norm": 3.3451247215270996,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.9316458702087402,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.2841,
            "eval_samples_per_second": 3671.769,
            "eval_steps_per_second": 31.684,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6244,
            "grad_norm": 2.26470947265625,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 3.0665934085845947,
            "eval_matthews_correlation": 0.6206942584175241,
            "eval_runtime": 0.281,
            "eval_samples_per_second": 3712.362,
            "eval_steps_per_second": 32.034,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.5968,
            "grad_norm": 2.951988458633423,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 3.096881151199341,
            "eval_matthews_correlation": 0.6283219912268083,
            "eval_runtime": 0.2833,
            "eval_samples_per_second": 3682.14,
            "eval_steps_per_second": 31.773,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.5964,
            "grad_norm": 4.519444465637207,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.103133201599121,
            "eval_matthews_correlation": 0.6457161787575496,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 3693.004,
            "eval_steps_per_second": 31.867,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5828,
            "grad_norm": 2.699218273162842,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.0954971313476562,
            "eval_matthews_correlation": 0.6409676231335113,
            "eval_runtime": 0.2932,
            "eval_samples_per_second": 3557.802,
            "eval_steps_per_second": 30.7,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5677,
            "grad_norm": 2.3737025260925293,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.167681932449341,
            "eval_matthews_correlation": 0.6342890666845706,
            "eval_runtime": 0.2816,
            "eval_samples_per_second": 3704.309,
            "eval_steps_per_second": 31.964,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5538,
            "grad_norm": 3.310429334640503,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 3.2341742515563965,
            "eval_matthews_correlation": 0.6480399678091215,
            "eval_runtime": 0.2785,
            "eval_samples_per_second": 3744.68,
            "eval_steps_per_second": 32.313,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5559,
            "grad_norm": 3.2604970932006836,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 3.188472270965576,
            "eval_matthews_correlation": 0.6532412821196949,
            "eval_runtime": 0.2778,
            "eval_samples_per_second": 3754.118,
            "eval_steps_per_second": 32.394,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.541,
            "grad_norm": 3.032397508621216,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 3.2680323123931885,
            "eval_matthews_correlation": 0.6506644630001874,
            "eval_runtime": 0.2827,
            "eval_samples_per_second": 3689.304,
            "eval_steps_per_second": 31.835,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5234,
            "grad_norm": 3.1356523036956787,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.3221852779388428,
            "eval_matthews_correlation": 0.6606471098852346,
            "eval_runtime": 0.2815,
            "eval_samples_per_second": 3705.702,
            "eval_steps_per_second": 31.976,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.5173,
            "grad_norm": 4.610592365264893,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.3173489570617676,
            "eval_matthews_correlation": 0.6482766090658513,
            "eval_runtime": 0.2846,
            "eval_samples_per_second": 3664.415,
            "eval_steps_per_second": 31.62,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5035,
            "grad_norm": 3.7256360054016113,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.338151454925537,
            "eval_matthews_correlation": 0.6479876361505273,
            "eval_runtime": 0.2842,
            "eval_samples_per_second": 3669.945,
            "eval_steps_per_second": 31.668,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.508,
            "grad_norm": 3.8099164962768555,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 3.3393869400024414,
            "eval_matthews_correlation": 0.6536603298693585,
            "eval_runtime": 0.2872,
            "eval_samples_per_second": 3631.911,
            "eval_steps_per_second": 31.34,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.4917,
            "grad_norm": 2.4237093925476074,
            "learning_rate": 2.4875621890547266e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 3.3711488246917725,
            "eval_matthews_correlation": 0.6484123006235729,
            "eval_runtime": 0.284,
            "eval_samples_per_second": 3671.904,
            "eval_steps_per_second": 31.685,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.5007,
            "grad_norm": 2.518824338912964,
            "learning_rate": 2.155887230514096e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 3.38376522064209,
            "eval_matthews_correlation": 0.6532412821196949,
            "eval_runtime": 0.2809,
            "eval_samples_per_second": 3713.667,
            "eval_steps_per_second": 32.045,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "train_runtime": 374.9027,
            "train_samples_per_second": 2280.859,
            "train_steps_per_second": 17.871,
            "total_flos": 2.305344177753293e+16,
            "train_loss": 0.7229539772316261,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 3.3221852779388428,
            "eval_matthews_correlation": 0.6606471098852346,
            "eval_runtime": 0.2802,
            "eval_samples_per_second": 3721.895,
            "eval_steps_per_second": 32.116,
            "epoch": 80.59701492537313,
            "step": 5400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 374.9027,
        "trainable_params_count": 0.305666,
        "memory_allocated": [
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008,
            591.531008
        ],
        "memory_reserved": [
            2850.029568,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672,
            2852.12672
        ]
    },
    "variant": "kd-lora"
}