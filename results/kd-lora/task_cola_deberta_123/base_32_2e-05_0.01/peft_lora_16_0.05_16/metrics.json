{
    "eval_loss": 3.3051891326904297,
    "eval_matthews_correlation": 0.665357196937062,
    "eval_runtime": 0.23,
    "eval_samples_per_second": 4534.698,
    "eval_steps_per_second": 39.13,
    "epoch": 80.59701492537313,
    "log_history": [
        {
            "loss": 1.5838,
            "grad_norm": 0.8167861104011536,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5269948244094849,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.23,
            "eval_samples_per_second": 4534.543,
            "eval_steps_per_second": 39.128,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4291,
            "grad_norm": 1.7945393323898315,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6253693103790283,
            "eval_matthews_correlation": 0.3964537186866496,
            "eval_runtime": 0.2275,
            "eval_samples_per_second": 4584.251,
            "eval_steps_per_second": 39.557,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0788,
            "grad_norm": 2.636491298675537,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9864153861999512,
            "eval_matthews_correlation": 0.5027729325169469,
            "eval_runtime": 0.2261,
            "eval_samples_per_second": 4613.189,
            "eval_steps_per_second": 39.807,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9722,
            "grad_norm": 1.6091419458389282,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.17362904548645,
            "eval_matthews_correlation": 0.5367820334111587,
            "eval_runtime": 0.2254,
            "eval_samples_per_second": 4627.609,
            "eval_steps_per_second": 39.931,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9049,
            "grad_norm": 2.056058645248413,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.2007927894592285,
            "eval_matthews_correlation": 0.5803450615832939,
            "eval_runtime": 0.2265,
            "eval_samples_per_second": 4604.211,
            "eval_steps_per_second": 39.73,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8444,
            "grad_norm": 2.1917896270751953,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.430082082748413,
            "eval_matthews_correlation": 0.582897151722857,
            "eval_runtime": 0.2656,
            "eval_samples_per_second": 3927.223,
            "eval_steps_per_second": 33.888,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8096,
            "grad_norm": 2.672839641571045,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.7104718685150146,
            "eval_matthews_correlation": 0.5984412364639732,
            "eval_runtime": 0.234,
            "eval_samples_per_second": 4457.583,
            "eval_steps_per_second": 38.464,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7873,
            "grad_norm": 2.8192410469055176,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.5276570320129395,
            "eval_matthews_correlation": 0.6066332644639029,
            "eval_runtime": 0.2278,
            "eval_samples_per_second": 4578.762,
            "eval_steps_per_second": 39.51,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7511,
            "grad_norm": 2.1376659870147705,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.545276641845703,
            "eval_matthews_correlation": 0.60819133045274,
            "eval_runtime": 0.232,
            "eval_samples_per_second": 4496.14,
            "eval_steps_per_second": 38.797,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7103,
            "grad_norm": 2.5373759269714355,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.7655029296875,
            "eval_matthews_correlation": 0.6209103735772308,
            "eval_runtime": 0.2616,
            "eval_samples_per_second": 3986.763,
            "eval_steps_per_second": 34.402,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6953,
            "grad_norm": 2.1820929050445557,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.836294174194336,
            "eval_matthews_correlation": 0.6190614534394121,
            "eval_runtime": 0.227,
            "eval_samples_per_second": 4595.529,
            "eval_steps_per_second": 39.655,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6683,
            "grad_norm": 2.627739429473877,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.9585349559783936,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.2255,
            "eval_samples_per_second": 4625.779,
            "eval_steps_per_second": 39.916,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6615,
            "grad_norm": 3.2975916862487793,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.920999526977539,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.3251,
            "eval_samples_per_second": 3208.002,
            "eval_steps_per_second": 27.682,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6297,
            "grad_norm": 2.2729740142822266,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 3.0564064979553223,
            "eval_matthews_correlation": 0.623185623360598,
            "eval_runtime": 0.2245,
            "eval_samples_per_second": 4645.792,
            "eval_steps_per_second": 40.088,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.602,
            "grad_norm": 2.942734718322754,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 3.085235834121704,
            "eval_matthews_correlation": 0.6284086224320302,
            "eval_runtime": 0.2644,
            "eval_samples_per_second": 3944.738,
            "eval_steps_per_second": 34.039,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.6024,
            "grad_norm": 4.456881999969482,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.092970848083496,
            "eval_matthews_correlation": 0.6383702690280213,
            "eval_runtime": 0.228,
            "eval_samples_per_second": 4574.73,
            "eval_steps_per_second": 39.475,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5882,
            "grad_norm": 2.7559163570404053,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.0816447734832764,
            "eval_matthews_correlation": 0.6384814558737449,
            "eval_runtime": 0.2252,
            "eval_samples_per_second": 4630.808,
            "eval_steps_per_second": 39.959,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5735,
            "grad_norm": 2.2838807106018066,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.1544032096862793,
            "eval_matthews_correlation": 0.6417812098009434,
            "eval_runtime": 0.2282,
            "eval_samples_per_second": 4570.696,
            "eval_steps_per_second": 39.44,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5596,
            "grad_norm": 3.3160810470581055,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 3.219581365585327,
            "eval_matthews_correlation": 0.6430953658298718,
            "eval_runtime": 0.2228,
            "eval_samples_per_second": 4680.537,
            "eval_steps_per_second": 40.388,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.562,
            "grad_norm": 3.237924098968506,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 3.1763274669647217,
            "eval_matthews_correlation": 0.6532412821196949,
            "eval_runtime": 0.2291,
            "eval_samples_per_second": 4551.811,
            "eval_steps_per_second": 39.277,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5473,
            "grad_norm": 3.0067431926727295,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 3.2479617595672607,
            "eval_matthews_correlation": 0.6481914570909114,
            "eval_runtime": 0.2236,
            "eval_samples_per_second": 4665.308,
            "eval_steps_per_second": 40.257,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5292,
            "grad_norm": 3.0592167377471924,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.3051891326904297,
            "eval_matthews_correlation": 0.665357196937062,
            "eval_runtime": 0.2678,
            "eval_samples_per_second": 3894.266,
            "eval_steps_per_second": 33.603,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.523,
            "grad_norm": 4.7429046630859375,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.305279493331909,
            "eval_matthews_correlation": 0.6454879429067257,
            "eval_runtime": 0.2267,
            "eval_samples_per_second": 4599.84,
            "eval_steps_per_second": 39.692,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5101,
            "grad_norm": 3.642338514328003,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.3237791061401367,
            "eval_matthews_correlation": 0.6546803561335549,
            "eval_runtime": 0.2295,
            "eval_samples_per_second": 4545.525,
            "eval_steps_per_second": 39.223,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.5142,
            "grad_norm": 3.8184974193573,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 3.3236424922943115,
            "eval_matthews_correlation": 0.6511813794482872,
            "eval_runtime": 0.2283,
            "eval_samples_per_second": 4567.842,
            "eval_steps_per_second": 39.416,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.4981,
            "grad_norm": 2.442596912384033,
            "learning_rate": 2.4875621890547266e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 3.353654384613037,
            "eval_matthews_correlation": 0.6508893919542889,
            "eval_runtime": 0.23,
            "eval_samples_per_second": 4535.224,
            "eval_steps_per_second": 39.134,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.5078,
            "grad_norm": 2.443721055984497,
            "learning_rate": 2.155887230514096e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 3.368823289871216,
            "eval_matthews_correlation": 0.6580702636158169,
            "eval_runtime": 0.2289,
            "eval_samples_per_second": 4556.049,
            "eval_steps_per_second": 39.314,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "train_runtime": 336.8167,
            "train_samples_per_second": 2538.77,
            "train_steps_per_second": 19.892,
            "total_flos": 2.304854954134733e+16,
            "train_loss": 0.7275564363267687,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 3.3051891326904297,
            "eval_matthews_correlation": 0.665357196937062,
            "eval_runtime": 0.23,
            "eval_samples_per_second": 4534.698,
            "eval_steps_per_second": 39.13,
            "epoch": 80.59701492537313,
            "step": 5400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 336.8167,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512
        ],
        "memory_reserved": [
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216
        ]
    },
    "variant": "kd-lora"
}