{
    "eval_loss": 3.0271408557891846,
    "eval_matthews_correlation": 0.6454879429067257,
    "eval_runtime": 0.2863,
    "eval_samples_per_second": 3642.741,
    "eval_steps_per_second": 31.433,
    "epoch": 47.76119402985075,
    "log_history": [
        {
            "loss": 1.5803,
            "grad_norm": 0.8369014859199524,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.516282558441162,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3048,
            "eval_samples_per_second": 3421.744,
            "eval_steps_per_second": 29.526,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3013,
            "grad_norm": 1.8504635095596313,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.8767774105072021,
            "eval_matthews_correlation": 0.4967522429154307,
            "eval_runtime": 0.2993,
            "eval_samples_per_second": 3484.393,
            "eval_steps_per_second": 30.067,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.012,
            "grad_norm": 1.535439372062683,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.075113296508789,
            "eval_matthews_correlation": 0.5598743897878832,
            "eval_runtime": 0.2897,
            "eval_samples_per_second": 3600.519,
            "eval_steps_per_second": 31.069,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9168,
            "grad_norm": 2.7944400310516357,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.346461296081543,
            "eval_matthews_correlation": 0.567550266689718,
            "eval_runtime": 0.3229,
            "eval_samples_per_second": 3229.61,
            "eval_steps_per_second": 27.868,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8356,
            "grad_norm": 2.7399749755859375,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.471346855163574,
            "eval_matthews_correlation": 0.5726807034874348,
            "eval_runtime": 0.2916,
            "eval_samples_per_second": 3576.628,
            "eval_steps_per_second": 30.863,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.7704,
            "grad_norm": 2.360496997833252,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.495060682296753,
            "eval_matthews_correlation": 0.5876475728279335,
            "eval_runtime": 0.3393,
            "eval_samples_per_second": 3074.177,
            "eval_steps_per_second": 26.527,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.7201,
            "grad_norm": 4.745460033416748,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.648369073867798,
            "eval_matthews_correlation": 0.610638611987945,
            "eval_runtime": 0.288,
            "eval_samples_per_second": 3621.688,
            "eval_steps_per_second": 31.251,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.6798,
            "grad_norm": 2.1696512699127197,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.7617506980895996,
            "eval_matthews_correlation": 0.6086838399461341,
            "eval_runtime": 0.2927,
            "eval_samples_per_second": 3563.671,
            "eval_steps_per_second": 30.751,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.6331,
            "grad_norm": 4.532663822174072,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.9291136264801025,
            "eval_matthews_correlation": 0.6324452383009407,
            "eval_runtime": 0.2894,
            "eval_samples_per_second": 3603.859,
            "eval_steps_per_second": 31.098,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.6111,
            "grad_norm": 2.539848804473877,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.953474760055542,
            "eval_matthews_correlation": 0.6311312807330612,
            "eval_runtime": 0.3279,
            "eval_samples_per_second": 3180.985,
            "eval_steps_per_second": 27.449,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.5786,
            "grad_norm": 2.845431089401245,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 3.0271408557891846,
            "eval_matthews_correlation": 0.6454879429067257,
            "eval_runtime": 0.3398,
            "eval_samples_per_second": 3069.656,
            "eval_steps_per_second": 26.488,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.5444,
            "grad_norm": 4.309682846069336,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 3.173018217086792,
            "eval_matthews_correlation": 0.6344946115340342,
            "eval_runtime": 0.2906,
            "eval_samples_per_second": 3588.969,
            "eval_steps_per_second": 30.969,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5331,
            "grad_norm": 4.583512783050537,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 3.187892198562622,
            "eval_matthews_correlation": 0.6260141184396594,
            "eval_runtime": 0.2869,
            "eval_samples_per_second": 3634.896,
            "eval_steps_per_second": 31.365,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.5079,
            "grad_norm": 2.5393660068511963,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 3.2696011066436768,
            "eval_matthews_correlation": 0.6235130412994164,
            "eval_runtime": 0.3388,
            "eval_samples_per_second": 3078.366,
            "eval_steps_per_second": 26.563,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4827,
            "grad_norm": 2.4337806701660156,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 3.31838059425354,
            "eval_matthews_correlation": 0.6262696480582318,
            "eval_runtime": 0.2872,
            "eval_samples_per_second": 3631.809,
            "eval_steps_per_second": 31.339,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.466,
            "grad_norm": 2.2523412704467773,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.3498761653900146,
            "eval_matthews_correlation": 0.6361192032001732,
            "eval_runtime": 0.2869,
            "eval_samples_per_second": 3635.826,
            "eval_steps_per_second": 31.373,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "train_runtime": 240.2841,
            "train_samples_per_second": 3558.704,
            "train_steps_per_second": 27.884,
            "total_flos": 1.3754070124724224e+16,
            "train_loss": 0.7608385705947875,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 3.0271408557891846,
            "eval_matthews_correlation": 0.6454879429067257,
            "eval_runtime": 0.2863,
            "eval_samples_per_second": 3642.741,
            "eval_steps_per_second": 31.433,
            "epoch": 47.76119402985075,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 240.2841,
        "trainable_params_count": 0.600578,
        "memory_allocated": [
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208,
            596.702208
        ],
        "memory_reserved": [
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552
        ]
    },
    "variant": "kd-lora"
}