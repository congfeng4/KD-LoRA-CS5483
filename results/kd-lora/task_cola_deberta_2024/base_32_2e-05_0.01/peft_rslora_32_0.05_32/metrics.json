{
    "eval_loss": 4.2102766036987305,
    "eval_matthews_correlation": 0.6685420830421551,
    "eval_runtime": 0.266,
    "eval_samples_per_second": 3920.852,
    "eval_steps_per_second": 33.833,
    "epoch": 56.71641791044776,
    "log_history": [
        {
            "loss": 1.5623,
            "grad_norm": 0.599361777305603,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5164110660552979,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2286,
            "eval_samples_per_second": 4563.311,
            "eval_steps_per_second": 39.377,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.128,
            "grad_norm": 4.835723400115967,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.9551788568496704,
            "eval_matthews_correlation": 0.5258978858175564,
            "eval_runtime": 0.2684,
            "eval_samples_per_second": 3886.458,
            "eval_steps_per_second": 33.536,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.9253,
            "grad_norm": 3.8507566452026367,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.1943295001983643,
            "eval_matthews_correlation": 0.5702308058201745,
            "eval_runtime": 0.2325,
            "eval_samples_per_second": 4485.574,
            "eval_steps_per_second": 38.706,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.7884,
            "grad_norm": 4.520050048828125,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.542215585708618,
            "eval_matthews_correlation": 0.5729657494988228,
            "eval_runtime": 0.2722,
            "eval_samples_per_second": 3831.411,
            "eval_steps_per_second": 33.061,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.6677,
            "grad_norm": 5.9704484939575195,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.6097288131713867,
            "eval_matthews_correlation": 0.6100178805092891,
            "eval_runtime": 0.2409,
            "eval_samples_per_second": 4329.112,
            "eval_steps_per_second": 37.356,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.5579,
            "grad_norm": 7.639875888824463,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.8666014671325684,
            "eval_matthews_correlation": 0.6432718914115204,
            "eval_runtime": 0.2318,
            "eval_samples_per_second": 4499.636,
            "eval_steps_per_second": 38.827,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.4737,
            "grad_norm": 8.6154146194458,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 3.214444875717163,
            "eval_matthews_correlation": 0.629703181950203,
            "eval_runtime": 0.2674,
            "eval_samples_per_second": 3900.468,
            "eval_steps_per_second": 33.657,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.409,
            "grad_norm": 7.400815963745117,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 3.37105393409729,
            "eval_matthews_correlation": 0.6354693809543039,
            "eval_runtime": 0.2702,
            "eval_samples_per_second": 3860.71,
            "eval_steps_per_second": 33.314,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.3404,
            "grad_norm": 6.658377647399902,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 3.5945284366607666,
            "eval_matthews_correlation": 0.6374564262486978,
            "eval_runtime": 0.2691,
            "eval_samples_per_second": 3875.282,
            "eval_steps_per_second": 33.44,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.3145,
            "grad_norm": 8.95659065246582,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 3.6189956665039062,
            "eval_matthews_correlation": 0.6510812244905186,
            "eval_runtime": 0.2659,
            "eval_samples_per_second": 3921.797,
            "eval_steps_per_second": 33.841,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2767,
            "grad_norm": 8.501770973205566,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 3.7853145599365234,
            "eval_matthews_correlation": 0.6521917905809458,
            "eval_runtime": 0.2668,
            "eval_samples_per_second": 3909.642,
            "eval_steps_per_second": 33.736,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.2486,
            "grad_norm": 11.66240119934082,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 4.000809192657471,
            "eval_matthews_correlation": 0.6536038619874603,
            "eval_runtime": 0.2286,
            "eval_samples_per_second": 4562.749,
            "eval_steps_per_second": 39.372,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.2286,
            "grad_norm": 7.251030921936035,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 4.029820919036865,
            "eval_matthews_correlation": 0.6359929134078908,
            "eval_runtime": 0.2304,
            "eval_samples_per_second": 4526.44,
            "eval_steps_per_second": 39.058,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.199,
            "grad_norm": 9.005861282348633,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 4.2102766036987305,
            "eval_matthews_correlation": 0.6685420830421551,
            "eval_runtime": 0.2259,
            "eval_samples_per_second": 4616.1,
            "eval_steps_per_second": 39.832,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1733,
            "grad_norm": 4.004824638366699,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 4.200157165527344,
            "eval_matthews_correlation": 0.6456336879168435,
            "eval_runtime": 0.2269,
            "eval_samples_per_second": 4596.65,
            "eval_steps_per_second": 39.664,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1577,
            "grad_norm": 1.7601202726364136,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 4.362234115600586,
            "eval_matthews_correlation": 0.6402133529850765,
            "eval_runtime": 0.277,
            "eval_samples_per_second": 3765.794,
            "eval_steps_per_second": 32.495,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1577,
            "grad_norm": 7.510593414306641,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 4.341944694519043,
            "eval_matthews_correlation": 0.6427206956430619,
            "eval_runtime": 0.2312,
            "eval_samples_per_second": 4511.87,
            "eval_steps_per_second": 38.933,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1383,
            "grad_norm": 5.365565776824951,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 4.320043563842773,
            "eval_matthews_correlation": 0.661735756420702,
            "eval_runtime": 0.2322,
            "eval_samples_per_second": 4491.008,
            "eval_steps_per_second": 38.753,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.1342,
            "grad_norm": 6.315692901611328,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 4.347043514251709,
            "eval_matthews_correlation": 0.6590429725668736,
            "eval_runtime": 0.283,
            "eval_samples_per_second": 3686.043,
            "eval_steps_per_second": 31.807,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "train_runtime": 251.0255,
            "train_samples_per_second": 3406.427,
            "train_steps_per_second": 26.691,
            "total_flos": 1.6329515588386816e+16,
            "train_loss": 0.4674431474585282,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 4.2102766036987305,
            "eval_matthews_correlation": 0.6685420830421551,
            "eval_runtime": 0.266,
            "eval_samples_per_second": 3920.852,
            "eval_steps_per_second": 33.833,
            "epoch": 56.71641791044776,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 32,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 251.0255,
        "trainable_params_count": 0.591362,
        "memory_allocated": [
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848,
            596.62848
        ],
        "memory_reserved": [
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584
        ]
    },
    "variant": "kd-lora"
}