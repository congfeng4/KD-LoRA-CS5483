{
    "eval_loss": 3.300567388534546,
    "eval_matthews_correlation": 0.63678867391954,
    "eval_runtime": 0.2288,
    "eval_samples_per_second": 4558.846,
    "eval_steps_per_second": 39.338,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 1.5823,
            "grad_norm": 0.9624894261360168,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5165578126907349,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2213,
            "eval_samples_per_second": 4712.955,
            "eval_steps_per_second": 40.668,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3997,
            "grad_norm": 1.882285237312317,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.618066668510437,
            "eval_matthews_correlation": 0.42241607930644726,
            "eval_runtime": 0.2318,
            "eval_samples_per_second": 4500.4,
            "eval_steps_per_second": 38.834,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0658,
            "grad_norm": 2.0302484035491943,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9826573133468628,
            "eval_matthews_correlation": 0.523253926058104,
            "eval_runtime": 0.2681,
            "eval_samples_per_second": 3890.069,
            "eval_steps_per_second": 33.567,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9665,
            "grad_norm": 3.985592842102051,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.212672472000122,
            "eval_matthews_correlation": 0.5521069582827846,
            "eval_runtime": 0.225,
            "eval_samples_per_second": 4636.044,
            "eval_steps_per_second": 40.004,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8981,
            "grad_norm": 3.1037099361419678,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.313042640686035,
            "eval_matthews_correlation": 0.5731072389988161,
            "eval_runtime": 0.2642,
            "eval_samples_per_second": 3948.002,
            "eval_steps_per_second": 34.067,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8458,
            "grad_norm": 3.664564609527588,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.3180770874023438,
            "eval_matthews_correlation": 0.5981172563866908,
            "eval_runtime": 0.2606,
            "eval_samples_per_second": 4001.558,
            "eval_steps_per_second": 34.529,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8075,
            "grad_norm": 4.553526401519775,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.4428040981292725,
            "eval_matthews_correlation": 0.606823117358914,
            "eval_runtime": 0.2293,
            "eval_samples_per_second": 4547.926,
            "eval_steps_per_second": 39.244,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7664,
            "grad_norm": 2.8285207748413086,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.582618236541748,
            "eval_matthews_correlation": 0.5963273779713936,
            "eval_runtime": 0.2298,
            "eval_samples_per_second": 4539.309,
            "eval_steps_per_second": 39.169,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7321,
            "grad_norm": 5.28190279006958,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.710221290588379,
            "eval_matthews_correlation": 0.6015706950519473,
            "eval_runtime": 0.2261,
            "eval_samples_per_second": 4612.026,
            "eval_steps_per_second": 39.797,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7157,
            "grad_norm": 3.1430280208587646,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.742295026779175,
            "eval_matthews_correlation": 0.6017582115322853,
            "eval_runtime": 0.2269,
            "eval_samples_per_second": 4597.432,
            "eval_steps_per_second": 39.671,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6907,
            "grad_norm": 3.3445208072662354,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.7491137981414795,
            "eval_matthews_correlation": 0.6125472225786625,
            "eval_runtime": 0.2309,
            "eval_samples_per_second": 4517.106,
            "eval_steps_per_second": 38.978,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.661,
            "grad_norm": 5.527674198150635,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.8599321842193604,
            "eval_matthews_correlation": 0.604716336729683,
            "eval_runtime": 0.2257,
            "eval_samples_per_second": 4622.02,
            "eval_steps_per_second": 39.883,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6554,
            "grad_norm": 5.8419036865234375,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.944253921508789,
            "eval_matthews_correlation": 0.6133109050075183,
            "eval_runtime": 0.229,
            "eval_samples_per_second": 4554.128,
            "eval_steps_per_second": 39.297,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6355,
            "grad_norm": 3.3430583477020264,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.942603349685669,
            "eval_matthews_correlation": 0.6007221525351318,
            "eval_runtime": 0.2253,
            "eval_samples_per_second": 4628.789,
            "eval_steps_per_second": 39.942,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.611,
            "grad_norm": 3.0520105361938477,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.9805591106414795,
            "eval_matthews_correlation": 0.6108743288323454,
            "eval_runtime": 0.2264,
            "eval_samples_per_second": 4606.509,
            "eval_steps_per_second": 39.749,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.6015,
            "grad_norm": 2.979264259338379,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.9541709423065186,
            "eval_matthews_correlation": 0.6188970025554703,
            "eval_runtime": 0.2263,
            "eval_samples_per_second": 4609.878,
            "eval_steps_per_second": 39.778,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5841,
            "grad_norm": 4.641911029815674,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.066401243209839,
            "eval_matthews_correlation": 0.6146094301507191,
            "eval_runtime": 0.2314,
            "eval_samples_per_second": 4506.859,
            "eval_steps_per_second": 38.889,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5631,
            "grad_norm": 4.925194263458252,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.0991263389587402,
            "eval_matthews_correlation": 0.6240838974095094,
            "eval_runtime": 0.2303,
            "eval_samples_per_second": 4528.825,
            "eval_steps_per_second": 39.079,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5643,
            "grad_norm": 3.5762412548065186,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 3.1009860038757324,
            "eval_matthews_correlation": 0.6244666931728993,
            "eval_runtime": 0.2336,
            "eval_samples_per_second": 4465.551,
            "eval_steps_per_second": 38.533,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5625,
            "grad_norm": 4.195999622344971,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 3.0805060863494873,
            "eval_matthews_correlation": 0.6217559489965282,
            "eval_runtime": 0.2316,
            "eval_samples_per_second": 4503.792,
            "eval_steps_per_second": 38.863,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5525,
            "grad_norm": 4.178139686584473,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 3.174720048904419,
            "eval_matthews_correlation": 0.621573943400159,
            "eval_runtime": 0.2691,
            "eval_samples_per_second": 3876.508,
            "eval_steps_per_second": 33.45,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5281,
            "grad_norm": 4.4310302734375,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.276601552963257,
            "eval_matthews_correlation": 0.6187489151157926,
            "eval_runtime": 0.3016,
            "eval_samples_per_second": 3458.554,
            "eval_steps_per_second": 29.844,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.5373,
            "grad_norm": 4.620718002319336,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.210921049118042,
            "eval_matthews_correlation": 0.6271935369003752,
            "eval_runtime": 0.2273,
            "eval_samples_per_second": 4588.429,
            "eval_steps_per_second": 39.593,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5204,
            "grad_norm": 4.432373523712158,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.245293617248535,
            "eval_matthews_correlation": 0.6239164540479953,
            "eval_runtime": 0.2264,
            "eval_samples_per_second": 4606.626,
            "eval_steps_per_second": 39.75,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.5184,
            "grad_norm": 4.219028949737549,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 3.269218683242798,
            "eval_matthews_correlation": 0.6137218790341886,
            "eval_runtime": 0.2263,
            "eval_samples_per_second": 4609.465,
            "eval_steps_per_second": 39.775,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.521,
            "grad_norm": 4.506032466888428,
            "learning_rate": 2.4875621890547266e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 3.2546446323394775,
            "eval_matthews_correlation": 0.629703181950203,
            "eval_runtime": 0.2262,
            "eval_samples_per_second": 4610.296,
            "eval_steps_per_second": 39.782,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "loss": 0.4995,
            "grad_norm": 5.791009426116943,
            "learning_rate": 2.155887230514096e-05,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "eval_loss": 3.349212408065796,
            "eval_matthews_correlation": 0.6292829640607693,
            "eval_runtime": 0.2265,
            "eval_samples_per_second": 4604.987,
            "eval_steps_per_second": 39.736,
            "epoch": 80.59701492537313,
            "step": 5400
        },
        {
            "loss": 0.5122,
            "grad_norm": 4.130023002624512,
            "learning_rate": 1.8242122719734662e-05,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "eval_loss": 3.2995476722717285,
            "eval_matthews_correlation": 0.6265913598426309,
            "eval_runtime": 0.2246,
            "eval_samples_per_second": 4643.317,
            "eval_steps_per_second": 40.067,
            "epoch": 83.58208955223881,
            "step": 5600
        },
        {
            "loss": 0.4958,
            "grad_norm": 3.901196002960205,
            "learning_rate": 1.4925373134328357e-05,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "eval_loss": 3.300567388534546,
            "eval_matthews_correlation": 0.63678867391954,
            "eval_runtime": 0.2303,
            "eval_samples_per_second": 4529.842,
            "eval_steps_per_second": 39.088,
            "epoch": 86.56716417910448,
            "step": 5800
        },
        {
            "loss": 0.4947,
            "grad_norm": 5.020888805389404,
            "learning_rate": 1.1608623548922057e-05,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "eval_loss": 3.3234660625457764,
            "eval_matthews_correlation": 0.6340992349486394,
            "eval_runtime": 0.2652,
            "eval_samples_per_second": 3932.451,
            "eval_steps_per_second": 33.933,
            "epoch": 89.55223880597015,
            "step": 6000
        },
        {
            "loss": 0.4849,
            "grad_norm": 4.290144443511963,
            "learning_rate": 8.291873963515755e-06,
            "epoch": 92.53731343283582,
            "step": 6200
        },
        {
            "eval_loss": 3.3389108180999756,
            "eval_matthews_correlation": 0.6340992349486394,
            "eval_runtime": 0.2277,
            "eval_samples_per_second": 4581.562,
            "eval_steps_per_second": 39.534,
            "epoch": 92.53731343283582,
            "step": 6200
        },
        {
            "loss": 0.4956,
            "grad_norm": 4.795284748077393,
            "learning_rate": 4.975124378109453e-06,
            "epoch": 95.5223880597015,
            "step": 6400
        },
        {
            "eval_loss": 3.3452556133270264,
            "eval_matthews_correlation": 0.6340992349486394,
            "eval_runtime": 0.226,
            "eval_samples_per_second": 4614.274,
            "eval_steps_per_second": 39.816,
            "epoch": 95.5223880597015,
            "step": 6400
        },
        {
            "loss": 0.4909,
            "grad_norm": 4.632822513580322,
            "learning_rate": 1.6583747927031512e-06,
            "epoch": 98.50746268656717,
            "step": 6600
        },
        {
            "eval_loss": 3.338634967803955,
            "eval_matthews_correlation": 0.6317871775012913,
            "eval_runtime": 0.2456,
            "eval_samples_per_second": 4246.71,
            "eval_steps_per_second": 36.645,
            "epoch": 98.50746268656717,
            "step": 6600
        },
        {
            "train_runtime": 409.9402,
            "train_samples_per_second": 2085.914,
            "train_steps_per_second": 16.344,
            "total_flos": 2.8500154482950144e+16,
            "train_loss": 0.6808506410513351,
            "epoch": 100.0,
            "step": 6700
        },
        {
            "eval_loss": 3.300567388534546,
            "eval_matthews_correlation": 0.63678867391954,
            "eval_runtime": 0.2288,
            "eval_samples_per_second": 4558.846,
            "eval_steps_per_second": 39.338,
            "epoch": 100.0,
            "step": 6700
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 409.9402,
        "trainable_params_count": 0.148994,
        "memory_allocated": [
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376,
            588.645376
        ],
        "memory_reserved": [
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912,
            2634.022912
        ]
    },
    "variant": "kd-lora"
}