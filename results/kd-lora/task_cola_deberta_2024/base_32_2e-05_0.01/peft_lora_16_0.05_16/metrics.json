{
    "eval_loss": 2.7941339015960693,
    "eval_matthews_correlation": 0.634951918264685,
    "eval_runtime": 0.2661,
    "eval_samples_per_second": 3920.082,
    "eval_steps_per_second": 33.826,
    "epoch": 47.76119402985075,
    "log_history": [
        {
            "loss": 1.5826,
            "grad_norm": 0.9732346534729004,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5165128707885742,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2594,
            "eval_samples_per_second": 4021.444,
            "eval_steps_per_second": 34.701,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3933,
            "grad_norm": 1.4616022109985352,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6181937456130981,
            "eval_matthews_correlation": 0.4356089650051953,
            "eval_runtime": 0.2278,
            "eval_samples_per_second": 4578.882,
            "eval_steps_per_second": 39.511,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.056,
            "grad_norm": 1.3818821907043457,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9950165748596191,
            "eval_matthews_correlation": 0.523253926058104,
            "eval_runtime": 0.2664,
            "eval_samples_per_second": 3915.188,
            "eval_steps_per_second": 33.784,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.957,
            "grad_norm": 3.097698926925659,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.212557792663574,
            "eval_matthews_correlation": 0.5598743897878832,
            "eval_runtime": 0.2285,
            "eval_samples_per_second": 4564.196,
            "eval_steps_per_second": 39.384,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8852,
            "grad_norm": 2.076401710510254,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.3726766109466553,
            "eval_matthews_correlation": 0.570240121346637,
            "eval_runtime": 0.2271,
            "eval_samples_per_second": 4592.466,
            "eval_steps_per_second": 39.628,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8355,
            "grad_norm": 2.174428939819336,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.360093355178833,
            "eval_matthews_correlation": 0.6032056943524631,
            "eval_runtime": 0.2299,
            "eval_samples_per_second": 4536.903,
            "eval_steps_per_second": 39.149,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.7944,
            "grad_norm": 3.4676315784454346,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.467353105545044,
            "eval_matthews_correlation": 0.6070286836001448,
            "eval_runtime": 0.2338,
            "eval_samples_per_second": 4461.985,
            "eval_steps_per_second": 38.502,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7548,
            "grad_norm": 1.9838770627975464,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.6169581413269043,
            "eval_matthews_correlation": 0.5936351080219947,
            "eval_runtime": 0.2644,
            "eval_samples_per_second": 3944.809,
            "eval_steps_per_second": 34.04,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7188,
            "grad_norm": 3.711852788925171,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.732941150665283,
            "eval_matthews_correlation": 0.6116847500337435,
            "eval_runtime": 0.2311,
            "eval_samples_per_second": 4513.219,
            "eval_steps_per_second": 38.944,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7007,
            "grad_norm": 2.09382963180542,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.789229154586792,
            "eval_matthews_correlation": 0.6137218790341886,
            "eval_runtime": 0.2269,
            "eval_samples_per_second": 4597.297,
            "eval_steps_per_second": 39.67,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6763,
            "grad_norm": 2.6275570392608643,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.7941339015960693,
            "eval_matthews_correlation": 0.634951918264685,
            "eval_runtime": 0.2286,
            "eval_samples_per_second": 4563.363,
            "eval_steps_per_second": 39.377,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6447,
            "grad_norm": 3.49690842628479,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.9031100273132324,
            "eval_matthews_correlation": 0.6217559489965282,
            "eval_runtime": 0.2684,
            "eval_samples_per_second": 3885.843,
            "eval_steps_per_second": 33.531,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.643,
            "grad_norm": 4.258389472961426,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.947396755218506,
            "eval_matthews_correlation": 0.6256796544244645,
            "eval_runtime": 0.2279,
            "eval_samples_per_second": 4575.836,
            "eval_steps_per_second": 39.485,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6237,
            "grad_norm": 2.2888758182525635,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.9745681285858154,
            "eval_matthews_correlation": 0.6157593279004692,
            "eval_runtime": 0.2289,
            "eval_samples_per_second": 4556.078,
            "eval_steps_per_second": 39.314,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.6014,
            "grad_norm": 2.1411962509155273,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.984698534011841,
            "eval_matthews_correlation": 0.6183257151834723,
            "eval_runtime": 0.2286,
            "eval_samples_per_second": 4562.526,
            "eval_steps_per_second": 39.37,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.5864,
            "grad_norm": 2.5588877201080322,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.9909310340881348,
            "eval_matthews_correlation": 0.6337676777494227,
            "eval_runtime": 0.26,
            "eval_samples_per_second": 4011.851,
            "eval_steps_per_second": 34.618,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "train_runtime": 198.6761,
            "train_samples_per_second": 4303.99,
            "train_steps_per_second": 33.723,
            "total_flos": 1.3658399728205824e+16,
            "train_loss": 0.8408649158477783,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.7941339015960693,
            "eval_matthews_correlation": 0.634951918264685,
            "eval_runtime": 0.2661,
            "eval_samples_per_second": 3920.082,
            "eval_steps_per_second": 33.826,
            "epoch": 47.76119402985075,
            "step": 3200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 16,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 198.6761,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512,
            591.36512
        ],
        "memory_reserved": [
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216,
            2638.217216
        ]
    },
    "variant": "kd-lora"
}