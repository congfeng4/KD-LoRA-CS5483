{
    "eval_loss": 2.9101998805999756,
    "eval_matthews_correlation": 0.6208288813242873,
    "eval_runtime": 0.2767,
    "eval_samples_per_second": 3769.35,
    "eval_steps_per_second": 32.526,
    "epoch": 77.61194029850746,
    "log_history": [
        {
            "loss": 1.5835,
            "grad_norm": 1.0307561159133911,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5169486999511719,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2189,
            "eval_samples_per_second": 4763.66,
            "eval_steps_per_second": 41.105,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.4499,
            "grad_norm": 0.861814558506012,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.498984932899475,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2865,
            "eval_samples_per_second": 3640.483,
            "eval_steps_per_second": 31.414,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1359,
            "grad_norm": 1.208729863166809,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.7965781688690186,
            "eval_matthews_correlation": 0.5153691855191354,
            "eval_runtime": 0.2799,
            "eval_samples_per_second": 3725.876,
            "eval_steps_per_second": 32.15,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0016,
            "grad_norm": 3.484804153442383,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.9924430847167969,
            "eval_matthews_correlation": 0.529144545456451,
            "eval_runtime": 0.2836,
            "eval_samples_per_second": 3677.253,
            "eval_steps_per_second": 31.731,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9371,
            "grad_norm": 1.878127932548523,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.141773223876953,
            "eval_matthews_correlation": 0.5520601255693537,
            "eval_runtime": 0.2822,
            "eval_samples_per_second": 3696.128,
            "eval_steps_per_second": 31.894,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8941,
            "grad_norm": 1.8208763599395752,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.1826975345611572,
            "eval_matthews_correlation": 0.5745572299732778,
            "eval_runtime": 0.2831,
            "eval_samples_per_second": 3684.1,
            "eval_steps_per_second": 31.79,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8621,
            "grad_norm": 2.680772542953491,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.3017053604125977,
            "eval_matthews_correlation": 0.5733495702281163,
            "eval_runtime": 0.2796,
            "eval_samples_per_second": 3730.438,
            "eval_steps_per_second": 32.19,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.8222,
            "grad_norm": 1.7779775857925415,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.4085710048675537,
            "eval_matthews_correlation": 0.6031932328167873,
            "eval_runtime": 0.2735,
            "eval_samples_per_second": 3813.838,
            "eval_steps_per_second": 32.909,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7898,
            "grad_norm": 2.745620012283325,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.565518617630005,
            "eval_matthews_correlation": 0.6033168402681877,
            "eval_runtime": 0.2819,
            "eval_samples_per_second": 3699.278,
            "eval_steps_per_second": 31.921,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7773,
            "grad_norm": 1.8873969316482544,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.5952439308166504,
            "eval_matthews_correlation": 0.5858661515147512,
            "eval_runtime": 0.2859,
            "eval_samples_per_second": 3648.389,
            "eval_steps_per_second": 31.482,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.7572,
            "grad_norm": 2.2714650630950928,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.598795175552368,
            "eval_matthews_correlation": 0.6013991943475097,
            "eval_runtime": 0.2802,
            "eval_samples_per_second": 3722.994,
            "eval_steps_per_second": 32.126,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.7277,
            "grad_norm": 4.4998698234558105,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.6765360832214355,
            "eval_matthews_correlation": 0.6137218790341886,
            "eval_runtime": 0.2886,
            "eval_samples_per_second": 3613.584,
            "eval_steps_per_second": 31.181,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.7235,
            "grad_norm": 3.6940107345581055,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.7794060707092285,
            "eval_matthews_correlation": 0.5981008799238268,
            "eval_runtime": 0.2797,
            "eval_samples_per_second": 3728.842,
            "eval_steps_per_second": 32.176,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.7109,
            "grad_norm": 2.0582032203674316,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.7472774982452393,
            "eval_matthews_correlation": 0.6031932328167873,
            "eval_runtime": 0.28,
            "eval_samples_per_second": 3724.778,
            "eval_steps_per_second": 32.141,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.6851,
            "grad_norm": 2.5611560344696045,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.736159086227417,
            "eval_matthews_correlation": 0.608358147712731,
            "eval_runtime": 0.2839,
            "eval_samples_per_second": 3673.415,
            "eval_steps_per_second": 31.698,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.6757,
            "grad_norm": 2.3528642654418945,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.7690794467926025,
            "eval_matthews_correlation": 0.6183257151834723,
            "eval_runtime": 0.282,
            "eval_samples_per_second": 3698.609,
            "eval_steps_per_second": 31.915,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.6578,
            "grad_norm": 2.9155678749084473,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 2.872750997543335,
            "eval_matthews_correlation": 0.6162367490845745,
            "eval_runtime": 0.3309,
            "eval_samples_per_second": 3151.996,
            "eval_steps_per_second": 27.198,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.6433,
            "grad_norm": 3.265735149383545,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 2.894315004348755,
            "eval_matthews_correlation": 0.6183257151834723,
            "eval_runtime": 0.2826,
            "eval_samples_per_second": 3691.318,
            "eval_steps_per_second": 31.852,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.6442,
            "grad_norm": 3.2940123081207275,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 2.8874216079711914,
            "eval_matthews_correlation": 0.6138670730002377,
            "eval_runtime": 0.2853,
            "eval_samples_per_second": 3656.397,
            "eval_steps_per_second": 31.551,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.6414,
            "grad_norm": 3.489108085632324,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 2.878371477127075,
            "eval_matthews_correlation": 0.6185029155864712,
            "eval_runtime": 0.3256,
            "eval_samples_per_second": 3202.926,
            "eval_steps_per_second": 27.638,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.6343,
            "grad_norm": 2.810642719268799,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 2.9101998805999756,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.2801,
            "eval_samples_per_second": 3724.04,
            "eval_steps_per_second": 32.135,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.6142,
            "grad_norm": 2.483689308166504,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.0318939685821533,
            "eval_matthews_correlation": 0.6133109050075183,
            "eval_runtime": 0.2804,
            "eval_samples_per_second": 3720.129,
            "eval_steps_per_second": 32.101,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.6226,
            "grad_norm": 3.4142258167266846,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.005361795425415,
            "eval_matthews_correlation": 0.6084494723188812,
            "eval_runtime": 0.2812,
            "eval_samples_per_second": 3709.759,
            "eval_steps_per_second": 32.011,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.6084,
            "grad_norm": 2.644026041030884,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.0245275497436523,
            "eval_matthews_correlation": 0.6133875937511768,
            "eval_runtime": 0.2806,
            "eval_samples_per_second": 3717.615,
            "eval_steps_per_second": 32.079,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.6035,
            "grad_norm": 3.140327215194702,
            "learning_rate": 2.8192371475953565e-05,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 3.023064136505127,
            "eval_matthews_correlation": 0.6158197390467447,
            "eval_runtime": 0.2834,
            "eval_samples_per_second": 3680.536,
            "eval_steps_per_second": 31.759,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "loss": 0.6083,
            "grad_norm": 2.9612019062042236,
            "learning_rate": 2.4875621890547266e-05,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 3.0111372470855713,
            "eval_matthews_correlation": 0.6186174601668025,
            "eval_runtime": 0.2105,
            "eval_samples_per_second": 4955.217,
            "eval_steps_per_second": 42.758,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "train_runtime": 357.6757,
            "train_samples_per_second": 2390.713,
            "train_steps_per_second": 18.732,
            "total_flos": 2.2124233924542464e+16,
            "train_loss": 0.8004447408822867,
            "epoch": 77.61194029850746,
            "step": 5200
        },
        {
            "eval_loss": 2.9101998805999756,
            "eval_matthews_correlation": 0.6208288813242873,
            "eval_runtime": 0.2767,
            "eval_samples_per_second": 3769.35,
            "eval_steps_per_second": 32.526,
            "epoch": 77.61194029850746,
            "step": 5200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 357.6757,
        "trainable_params_count": 0.15821,
        "memory_allocated": [
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544
        ],
        "memory_reserved": [
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288
        ]
    },
    "variant": "kd-lora"
}