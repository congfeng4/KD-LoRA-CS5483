{
    "eval_loss": 4.3196306228637695,
    "eval_matthews_correlation": 0.6758829936616813,
    "eval_runtime": 0.2225,
    "eval_samples_per_second": 4687.764,
    "eval_steps_per_second": 40.451,
    "epoch": 56.71641791044776,
    "log_history": [
        {
            "loss": 1.5725,
            "grad_norm": 0.7470505237579346,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5093120336532593,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2244,
            "eval_samples_per_second": 4648.937,
            "eval_steps_per_second": 40.115,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.1291,
            "grad_norm": 3.0460166931152344,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.9989359378814697,
            "eval_matthews_correlation": 0.5628601575342307,
            "eval_runtime": 0.2214,
            "eval_samples_per_second": 4710.413,
            "eval_steps_per_second": 40.646,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.845,
            "grad_norm": 2.8466856479644775,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 2.3379290103912354,
            "eval_matthews_correlation": 0.6060362102181063,
            "eval_runtime": 0.2271,
            "eval_samples_per_second": 4592.803,
            "eval_steps_per_second": 39.631,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.688,
            "grad_norm": 4.318022727966309,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.761357307434082,
            "eval_matthews_correlation": 0.6133696418485944,
            "eval_runtime": 0.2565,
            "eval_samples_per_second": 4065.721,
            "eval_steps_per_second": 35.083,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.555,
            "grad_norm": 3.2609152793884277,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 3.0345542430877686,
            "eval_matthews_correlation": 0.6256740929699375,
            "eval_runtime": 0.2214,
            "eval_samples_per_second": 4711.716,
            "eval_steps_per_second": 40.657,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.449,
            "grad_norm": 3.69502329826355,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 3.259028911590576,
            "eval_matthews_correlation": 0.6457161787575496,
            "eval_runtime": 0.2237,
            "eval_samples_per_second": 4662.598,
            "eval_steps_per_second": 40.233,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3699,
            "grad_norm": 4.277726650238037,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 3.4432759284973145,
            "eval_matthews_correlation": 0.6492539342618789,
            "eval_runtime": 0.2523,
            "eval_samples_per_second": 4133.631,
            "eval_steps_per_second": 35.669,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3116,
            "grad_norm": 5.265848636627197,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 3.74170184135437,
            "eval_matthews_correlation": 0.6181875257246454,
            "eval_runtime": 0.2295,
            "eval_samples_per_second": 4544.043,
            "eval_steps_per_second": 39.21,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2602,
            "grad_norm": 4.57484245300293,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 3.863793134689331,
            "eval_matthews_correlation": 0.6408545460827202,
            "eval_runtime": 0.2227,
            "eval_samples_per_second": 4682.676,
            "eval_steps_per_second": 40.407,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.228,
            "grad_norm": 4.615238666534424,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 4.023381233215332,
            "eval_matthews_correlation": 0.6383702690280213,
            "eval_runtime": 0.2399,
            "eval_samples_per_second": 4348.269,
            "eval_steps_per_second": 37.521,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2034,
            "grad_norm": 4.463271141052246,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 4.163663387298584,
            "eval_matthews_correlation": 0.6623908579700661,
            "eval_runtime": 0.2235,
            "eval_samples_per_second": 4667.129,
            "eval_steps_per_second": 40.272,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.1849,
            "grad_norm": 4.917492389678955,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 4.276309013366699,
            "eval_matthews_correlation": 0.646217143693263,
            "eval_runtime": 0.2224,
            "eval_samples_per_second": 4689.583,
            "eval_steps_per_second": 40.466,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.1644,
            "grad_norm": 6.189630508422852,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 4.370455265045166,
            "eval_matthews_correlation": 0.6435833191274509,
            "eval_runtime": 0.2224,
            "eval_samples_per_second": 4690.408,
            "eval_steps_per_second": 40.473,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.1511,
            "grad_norm": 4.509093761444092,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 4.3196306228637695,
            "eval_matthews_correlation": 0.6758829936616813,
            "eval_runtime": 0.2235,
            "eval_samples_per_second": 4667.095,
            "eval_steps_per_second": 40.272,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1325,
            "grad_norm": 2.7093160152435303,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 4.513789653778076,
            "eval_matthews_correlation": 0.6458160430668494,
            "eval_runtime": 0.223,
            "eval_samples_per_second": 4677.204,
            "eval_steps_per_second": 40.359,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.1195,
            "grad_norm": 2.1910996437072754,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 4.58650541305542,
            "eval_matthews_correlation": 0.643050604687314,
            "eval_runtime": 0.2218,
            "eval_samples_per_second": 4702.246,
            "eval_steps_per_second": 40.575,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1168,
            "grad_norm": 2.664644718170166,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 4.486371994018555,
            "eval_matthews_correlation": 0.6632431890370206,
            "eval_runtime": 0.2249,
            "eval_samples_per_second": 4637.037,
            "eval_steps_per_second": 40.013,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.105,
            "grad_norm": 3.102203607559204,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 4.570748329162598,
            "eval_matthews_correlation": 0.6454933691830679,
            "eval_runtime": 0.261,
            "eval_samples_per_second": 3996.874,
            "eval_steps_per_second": 34.489,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.0997,
            "grad_norm": 6.989168643951416,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 4.622190952301025,
            "eval_matthews_correlation": 0.6732477678270925,
            "eval_runtime": 0.2302,
            "eval_samples_per_second": 4530.499,
            "eval_steps_per_second": 39.093,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "train_runtime": 233.4698,
            "train_samples_per_second": 3662.573,
            "train_steps_per_second": 28.698,
            "total_flos": 1.6549847410671616e+16,
            "train_loss": 0.404506240643953,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 4.3196306228637695,
            "eval_matthews_correlation": 0.6758829936616813,
            "eval_runtime": 0.2225,
            "eval_samples_per_second": 4687.764,
            "eval_steps_per_second": 40.451,
            "epoch": 56.71641791044776,
            "step": 3800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 64,
        "lora_alpha": 64,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 233.4698,
        "trainable_params_count": 1.181186,
        "memory_allocated": [
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672,
            604.892672
        ],
        "memory_reserved": [
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584,
            2657.091584
        ]
    },
    "variant": "kd-lora"
}