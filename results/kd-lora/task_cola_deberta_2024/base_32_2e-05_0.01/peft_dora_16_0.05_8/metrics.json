{
    "eval_loss": 3.1128346920013428,
    "eval_matthews_correlation": 0.6244666931728993,
    "eval_runtime": 0.4525,
    "eval_samples_per_second": 2304.999,
    "eval_steps_per_second": 19.89,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 1.5823,
            "grad_norm": 0.9604125022888184,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.5165575742721558,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3168,
            "eval_samples_per_second": 3291.883,
            "eval_steps_per_second": 28.406,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3981,
            "grad_norm": 1.8852099180221558,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.6227983236312866,
            "eval_matthews_correlation": 0.42241607930644726,
            "eval_runtime": 0.3612,
            "eval_samples_per_second": 2887.308,
            "eval_steps_per_second": 24.914,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.0637,
            "grad_norm": 2.046004295349121,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.9875593185424805,
            "eval_matthews_correlation": 0.5285257385527052,
            "eval_runtime": 0.3484,
            "eval_samples_per_second": 2993.967,
            "eval_steps_per_second": 25.835,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.9644,
            "grad_norm": 4.0019097328186035,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 2.216440439224243,
            "eval_matthews_correlation": 0.5521069582827846,
            "eval_runtime": 0.3086,
            "eval_samples_per_second": 3379.496,
            "eval_steps_per_second": 29.162,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.8959,
            "grad_norm": 3.154425621032715,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.315774440765381,
            "eval_matthews_correlation": 0.5704260999182836,
            "eval_runtime": 0.3264,
            "eval_samples_per_second": 3195.447,
            "eval_steps_per_second": 27.573,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8433,
            "grad_norm": 3.700737237930298,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.322774648666382,
            "eval_matthews_correlation": 0.5984081258428807,
            "eval_runtime": 0.3068,
            "eval_samples_per_second": 3399.824,
            "eval_steps_per_second": 29.337,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8046,
            "grad_norm": 4.629317760467529,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.4455373287200928,
            "eval_matthews_correlation": 0.6093514522222457,
            "eval_runtime": 0.4366,
            "eval_samples_per_second": 2388.878,
            "eval_steps_per_second": 20.614,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7632,
            "grad_norm": 2.8659541606903076,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.5879664421081543,
            "eval_matthews_correlation": 0.5988647643057969,
            "eval_runtime": 0.4424,
            "eval_samples_per_second": 2357.636,
            "eval_steps_per_second": 20.344,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7287,
            "grad_norm": 5.358470439910889,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.7160136699676514,
            "eval_matthews_correlation": 0.5968831586006677,
            "eval_runtime": 0.3696,
            "eval_samples_per_second": 2821.884,
            "eval_steps_per_second": 24.35,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.712,
            "grad_norm": 3.1059515476226807,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.744792938232422,
            "eval_matthews_correlation": 0.6066332644639029,
            "eval_runtime": 0.3824,
            "eval_samples_per_second": 2727.247,
            "eval_steps_per_second": 23.533,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6866,
            "grad_norm": 3.356734037399292,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.7588744163513184,
            "eval_matthews_correlation": 0.6148341513971591,
            "eval_runtime": 0.3586,
            "eval_samples_per_second": 2908.437,
            "eval_steps_per_second": 25.097,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6569,
            "grad_norm": 5.621424198150635,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.868046283721924,
            "eval_matthews_correlation": 0.6072497164582199,
            "eval_runtime": 0.322,
            "eval_samples_per_second": 3239.401,
            "eval_steps_per_second": 27.953,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.6513,
            "grad_norm": 5.938474655151367,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.951669931411743,
            "eval_matthews_correlation": 0.6108743288323454,
            "eval_runtime": 0.4263,
            "eval_samples_per_second": 2446.51,
            "eval_steps_per_second": 21.111,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.6311,
            "grad_norm": 3.384766101837158,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.950833797454834,
            "eval_matthews_correlation": 0.60819133045274,
            "eval_runtime": 0.4575,
            "eval_samples_per_second": 2280.003,
            "eval_steps_per_second": 19.674,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.6062,
            "grad_norm": 3.0820610523223877,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 2.989149570465088,
            "eval_matthews_correlation": 0.6035113508865858,
            "eval_runtime": 0.3561,
            "eval_samples_per_second": 2929.07,
            "eval_steps_per_second": 25.275,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.5968,
            "grad_norm": 3.0057032108306885,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 2.967237949371338,
            "eval_matthews_correlation": 0.6165463827085729,
            "eval_runtime": 0.3994,
            "eval_samples_per_second": 2611.109,
            "eval_steps_per_second": 22.531,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.5792,
            "grad_norm": 4.67661190032959,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 3.0780858993530273,
            "eval_matthews_correlation": 0.6148341513971591,
            "eval_runtime": 0.5005,
            "eval_samples_per_second": 2083.784,
            "eval_steps_per_second": 17.981,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.5577,
            "grad_norm": 4.936216831207275,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 3.108829975128174,
            "eval_matthews_correlation": 0.6217559489965282,
            "eval_runtime": 0.396,
            "eval_samples_per_second": 2633.926,
            "eval_steps_per_second": 22.728,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.5595,
            "grad_norm": 3.7198104858398438,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 3.1128346920013428,
            "eval_matthews_correlation": 0.6244666931728993,
            "eval_runtime": 0.4612,
            "eval_samples_per_second": 2261.456,
            "eval_steps_per_second": 19.514,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.5573,
            "grad_norm": 4.168751239776611,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 3.0933942794799805,
            "eval_matthews_correlation": 0.6169205381504255,
            "eval_runtime": 0.4265,
            "eval_samples_per_second": 2445.381,
            "eval_steps_per_second": 21.101,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.5468,
            "grad_norm": 4.210059642791748,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 3.187201976776123,
            "eval_matthews_correlation": 0.6190614534394121,
            "eval_runtime": 0.4239,
            "eval_samples_per_second": 2460.46,
            "eval_steps_per_second": 21.231,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.5217,
            "grad_norm": 4.51207971572876,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 3.2948670387268066,
            "eval_matthews_correlation": 0.6162367490845745,
            "eval_runtime": 0.4504,
            "eval_samples_per_second": 2315.867,
            "eval_steps_per_second": 19.984,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.5316,
            "grad_norm": 4.664850234985352,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 3.223843574523926,
            "eval_matthews_correlation": 0.6223959683907928,
            "eval_runtime": 0.4214,
            "eval_samples_per_second": 2475.175,
            "eval_steps_per_second": 21.358,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.5148,
            "grad_norm": 4.487271308898926,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.26090931892395,
            "eval_matthews_correlation": 0.6214080153834024,
            "eval_runtime": 0.4197,
            "eval_samples_per_second": 2484.935,
            "eval_steps_per_second": 21.442,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 452.3122,
            "train_samples_per_second": 1890.508,
            "train_steps_per_second": 14.813,
            "total_flos": 2.0422369776500736e+16,
            "train_loss": 0.7480757220586141,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 3.1128346920013428,
            "eval_matthews_correlation": 0.6244666931728993,
            "eval_runtime": 0.4525,
            "eval_samples_per_second": 2304.999,
            "eval_steps_per_second": 19.89,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 452.3122,
        "trainable_params_count": 0.15821,
        "memory_allocated": [
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832,
            588.792832
        ],
        "memory_reserved": [
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552,
            2831.1552
        ]
    },
    "variant": "kd-lora"
}