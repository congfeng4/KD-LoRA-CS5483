{
    "eval_loss": 2.6293835639953613,
    "eval_pearson": 0.8577793110952405,
    "eval_spearman": 0.8560727850278709,
    "eval_runtime": 0.2075,
    "eval_samples_per_second": 7230.262,
    "eval_steps_per_second": 57.842,
    "epoch": 48.888888888888886,
    "log_history": [
        {
            "loss": 5.1342,
            "grad_norm": 4.346985816955566,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.64156174659729,
            "eval_pearson": 0.5494728628201416,
            "eval_spearman": 0.5459446534611949,
            "eval_runtime": 0.2083,
            "eval_samples_per_second": 7199.764,
            "eval_steps_per_second": 57.598,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.0815,
            "grad_norm": 6.509278774261475,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.5361273288726807,
            "eval_pearson": 0.835946718367426,
            "eval_spearman": 0.8321178105419772,
            "eval_runtime": 0.2075,
            "eval_samples_per_second": 7229.531,
            "eval_steps_per_second": 57.836,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.7879,
            "grad_norm": 6.82211446762085,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.627117395401001,
            "eval_pearson": 0.8524147308205905,
            "eval_spearman": 0.8489854062869214,
            "eval_runtime": 0.2076,
            "eval_samples_per_second": 7224.119,
            "eval_steps_per_second": 57.793,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6769,
            "grad_norm": 4.763228416442871,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.5252833366394043,
            "eval_pearson": 0.8529425020150735,
            "eval_spearman": 0.8505821912060183,
            "eval_runtime": 0.2054,
            "eval_samples_per_second": 7303.545,
            "eval_steps_per_second": 58.428,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5991,
            "grad_norm": 4.3618927001953125,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.556551694869995,
            "eval_pearson": 0.8564780101131207,
            "eval_spearman": 0.8539373571187525,
            "eval_runtime": 0.2073,
            "eval_samples_per_second": 7234.319,
            "eval_steps_per_second": 57.875,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5386,
            "grad_norm": 5.2045769691467285,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.5781078338623047,
            "eval_pearson": 0.8579538915051015,
            "eval_spearman": 0.8558312595831594,
            "eval_runtime": 0.2072,
            "eval_samples_per_second": 7240.464,
            "eval_steps_per_second": 57.924,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.4988,
            "grad_norm": 6.028397083282471,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.6293835639953613,
            "eval_pearson": 0.8577793110952405,
            "eval_spearman": 0.8560727850278709,
            "eval_runtime": 0.2091,
            "eval_samples_per_second": 7173.953,
            "eval_steps_per_second": 57.392,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.461,
            "grad_norm": 5.843578338623047,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.683711528778076,
            "eval_pearson": 0.8557073211938804,
            "eval_spearman": 0.8545324149713084,
            "eval_runtime": 0.2061,
            "eval_samples_per_second": 7276.539,
            "eval_steps_per_second": 58.212,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4372,
            "grad_norm": 2.9836416244506836,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.6659483909606934,
            "eval_pearson": 0.8541911280273815,
            "eval_spearman": 0.8530661167505181,
            "eval_runtime": 0.2073,
            "eval_samples_per_second": 7234.918,
            "eval_steps_per_second": 57.879,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4107,
            "grad_norm": 3.9469237327575684,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.6012301445007324,
            "eval_pearson": 0.8537815017684601,
            "eval_spearman": 0.8524659056321361,
            "eval_runtime": 0.2182,
            "eval_samples_per_second": 6873.812,
            "eval_steps_per_second": 54.99,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.3866,
            "grad_norm": 7.00005578994751,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.6638567447662354,
            "eval_pearson": 0.8539830563317384,
            "eval_spearman": 0.8524245907504141,
            "eval_runtime": 0.2044,
            "eval_samples_per_second": 7337.043,
            "eval_steps_per_second": 58.696,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "train_runtime": 98.6321,
            "train_samples_per_second": 5828.729,
            "train_steps_per_second": 45.624,
            "total_flos": 9485321926344704.0,
            "train_loss": 1.0011360029740768,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.6293835639953613,
            "eval_pearson": 0.8577793110952405,
            "eval_spearman": 0.8560727850278709,
            "eval_runtime": 0.2075,
            "eval_samples_per_second": 7230.262,
            "eval_steps_per_second": 57.842,
            "epoch": 48.888888888888886,
            "step": 2200
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "stsb",
        "seed": 123,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 5749
    },
    "train": {
        "train_time": 98.6321,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656,
            297.670656
        ],
        "memory_reserved": [
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344
        ]
    },
    "variant": "kd-lora"
}