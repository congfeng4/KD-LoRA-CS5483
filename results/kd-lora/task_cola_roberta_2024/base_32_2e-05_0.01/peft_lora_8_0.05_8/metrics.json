{
    "eval_loss": 1.3542183637619019,
    "eval_matthews_correlation": 0.5668277832443891,
    "eval_runtime": 0.1598,
    "eval_samples_per_second": 6526.829,
    "eval_steps_per_second": 56.32,
    "epoch": 71.64179104477611,
    "log_history": [
        {
            "loss": 0.9696,
            "grad_norm": 0.42388734221458435,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.9064807891845703,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1613,
            "eval_samples_per_second": 6466.033,
            "eval_steps_per_second": 55.795,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.7972,
            "grad_norm": 1.255902647972107,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.1343770027160645,
            "eval_matthews_correlation": 0.4063609883970663,
            "eval_runtime": 0.1595,
            "eval_samples_per_second": 6537.646,
            "eval_steps_per_second": 56.413,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.6543,
            "grad_norm": 1.3003660440444946,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.2394050359725952,
            "eval_matthews_correlation": 0.44176088083850046,
            "eval_runtime": 0.1575,
            "eval_samples_per_second": 6622.973,
            "eval_steps_per_second": 57.149,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.6118,
            "grad_norm": 1.306236743927002,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.372856855392456,
            "eval_matthews_correlation": 0.46936417904934724,
            "eval_runtime": 0.1607,
            "eval_samples_per_second": 6492.268,
            "eval_steps_per_second": 56.021,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.5869,
            "grad_norm": 1.9719747304916382,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.336151123046875,
            "eval_matthews_correlation": 0.46669500635694416,
            "eval_runtime": 0.1603,
            "eval_samples_per_second": 6504.895,
            "eval_steps_per_second": 56.13,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.5608,
            "grad_norm": 1.908907413482666,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.186047077178955,
            "eval_matthews_correlation": 0.5248207980411488,
            "eval_runtime": 0.1586,
            "eval_samples_per_second": 6577.248,
            "eval_steps_per_second": 56.755,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.5443,
            "grad_norm": 2.1151583194732666,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.3385008573532104,
            "eval_matthews_correlation": 0.51643905902784,
            "eval_runtime": 0.1629,
            "eval_samples_per_second": 6402.449,
            "eval_steps_per_second": 55.246,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.5263,
            "grad_norm": 2.1852755546569824,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.3332973718643188,
            "eval_matthews_correlation": 0.5111154619148318,
            "eval_runtime": 0.1616,
            "eval_samples_per_second": 6455.765,
            "eval_steps_per_second": 55.707,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5168,
            "grad_norm": 2.286057233810425,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.3141582012176514,
            "eval_matthews_correlation": 0.5329669602160133,
            "eval_runtime": 0.1684,
            "eval_samples_per_second": 6195.058,
            "eval_steps_per_second": 53.457,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.503,
            "grad_norm": 2.3642525672912598,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.2955762147903442,
            "eval_matthews_correlation": 0.5363967157085073,
            "eval_runtime": 0.1575,
            "eval_samples_per_second": 6622.722,
            "eval_steps_per_second": 57.147,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.4991,
            "grad_norm": 2.4737837314605713,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.3459588289260864,
            "eval_matthews_correlation": 0.5300972900950771,
            "eval_runtime": 0.1669,
            "eval_samples_per_second": 6249.379,
            "eval_steps_per_second": 53.926,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.4865,
            "grad_norm": 1.9003924131393433,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.3723782300949097,
            "eval_matthews_correlation": 0.5293023756875906,
            "eval_runtime": 0.1642,
            "eval_samples_per_second": 6351.592,
            "eval_steps_per_second": 54.808,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.4693,
            "grad_norm": 1.9357596635818481,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.4727751016616821,
            "eval_matthews_correlation": 0.5313208986648889,
            "eval_runtime": 0.1579,
            "eval_samples_per_second": 6606.54,
            "eval_steps_per_second": 57.008,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.4711,
            "grad_norm": 1.958938479423523,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.3979506492614746,
            "eval_matthews_correlation": 0.5422671648885407,
            "eval_runtime": 0.1586,
            "eval_samples_per_second": 6576.378,
            "eval_steps_per_second": 56.747,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.4656,
            "grad_norm": 1.7781083583831787,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.471091628074646,
            "eval_matthews_correlation": 0.5395109128667314,
            "eval_runtime": 0.1574,
            "eval_samples_per_second": 6627.86,
            "eval_steps_per_second": 57.192,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.4589,
            "grad_norm": 2.8682563304901123,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.4783012866973877,
            "eval_matthews_correlation": 0.5337999966053822,
            "eval_runtime": 0.1585,
            "eval_samples_per_second": 6582.473,
            "eval_steps_per_second": 56.8,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.4473,
            "grad_norm": 1.7256128787994385,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.4961320161819458,
            "eval_matthews_correlation": 0.5546666671852067,
            "eval_runtime": 0.1586,
            "eval_samples_per_second": 6577.713,
            "eval_steps_per_second": 56.759,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.4423,
            "grad_norm": 3.344634532928467,
            "learning_rate": 5.140961857379768e-05,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 1.42887544631958,
            "eval_matthews_correlation": 0.5625095574827523,
            "eval_runtime": 0.16,
            "eval_samples_per_second": 6519.339,
            "eval_steps_per_second": 56.255,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.4375,
            "grad_norm": 1.8824915885925293,
            "learning_rate": 4.8092868988391376e-05,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 1.3542183637619019,
            "eval_matthews_correlation": 0.5668277832443891,
            "eval_runtime": 0.1634,
            "eval_samples_per_second": 6382.134,
            "eval_steps_per_second": 55.071,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.4348,
            "grad_norm": 1.843532919883728,
            "learning_rate": 4.477611940298508e-05,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 1.4493542909622192,
            "eval_matthews_correlation": 0.5598395777855655,
            "eval_runtime": 0.1388,
            "eval_samples_per_second": 7514.105,
            "eval_steps_per_second": 64.839,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.4254,
            "grad_norm": 2.470252752304077,
            "learning_rate": 4.145936981757877e-05,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 1.4639155864715576,
            "eval_matthews_correlation": 0.5627810283916928,
            "eval_runtime": 0.1601,
            "eval_samples_per_second": 6513.738,
            "eval_steps_per_second": 56.207,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.4249,
            "grad_norm": 3.228794813156128,
            "learning_rate": 3.8142620232172474e-05,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 1.4821041822433472,
            "eval_matthews_correlation": 0.5599614989717403,
            "eval_runtime": 0.161,
            "eval_samples_per_second": 6478.078,
            "eval_steps_per_second": 55.899,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.4144,
            "grad_norm": 3.669635534286499,
            "learning_rate": 3.4825870646766175e-05,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 1.4719877243041992,
            "eval_matthews_correlation": 0.5600900419522739,
            "eval_runtime": 0.1585,
            "eval_samples_per_second": 6579.879,
            "eval_steps_per_second": 56.777,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.4138,
            "grad_norm": 2.1642587184906006,
            "learning_rate": 3.150912106135987e-05,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.5092188119888306,
            "eval_matthews_correlation": 0.5572552114140278,
            "eval_runtime": 0.1591,
            "eval_samples_per_second": 6554.778,
            "eval_steps_per_second": 56.561,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "train_runtime": 217.6587,
            "train_samples_per_second": 3928.627,
            "train_steps_per_second": 30.782,
            "total_flos": 2.0695972615028736e+16,
            "train_loss": 0.5234115473429362,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 1.3542183637619019,
            "eval_matthews_correlation": 0.5668277832443891,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6526.829,
            "eval_steps_per_second": 56.32,
            "epoch": 71.64179104477611,
            "step": 4800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "cola",
        "seed": 2024,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 217.6587,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656,
            358.726656
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}