{
    "eval_loss": 3.868644952774048,
    "eval_accuracy": 0.8431372549019608,
    "eval_f1": 0.8869257950530036,
    "eval_runtime": 0.0942,
    "eval_samples_per_second": 4330.93,
    "eval_steps_per_second": 42.46,
    "epoch": 68.96551724137932,
    "log_history": [
        {
            "loss": 1.3446,
            "grad_norm": 8.364911079406738,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 1.8437646627426147,
            "eval_accuracy": 0.8112745098039216,
            "eval_f1": 0.8718801996672212,
            "eval_runtime": 0.0897,
            "eval_samples_per_second": 4547.444,
            "eval_steps_per_second": 44.583,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.785,
            "grad_norm": 10.026150703430176,
            "learning_rate": 9.578544061302682e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 2.405029058456421,
            "eval_accuracy": 0.8235294117647058,
            "eval_f1": 0.8803986710963455,
            "eval_runtime": 0.0864,
            "eval_samples_per_second": 4722.416,
            "eval_steps_per_second": 46.298,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.5442,
            "grad_norm": 10.77120304107666,
            "learning_rate": 8.812260536398468e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 2.839411497116089,
            "eval_accuracy": 0.8627450980392157,
            "eval_f1": 0.9003558718861211,
            "eval_runtime": 0.0874,
            "eval_samples_per_second": 4665.585,
            "eval_steps_per_second": 45.741,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.3786,
            "grad_norm": 31.3956241607666,
            "learning_rate": 8.045977011494253e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 3.293968677520752,
            "eval_accuracy": 0.8553921568627451,
            "eval_f1": 0.8991452991452993,
            "eval_runtime": 0.086,
            "eval_samples_per_second": 4746.201,
            "eval_steps_per_second": 46.531,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.2759,
            "grad_norm": 17.891132354736328,
            "learning_rate": 7.279693486590039e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 3.6487131118774414,
            "eval_accuracy": 0.8627450980392157,
            "eval_f1": 0.903114186851211,
            "eval_runtime": 0.0866,
            "eval_samples_per_second": 4712.818,
            "eval_steps_per_second": 46.204,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.2014,
            "grad_norm": 12.871744155883789,
            "learning_rate": 6.513409961685824e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 3.75537109375,
            "eval_accuracy": 0.8627450980392157,
            "eval_f1": 0.9020979020979022,
            "eval_runtime": 0.0863,
            "eval_samples_per_second": 4725.363,
            "eval_steps_per_second": 46.327,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.1588,
            "grad_norm": 14.039529800415039,
            "learning_rate": 5.747126436781609e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 3.8675875663757324,
            "eval_accuracy": 0.8455882352941176,
            "eval_f1": 0.8888888888888888,
            "eval_runtime": 0.0845,
            "eval_samples_per_second": 4830.797,
            "eval_steps_per_second": 47.361,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.135,
            "grad_norm": 33.93098068237305,
            "learning_rate": 4.980842911877395e-05,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 3.8026251792907715,
            "eval_accuracy": 0.8455882352941176,
            "eval_f1": 0.8911917098445595,
            "eval_runtime": 0.0876,
            "eval_samples_per_second": 4655.343,
            "eval_steps_per_second": 45.641,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.107,
            "grad_norm": 10.974248886108398,
            "learning_rate": 4.21455938697318e-05,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 3.827547073364258,
            "eval_accuracy": 0.8553921568627451,
            "eval_f1": 0.8944543828264758,
            "eval_runtime": 0.0858,
            "eval_samples_per_second": 4754.231,
            "eval_steps_per_second": 46.61,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.0909,
            "grad_norm": 21.427473068237305,
            "learning_rate": 3.4482758620689657e-05,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 3.951160430908203,
            "eval_accuracy": 0.8431372549019608,
            "eval_f1": 0.8873239436619718,
            "eval_runtime": 0.088,
            "eval_samples_per_second": 4637.253,
            "eval_steps_per_second": 45.463,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "train_runtime": 125.8571,
            "train_samples_per_second": 2914.417,
            "train_steps_per_second": 23.042,
            "total_flos": 8652331742658560.0,
            "train_loss": 0.4021476001739502,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 3.868644952774048,
            "eval_accuracy": 0.8431372549019608,
            "eval_f1": 0.8869257950530036,
            "eval_runtime": 0.0942,
            "eval_samples_per_second": 4330.93,
            "eval_steps_per_second": 42.46,
            "epoch": 68.96551724137932,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "mrlora-lcoef",
        "rank": 16,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "roberta",
        "task": "mrpc",
        "seed": 42,
        "student_model_name": "./models/distilroberta-base",
        "teacher_model_name": "./models/roberta-base",
        "use_olora": false,
        "use_lcoef": true,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 125.8571,
        "trainable_params_count": 0.88709,
        "memory_allocated": [
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304,
            361.122304
        ],
        "memory_reserved": [
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336,
            1715.470336
        ]
    },
    "variant": "kd-lora"
}