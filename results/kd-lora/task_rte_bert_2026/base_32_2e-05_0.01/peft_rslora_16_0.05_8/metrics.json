{
    "eval_loss": 4.348100662231445,
    "eval_accuracy": 0.628158844765343,
    "eval_runtime": 0.0917,
    "eval_samples_per_second": 3020.183,
    "eval_steps_per_second": 32.71,
    "epoch": 100.0,
    "log_history": [
        {
            "loss": 1.5081,
            "grad_norm": 2.30732798576355,
            "learning_rate": 0.0001,
            "epoch": 10.0,
            "step": 200
        },
        {
            "eval_loss": 1.5902079343795776,
            "eval_accuracy": 0.555956678700361,
            "eval_runtime": 0.068,
            "eval_samples_per_second": 4071.854,
            "eval_steps_per_second": 44.1,
            "epoch": 10.0,
            "step": 200
        },
        {
            "loss": 1.1654,
            "grad_norm": 8.96444320678711,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 20.0,
            "step": 400
        },
        {
            "eval_loss": 2.042720317840576,
            "eval_accuracy": 0.5956678700361011,
            "eval_runtime": 0.0812,
            "eval_samples_per_second": 3410.133,
            "eval_steps_per_second": 36.933,
            "epoch": 20.0,
            "step": 400
        },
        {
            "loss": 0.7704,
            "grad_norm": 11.364445686340332,
            "learning_rate": 7.777777777777778e-05,
            "epoch": 30.0,
            "step": 600
        },
        {
            "eval_loss": 2.7109453678131104,
            "eval_accuracy": 0.6028880866425993,
            "eval_runtime": 0.1082,
            "eval_samples_per_second": 2559.717,
            "eval_steps_per_second": 27.723,
            "epoch": 30.0,
            "step": 600
        },
        {
            "loss": 0.5259,
            "grad_norm": 8.520727157592773,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 800
        },
        {
            "eval_loss": 3.306918144226074,
            "eval_accuracy": 0.6064981949458483,
            "eval_runtime": 0.1111,
            "eval_samples_per_second": 2494.016,
            "eval_steps_per_second": 27.011,
            "epoch": 40.0,
            "step": 800
        },
        {
            "loss": 0.3912,
            "grad_norm": 8.940330505371094,
            "learning_rate": 5.555555555555556e-05,
            "epoch": 50.0,
            "step": 1000
        },
        {
            "eval_loss": 3.663001775741577,
            "eval_accuracy": 0.6137184115523465,
            "eval_runtime": 0.0787,
            "eval_samples_per_second": 3519.756,
            "eval_steps_per_second": 38.12,
            "epoch": 50.0,
            "step": 1000
        },
        {
            "loss": 0.2881,
            "grad_norm": 7.7726311683654785,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 60.0,
            "step": 1200
        },
        {
            "eval_loss": 4.1448588371276855,
            "eval_accuracy": 0.6028880866425993,
            "eval_runtime": 0.0788,
            "eval_samples_per_second": 3514.56,
            "eval_steps_per_second": 38.064,
            "epoch": 60.0,
            "step": 1200
        },
        {
            "loss": 0.2398,
            "grad_norm": 9.449191093444824,
            "learning_rate": 3.3333333333333335e-05,
            "epoch": 70.0,
            "step": 1400
        },
        {
            "eval_loss": 4.348100662231445,
            "eval_accuracy": 0.628158844765343,
            "eval_runtime": 0.1004,
            "eval_samples_per_second": 2757.983,
            "eval_steps_per_second": 29.87,
            "epoch": 70.0,
            "step": 1400
        },
        {
            "loss": 0.2034,
            "grad_norm": 8.861797332763672,
            "learning_rate": 2.2222222222222223e-05,
            "epoch": 80.0,
            "step": 1600
        },
        {
            "eval_loss": 4.541845798492432,
            "eval_accuracy": 0.6137184115523465,
            "eval_runtime": 0.0987,
            "eval_samples_per_second": 2806.002,
            "eval_steps_per_second": 30.39,
            "epoch": 80.0,
            "step": 1600
        },
        {
            "loss": 0.1835,
            "grad_norm": 19.106426239013672,
            "learning_rate": 1.1111111111111112e-05,
            "epoch": 90.0,
            "step": 1800
        },
        {
            "eval_loss": 4.541415691375732,
            "eval_accuracy": 0.6028880866425993,
            "eval_runtime": 0.1151,
            "eval_samples_per_second": 2405.902,
            "eval_steps_per_second": 26.057,
            "epoch": 90.0,
            "step": 1800
        },
        {
            "loss": 0.166,
            "grad_norm": 10.233316421508789,
            "learning_rate": 0.0,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 4.638833999633789,
            "eval_accuracy": 0.6101083032490975,
            "eval_runtime": 0.0753,
            "eval_samples_per_second": 3680.368,
            "eval_steps_per_second": 39.86,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "train_runtime": 111.796,
            "train_samples_per_second": 2227.271,
            "train_steps_per_second": 17.89,
            "total_flos": 8623321922928640.0,
            "train_loss": 0.5441813774108887,
            "epoch": 100.0,
            "step": 2000
        },
        {
            "eval_loss": 4.348100662231445,
            "eval_accuracy": 0.628158844765343,
            "eval_runtime": 0.0917,
            "eval_samples_per_second": 3020.183,
            "eval_steps_per_second": 32.71,
            "epoch": 100.0,
            "step": 2000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "rte",
        "seed": 2026,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 2490
    },
    "train": {
        "train_time": 111.796,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016
        ],
        "memory_reserved": [
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344
        ]
    },
    "variant": "kd-lora"
}