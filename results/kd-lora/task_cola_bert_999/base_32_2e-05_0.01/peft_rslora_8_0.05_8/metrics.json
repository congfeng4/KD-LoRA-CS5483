{
    "eval_loss": 2.42254638671875,
    "eval_matthews_correlation": 0.5281412754154977,
    "eval_runtime": 0.1585,
    "eval_samples_per_second": 6580.899,
    "eval_steps_per_second": 56.786,
    "epoch": 41.791044776119406,
    "log_history": [
        {
            "loss": 1.4741,
            "grad_norm": 0.7562677264213562,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.477126121520996,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1543,
            "eval_samples_per_second": 6759.07,
            "eval_steps_per_second": 58.324,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.2482,
            "grad_norm": 1.9689140319824219,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.7963640689849854,
            "eval_matthews_correlation": 0.3791251444635796,
            "eval_runtime": 0.1544,
            "eval_samples_per_second": 6753.602,
            "eval_steps_per_second": 58.277,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1131,
            "grad_norm": 1.8441087007522583,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.7945899963378906,
            "eval_matthews_correlation": 0.4420560133836786,
            "eval_runtime": 0.1537,
            "eval_samples_per_second": 6787.563,
            "eval_steps_per_second": 58.57,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0319,
            "grad_norm": 3.2362632751464844,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.8681280612945557,
            "eval_matthews_correlation": 0.4759624503611039,
            "eval_runtime": 0.154,
            "eval_samples_per_second": 6770.734,
            "eval_steps_per_second": 58.424,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.9584,
            "grad_norm": 3.1998515129089355,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 2.0162150859832764,
            "eval_matthews_correlation": 0.4694118952751528,
            "eval_runtime": 0.1598,
            "eval_samples_per_second": 6524.95,
            "eval_steps_per_second": 56.303,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.8831,
            "grad_norm": 5.237644195556641,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.1575870513916016,
            "eval_matthews_correlation": 0.4846576381298429,
            "eval_runtime": 0.1523,
            "eval_samples_per_second": 6848.653,
            "eval_steps_per_second": 59.097,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.8386,
            "grad_norm": 4.739436149597168,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.1904540061950684,
            "eval_matthews_correlation": 0.5072784045554821,
            "eval_runtime": 0.1606,
            "eval_samples_per_second": 6495.652,
            "eval_steps_per_second": 56.051,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.7909,
            "grad_norm": 4.021053314208984,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.2995920181274414,
            "eval_matthews_correlation": 0.5039642659976749,
            "eval_runtime": 0.1537,
            "eval_samples_per_second": 6785.373,
            "eval_steps_per_second": 58.551,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.7342,
            "grad_norm": 5.8460187911987305,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.42254638671875,
            "eval_matthews_correlation": 0.5281412754154977,
            "eval_runtime": 0.1537,
            "eval_samples_per_second": 6784.363,
            "eval_steps_per_second": 58.542,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7039,
            "grad_norm": 4.195316314697266,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.499697208404541,
            "eval_matthews_correlation": 0.5067159264085137,
            "eval_runtime": 0.1568,
            "eval_samples_per_second": 6653.444,
            "eval_steps_per_second": 57.412,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.6705,
            "grad_norm": 8.200055122375488,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.5464606285095215,
            "eval_matthews_correlation": 0.5025517897100551,
            "eval_runtime": 0.154,
            "eval_samples_per_second": 6772.463,
            "eval_steps_per_second": 58.439,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.6396,
            "grad_norm": 4.42531156539917,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.606381893157959,
            "eval_matthews_correlation": 0.509687043672971,
            "eval_runtime": 0.1562,
            "eval_samples_per_second": 6676.789,
            "eval_steps_per_second": 57.614,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.614,
            "grad_norm": 5.84254264831543,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 2.6361083984375,
            "eval_matthews_correlation": 0.5104930835427627,
            "eval_runtime": 0.1551,
            "eval_samples_per_second": 6724.658,
            "eval_steps_per_second": 58.027,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.582,
            "grad_norm": 7.317796230316162,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.670879364013672,
            "eval_matthews_correlation": 0.5278612142968102,
            "eval_runtime": 0.1551,
            "eval_samples_per_second": 6724.358,
            "eval_steps_per_second": 58.024,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "train_runtime": 123.404,
            "train_samples_per_second": 6929.272,
            "train_steps_per_second": 54.293,
            "total_flos": 1.2072650692100096e+16,
            "train_loss": 0.8773312650408064,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 2.42254638671875,
            "eval_matthews_correlation": 0.5281412754154977,
            "eval_runtime": 0.1585,
            "eval_samples_per_second": 6580.899,
            "eval_steps_per_second": 56.786,
            "epoch": 41.791044776119406,
            "step": 2800
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "rslora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 123.404,
        "trainable_params_count": 0.739586,
        "memory_allocated": [
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016,
            297.686016
        ],
        "memory_reserved": [
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344
        ]
    },
    "variant": "kd-lora"
}