{
    "eval_loss": 2.086590528488159,
    "eval_matthews_correlation": 0.49816788996099576,
    "eval_runtime": 0.2029,
    "eval_samples_per_second": 5139.885,
    "eval_steps_per_second": 44.352,
    "epoch": 35.82089552238806,
    "log_history": [
        {
            "loss": 1.477,
            "grad_norm": 0.7473098635673523,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.4766185283660889,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2014,
            "eval_samples_per_second": 5179.502,
            "eval_steps_per_second": 44.694,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.3023,
            "grad_norm": 1.0869611501693726,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.74591064453125,
            "eval_matthews_correlation": 0.35291635752703904,
            "eval_runtime": 0.2061,
            "eval_samples_per_second": 5061.564,
            "eval_steps_per_second": 43.676,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 1.1521,
            "grad_norm": 1.112301230430603,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.7478584051132202,
            "eval_matthews_correlation": 0.43010813266156883,
            "eval_runtime": 0.2076,
            "eval_samples_per_second": 5024.803,
            "eval_steps_per_second": 43.359,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 1.0735,
            "grad_norm": 1.9887657165527344,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.7859241962432861,
            "eval_matthews_correlation": 0.4520739402545479,
            "eval_runtime": 0.1754,
            "eval_samples_per_second": 5945.882,
            "eval_steps_per_second": 51.307,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 1.0164,
            "grad_norm": 2.0545947551727295,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.9686837196350098,
            "eval_matthews_correlation": 0.45672417708659324,
            "eval_runtime": 0.2005,
            "eval_samples_per_second": 5203.257,
            "eval_steps_per_second": 44.899,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.9486,
            "grad_norm": 2.692753791809082,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 2.0771052837371826,
            "eval_matthews_correlation": 0.4778772791689758,
            "eval_runtime": 0.2021,
            "eval_samples_per_second": 5161.505,
            "eval_steps_per_second": 44.538,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.9052,
            "grad_norm": 2.3057503700256348,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 2.086590528488159,
            "eval_matthews_correlation": 0.49816788996099576,
            "eval_runtime": 0.1989,
            "eval_samples_per_second": 5244.728,
            "eval_steps_per_second": 45.257,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.8659,
            "grad_norm": 2.8368003368377686,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 2.161072015762329,
            "eval_matthews_correlation": 0.47933610275431493,
            "eval_runtime": 0.2056,
            "eval_samples_per_second": 5072.051,
            "eval_steps_per_second": 43.766,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.8127,
            "grad_norm": 2.6041910648345947,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 2.262800693511963,
            "eval_matthews_correlation": 0.4975566221061119,
            "eval_runtime": 0.2003,
            "eval_samples_per_second": 5208.436,
            "eval_steps_per_second": 44.943,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.7888,
            "grad_norm": 2.57484769821167,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 2.2889199256896973,
            "eval_matthews_correlation": 0.4948341053531188,
            "eval_runtime": 0.2009,
            "eval_samples_per_second": 5192.35,
            "eval_steps_per_second": 44.805,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.752,
            "grad_norm": 4.178954601287842,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 2.3924520015716553,
            "eval_matthews_correlation": 0.4833639583814578,
            "eval_runtime": 0.2012,
            "eval_samples_per_second": 5182.951,
            "eval_steps_per_second": 44.723,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.7248,
            "grad_norm": 2.813307762145996,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.4543867111206055,
            "eval_matthews_correlation": 0.4854632779262472,
            "eval_runtime": 0.2035,
            "eval_samples_per_second": 5125.468,
            "eval_steps_per_second": 44.227,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "train_runtime": 128.4947,
            "train_samples_per_second": 6654.747,
            "train_steps_per_second": 52.142,
            "total_flos": 1.0350160634707968e+16,
            "train_loss": 0.9849489720662435,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 2.086590528488159,
            "eval_matthews_correlation": 0.49816788996099576,
            "eval_runtime": 0.2029,
            "eval_samples_per_second": 5139.885,
            "eval_steps_per_second": 44.352,
            "epoch": 35.82089552238806,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "cola",
        "seed": 999,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 8551
    },
    "train": {
        "train_time": 128.4947,
        "trainable_params_count": 0.748802,
        "memory_allocated": [
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064,
            298.648064
        ],
        "memory_reserved": [
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912,
            1258.2912
        ]
    },
    "variant": "kd-lora"
}