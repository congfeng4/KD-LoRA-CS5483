{
    "eval_loss": 1.8234446048736572,
    "eval_matthews_correlation": 0.5961744294806522,
    "eval_runtime": 0.2861,
    "eval_samples_per_second": 3645.416,
    "eval_steps_per_second": 31.456,
    "epoch": 50.74626865671642,
    "log_history": [
        {
            "loss": 1.2022,
            "grad_norm": 0.3302256762981415,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 1.1666452884674072,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2759,
            "eval_samples_per_second": 3780.863,
            "eval_steps_per_second": 32.625,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 1.1239,
            "grad_norm": 0.8026761412620544,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 1.1565749645233154,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 3693.927,
            "eval_steps_per_second": 31.875,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.8604,
            "grad_norm": 1.4155535697937012,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 1.4316070079803467,
            "eval_matthews_correlation": 0.5049606016789446,
            "eval_runtime": 0.2807,
            "eval_samples_per_second": 3715.986,
            "eval_steps_per_second": 32.065,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.7299,
            "grad_norm": 1.2447930574417114,
            "learning_rate": 9.784411276948591e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 1.524132490158081,
            "eval_matthews_correlation": 0.536662198889055,
            "eval_runtime": 0.279,
            "eval_samples_per_second": 3738.408,
            "eval_steps_per_second": 32.259,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.6875,
            "grad_norm": 1.6099320650100708,
            "learning_rate": 9.452736318407961e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 1.5977522134780884,
            "eval_matthews_correlation": 0.5663656369027515,
            "eval_runtime": 0.2795,
            "eval_samples_per_second": 3731.759,
            "eval_steps_per_second": 32.201,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.6536,
            "grad_norm": 2.095834493637085,
            "learning_rate": 9.12106135986733e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 1.6903038024902344,
            "eval_matthews_correlation": 0.5626727648075698,
            "eval_runtime": 0.2828,
            "eval_samples_per_second": 3688.493,
            "eval_steps_per_second": 31.828,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.6266,
            "grad_norm": 2.3159639835357666,
            "learning_rate": 8.7893864013267e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 1.6771037578582764,
            "eval_matthews_correlation": 0.5762564573315502,
            "eval_runtime": 0.2786,
            "eval_samples_per_second": 3743.556,
            "eval_steps_per_second": 32.303,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.6059,
            "grad_norm": 3.014631986618042,
            "learning_rate": 8.45771144278607e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 1.7734339237213135,
            "eval_matthews_correlation": 0.5753011877541249,
            "eval_runtime": 0.2842,
            "eval_samples_per_second": 3670.447,
            "eval_steps_per_second": 31.672,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.5775,
            "grad_norm": 2.3466968536376953,
            "learning_rate": 8.126036484245439e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 1.7921772003173828,
            "eval_matthews_correlation": 0.5733495702281163,
            "eval_runtime": 0.283,
            "eval_samples_per_second": 3685.556,
            "eval_steps_per_second": 31.802,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.5601,
            "grad_norm": 2.0178415775299072,
            "learning_rate": 7.794361525704809e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 1.7888078689575195,
            "eval_matthews_correlation": 0.5813817583744711,
            "eval_runtime": 0.285,
            "eval_samples_per_second": 3659.801,
            "eval_steps_per_second": 31.58,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.541,
            "grad_norm": 1.2937085628509521,
            "learning_rate": 7.46268656716418e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 1.808135986328125,
            "eval_matthews_correlation": 0.5864941797290588,
            "eval_runtime": 0.3302,
            "eval_samples_per_second": 3159.032,
            "eval_steps_per_second": 27.259,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.535,
            "grad_norm": 1.3806339502334595,
            "learning_rate": 7.13101160862355e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 1.8234446048736572,
            "eval_matthews_correlation": 0.5961744294806522,
            "eval_runtime": 0.2824,
            "eval_samples_per_second": 3693.014,
            "eval_steps_per_second": 31.867,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.5133,
            "grad_norm": 1.5464547872543335,
            "learning_rate": 6.79933665008292e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 1.851723074913025,
            "eval_matthews_correlation": 0.5792266130251226,
            "eval_runtime": 0.2838,
            "eval_samples_per_second": 3674.711,
            "eval_steps_per_second": 31.709,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.5046,
            "grad_norm": 1.7285741567611694,
            "learning_rate": 6.46766169154229e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 1.877097725868225,
            "eval_matthews_correlation": 0.5936351080219947,
            "eval_runtime": 0.2833,
            "eval_samples_per_second": 3681.889,
            "eval_steps_per_second": 31.771,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.5005,
            "grad_norm": 2.0480918884277344,
            "learning_rate": 6.135986733001658e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 1.8779765367507935,
            "eval_matthews_correlation": 0.5863126487431982,
            "eval_runtime": 0.2846,
            "eval_samples_per_second": 3665.228,
            "eval_steps_per_second": 31.627,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.4901,
            "grad_norm": 3.004690408706665,
            "learning_rate": 5.8043117744610286e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 1.8703596591949463,
            "eval_matthews_correlation": 0.5839395532441031,
            "eval_runtime": 0.2813,
            "eval_samples_per_second": 3707.502,
            "eval_steps_per_second": 31.992,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.4742,
            "grad_norm": 1.7906054258346558,
            "learning_rate": 5.472636815920398e-05,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.9070910215377808,
            "eval_matthews_correlation": 0.5892439733711194,
            "eval_runtime": 0.281,
            "eval_samples_per_second": 3711.216,
            "eval_steps_per_second": 32.024,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "train_runtime": 234.0832,
            "train_samples_per_second": 3652.975,
            "train_steps_per_second": 28.622,
            "total_flos": 1.4465845258354688e+16,
            "train_loss": 0.658018071791705,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 1.8234446048736572,
            "eval_matthews_correlation": 0.5961744294806522,
            "eval_runtime": 0.2861,
            "eval_samples_per_second": 3645.416,
            "eval_steps_per_second": 31.456,
            "epoch": 50.74626865671642,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "dora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "cola",
        "seed": 2026,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 8551
    },
    "train": {
        "train_time": 234.0832,
        "trainable_params_count": 0.15821,
        "memory_allocated": [
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544,
            588.268544
        ],
        "memory_reserved": [
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288,
            2818.572288
        ]
    },
    "variant": "kd-lora"
}