{
    "eval_loss": 2.542701244354248,
    "eval_pearson": 0.8565782892932546,
    "eval_spearman": 0.8542695936810795,
    "eval_runtime": 0.206,
    "eval_samples_per_second": 7282.789,
    "eval_steps_per_second": 58.262,
    "epoch": 53.333333333333336,
    "log_history": [
        {
            "loss": 5.1884,
            "grad_norm": 6.343475341796875,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.566896915435791,
            "eval_pearson": 0.38510653306495835,
            "eval_spearman": 0.36551456269802457,
            "eval_runtime": 0.1823,
            "eval_samples_per_second": 8229.117,
            "eval_steps_per_second": 65.833,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.2952,
            "grad_norm": 7.539543151855469,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.4394021034240723,
            "eval_pearson": 0.8162569653214792,
            "eval_spearman": 0.8173065667554347,
            "eval_runtime": 0.1825,
            "eval_samples_per_second": 8218.399,
            "eval_steps_per_second": 65.747,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.7937,
            "grad_norm": 1.7937947511672974,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 2.466165542602539,
            "eval_pearson": 0.8392603558398999,
            "eval_spearman": 0.8374346311554058,
            "eval_runtime": 0.2073,
            "eval_samples_per_second": 7236.491,
            "eval_steps_per_second": 57.892,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6998,
            "grad_norm": 4.1961798667907715,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.478353261947632,
            "eval_pearson": 0.84519130066755,
            "eval_spearman": 0.8431935531108397,
            "eval_runtime": 0.2044,
            "eval_samples_per_second": 7339.765,
            "eval_steps_per_second": 58.718,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.6376,
            "grad_norm": 3.0170652866363525,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.4733238220214844,
            "eval_pearson": 0.8515513367170109,
            "eval_spearman": 0.8492208005805609,
            "eval_runtime": 0.2073,
            "eval_samples_per_second": 7236.366,
            "eval_steps_per_second": 57.891,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.5946,
            "grad_norm": 2.3680508136749268,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.5454232692718506,
            "eval_pearson": 0.8529498484408212,
            "eval_spearman": 0.851048640477315,
            "eval_runtime": 0.2048,
            "eval_samples_per_second": 7325.527,
            "eval_steps_per_second": 58.604,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.5543,
            "grad_norm": 2.8617444038391113,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.436582088470459,
            "eval_pearson": 0.8550991783029955,
            "eval_spearman": 0.8532743580674382,
            "eval_runtime": 0.2072,
            "eval_samples_per_second": 7238.04,
            "eval_steps_per_second": 57.904,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.5215,
            "grad_norm": 1.9167495965957642,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.542701244354248,
            "eval_pearson": 0.8565782892932546,
            "eval_spearman": 0.8542695936810795,
            "eval_runtime": 0.2039,
            "eval_samples_per_second": 7356.991,
            "eval_steps_per_second": 58.856,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.4854,
            "grad_norm": 3.153730630874634,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.473465919494629,
            "eval_pearson": 0.8550872209521851,
            "eval_spearman": 0.8534098338671545,
            "eval_runtime": 0.2039,
            "eval_samples_per_second": 7357.92,
            "eval_steps_per_second": 58.863,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.4694,
            "grad_norm": 4.215439319610596,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.475674867630005,
            "eval_pearson": 0.8546892291367064,
            "eval_spearman": 0.8530316930607862,
            "eval_runtime": 0.2042,
            "eval_samples_per_second": 7344.143,
            "eval_steps_per_second": 58.753,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.4446,
            "grad_norm": 4.694937705993652,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.461883783340454,
            "eval_pearson": 0.8518223287772612,
            "eval_spearman": 0.8506313610646539,
            "eval_runtime": 0.2067,
            "eval_samples_per_second": 7256.682,
            "eval_steps_per_second": 58.053,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.4222,
            "grad_norm": 1.8383954763412476,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.483978509902954,
            "eval_pearson": 0.8513110926986912,
            "eval_spearman": 0.8500822148256164,
            "eval_runtime": 0.2095,
            "eval_samples_per_second": 7159.185,
            "eval_steps_per_second": 57.273,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "train_runtime": 103.7739,
            "train_samples_per_second": 5539.93,
            "train_steps_per_second": 43.364,
            "total_flos": 1.0347623919648768e+16,
            "train_loss": 1.0088774013519286,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.542701244354248,
            "eval_pearson": 0.8565782892932546,
            "eval_spearman": 0.8542695936810795,
            "eval_runtime": 0.206,
            "eval_samples_per_second": 7282.789,
            "eval_steps_per_second": 58.262,
            "epoch": 53.333333333333336,
            "step": 2400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "lora",
        "rank": 8,
        "lora_alpha": 8,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "bert",
        "task": "stsb",
        "seed": 2024,
        "student_model_name": "./models/distilbert-base-uncased",
        "teacher_model_name": "./models/bert-base-uncased",
        "train_size": 5749
    },
    "train": {
        "train_time": 103.7739,
        "trainable_params_count": 0.738817,
        "memory_allocated": [
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088,
            298.457088
        ],
        "memory_reserved": [
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344,
            1094.713344
        ]
    },
    "variant": "kd-lora"
}