{
    "eval_loss": 2.898728847503662,
    "eval_pearson": 0.890621349723829,
    "eval_spearman": 0.8889200991214576,
    "eval_runtime": 0.3478,
    "eval_samples_per_second": 4313.264,
    "eval_steps_per_second": 34.506,
    "epoch": 57.77777777777778,
    "log_history": [
        {
            "loss": 8.0881,
            "grad_norm": 11.863314628601074,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 2.6366641521453857,
            "eval_pearson": 0.15905963936375728,
            "eval_spearman": 0.15464222189023266,
            "eval_runtime": 0.3031,
            "eval_samples_per_second": 4948.389,
            "eval_steps_per_second": 39.587,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 1.3817,
            "grad_norm": 19.293306350708008,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.9254648685455322,
            "eval_pearson": 0.8549614146256821,
            "eval_spearman": 0.8579438757650869,
            "eval_runtime": 0.3134,
            "eval_samples_per_second": 4785.578,
            "eval_steps_per_second": 38.285,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 0.7163,
            "grad_norm": 10.787463188171387,
            "learning_rate": 9.62962962962963e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 3.134953737258911,
            "eval_pearson": 0.8743708841590874,
            "eval_spearman": 0.8737605447970003,
            "eval_runtime": 0.3026,
            "eval_samples_per_second": 4957.162,
            "eval_steps_per_second": 39.657,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.564,
            "grad_norm": 4.3521199226379395,
            "learning_rate": 9.135802469135802e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 2.9240972995758057,
            "eval_pearson": 0.8764928860839075,
            "eval_spearman": 0.8763368021764846,
            "eval_runtime": 0.3032,
            "eval_samples_per_second": 4947.089,
            "eval_steps_per_second": 39.577,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.4687,
            "grad_norm": 2.6133131980895996,
            "learning_rate": 8.641975308641975e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 2.864882230758667,
            "eval_pearson": 0.885138703732765,
            "eval_spearman": 0.8835774688596246,
            "eval_runtime": 0.3017,
            "eval_samples_per_second": 4972.276,
            "eval_steps_per_second": 39.778,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.4213,
            "grad_norm": 4.933271884918213,
            "learning_rate": 8.148148148148148e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 2.8387057781219482,
            "eval_pearson": 0.8854940953380767,
            "eval_spearman": 0.8844086915233652,
            "eval_runtime": 0.365,
            "eval_samples_per_second": 4109.828,
            "eval_steps_per_second": 32.879,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.376,
            "grad_norm": 3.288083553314209,
            "learning_rate": 7.65432098765432e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 2.8342959880828857,
            "eval_pearson": 0.8870489956703587,
            "eval_spearman": 0.8855377046125934,
            "eval_runtime": 0.3002,
            "eval_samples_per_second": 4996.808,
            "eval_steps_per_second": 39.974,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.3484,
            "grad_norm": 5.532542705535889,
            "learning_rate": 7.160493827160494e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 2.9785797595977783,
            "eval_pearson": 0.888318258386687,
            "eval_spearman": 0.8885652249428208,
            "eval_runtime": 0.3005,
            "eval_samples_per_second": 4991.044,
            "eval_steps_per_second": 39.928,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.3208,
            "grad_norm": 3.4925954341888428,
            "learning_rate": 6.666666666666667e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 2.942432403564453,
            "eval_pearson": 0.8876168161447537,
            "eval_spearman": 0.8860957528741185,
            "eval_runtime": 0.3043,
            "eval_samples_per_second": 4929.978,
            "eval_steps_per_second": 39.44,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.3005,
            "grad_norm": 7.182427406311035,
            "learning_rate": 6.17283950617284e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 2.8461902141571045,
            "eval_pearson": 0.8906394973851475,
            "eval_spearman": 0.8877035214935796,
            "eval_runtime": 0.3112,
            "eval_samples_per_second": 4819.765,
            "eval_steps_per_second": 38.558,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.2893,
            "grad_norm": 2.6567766666412354,
            "learning_rate": 5.679012345679012e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 2.9320435523986816,
            "eval_pearson": 0.8904561090837001,
            "eval_spearman": 0.8888069723189089,
            "eval_runtime": 0.3538,
            "eval_samples_per_second": 4239.254,
            "eval_steps_per_second": 33.914,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.2712,
            "grad_norm": 2.250206470489502,
            "learning_rate": 5.185185185185185e-05,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 2.880016565322876,
            "eval_pearson": 0.8888660768840626,
            "eval_spearman": 0.8883116736079871,
            "eval_runtime": 0.3017,
            "eval_samples_per_second": 4971.161,
            "eval_steps_per_second": 39.769,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.2584,
            "grad_norm": 3.432504892349243,
            "learning_rate": 4.691358024691358e-05,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.898728847503662,
            "eval_pearson": 0.890621349723829,
            "eval_spearman": 0.8889200991214576,
            "eval_runtime": 0.3476,
            "eval_samples_per_second": 4314.696,
            "eval_steps_per_second": 34.518,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "train_runtime": 163.4906,
            "train_samples_per_second": 3516.409,
            "train_steps_per_second": 27.525,
            "total_flos": 1.1097057192312832e+16,
            "train_loss": 1.0619001491253193,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 2.898728847503662,
            "eval_pearson": 0.890621349723829,
            "eval_spearman": 0.8889200991214576,
            "eval_runtime": 0.3478,
            "eval_samples_per_second": 4313.264,
            "eval_steps_per_second": 34.506,
            "epoch": 57.77777777777778,
            "step": 2600
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./results",
        "use_rslora": false,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "num_train_epochs": 100,
        "peft": "olora",
        "rank": 16,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "type": 1,
        "model_family": "deberta",
        "task": "stsb",
        "seed": 123,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "train_size": 5749
    },
    "train": {
        "train_time": 163.4906,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472,
            590.825472
        ],
        "memory_reserved": [
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976,
            2648.702976
        ]
    },
    "variant": "kd-lora"
}