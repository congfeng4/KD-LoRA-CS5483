{
    "teacher_model_name": "./models/bert-base-uncased",
    "student_model_name": "./models/distilbert-base-uncased",
    "dataset_path": "./dataset",
    "train_batch_size": 32,
    "eval_batch_size": 32,
    "num_train_epochs": 3,
    "weight_decay": 0.01,
    "dir_name": "./results",
    "rank": 8,
    "lora_alpha": 16,
    "lora_dropout": 0.05,
    "teacher_learning_rate": 5e-05,
    "student_learning_rate": 0.0005,
    "task": "qnli",
    "peft": "lora",
    "model_family": "bert",
    "seed": 42,
    "teacher_fft_results": {
        "eval_loss": 0.36783942580223083,
        "eval_accuracy": 0.9093904448105437,
        "eval_runtime": 48.1275,
        "eval_samples_per_second": 113.511,
        "eval_steps_per_second": 3.553,
        "epoch": 3.0,
        "log_history": [
            {
                "loss": 0.5765,
                "grad_norm": 4.824987888336182,
                "learning_rate": 4.9490938709020565e-05,
                "epoch": 0.030543677458766034,
                "step": 100
            },
            {
                "loss": 0.4847,
                "grad_norm": 4.792031288146973,
                "learning_rate": 4.8981877418041134e-05,
                "epoch": 0.06108735491753207,
                "step": 200
            },
            {
                "loss": 0.4509,
                "grad_norm": 3.1509761810302734,
                "learning_rate": 4.8472816127061696e-05,
                "epoch": 0.0916310323762981,
                "step": 300
            },
            {
                "loss": 0.4622,
                "grad_norm": 6.785139083862305,
                "learning_rate": 4.7963754836082265e-05,
                "epoch": 0.12217470983506414,
                "step": 400
            },
            {
                "loss": 0.4303,
                "grad_norm": 7.268479824066162,
                "learning_rate": 4.7454693545102835e-05,
                "epoch": 0.15271838729383017,
                "step": 500
            },
            {
                "loss": 0.4182,
                "grad_norm": 6.00384521484375,
                "learning_rate": 4.6945632254123404e-05,
                "epoch": 0.1832620647525962,
                "step": 600
            },
            {
                "loss": 0.4032,
                "grad_norm": 4.915760517120361,
                "learning_rate": 4.6436570963143966e-05,
                "epoch": 0.21380574221136225,
                "step": 700
            },
            {
                "loss": 0.4022,
                "grad_norm": 3.7919788360595703,
                "learning_rate": 4.592750967216453e-05,
                "epoch": 0.24434941967012827,
                "step": 800
            },
            {
                "loss": 0.3915,
                "grad_norm": 5.627535820007324,
                "learning_rate": 4.54184483811851e-05,
                "epoch": 0.2748930971288943,
                "step": 900
            },
            {
                "loss": 0.373,
                "grad_norm": 5.970383167266846,
                "learning_rate": 4.490938709020566e-05,
                "epoch": 0.30543677458766033,
                "step": 1000
            },
            {
                "loss": 0.37,
                "grad_norm": 6.545066833496094,
                "learning_rate": 4.440032579922623e-05,
                "epoch": 0.3359804520464264,
                "step": 1100
            },
            {
                "loss": 0.3584,
                "grad_norm": 5.229125499725342,
                "learning_rate": 4.389126450824679e-05,
                "epoch": 0.3665241295051924,
                "step": 1200
            },
            {
                "loss": 0.3622,
                "grad_norm": 4.985395431518555,
                "learning_rate": 4.338220321726736e-05,
                "epoch": 0.39706780696395844,
                "step": 1300
            },
            {
                "loss": 0.3464,
                "grad_norm": 2.4267659187316895,
                "learning_rate": 4.287314192628793e-05,
                "epoch": 0.4276114844227245,
                "step": 1400
            },
            {
                "loss": 0.3285,
                "grad_norm": 3.358224868774414,
                "learning_rate": 4.236408063530849e-05,
                "epoch": 0.4581551618814905,
                "step": 1500
            },
            {
                "loss": 0.341,
                "grad_norm": 6.022531509399414,
                "learning_rate": 4.185501934432906e-05,
                "epoch": 0.48869883934025654,
                "step": 1600
            },
            {
                "loss": 0.3622,
                "grad_norm": 6.466411590576172,
                "learning_rate": 4.1345958053349623e-05,
                "epoch": 0.5192425167990226,
                "step": 1700
            },
            {
                "loss": 0.3497,
                "grad_norm": 4.040899276733398,
                "learning_rate": 4.083689676237019e-05,
                "epoch": 0.5497861942577886,
                "step": 1800
            },
            {
                "loss": 0.3131,
                "grad_norm": 4.209141731262207,
                "learning_rate": 4.0327835471390755e-05,
                "epoch": 0.5803298717165547,
                "step": 1900
            },
            {
                "loss": 0.3259,
                "grad_norm": 7.261871337890625,
                "learning_rate": 3.9818774180411324e-05,
                "epoch": 0.6108735491753207,
                "step": 2000
            },
            {
                "loss": 0.3289,
                "grad_norm": 7.865565776824951,
                "learning_rate": 3.9309712889431886e-05,
                "epoch": 0.6414172266340867,
                "step": 2100
            },
            {
                "loss": 0.3226,
                "grad_norm": 4.739218711853027,
                "learning_rate": 3.8800651598452456e-05,
                "epoch": 0.6719609040928528,
                "step": 2200
            },
            {
                "loss": 0.3213,
                "grad_norm": 9.240801811218262,
                "learning_rate": 3.8291590307473025e-05,
                "epoch": 0.7025045815516188,
                "step": 2300
            },
            {
                "loss": 0.3059,
                "grad_norm": 4.2126030921936035,
                "learning_rate": 3.778252901649359e-05,
                "epoch": 0.7330482590103848,
                "step": 2400
            },
            {
                "loss": 0.3116,
                "grad_norm": 4.917595386505127,
                "learning_rate": 3.7273467725514156e-05,
                "epoch": 0.7635919364691509,
                "step": 2500
            },
            {
                "loss": 0.3065,
                "grad_norm": 4.66594934463501,
                "learning_rate": 3.676440643453472e-05,
                "epoch": 0.7941356139279169,
                "step": 2600
            },
            {
                "loss": 0.2989,
                "grad_norm": 5.482423305511475,
                "learning_rate": 3.625534514355529e-05,
                "epoch": 0.8246792913866829,
                "step": 2700
            },
            {
                "loss": 0.3081,
                "grad_norm": 8.25089168548584,
                "learning_rate": 3.574628385257585e-05,
                "epoch": 0.855222968845449,
                "step": 2800
            },
            {
                "loss": 0.3131,
                "grad_norm": 3.5315423011779785,
                "learning_rate": 3.523722256159642e-05,
                "epoch": 0.885766646304215,
                "step": 2900
            },
            {
                "loss": 0.3098,
                "grad_norm": 4.768542766571045,
                "learning_rate": 3.472816127061698e-05,
                "epoch": 0.916310323762981,
                "step": 3000
            },
            {
                "loss": 0.2966,
                "grad_norm": 7.78577184677124,
                "learning_rate": 3.421909997963755e-05,
                "epoch": 0.9468540012217471,
                "step": 3100
            },
            {
                "loss": 0.2824,
                "grad_norm": 5.0096845626831055,
                "learning_rate": 3.371003868865812e-05,
                "epoch": 0.9773976786805131,
                "step": 3200
            },
            {
                "eval_loss": 0.2432880997657776,
                "eval_accuracy": 0.899505766062603,
                "eval_runtime": 50.2702,
                "eval_samples_per_second": 108.673,
                "eval_steps_per_second": 3.402,
                "epoch": 1.0,
                "step": 3274
            },
            {
                "loss": 0.2888,
                "grad_norm": 7.439581394195557,
                "learning_rate": 3.320097739767868e-05,
                "epoch": 1.0079413561392792,
                "step": 3300
            },
            {
                "loss": 0.1935,
                "grad_norm": 7.819731712341309,
                "learning_rate": 3.269191610669925e-05,
                "epoch": 1.0384850335980451,
                "step": 3400
            },
            {
                "loss": 0.1771,
                "grad_norm": 8.666839599609375,
                "learning_rate": 3.2182854815719814e-05,
                "epoch": 1.0690287110568113,
                "step": 3500
            },
            {
                "loss": 0.2141,
                "grad_norm": 4.217732906341553,
                "learning_rate": 3.167379352474038e-05,
                "epoch": 1.0995723885155773,
                "step": 3600
            },
            {
                "loss": 0.1857,
                "grad_norm": 5.816868782043457,
                "learning_rate": 3.1164732233760945e-05,
                "epoch": 1.1301160659743432,
                "step": 3700
            },
            {
                "loss": 0.1857,
                "grad_norm": 3.324172019958496,
                "learning_rate": 3.0655670942781514e-05,
                "epoch": 1.1606597434331094,
                "step": 3800
            },
            {
                "loss": 0.1943,
                "grad_norm": 6.541082859039307,
                "learning_rate": 3.0146609651802077e-05,
                "epoch": 1.1912034208918754,
                "step": 3900
            },
            {
                "loss": 0.1799,
                "grad_norm": 7.219082832336426,
                "learning_rate": 2.9637548360822642e-05,
                "epoch": 1.2217470983506413,
                "step": 4000
            },
            {
                "loss": 0.2037,
                "grad_norm": 4.260965824127197,
                "learning_rate": 2.9128487069843208e-05,
                "epoch": 1.2522907758094075,
                "step": 4100
            },
            {
                "loss": 0.1835,
                "grad_norm": 1.906388759613037,
                "learning_rate": 2.8619425778863777e-05,
                "epoch": 1.2828344532681735,
                "step": 4200
            },
            {
                "loss": 0.1888,
                "grad_norm": 7.5193915367126465,
                "learning_rate": 2.8110364487884343e-05,
                "epoch": 1.3133781307269397,
                "step": 4300
            },
            {
                "loss": 0.1771,
                "grad_norm": 4.586146354675293,
                "learning_rate": 2.760130319690491e-05,
                "epoch": 1.3439218081857056,
                "step": 4400
            },
            {
                "loss": 0.2003,
                "grad_norm": 7.687280654907227,
                "learning_rate": 2.7092241905925474e-05,
                "epoch": 1.3744654856444716,
                "step": 4500
            },
            {
                "loss": 0.1983,
                "grad_norm": 6.199924945831299,
                "learning_rate": 2.658318061494604e-05,
                "epoch": 1.4050091631032378,
                "step": 4600
            },
            {
                "loss": 0.1837,
                "grad_norm": 10.057055473327637,
                "learning_rate": 2.6074119323966606e-05,
                "epoch": 1.4355528405620037,
                "step": 4700
            },
            {
                "loss": 0.21,
                "grad_norm": 4.495954990386963,
                "learning_rate": 2.556505803298717e-05,
                "epoch": 1.4660965180207697,
                "step": 4800
            },
            {
                "loss": 0.1932,
                "grad_norm": 8.175533294677734,
                "learning_rate": 2.5055996742007737e-05,
                "epoch": 1.4966401954795359,
                "step": 4900
            },
            {
                "loss": 0.1896,
                "grad_norm": 7.707575798034668,
                "learning_rate": 2.4546935451028307e-05,
                "epoch": 1.5271838729383018,
                "step": 5000
            },
            {
                "loss": 0.1741,
                "grad_norm": 5.820305824279785,
                "learning_rate": 2.403787416004887e-05,
                "epoch": 1.5577275503970678,
                "step": 5100
            },
            {
                "loss": 0.1814,
                "grad_norm": 8.099200248718262,
                "learning_rate": 2.3528812869069435e-05,
                "epoch": 1.588271227855834,
                "step": 5200
            },
            {
                "loss": 0.1809,
                "grad_norm": 7.212009429931641,
                "learning_rate": 2.3019751578090004e-05,
                "epoch": 1.6188149053146,
                "step": 5300
            },
            {
                "loss": 0.1913,
                "grad_norm": 4.769258499145508,
                "learning_rate": 2.251069028711057e-05,
                "epoch": 1.6493585827733659,
                "step": 5400
            },
            {
                "loss": 0.1627,
                "grad_norm": 9.886427879333496,
                "learning_rate": 2.2001628996131135e-05,
                "epoch": 1.679902260232132,
                "step": 5500
            },
            {
                "loss": 0.1961,
                "grad_norm": 4.0775227546691895,
                "learning_rate": 2.14925677051517e-05,
                "epoch": 1.710445937690898,
                "step": 5600
            },
            {
                "loss": 0.1946,
                "grad_norm": 4.991321563720703,
                "learning_rate": 2.098350641417227e-05,
                "epoch": 1.740989615149664,
                "step": 5700
            },
            {
                "loss": 0.1755,
                "grad_norm": 6.589201927185059,
                "learning_rate": 2.0474445123192832e-05,
                "epoch": 1.7715332926084302,
                "step": 5800
            },
            {
                "loss": 0.1837,
                "grad_norm": 4.4850172996521,
                "learning_rate": 1.9965383832213398e-05,
                "epoch": 1.8020769700671961,
                "step": 5900
            },
            {
                "loss": 0.1842,
                "grad_norm": 9.88807487487793,
                "learning_rate": 1.9456322541233964e-05,
                "epoch": 1.832620647525962,
                "step": 6000
            },
            {
                "loss": 0.1786,
                "grad_norm": 4.287905693054199,
                "learning_rate": 1.894726125025453e-05,
                "epoch": 1.8631643249847283,
                "step": 6100
            },
            {
                "loss": 0.1677,
                "grad_norm": 2.872436285018921,
                "learning_rate": 1.84381999592751e-05,
                "epoch": 1.8937080024434942,
                "step": 6200
            },
            {
                "loss": 0.1908,
                "grad_norm": 3.4089415073394775,
                "learning_rate": 1.7929138668295665e-05,
                "epoch": 1.9242516799022602,
                "step": 6300
            },
            {
                "loss": 0.1957,
                "grad_norm": 3.093609094619751,
                "learning_rate": 1.742007737731623e-05,
                "epoch": 1.9547953573610264,
                "step": 6400
            },
            {
                "loss": 0.183,
                "grad_norm": 3.9364688396453857,
                "learning_rate": 1.6911016086336796e-05,
                "epoch": 1.9853390348197923,
                "step": 6500
            },
            {
                "eval_loss": 0.26223617792129517,
                "eval_accuracy": 0.9114039904814205,
                "eval_runtime": 47.3222,
                "eval_samples_per_second": 115.443,
                "eval_steps_per_second": 3.614,
                "epoch": 2.0,
                "step": 6548
            },
            {
                "loss": 0.1149,
                "grad_norm": 2.1708672046661377,
                "learning_rate": 1.6401954795357362e-05,
                "epoch": 2.0158827122785583,
                "step": 6600
            },
            {
                "loss": 0.0787,
                "grad_norm": 4.273773670196533,
                "learning_rate": 1.5892893504377928e-05,
                "epoch": 2.0464263897373245,
                "step": 6700
            },
            {
                "loss": 0.0831,
                "grad_norm": 15.125836372375488,
                "learning_rate": 1.5383832213398493e-05,
                "epoch": 2.0769700671960902,
                "step": 6800
            },
            {
                "loss": 0.0853,
                "grad_norm": 6.604144096374512,
                "learning_rate": 1.4874770922419059e-05,
                "epoch": 2.1075137446548564,
                "step": 6900
            },
            {
                "loss": 0.0815,
                "grad_norm": 11.016403198242188,
                "learning_rate": 1.4365709631439625e-05,
                "epoch": 2.1380574221136226,
                "step": 7000
            },
            {
                "loss": 0.0763,
                "grad_norm": 6.971714973449707,
                "learning_rate": 1.3856648340460194e-05,
                "epoch": 2.1686010995723883,
                "step": 7100
            },
            {
                "loss": 0.1007,
                "grad_norm": 0.7327275276184082,
                "learning_rate": 1.3347587049480758e-05,
                "epoch": 2.1991447770311545,
                "step": 7200
            },
            {
                "loss": 0.0816,
                "grad_norm": 13.634459495544434,
                "learning_rate": 1.2838525758501324e-05,
                "epoch": 2.2296884544899207,
                "step": 7300
            },
            {
                "loss": 0.0843,
                "grad_norm": 14.806649208068848,
                "learning_rate": 1.232946446752189e-05,
                "epoch": 2.2602321319486864,
                "step": 7400
            },
            {
                "loss": 0.0759,
                "grad_norm": 0.22515597939491272,
                "learning_rate": 1.1820403176542457e-05,
                "epoch": 2.2907758094074526,
                "step": 7500
            },
            {
                "loss": 0.0887,
                "grad_norm": 3.1413416862487793,
                "learning_rate": 1.1311341885563023e-05,
                "epoch": 2.321319486866219,
                "step": 7600
            },
            {
                "loss": 0.0703,
                "grad_norm": 2.6617813110351562,
                "learning_rate": 1.0802280594583588e-05,
                "epoch": 2.3518631643249845,
                "step": 7700
            },
            {
                "loss": 0.1018,
                "grad_norm": 4.768725395202637,
                "learning_rate": 1.0293219303604154e-05,
                "epoch": 2.3824068417837507,
                "step": 7800
            },
            {
                "loss": 0.0782,
                "grad_norm": 1.269933819770813,
                "learning_rate": 9.784158012624722e-06,
                "epoch": 2.412950519242517,
                "step": 7900
            },
            {
                "loss": 0.0951,
                "grad_norm": 16.250682830810547,
                "learning_rate": 9.275096721645286e-06,
                "epoch": 2.4434941967012827,
                "step": 8000
            },
            {
                "loss": 0.096,
                "grad_norm": 10.966548919677734,
                "learning_rate": 8.766035430665853e-06,
                "epoch": 2.474037874160049,
                "step": 8100
            },
            {
                "loss": 0.0943,
                "grad_norm": 6.8954758644104,
                "learning_rate": 8.256974139686419e-06,
                "epoch": 2.504581551618815,
                "step": 8200
            },
            {
                "loss": 0.0799,
                "grad_norm": 15.76633071899414,
                "learning_rate": 7.747912848706985e-06,
                "epoch": 2.5351252290775808,
                "step": 8300
            },
            {
                "loss": 0.0919,
                "grad_norm": 9.637504577636719,
                "learning_rate": 7.238851557727551e-06,
                "epoch": 2.565668906536347,
                "step": 8400
            },
            {
                "loss": 0.1113,
                "grad_norm": 11.289158821105957,
                "learning_rate": 6.729790266748116e-06,
                "epoch": 2.596212583995113,
                "step": 8500
            },
            {
                "loss": 0.0708,
                "grad_norm": 4.540356159210205,
                "learning_rate": 6.2207289757686834e-06,
                "epoch": 2.6267562614538793,
                "step": 8600
            },
            {
                "loss": 0.0795,
                "grad_norm": 6.829370498657227,
                "learning_rate": 5.711667684789248e-06,
                "epoch": 2.657299938912645,
                "step": 8700
            },
            {
                "loss": 0.0762,
                "grad_norm": 9.919584274291992,
                "learning_rate": 5.202606393809815e-06,
                "epoch": 2.6878436163714112,
                "step": 8800
            },
            {
                "loss": 0.0818,
                "grad_norm": 7.549149036407471,
                "learning_rate": 4.693545102830381e-06,
                "epoch": 2.718387293830177,
                "step": 8900
            },
            {
                "loss": 0.0866,
                "grad_norm": 7.2999067306518555,
                "learning_rate": 4.184483811850947e-06,
                "epoch": 2.748930971288943,
                "step": 9000
            },
            {
                "loss": 0.0973,
                "grad_norm": 13.509136199951172,
                "learning_rate": 3.675422520871513e-06,
                "epoch": 2.7794746487477093,
                "step": 9100
            },
            {
                "loss": 0.0925,
                "grad_norm": 10.674516677856445,
                "learning_rate": 3.166361229892079e-06,
                "epoch": 2.8100183262064755,
                "step": 9200
            },
            {
                "loss": 0.0691,
                "grad_norm": 16.18625259399414,
                "learning_rate": 2.657299938912645e-06,
                "epoch": 2.8405620036652413,
                "step": 9300
            },
            {
                "loss": 0.084,
                "grad_norm": 0.7751460671424866,
                "learning_rate": 2.148238647933211e-06,
                "epoch": 2.8711056811240074,
                "step": 9400
            },
            {
                "loss": 0.0817,
                "grad_norm": 19.258981704711914,
                "learning_rate": 1.6391773569537775e-06,
                "epoch": 2.901649358582773,
                "step": 9500
            },
            {
                "loss": 0.0877,
                "grad_norm": 24.476774215698242,
                "learning_rate": 1.1301160659743434e-06,
                "epoch": 2.9321930360415394,
                "step": 9600
            },
            {
                "loss": 0.069,
                "grad_norm": 0.53551185131073,
                "learning_rate": 6.210547749949094e-07,
                "epoch": 2.9627367135003055,
                "step": 9700
            },
            {
                "loss": 0.0908,
                "grad_norm": 4.067531108856201,
                "learning_rate": 1.1199348401547546e-07,
                "epoch": 2.9932803909590717,
                "step": 9800
            },
            {
                "eval_loss": 0.36783942580223083,
                "eval_accuracy": 0.9093904448105437,
                "eval_runtime": 48.5001,
                "eval_samples_per_second": 112.639,
                "eval_steps_per_second": 3.526,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "train_runtime": 8693.7283,
                "train_samples_per_second": 36.144,
                "train_steps_per_second": 1.13,
                "total_flos": 8.267712381471744e+16,
                "train_loss": 0.2106861675909497,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "eval_loss": 0.36783942580223083,
                "eval_accuracy": 0.9093904448105437,
                "eval_runtime": 48.1275,
                "eval_samples_per_second": 113.511,
                "eval_steps_per_second": 3.553,
                "epoch": 3.0,
                "step": 9822
            }
        ],
        "train": {
            "train_time": 8693.7283,
            "trainable_params_count": 109.483778,
            "memory_allocated": [
                1343.478272,
                1343.478272,
                1343.478272
            ],
            "memory_reserved": [
                11987.320832,
                11987.320832,
                11987.320832
            ]
        }
    },
    "teacher_lora_results": {
        "eval_loss": 0.2404734194278717,
        "eval_accuracy": 0.90426505583013,
        "eval_runtime": 49.3384,
        "eval_samples_per_second": 110.725,
        "eval_steps_per_second": 3.466,
        "epoch": 3.0,
        "log_history": [
            {
                "loss": 0.5769,
                "grad_norm": 2.1423909664154053,
                "learning_rate": 0.0004949093870902057,
                "epoch": 0.030543677458766034,
                "step": 100
            },
            {
                "loss": 0.4672,
                "grad_norm": 1.9639486074447632,
                "learning_rate": 0.0004898187741804113,
                "epoch": 0.06108735491753207,
                "step": 200
            },
            {
                "loss": 0.4154,
                "grad_norm": 2.1825551986694336,
                "learning_rate": 0.00048472816127061695,
                "epoch": 0.0916310323762981,
                "step": 300
            },
            {
                "loss": 0.4371,
                "grad_norm": 1.2410697937011719,
                "learning_rate": 0.0004796375483608226,
                "epoch": 0.12217470983506414,
                "step": 400
            },
            {
                "loss": 0.387,
                "grad_norm": 1.7095988988876343,
                "learning_rate": 0.00047454693545102833,
                "epoch": 0.15271838729383017,
                "step": 500
            },
            {
                "loss": 0.4058,
                "grad_norm": 1.727160096168518,
                "learning_rate": 0.000469456322541234,
                "epoch": 0.1832620647525962,
                "step": 600
            },
            {
                "loss": 0.3732,
                "grad_norm": 1.8025809526443481,
                "learning_rate": 0.00046436570963143966,
                "epoch": 0.21380574221136225,
                "step": 700
            },
            {
                "loss": 0.38,
                "grad_norm": 2.392357110977173,
                "learning_rate": 0.0004592750967216453,
                "epoch": 0.24434941967012827,
                "step": 800
            },
            {
                "loss": 0.3872,
                "grad_norm": 1.291074275970459,
                "learning_rate": 0.00045418448381185093,
                "epoch": 0.2748930971288943,
                "step": 900
            },
            {
                "loss": 0.3685,
                "grad_norm": 3.237326145172119,
                "learning_rate": 0.0004490938709020566,
                "epoch": 0.30543677458766033,
                "step": 1000
            },
            {
                "loss": 0.3648,
                "grad_norm": 1.0642414093017578,
                "learning_rate": 0.00044400325799226226,
                "epoch": 0.3359804520464264,
                "step": 1100
            },
            {
                "loss": 0.3588,
                "grad_norm": 1.4720213413238525,
                "learning_rate": 0.0004389126450824679,
                "epoch": 0.3665241295051924,
                "step": 1200
            },
            {
                "loss": 0.3522,
                "grad_norm": 2.1829400062561035,
                "learning_rate": 0.0004338220321726736,
                "epoch": 0.39706780696395844,
                "step": 1300
            },
            {
                "loss": 0.3449,
                "grad_norm": 1.4980289936065674,
                "learning_rate": 0.0004287314192628793,
                "epoch": 0.4276114844227245,
                "step": 1400
            },
            {
                "loss": 0.3332,
                "grad_norm": 1.730637550354004,
                "learning_rate": 0.0004236408063530849,
                "epoch": 0.4581551618814905,
                "step": 1500
            },
            {
                "loss": 0.3452,
                "grad_norm": 1.4762623310089111,
                "learning_rate": 0.0004185501934432906,
                "epoch": 0.48869883934025654,
                "step": 1600
            },
            {
                "loss": 0.3695,
                "grad_norm": 2.2162954807281494,
                "learning_rate": 0.00041345958053349625,
                "epoch": 0.5192425167990226,
                "step": 1700
            },
            {
                "loss": 0.3551,
                "grad_norm": 1.8739869594573975,
                "learning_rate": 0.0004083689676237019,
                "epoch": 0.5497861942577886,
                "step": 1800
            },
            {
                "loss": 0.3277,
                "grad_norm": 1.3500124216079712,
                "learning_rate": 0.0004032783547139076,
                "epoch": 0.5803298717165547,
                "step": 1900
            },
            {
                "loss": 0.346,
                "grad_norm": 1.996389389038086,
                "learning_rate": 0.0003981877418041132,
                "epoch": 0.6108735491753207,
                "step": 2000
            },
            {
                "loss": 0.3444,
                "grad_norm": 1.624251365661621,
                "learning_rate": 0.00039309712889431885,
                "epoch": 0.6414172266340867,
                "step": 2100
            },
            {
                "loss": 0.337,
                "grad_norm": 1.6686499118804932,
                "learning_rate": 0.0003880065159845245,
                "epoch": 0.6719609040928528,
                "step": 2200
            },
            {
                "loss": 0.3391,
                "grad_norm": 2.855942726135254,
                "learning_rate": 0.00038291590307473023,
                "epoch": 0.7025045815516188,
                "step": 2300
            },
            {
                "loss": 0.3263,
                "grad_norm": 1.927340030670166,
                "learning_rate": 0.0003778252901649359,
                "epoch": 0.7330482590103848,
                "step": 2400
            },
            {
                "loss": 0.3273,
                "grad_norm": 1.155693769454956,
                "learning_rate": 0.00037273467725514156,
                "epoch": 0.7635919364691509,
                "step": 2500
            },
            {
                "loss": 0.3227,
                "grad_norm": 1.551585078239441,
                "learning_rate": 0.00036764406434534717,
                "epoch": 0.7941356139279169,
                "step": 2600
            },
            {
                "loss": 0.3118,
                "grad_norm": 1.9988250732421875,
                "learning_rate": 0.00036255345143555284,
                "epoch": 0.8246792913866829,
                "step": 2700
            },
            {
                "loss": 0.3294,
                "grad_norm": 2.7793891429901123,
                "learning_rate": 0.0003574628385257585,
                "epoch": 0.855222968845449,
                "step": 2800
            },
            {
                "loss": 0.328,
                "grad_norm": 1.415643334388733,
                "learning_rate": 0.00035237222561596416,
                "epoch": 0.885766646304215,
                "step": 2900
            },
            {
                "loss": 0.3188,
                "grad_norm": 2.7995479106903076,
                "learning_rate": 0.00034728161270616983,
                "epoch": 0.916310323762981,
                "step": 3000
            },
            {
                "loss": 0.3007,
                "grad_norm": 1.7644579410552979,
                "learning_rate": 0.0003421909997963755,
                "epoch": 0.9468540012217471,
                "step": 3100
            },
            {
                "loss": 0.3152,
                "grad_norm": 1.3415066003799438,
                "learning_rate": 0.00033710038688658116,
                "epoch": 0.9773976786805131,
                "step": 3200
            },
            {
                "eval_loss": 0.25053882598876953,
                "eval_accuracy": 0.8985905180303863,
                "eval_runtime": 50.811,
                "eval_samples_per_second": 107.516,
                "eval_steps_per_second": 3.365,
                "epoch": 1.0,
                "step": 3274
            },
            {
                "loss": 0.3275,
                "grad_norm": 1.5227282047271729,
                "learning_rate": 0.0003320097739767868,
                "epoch": 1.0079413561392792,
                "step": 3300
            },
            {
                "loss": 0.3039,
                "grad_norm": 2.774040460586548,
                "learning_rate": 0.0003269191610669925,
                "epoch": 1.0384850335980451,
                "step": 3400
            },
            {
                "loss": 0.2857,
                "grad_norm": 1.4592822790145874,
                "learning_rate": 0.00032182854815719815,
                "epoch": 1.0690287110568113,
                "step": 3500
            },
            {
                "loss": 0.3044,
                "grad_norm": 1.6597265005111694,
                "learning_rate": 0.0003167379352474038,
                "epoch": 1.0995723885155773,
                "step": 3600
            },
            {
                "loss": 0.2854,
                "grad_norm": 2.9012632369995117,
                "learning_rate": 0.0003116473223376095,
                "epoch": 1.1301160659743432,
                "step": 3700
            },
            {
                "loss": 0.2924,
                "grad_norm": 1.468529462814331,
                "learning_rate": 0.0003065567094278151,
                "epoch": 1.1606597434331094,
                "step": 3800
            },
            {
                "loss": 0.2869,
                "grad_norm": 1.4275422096252441,
                "learning_rate": 0.00030146609651802075,
                "epoch": 1.1912034208918754,
                "step": 3900
            },
            {
                "loss": 0.2694,
                "grad_norm": 3.0228240489959717,
                "learning_rate": 0.0002963754836082264,
                "epoch": 1.2217470983506413,
                "step": 4000
            },
            {
                "loss": 0.302,
                "grad_norm": 2.7962465286254883,
                "learning_rate": 0.0002912848706984321,
                "epoch": 1.2522907758094075,
                "step": 4100
            },
            {
                "loss": 0.2805,
                "grad_norm": 1.2534416913986206,
                "learning_rate": 0.0002861942577886378,
                "epoch": 1.2828344532681735,
                "step": 4200
            },
            {
                "loss": 0.294,
                "grad_norm": 1.7840255498886108,
                "learning_rate": 0.0002811036448788434,
                "epoch": 1.3133781307269397,
                "step": 4300
            },
            {
                "loss": 0.2747,
                "grad_norm": 1.8015047311782837,
                "learning_rate": 0.0002760130319690491,
                "epoch": 1.3439218081857056,
                "step": 4400
            },
            {
                "loss": 0.2967,
                "grad_norm": 1.7662135362625122,
                "learning_rate": 0.00027092241905925474,
                "epoch": 1.3744654856444716,
                "step": 4500
            },
            {
                "loss": 0.2917,
                "grad_norm": 2.5072951316833496,
                "learning_rate": 0.0002658318061494604,
                "epoch": 1.4050091631032378,
                "step": 4600
            },
            {
                "loss": 0.2927,
                "grad_norm": 1.253636360168457,
                "learning_rate": 0.00026074119323966607,
                "epoch": 1.4355528405620037,
                "step": 4700
            },
            {
                "loss": 0.2968,
                "grad_norm": 1.1080819368362427,
                "learning_rate": 0.00025565058032987173,
                "epoch": 1.4660965180207697,
                "step": 4800
            },
            {
                "loss": 0.2923,
                "grad_norm": 2.8002099990844727,
                "learning_rate": 0.00025055996742007734,
                "epoch": 1.4966401954795359,
                "step": 4900
            },
            {
                "loss": 0.2873,
                "grad_norm": 2.4353995323181152,
                "learning_rate": 0.00024546935451028306,
                "epoch": 1.5271838729383018,
                "step": 5000
            },
            {
                "loss": 0.2667,
                "grad_norm": 1.6600030660629272,
                "learning_rate": 0.0002403787416004887,
                "epoch": 1.5577275503970678,
                "step": 5100
            },
            {
                "loss": 0.2852,
                "grad_norm": 2.406611919403076,
                "learning_rate": 0.00023528812869069436,
                "epoch": 1.588271227855834,
                "step": 5200
            },
            {
                "loss": 0.2749,
                "grad_norm": 2.446932792663574,
                "learning_rate": 0.00023019751578090002,
                "epoch": 1.6188149053146,
                "step": 5300
            },
            {
                "loss": 0.2888,
                "grad_norm": 1.6448471546173096,
                "learning_rate": 0.0002251069028711057,
                "epoch": 1.6493585827733659,
                "step": 5400
            },
            {
                "loss": 0.2656,
                "grad_norm": 1.39668607711792,
                "learning_rate": 0.00022001628996131135,
                "epoch": 1.679902260232132,
                "step": 5500
            },
            {
                "loss": 0.2959,
                "grad_norm": 1.432026982307434,
                "learning_rate": 0.000214925677051517,
                "epoch": 1.710445937690898,
                "step": 5600
            },
            {
                "loss": 0.2883,
                "grad_norm": 1.8370460271835327,
                "learning_rate": 0.00020983506414172268,
                "epoch": 1.740989615149664,
                "step": 5700
            },
            {
                "loss": 0.2718,
                "grad_norm": 1.2686455249786377,
                "learning_rate": 0.00020474445123192834,
                "epoch": 1.7715332926084302,
                "step": 5800
            },
            {
                "loss": 0.2836,
                "grad_norm": 1.149473786354065,
                "learning_rate": 0.00019965383832213398,
                "epoch": 1.8020769700671961,
                "step": 5900
            },
            {
                "loss": 0.2787,
                "grad_norm": 1.6655503511428833,
                "learning_rate": 0.00019456322541233965,
                "epoch": 1.832620647525962,
                "step": 6000
            },
            {
                "loss": 0.2686,
                "grad_norm": 1.2002766132354736,
                "learning_rate": 0.0001894726125025453,
                "epoch": 1.8631643249847283,
                "step": 6100
            },
            {
                "loss": 0.2663,
                "grad_norm": 1.0904589891433716,
                "learning_rate": 0.00018438199959275097,
                "epoch": 1.8937080024434942,
                "step": 6200
            },
            {
                "loss": 0.2723,
                "grad_norm": 1.8614563941955566,
                "learning_rate": 0.00017929138668295664,
                "epoch": 1.9242516799022602,
                "step": 6300
            },
            {
                "loss": 0.279,
                "grad_norm": 1.5537246465682983,
                "learning_rate": 0.0001742007737731623,
                "epoch": 1.9547953573610264,
                "step": 6400
            },
            {
                "loss": 0.2634,
                "grad_norm": 1.8437144756317139,
                "learning_rate": 0.00016911016086336794,
                "epoch": 1.9853390348197923,
                "step": 6500
            },
            {
                "eval_loss": 0.2565332353115082,
                "eval_accuracy": 0.8982244188174996,
                "eval_runtime": 48.2718,
                "eval_samples_per_second": 113.172,
                "eval_steps_per_second": 3.542,
                "epoch": 2.0,
                "step": 6548
            },
            {
                "loss": 0.2524,
                "grad_norm": 2.4506964683532715,
                "learning_rate": 0.0001640195479535736,
                "epoch": 2.0158827122785583,
                "step": 6600
            },
            {
                "loss": 0.2435,
                "grad_norm": 3.5291080474853516,
                "learning_rate": 0.0001589289350437793,
                "epoch": 2.0464263897373245,
                "step": 6700
            },
            {
                "loss": 0.2562,
                "grad_norm": 1.536868929862976,
                "learning_rate": 0.00015383832213398493,
                "epoch": 2.0769700671960902,
                "step": 6800
            },
            {
                "loss": 0.2428,
                "grad_norm": 1.566401720046997,
                "learning_rate": 0.0001487477092241906,
                "epoch": 2.1075137446548564,
                "step": 6900
            },
            {
                "loss": 0.2554,
                "grad_norm": 1.5747032165527344,
                "learning_rate": 0.00014365709631439623,
                "epoch": 2.1380574221136226,
                "step": 7000
            },
            {
                "loss": 0.2457,
                "grad_norm": 1.4004708528518677,
                "learning_rate": 0.00013856648340460193,
                "epoch": 2.1686010995723883,
                "step": 7100
            },
            {
                "loss": 0.2539,
                "grad_norm": 2.3762524127960205,
                "learning_rate": 0.0001334758704948076,
                "epoch": 2.1991447770311545,
                "step": 7200
            },
            {
                "loss": 0.2475,
                "grad_norm": 2.259617805480957,
                "learning_rate": 0.00012838525758501323,
                "epoch": 2.2296884544899207,
                "step": 7300
            },
            {
                "loss": 0.2641,
                "grad_norm": 2.0478806495666504,
                "learning_rate": 0.0001232946446752189,
                "epoch": 2.2602321319486864,
                "step": 7400
            },
            {
                "loss": 0.2351,
                "grad_norm": 1.46132493019104,
                "learning_rate": 0.00011820403176542456,
                "epoch": 2.2907758094074526,
                "step": 7500
            },
            {
                "loss": 0.2601,
                "grad_norm": 2.7795355319976807,
                "learning_rate": 0.00011311341885563022,
                "epoch": 2.321319486866219,
                "step": 7600
            },
            {
                "loss": 0.23,
                "grad_norm": 1.5668628215789795,
                "learning_rate": 0.00010802280594583588,
                "epoch": 2.3518631643249845,
                "step": 7700
            },
            {
                "loss": 0.2525,
                "grad_norm": 2.1677961349487305,
                "learning_rate": 0.00010293219303604153,
                "epoch": 2.3824068417837507,
                "step": 7800
            },
            {
                "loss": 0.247,
                "grad_norm": 1.281075358390808,
                "learning_rate": 9.784158012624721e-05,
                "epoch": 2.412950519242517,
                "step": 7900
            },
            {
                "loss": 0.2465,
                "grad_norm": 1.3001006841659546,
                "learning_rate": 9.275096721645286e-05,
                "epoch": 2.4434941967012827,
                "step": 8000
            },
            {
                "loss": 0.2555,
                "grad_norm": 1.2431544065475464,
                "learning_rate": 8.766035430665853e-05,
                "epoch": 2.474037874160049,
                "step": 8100
            },
            {
                "loss": 0.2353,
                "grad_norm": 1.4386775493621826,
                "learning_rate": 8.256974139686418e-05,
                "epoch": 2.504581551618815,
                "step": 8200
            },
            {
                "loss": 0.2592,
                "grad_norm": 1.5707319974899292,
                "learning_rate": 7.747912848706984e-05,
                "epoch": 2.5351252290775808,
                "step": 8300
            },
            {
                "loss": 0.2442,
                "grad_norm": 1.9445079565048218,
                "learning_rate": 7.23885155772755e-05,
                "epoch": 2.565668906536347,
                "step": 8400
            },
            {
                "loss": 0.2649,
                "grad_norm": 1.3363783359527588,
                "learning_rate": 6.729790266748116e-05,
                "epoch": 2.596212583995113,
                "step": 8500
            },
            {
                "loss": 0.2428,
                "grad_norm": 1.6911835670471191,
                "learning_rate": 6.220728975768683e-05,
                "epoch": 2.6267562614538793,
                "step": 8600
            },
            {
                "loss": 0.2586,
                "grad_norm": 2.150747537612915,
                "learning_rate": 5.7116676847892485e-05,
                "epoch": 2.657299938912645,
                "step": 8700
            },
            {
                "loss": 0.2381,
                "grad_norm": 1.6144208908081055,
                "learning_rate": 5.202606393809815e-05,
                "epoch": 2.6878436163714112,
                "step": 8800
            },
            {
                "loss": 0.2391,
                "grad_norm": 0.9808982014656067,
                "learning_rate": 4.693545102830381e-05,
                "epoch": 2.718387293830177,
                "step": 8900
            },
            {
                "loss": 0.2342,
                "grad_norm": 1.5027153491973877,
                "learning_rate": 4.184483811850947e-05,
                "epoch": 2.748930971288943,
                "step": 9000
            },
            {
                "loss": 0.2501,
                "grad_norm": 1.399503231048584,
                "learning_rate": 3.675422520871513e-05,
                "epoch": 2.7794746487477093,
                "step": 9100
            },
            {
                "loss": 0.245,
                "grad_norm": 3.1567702293395996,
                "learning_rate": 3.166361229892079e-05,
                "epoch": 2.8100183262064755,
                "step": 9200
            },
            {
                "loss": 0.2288,
                "grad_norm": 2.131307601928711,
                "learning_rate": 2.657299938912645e-05,
                "epoch": 2.8405620036652413,
                "step": 9300
            },
            {
                "loss": 0.2525,
                "grad_norm": 1.6193753480911255,
                "learning_rate": 2.148238647933211e-05,
                "epoch": 2.8711056811240074,
                "step": 9400
            },
            {
                "loss": 0.2485,
                "grad_norm": 1.8726189136505127,
                "learning_rate": 1.6391773569537775e-05,
                "epoch": 2.901649358582773,
                "step": 9500
            },
            {
                "loss": 0.241,
                "grad_norm": 1.2585607767105103,
                "learning_rate": 1.1301160659743432e-05,
                "epoch": 2.9321930360415394,
                "step": 9600
            },
            {
                "loss": 0.2281,
                "grad_norm": 1.6938289403915405,
                "learning_rate": 6.210547749949094e-06,
                "epoch": 2.9627367135003055,
                "step": 9700
            },
            {
                "loss": 0.2443,
                "grad_norm": 2.461414098739624,
                "learning_rate": 1.1199348401547546e-06,
                "epoch": 2.9932803909590717,
                "step": 9800
            },
            {
                "eval_loss": 0.2404734194278717,
                "eval_accuracy": 0.90426505583013,
                "eval_runtime": 48.4491,
                "eval_samples_per_second": 112.758,
                "eval_steps_per_second": 3.529,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "train_runtime": 6244.6432,
                "train_samples_per_second": 50.32,
                "train_steps_per_second": 1.573,
                "total_flos": 8.296329040533504e+16,
                "train_loss": 0.29733896041882546,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "eval_loss": 0.2404734194278717,
                "eval_accuracy": 0.90426505583013,
                "eval_runtime": 49.3384,
                "eval_samples_per_second": 110.725,
                "eval_steps_per_second": 3.466,
                "epoch": 3.0,
                "step": 9822
            }
        ],
        "train": {
            "train_time": 6244.6432,
            "trainable_params_count": 0.29645,
            "memory_allocated": [
                1353.82528,
                1353.82528,
                1353.82528
            ],
            "memory_reserved": [
                9938.403328,
                9938.403328,
                9938.403328
            ]
        }
    },
    "student_lora_results": {
        "eval_loss": 2.215202808380127,
        "eval_accuracy": 0.8674720849350174,
        "eval_runtime": 26.5904,
        "eval_samples_per_second": 205.45,
        "eval_steps_per_second": 6.431,
        "epoch": 3.0,
        "log_history": [
            {
                "loss": 1.2469,
                "grad_norm": 2.1487865447998047,
                "learning_rate": 0.0004949093870902057,
                "epoch": 0.030543677458766034,
                "step": 100
            },
            {
                "loss": 1.0124,
                "grad_norm": 1.5281968116760254,
                "learning_rate": 0.0004898187741804113,
                "epoch": 0.06108735491753207,
                "step": 200
            },
            {
                "loss": 0.937,
                "grad_norm": 2.245955228805542,
                "learning_rate": 0.00048472816127061695,
                "epoch": 0.0916310323762981,
                "step": 300
            },
            {
                "loss": 0.9341,
                "grad_norm": 2.1881563663482666,
                "learning_rate": 0.0004796375483608226,
                "epoch": 0.12217470983506414,
                "step": 400
            },
            {
                "loss": 0.8879,
                "grad_norm": 3.421105146408081,
                "learning_rate": 0.00047454693545102833,
                "epoch": 0.15271838729383017,
                "step": 500
            },
            {
                "loss": 0.8929,
                "grad_norm": 2.5739362239837646,
                "learning_rate": 0.000469456322541234,
                "epoch": 0.1832620647525962,
                "step": 600
            },
            {
                "loss": 0.8263,
                "grad_norm": 2.414217710494995,
                "learning_rate": 0.00046436570963143966,
                "epoch": 0.21380574221136225,
                "step": 700
            },
            {
                "loss": 0.8622,
                "grad_norm": 2.7134644985198975,
                "learning_rate": 0.0004592750967216453,
                "epoch": 0.24434941967012827,
                "step": 800
            },
            {
                "loss": 0.8766,
                "grad_norm": 2.9522337913513184,
                "learning_rate": 0.00045418448381185093,
                "epoch": 0.2748930971288943,
                "step": 900
            },
            {
                "loss": 0.8376,
                "grad_norm": 2.7213852405548096,
                "learning_rate": 0.0004490938709020566,
                "epoch": 0.30543677458766033,
                "step": 1000
            },
            {
                "loss": 0.836,
                "grad_norm": 2.247129201889038,
                "learning_rate": 0.00044400325799226226,
                "epoch": 0.3359804520464264,
                "step": 1100
            },
            {
                "loss": 0.8301,
                "grad_norm": 2.805251359939575,
                "learning_rate": 0.0004389126450824679,
                "epoch": 0.3665241295051924,
                "step": 1200
            },
            {
                "loss": 0.8162,
                "grad_norm": 2.7445614337921143,
                "learning_rate": 0.0004338220321726736,
                "epoch": 0.39706780696395844,
                "step": 1300
            },
            {
                "loss": 0.8104,
                "grad_norm": 2.029755115509033,
                "learning_rate": 0.0004287314192628793,
                "epoch": 0.4276114844227245,
                "step": 1400
            },
            {
                "loss": 0.7902,
                "grad_norm": 3.029935359954834,
                "learning_rate": 0.0004236408063530849,
                "epoch": 0.4581551618814905,
                "step": 1500
            },
            {
                "loss": 0.7829,
                "grad_norm": 4.2215094566345215,
                "learning_rate": 0.0004185501934432906,
                "epoch": 0.48869883934025654,
                "step": 1600
            },
            {
                "loss": 0.8457,
                "grad_norm": 3.1529359817504883,
                "learning_rate": 0.00041345958053349625,
                "epoch": 0.5192425167990226,
                "step": 1700
            },
            {
                "loss": 0.822,
                "grad_norm": 3.2270431518554688,
                "learning_rate": 0.0004083689676237019,
                "epoch": 0.5497861942577886,
                "step": 1800
            },
            {
                "loss": 0.7735,
                "grad_norm": 3.3218801021575928,
                "learning_rate": 0.0004032783547139076,
                "epoch": 0.5803298717165547,
                "step": 1900
            },
            {
                "loss": 0.785,
                "grad_norm": 2.9567019939422607,
                "learning_rate": 0.0003981877418041132,
                "epoch": 0.6108735491753207,
                "step": 2000
            },
            {
                "loss": 0.7785,
                "grad_norm": 2.7145745754241943,
                "learning_rate": 0.00039309712889431885,
                "epoch": 0.6414172266340867,
                "step": 2100
            },
            {
                "loss": 0.7664,
                "grad_norm": 1.9777144193649292,
                "learning_rate": 0.0003880065159845245,
                "epoch": 0.6719609040928528,
                "step": 2200
            },
            {
                "loss": 0.7864,
                "grad_norm": 3.951655626296997,
                "learning_rate": 0.00038291590307473023,
                "epoch": 0.7025045815516188,
                "step": 2300
            },
            {
                "loss": 0.7356,
                "grad_norm": 2.0039899349212646,
                "learning_rate": 0.0003778252901649359,
                "epoch": 0.7330482590103848,
                "step": 2400
            },
            {
                "loss": 0.7613,
                "grad_norm": 1.886080026626587,
                "learning_rate": 0.00037273467725514156,
                "epoch": 0.7635919364691509,
                "step": 2500
            },
            {
                "loss": 0.7829,
                "grad_norm": 3.8056912422180176,
                "learning_rate": 0.00036764406434534717,
                "epoch": 0.7941356139279169,
                "step": 2600
            },
            {
                "loss": 0.7454,
                "grad_norm": 5.303264141082764,
                "learning_rate": 0.00036255345143555284,
                "epoch": 0.8246792913866829,
                "step": 2700
            },
            {
                "loss": 0.7502,
                "grad_norm": 8.81544303894043,
                "learning_rate": 0.0003574628385257585,
                "epoch": 0.855222968845449,
                "step": 2800
            },
            {
                "loss": 0.7552,
                "grad_norm": 2.2855112552642822,
                "learning_rate": 0.00035237222561596416,
                "epoch": 0.885766646304215,
                "step": 2900
            },
            {
                "loss": 0.7667,
                "grad_norm": 5.858419418334961,
                "learning_rate": 0.00034728161270616983,
                "epoch": 0.916310323762981,
                "step": 3000
            },
            {
                "loss": 0.7235,
                "grad_norm": 7.1933794021606445,
                "learning_rate": 0.0003421909997963755,
                "epoch": 0.9468540012217471,
                "step": 3100
            },
            {
                "loss": 0.7386,
                "grad_norm": 3.3063900470733643,
                "learning_rate": 0.00033710038688658116,
                "epoch": 0.9773976786805131,
                "step": 3200
            },
            {
                "eval_loss": 1.9281587600708008,
                "eval_accuracy": 0.8478857770455793,
                "eval_runtime": 24.6155,
                "eval_samples_per_second": 221.933,
                "eval_steps_per_second": 6.947,
                "epoch": 1.0,
                "step": 3274
            },
            {
                "loss": 0.7349,
                "grad_norm": 2.3426036834716797,
                "learning_rate": 0.0003320097739767868,
                "epoch": 1.0079413561392792,
                "step": 3300
            },
            {
                "loss": 0.7115,
                "grad_norm": 4.16494083404541,
                "learning_rate": 0.0003269191610669925,
                "epoch": 1.0384850335980451,
                "step": 3400
            },
            {
                "loss": 0.6583,
                "grad_norm": 3.2487292289733887,
                "learning_rate": 0.00032182854815719815,
                "epoch": 1.0690287110568113,
                "step": 3500
            },
            {
                "loss": 0.7144,
                "grad_norm": 3.46894907951355,
                "learning_rate": 0.0003167379352474038,
                "epoch": 1.0995723885155773,
                "step": 3600
            },
            {
                "loss": 0.6928,
                "grad_norm": 4.6842498779296875,
                "learning_rate": 0.0003116473223376095,
                "epoch": 1.1301160659743432,
                "step": 3700
            },
            {
                "loss": 0.7064,
                "grad_norm": 4.83842134475708,
                "learning_rate": 0.0003065567094278151,
                "epoch": 1.1606597434331094,
                "step": 3800
            },
            {
                "loss": 0.68,
                "grad_norm": 3.7189126014709473,
                "learning_rate": 0.00030146609651802075,
                "epoch": 1.1912034208918754,
                "step": 3900
            },
            {
                "loss": 0.6637,
                "grad_norm": 3.0060219764709473,
                "learning_rate": 0.0002963754836082264,
                "epoch": 1.2217470983506413,
                "step": 4000
            },
            {
                "loss": 0.7166,
                "grad_norm": 4.179808139801025,
                "learning_rate": 0.0002912848706984321,
                "epoch": 1.2522907758094075,
                "step": 4100
            },
            {
                "loss": 0.6808,
                "grad_norm": 2.411332130432129,
                "learning_rate": 0.0002861942577886378,
                "epoch": 1.2828344532681735,
                "step": 4200
            },
            {
                "loss": 0.6718,
                "grad_norm": 3.927222967147827,
                "learning_rate": 0.0002811036448788434,
                "epoch": 1.3133781307269397,
                "step": 4300
            },
            {
                "loss": 0.6763,
                "grad_norm": 3.192371129989624,
                "learning_rate": 0.0002760130319690491,
                "epoch": 1.3439218081857056,
                "step": 4400
            },
            {
                "loss": 0.6736,
                "grad_norm": 3.465066909790039,
                "learning_rate": 0.00027092241905925474,
                "epoch": 1.3744654856444716,
                "step": 4500
            },
            {
                "loss": 0.6672,
                "grad_norm": 3.2301526069641113,
                "learning_rate": 0.0002658318061494604,
                "epoch": 1.4050091631032378,
                "step": 4600
            },
            {
                "loss": 0.6813,
                "grad_norm": 2.8572912216186523,
                "learning_rate": 0.00026074119323966607,
                "epoch": 1.4355528405620037,
                "step": 4700
            },
            {
                "loss": 0.7099,
                "grad_norm": 1.9058789014816284,
                "learning_rate": 0.00025565058032987173,
                "epoch": 1.4660965180207697,
                "step": 4800
            },
            {
                "loss": 0.6769,
                "grad_norm": 4.116247177124023,
                "learning_rate": 0.00025055996742007734,
                "epoch": 1.4966401954795359,
                "step": 4900
            },
            {
                "loss": 0.6895,
                "grad_norm": 2.6629228591918945,
                "learning_rate": 0.00024546935451028306,
                "epoch": 1.5271838729383018,
                "step": 5000
            },
            {
                "loss": 0.6343,
                "grad_norm": 2.5209624767303467,
                "learning_rate": 0.0002403787416004887,
                "epoch": 1.5577275503970678,
                "step": 5100
            },
            {
                "loss": 0.689,
                "grad_norm": 3.0486929416656494,
                "learning_rate": 0.00023528812869069436,
                "epoch": 1.588271227855834,
                "step": 5200
            },
            {
                "loss": 0.6563,
                "grad_norm": 2.842383861541748,
                "learning_rate": 0.00023019751578090002,
                "epoch": 1.6188149053146,
                "step": 5300
            },
            {
                "loss": 0.6697,
                "grad_norm": 5.832738876342773,
                "learning_rate": 0.0002251069028711057,
                "epoch": 1.6493585827733659,
                "step": 5400
            },
            {
                "loss": 0.6604,
                "grad_norm": 2.639415979385376,
                "learning_rate": 0.00022001628996131135,
                "epoch": 1.679902260232132,
                "step": 5500
            },
            {
                "loss": 0.6745,
                "grad_norm": 2.0808684825897217,
                "learning_rate": 0.000214925677051517,
                "epoch": 1.710445937690898,
                "step": 5600
            },
            {
                "loss": 0.6928,
                "grad_norm": 2.0301425457000732,
                "learning_rate": 0.00020983506414172268,
                "epoch": 1.740989615149664,
                "step": 5700
            },
            {
                "loss": 0.6541,
                "grad_norm": 3.0065505504608154,
                "learning_rate": 0.00020474445123192834,
                "epoch": 1.7715332926084302,
                "step": 5800
            },
            {
                "loss": 0.6749,
                "grad_norm": 2.2967045307159424,
                "learning_rate": 0.00019965383832213398,
                "epoch": 1.8020769700671961,
                "step": 5900
            },
            {
                "loss": 0.664,
                "grad_norm": 2.3255677223205566,
                "learning_rate": 0.00019456322541233965,
                "epoch": 1.832620647525962,
                "step": 6000
            },
            {
                "loss": 0.6579,
                "grad_norm": 2.563354730606079,
                "learning_rate": 0.0001894726125025453,
                "epoch": 1.8631643249847283,
                "step": 6100
            },
            {
                "loss": 0.627,
                "grad_norm": 1.7298686504364014,
                "learning_rate": 0.00018438199959275097,
                "epoch": 1.8937080024434942,
                "step": 6200
            },
            {
                "loss": 0.6692,
                "grad_norm": 2.9251554012298584,
                "learning_rate": 0.00017929138668295664,
                "epoch": 1.9242516799022602,
                "step": 6300
            },
            {
                "loss": 0.6739,
                "grad_norm": 2.497084856033325,
                "learning_rate": 0.0001742007737731623,
                "epoch": 1.9547953573610264,
                "step": 6400
            },
            {
                "loss": 0.6407,
                "grad_norm": 2.5331904888153076,
                "learning_rate": 0.00016911016086336794,
                "epoch": 1.9853390348197923,
                "step": 6500
            },
            {
                "eval_loss": 2.163477659225464,
                "eval_accuracy": 0.8623466959546037,
                "eval_runtime": 25.6212,
                "eval_samples_per_second": 213.222,
                "eval_steps_per_second": 6.674,
                "epoch": 2.0,
                "step": 6548
            },
            {
                "loss": 0.6541,
                "grad_norm": 2.4272451400756836,
                "learning_rate": 0.0001640195479535736,
                "epoch": 2.0158827122785583,
                "step": 6600
            },
            {
                "loss": 0.6067,
                "grad_norm": 4.925451278686523,
                "learning_rate": 0.0001589289350437793,
                "epoch": 2.0464263897373245,
                "step": 6700
            },
            {
                "loss": 0.6384,
                "grad_norm": 5.196434497833252,
                "learning_rate": 0.00015383832213398493,
                "epoch": 2.0769700671960902,
                "step": 6800
            },
            {
                "loss": 0.5984,
                "grad_norm": 4.57111120223999,
                "learning_rate": 0.0001487477092241906,
                "epoch": 2.1075137446548564,
                "step": 6900
            },
            {
                "loss": 0.6519,
                "grad_norm": 5.923179626464844,
                "learning_rate": 0.00014365709631439623,
                "epoch": 2.1380574221136226,
                "step": 7000
            },
            {
                "loss": 0.6163,
                "grad_norm": 2.756920337677002,
                "learning_rate": 0.00013856648340460193,
                "epoch": 2.1686010995723883,
                "step": 7100
            },
            {
                "loss": 0.6449,
                "grad_norm": 2.4690334796905518,
                "learning_rate": 0.0001334758704948076,
                "epoch": 2.1991447770311545,
                "step": 7200
            },
            {
                "loss": 0.6082,
                "grad_norm": 4.775146961212158,
                "learning_rate": 0.00012838525758501323,
                "epoch": 2.2296884544899207,
                "step": 7300
            },
            {
                "loss": 0.6256,
                "grad_norm": 2.6818225383758545,
                "learning_rate": 0.0001232946446752189,
                "epoch": 2.2602321319486864,
                "step": 7400
            },
            {
                "loss": 0.6011,
                "grad_norm": 3.511277437210083,
                "learning_rate": 0.00011820403176542456,
                "epoch": 2.2907758094074526,
                "step": 7500
            },
            {
                "loss": 0.6457,
                "grad_norm": 2.7274417877197266,
                "learning_rate": 0.00011311341885563022,
                "epoch": 2.321319486866219,
                "step": 7600
            },
            {
                "loss": 0.6019,
                "grad_norm": 3.4212918281555176,
                "learning_rate": 0.00010802280594583588,
                "epoch": 2.3518631643249845,
                "step": 7700
            },
            {
                "loss": 0.5946,
                "grad_norm": 3.5811197757720947,
                "learning_rate": 0.00010293219303604153,
                "epoch": 2.3824068417837507,
                "step": 7800
            },
            {
                "loss": 0.6393,
                "grad_norm": 2.9111387729644775,
                "learning_rate": 9.784158012624721e-05,
                "epoch": 2.412950519242517,
                "step": 7900
            },
            {
                "loss": 0.6285,
                "grad_norm": 3.728173017501831,
                "learning_rate": 9.275096721645286e-05,
                "epoch": 2.4434941967012827,
                "step": 8000
            },
            {
                "loss": 0.6272,
                "grad_norm": 4.465909481048584,
                "learning_rate": 8.766035430665853e-05,
                "epoch": 2.474037874160049,
                "step": 8100
            },
            {
                "loss": 0.6047,
                "grad_norm": 3.870943784713745,
                "learning_rate": 8.256974139686418e-05,
                "epoch": 2.504581551618815,
                "step": 8200
            },
            {
                "loss": 0.6419,
                "grad_norm": 4.657590389251709,
                "learning_rate": 7.747912848706984e-05,
                "epoch": 2.5351252290775808,
                "step": 8300
            },
            {
                "loss": 0.6082,
                "grad_norm": 2.754530668258667,
                "learning_rate": 7.23885155772755e-05,
                "epoch": 2.565668906536347,
                "step": 8400
            },
            {
                "loss": 0.6309,
                "grad_norm": 2.2627241611480713,
                "learning_rate": 6.729790266748116e-05,
                "epoch": 2.596212583995113,
                "step": 8500
            },
            {
                "loss": 0.5851,
                "grad_norm": 2.080745220184326,
                "learning_rate": 6.220728975768683e-05,
                "epoch": 2.6267562614538793,
                "step": 8600
            },
            {
                "loss": 0.626,
                "grad_norm": 2.748231887817383,
                "learning_rate": 5.7116676847892485e-05,
                "epoch": 2.657299938912645,
                "step": 8700
            },
            {
                "loss": 0.5904,
                "grad_norm": 3.0492119789123535,
                "learning_rate": 5.202606393809815e-05,
                "epoch": 2.6878436163714112,
                "step": 8800
            },
            {
                "loss": 0.6073,
                "grad_norm": 2.238675832748413,
                "learning_rate": 4.693545102830381e-05,
                "epoch": 2.718387293830177,
                "step": 8900
            },
            {
                "loss": 0.5847,
                "grad_norm": 3.0115418434143066,
                "learning_rate": 4.184483811850947e-05,
                "epoch": 2.748930971288943,
                "step": 9000
            },
            {
                "loss": 0.6141,
                "grad_norm": 2.7335236072540283,
                "learning_rate": 3.675422520871513e-05,
                "epoch": 2.7794746487477093,
                "step": 9100
            },
            {
                "loss": 0.5807,
                "grad_norm": 4.240789413452148,
                "learning_rate": 3.166361229892079e-05,
                "epoch": 2.8100183262064755,
                "step": 9200
            },
            {
                "loss": 0.5707,
                "grad_norm": 2.544285297393799,
                "learning_rate": 2.657299938912645e-05,
                "epoch": 2.8405620036652413,
                "step": 9300
            },
            {
                "loss": 0.5888,
                "grad_norm": 4.552604675292969,
                "learning_rate": 2.148238647933211e-05,
                "epoch": 2.8711056811240074,
                "step": 9400
            },
            {
                "loss": 0.5997,
                "grad_norm": 2.9947004318237305,
                "learning_rate": 1.6391773569537775e-05,
                "epoch": 2.901649358582773,
                "step": 9500
            },
            {
                "loss": 0.5627,
                "grad_norm": 2.083479166030884,
                "learning_rate": 1.1301160659743432e-05,
                "epoch": 2.9321930360415394,
                "step": 9600
            },
            {
                "loss": 0.5351,
                "grad_norm": 2.9511117935180664,
                "learning_rate": 6.210547749949094e-06,
                "epoch": 2.9627367135003055,
                "step": 9700
            },
            {
                "loss": 0.5576,
                "grad_norm": 3.428431749343872,
                "learning_rate": 1.1199348401547546e-06,
                "epoch": 2.9932803909590717,
                "step": 9800
            },
            {
                "eval_loss": 2.215202808380127,
                "eval_accuracy": 0.8674720849350174,
                "eval_runtime": 27.4806,
                "eval_samples_per_second": 198.795,
                "eval_steps_per_second": 6.223,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "train_runtime": 3180.4567,
                "train_samples_per_second": 98.8,
                "train_steps_per_second": 3.088,
                "total_flos": 4.233902907444019e+16,
                "train_loss": 0.7029107985538272,
                "epoch": 3.0,
                "step": 9822
            },
            {
                "eval_loss": 2.215202808380127,
                "eval_accuracy": 0.8674720849350174,
                "eval_runtime": 26.5904,
                "eval_samples_per_second": 205.45,
                "eval_steps_per_second": 6.431,
                "epoch": 3.0,
                "step": 9822
            }
        ],
        "train": {
            "train_time": 3180.4567,
            "trainable_params_count": 0.739586,
            "memory_allocated": [
                1183.077888,
                1183.077888,
                1183.077888
            ],
            "memory_reserved": [
                5643.436032,
                5643.436032,
                5643.436032
            ]
        }
    }
}