{
    "eval_loss": 0.4557637572288513,
    "eval_matthews_correlation": 0.5468625515611443,
    "eval_runtime": 0.5783,
    "eval_samples_per_second": 1803.483,
    "eval_steps_per_second": 15.562,
    "epoch": 3.0,
    "log_history": [
        {
            "loss": 0.6345,
            "grad_norm": 1.0397685766220093,
            "learning_rate": 0.0004776119402985075,
            "epoch": 0.14925373134328357,
            "step": 10
        },
        {
            "eval_loss": 0.6265103816986084,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5874,
            "eval_samples_per_second": 1775.604,
            "eval_steps_per_second": 15.322,
            "epoch": 0.14925373134328357,
            "step": 10
        },
        {
            "loss": 0.6115,
            "grad_norm": 0.5523064136505127,
            "learning_rate": 0.0004527363184079602,
            "epoch": 0.29850746268656714,
            "step": 20
        },
        {
            "eval_loss": 0.5798861980438232,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.5209,
            "eval_samples_per_second": 2002.426,
            "eval_steps_per_second": 17.279,
            "epoch": 0.29850746268656714,
            "step": 20
        },
        {
            "loss": 0.5682,
            "grad_norm": 4.568929195404053,
            "learning_rate": 0.00043034825870646765,
            "epoch": 0.44776119402985076,
            "step": 30
        },
        {
            "eval_loss": 0.4887162148952484,
            "eval_matthews_correlation": 0.3393150349592275,
            "eval_runtime": 0.5353,
            "eval_samples_per_second": 1948.298,
            "eval_steps_per_second": 16.812,
            "epoch": 0.44776119402985076,
            "step": 30
        },
        {
            "loss": 0.4855,
            "grad_norm": 2.8445935249328613,
            "learning_rate": 0.0004079601990049751,
            "epoch": 0.5970149253731343,
            "step": 40
        },
        {
            "eval_loss": 0.5355488061904907,
            "eval_matthews_correlation": 0.4051968022406895,
            "eval_runtime": 0.564,
            "eval_samples_per_second": 1849.268,
            "eval_steps_per_second": 15.957,
            "epoch": 0.5970149253731343,
            "step": 40
        },
        {
            "loss": 0.4758,
            "grad_norm": 4.537001609802246,
            "learning_rate": 0.00038308457711442787,
            "epoch": 0.746268656716418,
            "step": 50
        },
        {
            "eval_loss": 0.513334333896637,
            "eval_matthews_correlation": 0.4264149944629339,
            "eval_runtime": 0.5253,
            "eval_samples_per_second": 1985.557,
            "eval_steps_per_second": 17.133,
            "epoch": 0.746268656716418,
            "step": 50
        },
        {
            "loss": 0.4942,
            "grad_norm": 3.430058479309082,
            "learning_rate": 0.00035820895522388057,
            "epoch": 0.8955223880597015,
            "step": 60
        },
        {
            "eval_loss": 0.4679931402206421,
            "eval_matthews_correlation": 0.4820577747949163,
            "eval_runtime": 0.5306,
            "eval_samples_per_second": 1965.738,
            "eval_steps_per_second": 16.962,
            "epoch": 0.8955223880597015,
            "step": 60
        },
        {
            "loss": 0.4406,
            "grad_norm": 4.130706310272217,
            "learning_rate": 0.0003333333333333333,
            "epoch": 1.044776119402985,
            "step": 70
        },
        {
            "eval_loss": 0.48137030005455017,
            "eval_matthews_correlation": 0.4911444953794644,
            "eval_runtime": 0.5612,
            "eval_samples_per_second": 1858.413,
            "eval_steps_per_second": 16.036,
            "epoch": 1.044776119402985,
            "step": 70
        },
        {
            "loss": 0.4115,
            "grad_norm": 7.16506814956665,
            "learning_rate": 0.0003084577114427861,
            "epoch": 1.1940298507462686,
            "step": 80
        },
        {
            "eval_loss": 0.6122536063194275,
            "eval_matthews_correlation": 0.44706000072931473,
            "eval_runtime": 0.5885,
            "eval_samples_per_second": 1772.288,
            "eval_steps_per_second": 15.293,
            "epoch": 1.1940298507462686,
            "step": 80
        },
        {
            "loss": 0.4262,
            "grad_norm": 2.7120590209960938,
            "learning_rate": 0.0002835820895522388,
            "epoch": 1.3432835820895521,
            "step": 90
        },
        {
            "eval_loss": 0.4768770933151245,
            "eval_matthews_correlation": 0.48839034585258967,
            "eval_runtime": 0.531,
            "eval_samples_per_second": 1964.284,
            "eval_steps_per_second": 16.95,
            "epoch": 1.3432835820895521,
            "step": 90
        },
        {
            "loss": 0.432,
            "grad_norm": 2.4598422050476074,
            "learning_rate": 0.00025870646766169153,
            "epoch": 1.4925373134328357,
            "step": 100
        },
        {
            "eval_loss": 0.433508962392807,
            "eval_matthews_correlation": 0.5263656926265686,
            "eval_runtime": 0.5523,
            "eval_samples_per_second": 1888.298,
            "eval_steps_per_second": 16.294,
            "epoch": 1.4925373134328357,
            "step": 100
        },
        {
            "loss": 0.4283,
            "grad_norm": 2.735257625579834,
            "learning_rate": 0.00023383084577114428,
            "epoch": 1.6417910447761193,
            "step": 110
        },
        {
            "eval_loss": 0.43996894359588623,
            "eval_matthews_correlation": 0.5319354120310512,
            "eval_runtime": 0.5645,
            "eval_samples_per_second": 1847.654,
            "eval_steps_per_second": 15.943,
            "epoch": 1.6417910447761193,
            "step": 110
        },
        {
            "loss": 0.4086,
            "grad_norm": 2.1378631591796875,
            "learning_rate": 0.00021144278606965175,
            "epoch": 1.7910447761194028,
            "step": 120
        },
        {
            "eval_loss": 0.5258052945137024,
            "eval_matthews_correlation": 0.488445640649576,
            "eval_runtime": 0.5746,
            "eval_samples_per_second": 1815.287,
            "eval_steps_per_second": 15.664,
            "epoch": 1.7910447761194028,
            "step": 120
        },
        {
            "loss": 0.4294,
            "grad_norm": 2.5395281314849854,
            "learning_rate": 0.00018656716417910448,
            "epoch": 1.9402985074626866,
            "step": 130
        },
        {
            "eval_loss": 0.46731749176979065,
            "eval_matthews_correlation": 0.5259287977773666,
            "eval_runtime": 0.4981,
            "eval_samples_per_second": 2093.945,
            "eval_steps_per_second": 18.069,
            "epoch": 1.9402985074626866,
            "step": 130
        },
        {
            "loss": 0.4172,
            "grad_norm": 3.9595680236816406,
            "learning_rate": 0.00016169154228855723,
            "epoch": 2.08955223880597,
            "step": 140
        },
        {
            "eval_loss": 0.4292648136615753,
            "eval_matthews_correlation": 0.5390322970786539,
            "eval_runtime": 0.5354,
            "eval_samples_per_second": 1948.024,
            "eval_steps_per_second": 16.809,
            "epoch": 2.08955223880597,
            "step": 140
        },
        {
            "loss": 0.4124,
            "grad_norm": 2.7031707763671875,
            "learning_rate": 0.00013681592039800993,
            "epoch": 2.2388059701492535,
            "step": 150
        },
        {
            "eval_loss": 0.4582718312740326,
            "eval_matthews_correlation": 0.5290419680495485,
            "eval_runtime": 0.5511,
            "eval_samples_per_second": 1892.476,
            "eval_steps_per_second": 16.33,
            "epoch": 2.2388059701492535,
            "step": 150
        },
        {
            "loss": 0.3912,
            "grad_norm": 2.423560619354248,
            "learning_rate": 0.00011194029850746269,
            "epoch": 2.388059701492537,
            "step": 160
        },
        {
            "eval_loss": 0.43736594915390015,
            "eval_matthews_correlation": 0.544301235611677,
            "eval_runtime": 0.5303,
            "eval_samples_per_second": 1966.782,
            "eval_steps_per_second": 16.971,
            "epoch": 2.388059701492537,
            "step": 160
        },
        {
            "loss": 0.3848,
            "grad_norm": 5.089109420776367,
            "learning_rate": 8.706467661691543e-05,
            "epoch": 2.5373134328358207,
            "step": 170
        },
        {
            "eval_loss": 0.4544920027256012,
            "eval_matthews_correlation": 0.5468753188432375,
            "eval_runtime": 0.5308,
            "eval_samples_per_second": 1964.805,
            "eval_steps_per_second": 16.954,
            "epoch": 2.5373134328358207,
            "step": 170
        },
        {
            "loss": 0.3893,
            "grad_norm": 3.231407880783081,
            "learning_rate": 6.218905472636816e-05,
            "epoch": 2.6865671641791042,
            "step": 180
        },
        {
            "eval_loss": 0.41470324993133545,
            "eval_matthews_correlation": 0.5679361809424823,
            "eval_runtime": 0.5062,
            "eval_samples_per_second": 2060.331,
            "eval_steps_per_second": 17.779,
            "epoch": 2.6865671641791042,
            "step": 180
        },
        {
            "loss": 0.3346,
            "grad_norm": 3.1573774814605713,
            "learning_rate": 3.7313432835820896e-05,
            "epoch": 2.835820895522388,
            "step": 190
        },
        {
            "eval_loss": 0.4588819742202759,
            "eval_matthews_correlation": 0.5495443671948597,
            "eval_runtime": 0.5421,
            "eval_samples_per_second": 1923.86,
            "eval_steps_per_second": 16.601,
            "epoch": 2.835820895522388,
            "step": 190
        },
        {
            "loss": 0.3751,
            "grad_norm": 2.524914264678955,
            "learning_rate": 1.2437810945273633e-05,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.4659682810306549,
            "eval_matthews_correlation": 0.5469451017688902,
            "eval_runtime": 0.5283,
            "eval_samples_per_second": 1974.118,
            "eval_steps_per_second": 17.035,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "train_runtime": 40.4958,
            "train_samples_per_second": 633.473,
            "train_steps_per_second": 4.963,
            "total_flos": 1709130501849088.0,
            "train_loss": 0.4473551840924505,
            "epoch": 3.0,
            "step": 201
        },
        {
            "eval_loss": 0.4557637572288513,
            "eval_matthews_correlation": 0.5468625515611443,
            "eval_runtime": 0.5783,
            "eval_samples_per_second": 1803.483,
            "eval_steps_per_second": 15.562,
            "epoch": 3.0,
            "step": 201
        }
    ],
    "args": {
        "teacher_model_name": "./models/roberta-base",
        "student_model_name": "./models/distilroberta-base",
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "num_train_epochs": 3,
        "weight_decay": 0.01,
        "dir_name": "./converge",
        "rank": 4,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "use_rslora": true,
        "teacher_learning_rate": 5e-05,
        "student_learning_rate": 0.0005,
        "task": "cola",
        "peft": "mrlora-rs",
        "seed": 42,
        "type": 1,
        "from_disk": 1,
        "model_family": "roberta",
        "lora_ranks": [
            4,
            2,
            1
        ],
        "train_size": 8551
    },
    "train": {
        "train_time": 40.4958,
        "trainable_params_count": 0.85025,
        "memory_allocated": [
            530.911744,
            530.911744,
            530.911744
        ],
        "memory_reserved": [
            2998.92736,
            2998.92736,
            2998.92736
        ]
    },
    "variant": "lora"
}