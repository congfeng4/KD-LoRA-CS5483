{
    "eval_loss": 0.681423544883728,
    "eval_matthews_correlation": 0.3210203032701329,
    "eval_runtime": 0.1789,
    "eval_samples_per_second": 5828.721,
    "eval_steps_per_second": 50.296,
    "epoch": 3.0,
    "log_history": [
        {
            "loss": 0.7397,
            "grad_norm": 1.1557531356811523,
            "learning_rate": 9.502487562189055e-05,
            "epoch": 0.14925373134328357,
            "step": 10
        },
        {
            "eval_loss": 0.6273568868637085,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1959,
            "eval_samples_per_second": 5323.485,
            "eval_steps_per_second": 45.936,
            "epoch": 0.14925373134328357,
            "step": 10
        },
        {
            "loss": 0.655,
            "grad_norm": 0.973587155342102,
            "learning_rate": 9.00497512437811e-05,
            "epoch": 0.29850746268656714,
            "step": 20
        },
        {
            "eval_loss": 0.6505091190338135,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1907,
            "eval_samples_per_second": 5470.293,
            "eval_steps_per_second": 47.203,
            "epoch": 0.29850746268656714,
            "step": 20
        },
        {
            "loss": 0.6541,
            "grad_norm": 0.2501210570335388,
            "learning_rate": 8.507462686567164e-05,
            "epoch": 0.44776119402985076,
            "step": 30
        },
        {
            "eval_loss": 0.6260606050491333,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1542,
            "eval_samples_per_second": 6765.519,
            "eval_steps_per_second": 58.379,
            "epoch": 0.44776119402985076,
            "step": 30
        },
        {
            "loss": 0.6096,
            "grad_norm": 0.8171035051345825,
            "learning_rate": 8.00995024875622e-05,
            "epoch": 0.5970149253731343,
            "step": 40
        },
        {
            "eval_loss": 0.6308245658874512,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1505,
            "eval_samples_per_second": 6928.715,
            "eval_steps_per_second": 59.788,
            "epoch": 0.5970149253731343,
            "step": 40
        },
        {
            "loss": 0.6554,
            "grad_norm": 1.0814720392227173,
            "learning_rate": 7.512437810945275e-05,
            "epoch": 0.746268656716418,
            "step": 50
        },
        {
            "eval_loss": 0.6322606205940247,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1782,
            "eval_samples_per_second": 5853.82,
            "eval_steps_per_second": 50.512,
            "epoch": 0.746268656716418,
            "step": 50
        },
        {
            "loss": 0.6528,
            "grad_norm": 0.2918381690979004,
            "learning_rate": 7.014925373134329e-05,
            "epoch": 0.8955223880597015,
            "step": 60
        },
        {
            "eval_loss": 0.6217000484466553,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1986,
            "eval_samples_per_second": 5252.782,
            "eval_steps_per_second": 45.326,
            "epoch": 0.8955223880597015,
            "step": 60
        },
        {
            "loss": 0.6283,
            "grad_norm": 0.46436771750450134,
            "learning_rate": 6.517412935323384e-05,
            "epoch": 1.044776119402985,
            "step": 70
        },
        {
            "eval_loss": 0.6287468671798706,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.178,
            "eval_samples_per_second": 5859.716,
            "eval_steps_per_second": 50.563,
            "epoch": 1.044776119402985,
            "step": 70
        },
        {
            "loss": 0.6115,
            "grad_norm": 1.427231788635254,
            "learning_rate": 6.019900497512438e-05,
            "epoch": 1.1940298507462686,
            "step": 80
        },
        {
            "eval_loss": 0.625440776348114,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1645,
            "eval_samples_per_second": 6340.205,
            "eval_steps_per_second": 54.709,
            "epoch": 1.1940298507462686,
            "step": 80
        },
        {
            "loss": 0.5937,
            "grad_norm": 0.6792752146720886,
            "learning_rate": 5.5223880597014934e-05,
            "epoch": 1.3432835820895521,
            "step": 90
        },
        {
            "eval_loss": 0.6240359544754028,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.1741,
            "eval_samples_per_second": 5989.886,
            "eval_steps_per_second": 51.686,
            "epoch": 1.3432835820895521,
            "step": 90
        },
        {
            "loss": 0.5826,
            "grad_norm": 0.7846203446388245,
            "learning_rate": 5.024875621890548e-05,
            "epoch": 1.4925373134328357,
            "step": 100
        },
        {
            "eval_loss": 0.6319979429244995,
            "eval_matthews_correlation": 0.0463559874942472,
            "eval_runtime": 0.1842,
            "eval_samples_per_second": 5661.787,
            "eval_steps_per_second": 48.855,
            "epoch": 1.4925373134328357,
            "step": 100
        },
        {
            "loss": 0.5765,
            "grad_norm": 2.4265873432159424,
            "learning_rate": 4.5273631840796025e-05,
            "epoch": 1.6417910447761193,
            "step": 110
        },
        {
            "eval_loss": 0.6434078216552734,
            "eval_matthews_correlation": 0.11382192951310593,
            "eval_runtime": 0.1812,
            "eval_samples_per_second": 5756.744,
            "eval_steps_per_second": 49.675,
            "epoch": 1.6417910447761193,
            "step": 110
        },
        {
            "loss": 0.5594,
            "grad_norm": 2.310934066772461,
            "learning_rate": 4.029850746268657e-05,
            "epoch": 1.7910447761194028,
            "step": 120
        },
        {
            "eval_loss": 0.6349505186080933,
            "eval_matthews_correlation": 0.15650538724366975,
            "eval_runtime": 0.1734,
            "eval_samples_per_second": 6014.104,
            "eval_steps_per_second": 51.895,
            "epoch": 1.7910447761194028,
            "step": 120
        },
        {
            "loss": 0.5227,
            "grad_norm": 1.224606990814209,
            "learning_rate": 3.5323383084577115e-05,
            "epoch": 1.9402985074626866,
            "step": 130
        },
        {
            "eval_loss": 0.667560875415802,
            "eval_matthews_correlation": 0.1762247253883861,
            "eval_runtime": 0.1723,
            "eval_samples_per_second": 6052.136,
            "eval_steps_per_second": 52.224,
            "epoch": 1.9402985074626866,
            "step": 130
        },
        {
            "loss": 0.5054,
            "grad_norm": 1.2691501379013062,
            "learning_rate": 3.0348258706467664e-05,
            "epoch": 2.08955223880597,
            "step": 140
        },
        {
            "eval_loss": 0.6995013356208801,
            "eval_matthews_correlation": 0.20521028256276466,
            "eval_runtime": 0.17,
            "eval_samples_per_second": 6136.324,
            "eval_steps_per_second": 52.95,
            "epoch": 2.08955223880597,
            "step": 140
        },
        {
            "loss": 0.5142,
            "grad_norm": 2.3453967571258545,
            "learning_rate": 2.537313432835821e-05,
            "epoch": 2.2388059701492535,
            "step": 150
        },
        {
            "eval_loss": 0.6813710331916809,
            "eval_matthews_correlation": 0.30281967736946735,
            "eval_runtime": 0.184,
            "eval_samples_per_second": 5668.089,
            "eval_steps_per_second": 48.91,
            "epoch": 2.2388059701492535,
            "step": 150
        },
        {
            "loss": 0.5084,
            "grad_norm": 1.9739162921905518,
            "learning_rate": 2.0398009950248755e-05,
            "epoch": 2.388059701492537,
            "step": 160
        },
        {
            "eval_loss": 0.681423544883728,
            "eval_matthews_correlation": 0.3210203032701329,
            "eval_runtime": 0.1653,
            "eval_samples_per_second": 6310.6,
            "eval_steps_per_second": 54.454,
            "epoch": 2.388059701492537,
            "step": 160
        },
        {
            "loss": 0.4933,
            "grad_norm": 3.036275625228882,
            "learning_rate": 1.5422885572139304e-05,
            "epoch": 2.5373134328358207,
            "step": 170
        },
        {
            "eval_loss": 0.7188911437988281,
            "eval_matthews_correlation": 0.2867342894727092,
            "eval_runtime": 0.1798,
            "eval_samples_per_second": 5802.012,
            "eval_steps_per_second": 50.065,
            "epoch": 2.5373134328358207,
            "step": 170
        },
        {
            "loss": 0.5069,
            "grad_norm": 1.650412917137146,
            "learning_rate": 1.0447761194029851e-05,
            "epoch": 2.6865671641791042,
            "step": 180
        },
        {
            "eval_loss": 0.7277896404266357,
            "eval_matthews_correlation": 0.2867342894727092,
            "eval_runtime": 0.1777,
            "eval_samples_per_second": 5869.197,
            "eval_steps_per_second": 50.645,
            "epoch": 2.6865671641791042,
            "step": 180
        },
        {
            "loss": 0.4615,
            "grad_norm": 1.0455033779144287,
            "learning_rate": 5.472636815920398e-06,
            "epoch": 2.835820895522388,
            "step": 190
        },
        {
            "eval_loss": 0.7286192178726196,
            "eval_matthews_correlation": 0.30596663392312623,
            "eval_runtime": 0.1688,
            "eval_samples_per_second": 6178.731,
            "eval_steps_per_second": 53.316,
            "epoch": 2.835820895522388,
            "step": 190
        },
        {
            "loss": 0.4799,
            "grad_norm": 1.3281978368759155,
            "learning_rate": 4.975124378109453e-07,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.7301738262176514,
            "eval_matthews_correlation": 0.3097056527455597,
            "eval_runtime": 0.1694,
            "eval_samples_per_second": 6156.003,
            "eval_steps_per_second": 53.12,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "train_runtime": 13.683,
            "train_samples_per_second": 1874.804,
            "train_steps_per_second": 14.69,
            "total_flos": 865187071000576.0,
            "train_loss": 0.5752318993729738,
            "epoch": 3.0,
            "step": 201
        },
        {
            "eval_loss": 0.681423544883728,
            "eval_matthews_correlation": 0.3210203032701329,
            "eval_runtime": 0.1789,
            "eval_samples_per_second": 5828.721,
            "eval_steps_per_second": 50.296,
            "epoch": 3.0,
            "step": 201
        }
    ],
    "args": {
        "teacher_model_name": "./models/roberta-base",
        "student_model_name": "./models/distilroberta-base",
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "num_train_epochs": 3,
        "weight_decay": 0.01,
        "dir_name": "./converge",
        "rank": 4,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "use_rslora": false,
        "teacher_learning_rate": 5e-05,
        "student_learning_rate": 0.0001,
        "task": "cola",
        "peft": "lora",
        "seed": 42,
        "type": 1,
        "from_disk": 1,
        "model_family": "roberta",
        "train_size": 8551
    },
    "train": {
        "train_time": 13.683,
        "trainable_params_count": 0.665858,
        "memory_allocated": [
            357.547008,
            357.547008,
            357.547008
        ],
        "memory_reserved": [
            1174.40512,
            1174.40512,
            1174.40512
        ]
    },
    "variant": "kd-lora"
}