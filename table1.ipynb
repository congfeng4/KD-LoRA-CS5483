{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "95587a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9375c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "    'wnli': 'WNLI',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T07:17:15.910759Z",
     "start_time": "2026-01-26T07:17:15.782704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_experiment_data(json_file):\n",
    "    variant = Path(json_file).relative_to('./results').parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data['variant'] = variant\n",
    "    # with open(json_file, 'w') as f:\n",
    "    #     json.dump(data, f, indent=4)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    eval_runtime = data.get('eval_runtime', -1)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', -1)\n",
    "    train_runtime = dictor(data, 'train.train_time', -1)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else -1\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "    if 'mrlora' in peft_method:\n",
    "        rank = 2*rank - 1 # r = 2*R - 1\n",
    "        \n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb26f5",
   "metadata": {},
   "source": [
    "## FFT, KD-LoRA, LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59549e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RANKS = [15, 31]\n",
    "CAPTION = \"Results on GLUE development set for BERT-base (BERT-b), DeBERTa-v3-base (DeB-b), and RoBERTa-base (RoB-b). \" +\\\n",
    "    \"We compare different fine-tuning strategies: Fully Fine-Tuning (FFT), MR-LoRA Fine-Tuning (MR), and Knowledge Distillation MR-LoRA Fine-Tuning (KD). \" \\\n",
    "    \"Results of two total ranks $r={}$ are reported. \".format(', '.join(map(str, TOTAL_RANKS))) +\\\n",
    "    \"We report the average correlation for STS-B. \" +\\\n",
    "    \"We report mean of 3 runs using different random seeds. \"\n",
    "LABEL = 'tab:perf-params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "968d8c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results on GLUE development set for BERT-base (BERT-b), DeBERTa-v3-base (DeB-b), and RoBERTa-base (RoB-b). We compare different fine-tuning strategies: Fully Fine-Tuning (FFT), MR-LoRA Fine-Tuning (MR), and Knowledge Distillation MR-LoRA Fine-Tuning (KD). Results of two total ranks $r=15, 31$ are reported. We report the average correlation for STS-B. We report mean of 3 runs using different random seeds. '"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0363da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.variant == 'fft') | (df.peft.str.contains('mrlora-rs') & df['rank'].isin(TOTAL_RANKS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b780cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bert', 'deberta', 'roberta'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6c3aeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in METRIC_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in TASK_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in FAMILY_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6cf5213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df.value * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3c252280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15, 31,  8]),\n",
       " array(['BERT-b', 'DeB-b', 'RoB-b'], dtype=object),\n",
       " array(['mrlora-rs', 'lora'], dtype=object),\n",
       " array(['WNLI', 'MNLI', 'CoLA', 'MRPC', 'QQP', 'SST-2', 'RTE', 'QNLI',\n",
       "        'STS-B'], dtype=object),\n",
       " array(['Acc', 'm', 'mm', 'Mcc', 'F1', 'Corr_p', 'Corr_s'], dtype=object))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique(), df.family.unique(), df.peft.unique(), df.task.unique(), df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd94db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 格式化 params 的函数\n",
    "def format_params(x):\n",
    "    val = float(x)\n",
    "    # 如果是整数（如 184.0），显示为 184M\n",
    "    if val.is_integer():\n",
    "        return f\"{int(val)}M\"\n",
    "    # 如果有小数（如 0.312），保留两位显示为 0.31M\n",
    "    else:\n",
    "        return f\"{val:.2f}M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5790017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   MNLI  SST-2   CoLA          QQP   QNLI    RTE   MRPC  STS-B   WNLI    All\n",
      "                                   m/mm    Acc    Mcc       Acc/F1    Acc    Acc    Acc   Corr    Acc   Ave.\n",
      "BERT-b FFT         109.48M  83.27/83.58  92.55  55.21  90.93/88.01  90.74  64.98  87.01  88.03  42.25  77.57\n",
      "       KD$_{r=31}$ 1.16M    81.03/81.63  89.68  43.73  88.63/84.61  88.80  59.21  82.35  85.00  56.34  75.41\n",
      "       KD$_{r=15}$ 0.87M    80.16/80.86  90.37  45.03  87.98/83.67  87.97  55.96  79.17  84.77  35.21  73.57\n",
      "       MR$_{r=31}$ 1.14M    82.85/83.90  92.20  52.10  89.49/85.74  90.32  63.54  83.58  88.44  56.34  77.70\n",
      "       MR$_{r=15}$ 0.55M    81.76/82.57  91.63  52.32  88.89/84.98  90.46  61.37  83.33  88.06  56.34  77.36\n",
      "DeB-b  FFT         184.42M  89.21/89.52  95.87  64.58  92.30/89.81  93.68  80.14  89.46  91.23  56.34  83.54\n",
      "       KD$_{r=31}$ 0.57M    87.63/87.19  94.15  57.52  90.63/87.33  92.02  58.48  81.37  86.94  56.34  78.61\n",
      "       KD$_{r=15}$ 0.28M    87.46/87.37  94.15  54.96  90.09/86.75  91.89  53.79  85.05  84.42  56.34  77.15\n",
      "       MR$_{r=31}$ 1.15M    90.14/90.08  95.87  67.31  91.59/88.86  94.14  72.92  85.78  85.78  56.34  82.30\n",
      "       MR$_{r=15}$ 0.56M    90.13/90.23  94.72  67.24  91.26/88.37  94.33  67.51  83.09  61.42  56.34  77.36\n",
      "RoB-b  FFT         124.65M  87.09/87.21  92.55  59.89  90.70/87.66  92.28  62.45  90.44  90.51  56.34  80.09\n",
      "       KD$_{r=31}$ 1.16M    83.06/83.17  92.32  49.54  88.78/84.71  88.27  54.87  80.88  86.13  56.34  76.01\n",
      "       KD$_{r=15}$ 0.87M    82.49/82.89  90.94  52.33  88.56/84.42  89.49  58.84  79.66  85.59  45.07  75.19\n",
      "       MR$_{r=31}$ 1.74M    86.82/86.64  94.27  51.83  89.84/86.54  92.62  52.71  87.99  35.03  56.34  67.26\n",
      "       MR$_{r=15}$ 1.15M    86.67/86.92  94.15  50.19  89.43/86.02  92.44  63.54  84.31  87.71  56.34  76.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_74239/1286029527.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_transformed = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define the Method Label logic\n",
    "def get_method_name(row):\n",
    "    if row['variant'] == 'fft':\n",
    "        return 'FFT'\n",
    "    elif row['variant'] == 'lora':\n",
    "        return f\"MR$_{{r={int(row['rank'])}}}$\"\n",
    "    elif row['variant'] == 'kd-lora':\n",
    "        return f\"KD$_{{r={int(row['rank'])}}}$\"\n",
    "    return row['variant']\n",
    "\n",
    "df['Method'] = df.apply(get_method_name, axis=1)\n",
    "df['params'] = df.groupby(['variant', 'rank', 'family'])['params'].transform('first')\n",
    "df['params_formatted'] = df['params'].apply(format_params)\n",
    "\n",
    "# 2. Combine multi-metric tasks (MNLI m/mm and QQP Acc/F1)\n",
    "# We create a helper function to merge values into strings\n",
    "def format_values(group):\n",
    "    task = group['task'].iloc[0]\n",
    "    if task == 'MNLI':\n",
    "        # Assumes 'm' and 'mm' metrics exist for MNLI\n",
    "        m = group[group['metric'] == 'm']['value'].iloc[0]\n",
    "        mm = group[group['metric'] == 'mm']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{m:.2f}/{mm:.2f}\", 'met': 'm/mm'})\n",
    "    elif task == 'QQP':\n",
    "        # Assumes 'Acc' and 'F1' metrics exist for QQP\n",
    "        acc = group[group['metric'] == 'Acc']['value'].iloc[0]\n",
    "        f1 = group[group['metric'] == 'F1']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{acc:.2f}/{f1:.2f}\", 'met': 'Acc/F1'})\n",
    "    elif task == 'STS-B':\n",
    "        corr_s = group[group['metric'] == 'Corr_s']['value'].iloc[0]\n",
    "        corr_p = group[group['metric'] == 'Corr_p']['value'].iloc[0]\n",
    "        corr_mean = (corr_s + corr_p) / 2\n",
    "        return pd.Series({'val': f\"{corr_mean:.2f}\", 'met': 'Corr'})\n",
    "    else:\n",
    "        # Standard tasks with single metrics\n",
    "        return pd.Series({'val': f\"{group['value'].iloc[0]:.2f}\", 'met': group['metric'].iloc[0]})\n",
    "# 1. Update the transformations to include 'family'\n",
    "# Modify your groupby to include the family field\n",
    "df_transformed = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n",
    "\n",
    "# 1. Create a numeric version of the task scores for averaging\n",
    "def get_task_score(group):\n",
    "    # Average the 'value' column for the task (e.g., average of m and mm for MNLI)\n",
    "    return group['value'].mean()\n",
    "\n",
    "# Update task means for averaging\n",
    "task_means = df.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted', 'task'])['value'].mean().reset_index()\n",
    "\n",
    "# Update 'All' average to be family-specific\n",
    "all_avg = task_means.groupby(['family', 'variant', 'rank', 'Method', 'params_formatted'])['value'].mean().reset_index()\n",
    "all_avg['task'] = 'All'\n",
    "all_avg['met'] = 'Ave.'\n",
    "all_avg['val'] = all_avg['value'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Append with family preserved\n",
    "df_with_avg = pd.concat([df_transformed, all_avg[['family', 'variant', 'rank', 'Method', 'params_formatted', 'task', 'met', 'val']]], ignore_index=True)\n",
    "\n",
    "# 2. Pivot with 'family' as the top index level\n",
    "pivot_df = df_with_avg.pivot(\n",
    "    index=['family', 'variant', 'rank', 'Method', 'params_formatted'],\n",
    "    columns=['task', 'met'],\n",
    "    values='val'\n",
    ")\n",
    "\n",
    "# 3. Custom Sorting: Family first, then your existing logic\n",
    "pivot_df = pivot_df.sort_index(level=['family', 'variant', 'rank'], ascending=[True, True, False])\n",
    "\n",
    "# 4. Clean up Index\n",
    "# Keep 'family', 'Method', and 'params_formatted'\n",
    "pivot_df.index = pivot_df.index.droplevel(['variant', 'rank'])\n",
    "\n",
    "# Set index names (you can leave family as a label or remove it for a cleaner look)\n",
    "pivot_df.index.names = ['Family', 'Method', r'\\# Params']\n",
    "\n",
    "# 5. Column Ordering (to match the image)\n",
    "task_order = ['MNLI', 'SST-2', 'CoLA', 'QQP', 'QNLI', 'RTE', 'MRPC', 'STS-B', 'WNLI', 'All']\n",
    "# Filter tasks to only those present in your data\n",
    "existing_tasks = [t for t in task_order if t in pivot_df.columns.get_level_values(0)]\n",
    "pivot_df = pivot_df.reindex(columns=existing_tasks, level=0)\n",
    "\n",
    "pivot_df.columns.names = [None, None]\n",
    "pivot_df.index.names = [None, None, None]\n",
    "\n",
    "# Display result\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1fd63c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use Styler to generate the LaTeX code\n",
    "latex_code = pivot_df.style.to_latex(\n",
    "    column_format='l|l|c|' + 'c' * len(pivot_df.columns),\n",
    "    hrules=True,\n",
    "    multicol_align=\"c\",\n",
    "    multirow_align=\"c\"\n",
    ").strip()\n",
    "\n",
    "# 3. Adjust spacing for the 'tight' look in the image\n",
    "final_latex = (\n",
    "    \"\\\\begin{table}[h]\\n\"\n",
    "    \"\\\\centering\\n\"\n",
    "    \"\\\\setlength{\\\\tabcolsep}{4pt} % Smaller column gap\\n\"\n",
    "    \"\\\\renewcommand{\\\\arraystretch}{1.2} % Better vertical spacing\\n\"\n",
    "    \"\\\\caption{\" + CAPTION + \"}\\n\"\n",
    "    \"\\\\label{\" + LABEL + \"}\\n\"\n",
    "    \"\\\\resizebox{\\\\textwidth}{!}{% <--- Start resize\\n\"\n",
    "    f\"{latex_code}\"\n",
    "    \"% <--- End resize\\n}\\n\"\n",
    "    \"\\\\end{table}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f8ab321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_latex = final_latex.replace('&  &  &',\n",
    " r'\\multirow{2}{*}{\\textbf{Model}} & \\multirow{2}{*}{\\textbf{Method}} & \\multirow{2}{*}{\\textbf{\\# Params}} &', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "719df74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{4pt} % Smaller column gap\n",
      "\\renewcommand{\\arraystretch}{1.2} % Better vertical spacing\n",
      "\\caption{Results on GLUE development set for BERT-base (BERT-b), DeBERTa-v3-base (DeB-b), and RoBERTa-base (RoB-b). We compare different fine-tuning strategies: Fully Fine-Tuning (FFT), MR-LoRA Fine-Tuning (MR), and Knowledge Distillation MR-LoRA Fine-Tuning (KD). Results of two total ranks $r=15, 31$ are reported. We report the average correlation for STS-B. We report mean of 3 runs using different random seeds. }\n",
      "\\label{tab:perf-params}\n",
      "\\resizebox{\\textwidth}{!}{% <--- Start resize\n",
      "\\begin{tabular}{l|l|c|cccccccccc}\n",
      "\\toprule\n",
      " \\multirow{2}{*}{\\textbf{Model}} & \\multirow{2}{*}{\\textbf{Method}} & \\multirow{2}{*}{\\textbf{\\# Params}} & \\textbf{MNLI} & \\textbf{SST-2} & \\textbf{CoLA} & \\textbf{QQP} & \\textbf{QNLI} & \\textbf{RTE} & \\textbf{MRPC} & \\textbf{STS-B} & \\textbf{WNLI} & \\textbf{All} \\\\\n",
      " &  &  & m/mm & Acc & Mcc & Acc/F1 & Acc & Acc & Acc & Corr & Acc & Ave. \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{5}{*}{BERT-b} & FFT & 109.48M & 83.27/83.58 & 92.55 & 55.21 & 90.93/88.01 & 90.74 & 64.98 & 87.01 & 88.03 & 42.25 & 77.57 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 81.03/81.63 & 89.68 & 43.73 & 88.63/84.61 & 88.80 & 59.21 & 82.35 & 85.00 & 56.34 & 75.41 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 80.16/80.86 & 90.37 & 45.03 & 87.98/83.67 & 87.97 & 55.96 & 79.17 & 84.77 & 35.21 & 73.57 \\\\\n",
      " & MR$_{r=31}$ & 1.14M & 82.85/83.90 & 92.20 & 52.10 & 89.49/85.74 & 90.32 & 63.54 & 83.58 & 88.44 & 56.34 & 77.70 \\\\\n",
      " & MR$_{r=15}$ & 0.55M & 81.76/82.57 & 91.63 & 52.32 & 88.89/84.98 & 90.46 & 61.37 & 83.33 & 88.06 & 56.34 & 77.36 \\\\\n",
      "\\multirow[c]{5}{*}{DeB-b} & FFT & 184.42M & 89.21/89.52 & 95.87 & 64.58 & 92.30/89.81 & 93.68 & 80.14 & 89.46 & 91.23 & 56.34 & 83.54 \\\\\n",
      " & KD$_{r=31}$ & 0.57M & 87.63/87.19 & 94.15 & 57.52 & 90.63/87.33 & 92.02 & 58.48 & 81.37 & 86.94 & 56.34 & 78.61 \\\\\n",
      " & KD$_{r=15}$ & 0.28M & 87.46/87.37 & 94.15 & 54.96 & 90.09/86.75 & 91.89 & 53.79 & 85.05 & 84.42 & 56.34 & 77.15 \\\\\n",
      " & MR$_{r=31}$ & 1.15M & 90.14/90.08 & 95.87 & 67.31 & 91.59/88.86 & 94.14 & 72.92 & 85.78 & 85.78 & 56.34 & 82.30 \\\\\n",
      " & MR$_{r=15}$ & 0.56M & 90.13/90.23 & 94.72 & 67.24 & 91.26/88.37 & 94.33 & 67.51 & 83.09 & 61.42 & 56.34 & 77.36 \\\\\n",
      "\\multirow[c]{5}{*}{RoB-b} & FFT & 124.65M & 87.09/87.21 & 92.55 & 59.89 & 90.70/87.66 & 92.28 & 62.45 & 90.44 & 90.51 & 56.34 & 80.09 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 83.06/83.17 & 92.32 & 49.54 & 88.78/84.71 & 88.27 & 54.87 & 80.88 & 86.13 & 56.34 & 76.01 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 82.49/82.89 & 90.94 & 52.33 & 88.56/84.42 & 89.49 & 58.84 & 79.66 & 85.59 & 45.07 & 75.19 \\\\\n",
      " & MR$_{r=31}$ & 1.74M & 86.82/86.64 & 94.27 & 51.83 & 89.84/86.54 & 92.62 & 52.71 & 87.99 & 35.03 & 56.34 & 67.26 \\\\\n",
      " & MR$_{r=15}$ & 1.15M & 86.67/86.92 & 94.15 & 50.19 & 89.43/86.02 & 92.44 & 63.54 & 84.31 & 87.71 & 56.34 & 76.75 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}% <--- End resize\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "task_values = list(TASK_NAME_MAP.values()) + ['All']\n",
    "for task in task_values:\n",
    "    final_latex = final_latex.replace('& ' + task, r'& \\textbf{'+task+'}')\n",
    "\n",
    "print(final_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b0899991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\setlength{\\tabcolsep}{4pt} % Smaller column gap\n",
      "\\renewcommand{\\arraystretch}{1.2} % Better vertical spacing\n",
      "\\caption{Results on GLUE development set for BERT-base (BERT-b), DeBERTa-v3-base (DeB-b), and RoBERTa-base (RoB-b). We compare different fine-tuning strategies: Fully Fine-Tuning (FFT), MR-LoRA Fine-Tuning (MR), and Knowledge Distillation MR-LoRA Fine-Tuning (KD). Results of two total ranks $r=15, 31$ are reported. We report the average correlation for STS-B. We report mean of 3 runs using different random seeds. }\n",
      "\\label{tab:perf-params}\n",
      "\\resizebox{\\textwidth}{!}{% <--- Start resize\n",
      "\\begin{tabular}{l|l|c|cccccccccc}\n",
      "\\toprule\n",
      " \\multirow{2}{*}{\\textbf{Model}} & \\multirow{2}{*}{\\textbf{Method}} & \\multirow{2}{*}{\\textbf{\\# Params}} & \\textbf{MNLI} & \\textbf{SST-2} & \\textbf{CoLA} & \\textbf{QQP} & \\textbf{QNLI} & \\textbf{RTE} & \\textbf{MRPC} & \\textbf{STS-B} & \\textbf{WNLI} & \\textbf{All} \\\\\n",
      " &  &  & m/mm & Acc & Mcc & Acc/F1 & Acc & Acc & Acc & Corr & Acc & Ave. \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{5}{*}{BERT-b} & FFT & 109.48M & 83.27/83.58 & 92.55 & 55.21 & 90.93/88.01 & 90.74 & 64.98 & 87.01 & 88.03 & 42.25 & 77.57 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 81.03/81.63 & 89.68 & 43.73 & 88.63/84.61 & 88.80 & 59.21 & 82.35 & 85.00 & 56.34 & 75.41 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 80.16/80.86 & 90.37 & 45.03 & 87.98/83.67 & 87.97 & 55.96 & 79.17 & 84.77 & 35.21 & 73.57 \\\\\n",
      " & MR$_{r=31}$ & 1.14M & 82.85/83.90 & 92.20 & 52.10 & 89.49/85.74 & 90.32 & 63.54 & 83.58 & 88.44 & 56.34 & 77.70 \\\\\n",
      " & MR$_{r=15}$ & 0.55M & 81.76/82.57 & 91.63 & 52.32 & 88.89/84.98 & 90.46 & 61.37 & 83.33 & 88.06 & 56.34 & 77.36 \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{5}{*}{DeB-b} & FFT & 184.42M & 89.21/89.52 & 95.87 & 64.58 & 92.30/89.81 & 93.68 & 80.14 & 89.46 & 91.23 & 56.34 & 83.54 \\\\\n",
      " & KD$_{r=31}$ & 0.57M & 87.63/87.19 & 94.15 & 57.52 & 90.63/87.33 & 92.02 & 58.48 & 81.37 & 86.94 & 56.34 & 78.61 \\\\\n",
      " & KD$_{r=15}$ & 0.28M & 87.46/87.37 & 94.15 & 54.96 & 90.09/86.75 & 91.89 & 53.79 & 85.05 & 84.42 & 56.34 & 77.15 \\\\\n",
      " & MR$_{r=31}$ & 1.15M & 90.14/90.08 & 95.87 & 67.31 & 91.59/88.86 & 94.14 & 72.92 & 85.78 & 85.78 & 56.34 & 82.30 \\\\\n",
      " & MR$_{r=15}$ & 0.56M & 90.13/90.23 & 94.72 & 67.24 & 91.26/88.37 & 94.33 & 67.51 & 83.09 & 61.42 & 56.34 & 77.36 \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{5}{*}{RoB-b} & FFT & 124.65M & 87.09/87.21 & 92.55 & 59.89 & 90.70/87.66 & 92.28 & 62.45 & 90.44 & 90.51 & 56.34 & 80.09 \\\\\n",
      " & KD$_{r=31}$ & 1.16M & 83.06/83.17 & 92.32 & 49.54 & 88.78/84.71 & 88.27 & 54.87 & 80.88 & 86.13 & 56.34 & 76.01 \\\\\n",
      " & KD$_{r=15}$ & 0.87M & 82.49/82.89 & 90.94 & 52.33 & 88.56/84.42 & 89.49 & 58.84 & 79.66 & 85.59 & 45.07 & 75.19 \\\\\n",
      " & MR$_{r=31}$ & 1.74M & 86.82/86.64 & 94.27 & 51.83 & 89.84/86.54 & 92.62 & 52.71 & 87.99 & 35.03 & 56.34 & 67.26 \\\\\n",
      " & MR$_{r=15}$ & 1.15M & 86.67/86.92 & 94.15 & 50.19 & 89.43/86.02 & 92.44 & 63.54 & 84.31 & 87.71 & 56.34 & 76.75 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}% <--- End resize\n",
      "}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def add_latex_family_dividers(latex_str):\n",
    "    # This regex looks for a line starting with a family name (not an empty cell)\n",
    "    # It avoids the header by looking for rows after the first \\midrule\n",
    "    \n",
    "    # 1. Find the start of the data rows (usually after the metric header)\n",
    "    header_end_split = latex_str.split('\\\\midrule', 1)\n",
    "    if len(header_end_split) < 2:\n",
    "        return latex_str\n",
    "    \n",
    "    header = header_end_split[0] + '\\\\midrule'\n",
    "    body = header_end_split[1]\n",
    "\n",
    "    # 2. Regex to find the start of a NEW family block.\n",
    "    # In MultiIndex LaTeX, a new index level starts with text, \n",
    "    # while sub-rows start with ' &' or '  &'.\n",
    "    # We look for: Start of line + word characters + '&'\n",
    "    # But we skip the very first line of the body to avoid double midrules.\n",
    "    \n",
    "    lines = body.split('\\n')\n",
    "    new_body = []\n",
    "    \n",
    "    # We track if we are at the very first data line\n",
    "    first_data_line = True\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if the line starts a new family (e.g., 'BERT-b &')\n",
    "        # This regex matches lines that start with text before the first '&'\n",
    "        if re.match(r'\\\\multirow.* &', line.strip()):\n",
    "            if not first_data_line:\n",
    "                # Insert a midrule before this line\n",
    "                new_body.append('\\\\midrule')\n",
    "            first_data_line = False\n",
    "        \n",
    "        new_body.append(line)\n",
    "\n",
    "    return header + '\\n'.join(new_body)\n",
    "\n",
    "# Usage:\n",
    "final_latex = add_latex_family_dividers(final_latex)\n",
    "print(final_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5287253d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2924"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('./MrLoRA/table1.tex').write_text(final_latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
