{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95587a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9375c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T07:17:15.910759Z",
     "start_time": "2026-01-26T07:17:15.782704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_experiment_data(json_file):\n",
    "    variant = Path(json_file).relative_to('./results').parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data['variant'] = variant\n",
    "    # with open(json_file, 'w') as f:\n",
    "    #     json.dump(data, f, indent=4)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    eval_runtime = data.get('eval_runtime', -1)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', -1)\n",
    "    train_runtime = dictor(data, 'train.train_time', -1)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else -1\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "    if 'mrlora' in peft_method:\n",
    "        rank = 2*rank - 1 # r = 2*R - 1\n",
    "        \n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb26f5",
   "metadata": {},
   "source": [
    "## FFT, KD-LoRA, LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59549e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RANKS = [15, 31]\n",
    "MODEL_FAMILY = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0363da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.variant == 'fft') | (df.peft.str.contains('mrlora') & df['rank'].isin(TOTAL_RANKS))]\n",
    "df = df[df.family == MODEL_FAMILY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c3aeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in METRIC_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in TASK_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6cf5213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df.value * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c252280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15, 31,  8]),\n",
       " array(['bert'], dtype=object),\n",
       " array(['mrlora', 'mrlora-rs', 'lora'], dtype=object),\n",
       " array(['wnli', 'CoLA', 'SST-2', 'MRPC', 'MNLI', 'QNLI', 'STS-B', 'QQP',\n",
       "        'RTE'], dtype=object),\n",
       " array(['Acc', 'Mcc', 'F1', 'm', 'mm', 'Corr_p', 'Corr_s'], dtype=object))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique(), df.family.unique(), df.peft.unique(), df.task.unique(), df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd94db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 格式化 params 的函数\n",
    "def format_params(x):\n",
    "    val = float(x)\n",
    "    # 如果是整数（如 184.0），显示为 184M\n",
    "    if val.is_integer():\n",
    "        return f\"{int(val)}M\"\n",
    "    # 如果有小数（如 0.312），保留两位显示为 0.31M\n",
    "    else:\n",
    "        return f\"{val:.2f}M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5790017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task                               MNLI  SST-2   CoLA          QQP   QNLI    RTE   MRPC        STS-B\n",
      "met                                m/mm    Acc    Mcc       Acc/F1    Acc    Acc    Acc   Pear/Spear\n",
      "Method           \\# Params                                                                          \n",
      "Full FT          109.48M    83.27/83.58  92.55  55.21  90.93/88.01  90.74  64.98  87.01  88.26/87.79\n",
      "KD-LoRA$_{r=31}$ 1.16M      80.02/80.44  89.68  44.28  87.72/83.40  86.53  55.23  71.81  83.46/83.21\n",
      "KD-LoRA$_{r=15}$ 0.87M      79.24/80.04  90.60  42.10  87.44/82.96  86.14  53.07  72.55  83.32/83.26\n",
      "LoRA$_{r=31}$    1.14M      82.80/83.43  91.28  50.23  89.07/85.27  90.44  55.96  78.92  87.78/87.62\n",
      "LoRA$_{r=15}$    0.55M      83.16/83.54  91.51  48.60  88.64/84.63  90.26  56.32  79.66  87.32/87.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:63: SyntaxWarning: invalid escape sequence '\\#'\n",
      "<>:63: SyntaxWarning: invalid escape sequence '\\#'\n",
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_74239/847689742.py:63: SyntaxWarning: invalid escape sequence '\\#'\n",
      "  pivot_df.index.names = ['Method', '\\# Params']\n",
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_74239/847689742.py:39: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_transformed = df.groupby(['variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define the Method Label logic\n",
    "def get_method_name(row):\n",
    "    if row['variant'] == 'fft':\n",
    "        return 'Full FT'\n",
    "    elif row['variant'] == 'lora':\n",
    "        return f\"LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    elif row['variant'] == 'kd-lora':\n",
    "        return f\"KD-LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    return row['variant']\n",
    "\n",
    "df['Method'] = df.apply(get_method_name, axis=1)\n",
    "df['params'] = df.groupby(['variant', 'rank'])['params'].transform('first')\n",
    "df['params_formatted'] = df['params'].apply(format_params)\n",
    "\n",
    "# 2. Combine multi-metric tasks (MNLI m/mm and QQP Acc/F1)\n",
    "# We create a helper function to merge values into strings\n",
    "def format_values(group):\n",
    "    task = group['task'].iloc[0]\n",
    "    if task == 'MNLI':\n",
    "        # Assumes 'm' and 'mm' metrics exist for MNLI\n",
    "        m = group[group['metric'] == 'm']['value'].iloc[0]\n",
    "        mm = group[group['metric'] == 'mm']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{m:.2f}/{mm:.2f}\", 'met': 'm/mm'})\n",
    "    elif task == 'QQP':\n",
    "        # Assumes 'Acc' and 'F1' metrics exist for QQP\n",
    "        acc = group[group['metric'] == 'Acc']['value'].iloc[0]\n",
    "        f1 = group[group['metric'] == 'F1']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{acc:.2f}/{f1:.2f}\", 'met': 'Acc/F1'})\n",
    "    elif task == 'STS-B':\n",
    "        corr_s = group[group['metric'] == 'Corr_s']['value'].iloc[0]\n",
    "        corr_p = group[group['metric'] == 'Corr_p']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{corr_p:.2f}/{corr_s:.2f}\", 'met': 'Pear/Spear'})\n",
    "    else:\n",
    "        # Standard tasks with single metrics\n",
    "        return pd.Series({'val': f\"{group['value'].iloc[0]:.2f}\", 'met': group['metric'].iloc[0]})\n",
    "\n",
    "df_transformed = df.groupby(['variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n",
    "\n",
    "# 3. Pivot the table\n",
    "# Index: Method and Params\n",
    "# Columns: Task and the combined Metric name\n",
    "pivot_df = df_transformed.pivot(\n",
    "    index=['variant', 'rank', 'Method', 'params_formatted'],\n",
    "    columns=['task', 'met'],\n",
    "    values='val'\n",
    ")\n",
    "\n",
    "# 4. Custom Sorting\n",
    "# Use variant to put 'fft' first, then rank descending (31 then 15)\n",
    "pivot_df = pivot_df.sort_index(level=['variant', 'rank'], ascending=[True, False])\n",
    "\n",
    "# Clean up index: remove the helper columns used for sorting\n",
    "pivot_df.index = pivot_df.index.droplevel(['variant', 'rank'])\n",
    "\n",
    "# 5. Column Ordering (to match the image)\n",
    "task_order = ['MNLI', 'SST-2', 'CoLA', 'QQP', 'QNLI', 'RTE', 'MRPC', 'STS-B', 'All']\n",
    "# Filter tasks to only those present in your data\n",
    "existing_tasks = [t for t in task_order if t in pivot_df.columns.get_level_values(0)]\n",
    "pivot_df = pivot_df.reindex(columns=existing_tasks, level=0)\n",
    "\n",
    "pivot_df.index.names = ['Method', '\\# Params']\n",
    "\n",
    "# Display result\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec9136d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l|c|cccccccc}\n",
      "\\toprule\n",
      " &  & MNLI & SST-2 & CoLA & QQP & QNLI & RTE & MRPC & STS-B \\\\\n",
      " &  & m/mm & Acc & Mcc & Acc/F1 & Acc & Acc & Acc & Pear/Spear \\\\\n",
      "Method & \\# Params &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Full FT & 109.48M & 83.27/83.58 & 92.55 & 55.21 & 90.93/88.01 & 90.74 & 64.98 & 87.01 & 88.26/87.79 \\\\\n",
      "\\cline{1-10}\n",
      "KD-LoRA$_{r=31}$ & 1.16M & 80.02/80.44 & 89.68 & 44.28 & 87.72/83.40 & 86.53 & 55.23 & 71.81 & 83.46/83.21 \\\\\n",
      "\\cline{1-10}\n",
      "KD-LoRA$_{r=15}$ & 0.87M & 79.24/80.04 & 90.60 & 42.10 & 87.44/82.96 & 86.14 & 53.07 & 72.55 & 83.32/83.26 \\\\\n",
      "\\cline{1-10}\n",
      "LoRA$_{r=31}$ & 1.14M & 82.80/83.43 & 91.28 & 50.23 & 89.07/85.27 & 90.44 & 55.96 & 78.92 & 87.78/87.62 \\\\\n",
      "\\cline{1-10}\n",
      "LoRA$_{r=15}$ & 0.55M & 83.16/83.54 & 91.51 & 48.60 & 88.64/84.63 & 90.26 & 56.32 & 79.66 & 87.32/87.12 \\\\\n",
      "\\cline{1-10}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成 LaTeX 代码\n",
    "latex_code = pivot_df.to_latex(\n",
    "    # multicol_aggregator='center', \n",
    "    column_format='l|c|' + 'c'*len(pivot_df.columns),\n",
    "    caption=\"\",\n",
    "    \n",
    "    label=\"\"\n",
    ")\n",
    "latex_code = latex_code.replace('task', '').replace('met', '')\n",
    "print(latex_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
