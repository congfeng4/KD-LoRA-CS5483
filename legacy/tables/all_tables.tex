\begin{table}[ht]
\centering
\begin{tabular}{lccccccccc}
\toprule
Method & CoLA & MNLI & MRPC & QNLI & QQP & RTE & SST-2 & STS-B & WNLI \\
\midrule
LoRA & 0.509 & 0.821 & 0.852 & 0.901 & 0.843 & 0.588 & 0.910 & 0.868 & 0.563 \\
DoRA & 0.498 & 0.823 & 0.858 & 0.900 & 0.844 & 0.592 & 0.913 & 0.870 & 0.563 \\
MrLoRA & 0.500 & \textbf{0.828} & 0.866 & 0.903 & 0.848 & 0.595 & \textbf{0.916} & 0.873 & 0.567 \\
MrLoRA-RS & 0.518 & 0.826 & \textbf{0.887} & \textbf{0.908} & \textbf{0.853} & \textbf{0.628} & 0.915 & \textbf{0.882} & 0.563 \\
OLoRA & 0.485 & 0.822 & 0.857 & 0.903 & 0.844 & 0.578 & 0.911 & 0.870 & 0.563 \\
RSLoRA & \textbf{0.521} & 0.825 & 0.882 & 0.905 & 0.849 & 0.604 & \textbf{0.916} & 0.876 & \textbf{0.570} \\
\bottomrule
\end{tabular}
\caption{Performance of LoRA variants on GLUE tasks (bert family)}
\label{tab:bert_glue}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lccccccccc}
\toprule
Method & CoLA & MNLI & MRPC & QNLI & QQP & RTE & SST-2 & STS-B & WNLI \\
\midrule
LoRA & 0.515 & 0.865 & 0.847 & 0.918 & 0.854 & 0.599 & 0.933 & 0.870 & 0.560 \\
DoRA & 0.529 & 0.865 & 0.846 & 0.918 & 0.854 & 0.602 & 0.933 & 0.868 & 0.560 \\
MrLoRA & \textbf{0.543} & \textbf{0.867} & 0.872 & \textbf{0.922} & 0.858 & 0.625 & 0.939 & 0.872 & \textbf{0.563} \\
MrLoRA-RS & 0.517 & 0.740 & \textbf{0.902} & 0.715 & 0.645 & 0.580 & \textbf{0.942} & 0.744 & \textbf{0.563} \\
OLoRA & 0.487 & 0.863 & 0.864 & 0.920 & 0.853 & \textbf{0.637} & 0.939 & 0.874 & 0.560 \\
RSLoRA & 0.526 & 0.740 & 0.879 & 0.916 & \textbf{0.860} & 0.614 & 0.935 & \textbf{0.880} & \textbf{0.563} \\
\bottomrule
\end{tabular}
\caption{Performance of LoRA variants on GLUE tasks (roberta family)}
\label{tab:roberta_glue}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lccccccccc}
\toprule
Method & CoLA & MNLI & MRPC & QNLI & QQP & RTE & SST-2 & STS-B & WNLI \\
\midrule
LoRA & 0.627 & 0.901 & 0.846 & 0.938 & 0.873 & 0.527 & 0.950 & 0.836 & \textbf{0.563} \\
DoRA & 0.626 & 0.902 & 0.850 & 0.937 & 0.874 & 0.527 & 0.952 & 0.650 & \textbf{0.563} \\
MrLoRA & 0.631 & \textbf{0.902} & 0.848 & 0.940 & 0.878 & 0.607 & \textbf{0.955} & 0.851 & \textbf{0.563} \\
MrLoRA-RS & \textbf{0.661} & 0.902 & \textbf{0.894} & 0.941 & \textbf{0.885} & \textbf{0.694} & 0.950 & 0.586 & \textbf{0.563} \\
OLoRA & 0.618 & 0.899 & 0.864 & 0.938 & 0.875 & 0.599 & 0.953 & \textbf{0.872} & \textbf{0.563} \\
RSLoRA & 0.628 & 0.901 & 0.874 & \textbf{0.941} & 0.881 & 0.637 & 0.952 & 0.665 & \textbf{0.563} \\
\bottomrule
\end{tabular}
\caption{Performance of LoRA variants on GLUE tasks (deberta family)}
\label{tab:deberta_glue}
\end{table}

