\begin{table}[ht]
\centering
\begin{tabular}{lccccccccc}
\toprule
Method & CoLA & MNLI & MRPC & QNLI & QQP & RTE & SST-2 & STS-B & WNLI \\
\midrule
LoRA & 0.627 & 0.901 & 0.846 & 0.938 & 0.873 & 0.527 & 0.950 & 0.836 & \textbf{0.563} \\
DoRA & 0.626 & 0.902 & 0.850 & 0.937 & 0.874 & 0.527 & 0.952 & 0.650 & \textbf{0.563} \\
MrLoRA & 0.631 & \textbf{0.902} & 0.848 & 0.940 & 0.878 & 0.607 & \textbf{0.955} & 0.851 & \textbf{0.563} \\
MrLoRA-RS & \textbf{0.661} & 0.902 & \textbf{0.894} & 0.941 & \textbf{0.885} & \textbf{0.694} & 0.950 & 0.586 & \textbf{0.563} \\
OLoRA & 0.618 & 0.899 & 0.864 & 0.938 & 0.875 & 0.599 & 0.953 & \textbf{0.872} & \textbf{0.563} \\
RSLoRA & 0.628 & 0.901 & 0.874 & \textbf{0.941} & 0.881 & 0.637 & 0.952 & 0.665 & \textbf{0.563} \\
\bottomrule
\end{tabular}
\caption{Performance of LoRA variants on GLUE tasks (deberta family)}
\label{tab:deberta_glue}
\end{table}