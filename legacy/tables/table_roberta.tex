\begin{table}[ht]
\centering
\begin{tabular}{lccccccccc}
\toprule
Method & CoLA & MNLI & MRPC & QNLI & QQP & RTE & SST-2 & STS-B & WNLI \\
\midrule
LoRA & 0.515 & 0.865 & 0.847 & 0.918 & 0.854 & 0.599 & 0.933 & 0.870 & 0.560 \\
DoRA & 0.529 & 0.865 & 0.846 & 0.918 & 0.854 & 0.602 & 0.933 & 0.868 & 0.560 \\
MrLoRA & \textbf{0.543} & \textbf{0.867} & 0.872 & \textbf{0.922} & 0.858 & 0.625 & 0.939 & 0.872 & \textbf{0.563} \\
MrLoRA-RS & 0.517 & 0.740 & \textbf{0.902} & 0.715 & 0.645 & 0.580 & \textbf{0.942} & 0.744 & \textbf{0.563} \\
OLoRA & 0.487 & 0.863 & 0.864 & 0.920 & 0.853 & \textbf{0.637} & 0.939 & 0.874 & 0.560 \\
RSLoRA & 0.526 & 0.740 & 0.879 & 0.916 & \textbf{0.860} & 0.614 & 0.935 & \textbf{0.880} & \textbf{0.563} \\
\bottomrule
\end{tabular}
\caption{Performance of LoRA variants on GLUE tasks (roberta family)}
\label{tab:roberta_glue}
\end{table}