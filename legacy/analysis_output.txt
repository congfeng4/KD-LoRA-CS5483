Loaded DataFrame shape: (11, 10)

Column names: ['Task', 'BERT-b/DBERT-b FFT', 'BERT-b/DBERT-b LoRA', 'BERT-b/DBERT-b KD-LoRA', 'DeB-b/DeB-s FFT', 'DeB-b/DeB-s LoRA', 'DeB-b/DeB-s KD-LoRA', 'RoB-b/DRoB-b FFT', 'RoB-b/DRoB-b LoRA', 'RoB-b/DRoB-b KD-LoRA']

First few rows:
      Task  BERT-b/DBERT-b FFT  ...  RoB-b/DRoB-b LoRA  RoB-b/DRoB-b KD-LoRA
0     CoLA                57.7  ...               59.4                  56.8
1   MNLI_m                84.5  ...               87.2                  83.3
2  MNLI_mm                84.9  ...               86.9                  83.4
3     MRPC                89.0  ...               89.9                  89.3
4     QNLI                91.8  ...               92.8                  90.7

[5 rows x 10 columns]

Average scores per model family per strategy (excluding Score row):
     Model_Family Strategy  Score
0  BERT-b/DBERT-b      FFT  80.78
1  BERT-b/DBERT-b  KD-LoRA  78.88
2  BERT-b/DBERT-b     LoRA  80.09
3     DeB-b/DeB-s      FFT  86.52
4     DeB-b/DeB-s  KD-LoRA  84.05
5     DeB-b/DeB-s     LoRA  85.26
6    RoB-b/DRoB-b      FFT  82.58
7    RoB-b/DRoB-b  KD-LoRA  79.32
8    RoB-b/DRoB-b     LoRA  81.74

Relative performance drops (positive means first better than second):
         BERT-b/DBERT-b_FFT_to_LoRA  ...  RoB-b/DRoB-b_LoRA_to_KD_LoRA
Task                                 ...                              
CoLA                            0.8  ...                           2.6
MNLI_m                          1.1  ...                           3.9
MNLI_mm                         1.0  ...                           3.5
MRPC                           -0.2  ...                           0.6
QNLI                            0.7  ...                           2.1
QQP                             1.8  ...                           1.3
RTE                             1.5  ...                           6.5
SST-2                           0.2  ...                           1.3
STS-B                           0.6  ...                           2.4
WNLI                           -0.6  ...                           0.0

[10 rows x 9 columns]

Tasks where KD-LoRA performs better than LoRA:
BERT-b/DBERT-b: ['QQP']
DeB-b/DeB-s: []
RoB-b/DRoB-b: []

Tasks where KD-LoRA performs better than FFT:
BERT-b/DBERT-b: []
DeB-b/DeB-s: ['CoLA']
RoB-b/DRoB-b: []

Tasks where LoRA underperforms FFT by >2.0%:
BERT-b/DBERT-b: []
DeB-b/DeB-s: ['WNLI']
RoB-b/DRoB-b: ['RTE']

Computed average scores across tasks (verification):
BERT-b/DBERT-b FFT        80.78
BERT-b/DBERT-b LoRA       80.09
BERT-b/DBERT-b KD-LoRA    78.88
DeB-b/DeB-s FFT           86.52
DeB-b/DeB-s LoRA          85.26
DeB-b/DeB-s KD-LoRA       84.05
RoB-b/DRoB-b FFT          82.58
RoB-b/DRoB-b LoRA         81.74
RoB-b/DRoB-b KD-LoRA      79.32
dtype: float64

Provided Score row:
BERT-b/DBERT-b FFT        80.8
BERT-b/DBERT-b LoRA       80.1
BERT-b/DBERT-b KD-LoRA    78.9
DeB-b/DeB-s FFT           86.5
DeB-b/DeB-s LoRA          85.3
DeB-b/DeB-s KD-LoRA       84.1
RoB-b/DRoB-b FFT          82.6
RoB-b/DRoB-b LoRA         81.7
RoB-b/DRoB-b KD-LoRA      79.3
Name: 10, dtype: float64

Plots saved to 'analysis_plots' directory.

============================================================
ANALYSIS SUMMARY
============================================================
Best performing model family: DeB-b/DeB-s (average across strategies: 85.3%)
Best performing strategy: FFT (average across models: 83.3%)
Average performance drop from FFT to KD-LoRA: 2.54 percentage points

Most robust tasks to distillation (smallest drop from FFT to KD-LoRA):
  SST-2: 0.80% drop
  MRPC: 1.23% drop
  QQP: 1.47% drop

Most sensitive tasks to distillation (largest drop from FFT to KD-LoRA):
  RTE: 7.77% drop
  WNLI: 3.53% drop
  MNLI_m: 2.80% drop

Surprising results (KD-LoRA outperforming LoRA):
  BERT-b/DBERT-b: ['QQP']

Surprising results (KD-LoRA outperforming FFT):
  DeB-b/DeB-s: ['CoLA']

============================================================
Analysis complete.
============================================================
