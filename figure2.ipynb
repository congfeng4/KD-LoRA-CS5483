{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95587a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9375c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T07:17:15.910759Z",
     "start_time": "2026-01-26T07:17:15.782704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_experiment_data(json_file):\n",
    "    variant = Path(json_file).relative_to('./results').parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data['variant'] = variant\n",
    "    # with open(json_file, 'w') as f:\n",
    "    #     json.dump(data, f, indent=4)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    eval_runtime = data.get('eval_runtime', -1)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', -1)\n",
    "    train_runtime = dictor(data, 'train.train_time', -1)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else -1\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "    if 'mrlora' in peft_method:\n",
    "        rank = 2*rank - 1 # r = 2*R - 1\n",
    "        \n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df = aggregate_experiment_results('./results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3aeb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in METRIC_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in TASK_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf5213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df.value * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb26f5",
   "metadata": {},
   "source": [
    "## FFT, KD-LoRA, LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd94db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 格式化 params 的函数\n",
    "def format_params(x):\n",
    "    val = float(x)\n",
    "    # 如果是整数（如 184.0），显示为 184M\n",
    "    if val.is_integer():\n",
    "        return f\"{int(val)}M\"\n",
    "    # 如果有小数（如 0.312），保留两位显示为 0.31M\n",
    "    else:\n",
    "        return f\"{val:.2f}M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59549e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RANKS = [15, 31]\n",
    "MODEL_FAMILY = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e530d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c252280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16,   8,  32,  64, 127,  15,  31,  63]),\n",
       " array(['bert', 'deberta', 'roberta'], dtype=object),\n",
       " array(['olora', 'rslora', 'lora', 'dora', 'mrlora-rs', 'mrlora'],\n",
       "       dtype=object),\n",
       " array(['wnli', 'MNLI', 'CoLA', 'MRPC', 'QQP', 'SST-2', 'RTE', 'QNLI',\n",
       "        'STS-B'], dtype=object),\n",
       " array(['Acc', 'm', 'mm', 'Mcc', 'F1', 'Corr_p', 'Corr_s'], dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique(), df.family.unique(), df.peft.unique(), df.task.unique(), df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5790017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              MNLI  SST-2   CoLA          QQP   QNLI    RTE   MRPC  STS-B    All\n",
      "                              m/mm    Acc    Mcc       Acc/F1    Acc    Acc    Acc   Corr   Ave.\n",
      "FFT           109.48M  89.21/89.52  92.55  64.58  92.30/89.81  90.74  62.45  90.44  88.03  80.40\n",
      "KD$_{r=127}$  2.93M    88.08/87.33  90.02  58.55  91.01/88.07  89.55  59.21  68.38  86.12  74.80\n",
      "KD$_{r=64}$   1.77M    85.55/85.76  87.84  44.22  88.23/83.55  86.03  52.71  71.08  82.11  72.82\n",
      "KD$_{r=63}$   1.75M    87.76/87.43  90.37  58.80  90.63/87.28  88.74  62.45  74.02  85.81  75.50\n",
      "KD$_{r=32}$   1.19M    85.53/85.84  88.30  43.60  88.22/83.65  86.23  52.71  71.08  83.36  72.43\n",
      "KD$_{r=31}$   1.16M    87.39/86.95  89.68  55.73  89.96/86.45  86.53  53.79  71.57  83.34  75.59\n",
      "KD$_{r=16}$   0.89M    86.08/86.26  88.76  47.25  88.62/84.21  86.67  52.71  70.59  69.10  72.09\n",
      "KD$_{r=15}$   0.87M    86.94/86.71  90.60  54.43  89.55/85.99  86.14  54.87  73.28  83.29  74.49\n",
      "KD$_{r=8}$    0.74M    85.79/86.02  89.22  48.94  88.27/83.52  86.78  54.51  71.32  82.57  72.26\n",
      "LoRA$_{r=63}$ 2.32M            NaN    NaN    NaN  88.84/84.89  90.92  47.29  83.82    NaN  76.00\n",
      "LoRA$_{r=32}$ 1.20M    82.66/82.94    NaN    NaN  89.09/85.60  90.43  58.84  76.96  86.77  78.27\n",
      "LoRA$_{r=31}$ 1.14M    90.19/90.01  95.30  62.16  90.77/87.72  90.44  60.65  80.88  87.70  76.65\n",
      "LoRA$_{r=16}$ 0.59M    89.96/89.90  90.37  65.53  90.78/87.79  90.46  61.73  81.13  87.44  77.57\n",
      "LoRA$_{r=15}$ 0.55M    90.16/90.05  91.51  63.60  90.61/87.58  90.26  64.26  81.86  87.22  77.66\n",
      "LoRA$_{r=8}$  0.30M    90.07/90.08  91.63  63.32  90.99/88.13  90.28  65.34  78.43  87.76  76.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_31229/1563040795.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_transformed = df.groupby(['variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Define the Method Label logic\n",
    "def get_method_name(row):\n",
    "    if row['variant'] == 'fft':\n",
    "        return 'FFT'\n",
    "    elif row['variant'] == 'lora':\n",
    "        return f\"LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    elif row['variant'] == 'kd-lora':\n",
    "        return f\"KD$_{{r={int(row['rank'])}}}$\"\n",
    "        # return f\"KD-LoRA$_{{r={int(row['rank'])}}}$\"\n",
    "    return row['variant']\n",
    "\n",
    "df['Method'] = df.apply(get_method_name, axis=1)\n",
    "df['params'] = df.groupby(['variant', 'rank'])['params'].transform('first')\n",
    "df['params_formatted'] = df['params'].apply(format_params)\n",
    "\n",
    "# 2. Combine multi-metric tasks (MNLI m/mm and QQP Acc/F1)\n",
    "# We create a helper function to merge values into strings\n",
    "def format_values(group):\n",
    "    task = group['task'].iloc[0]\n",
    "    if task == 'MNLI':\n",
    "        # Assumes 'm' and 'mm' metrics exist for MNLI\n",
    "        m = group[group['metric'] == 'm']['value'].iloc[0]\n",
    "        mm = group[group['metric'] == 'mm']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{m:.2f}/{mm:.2f}\", 'met': 'm/mm'})\n",
    "    elif task == 'QQP':\n",
    "        # Assumes 'Acc' and 'F1' metrics exist for QQP\n",
    "        acc = group[group['metric'] == 'Acc']['value'].iloc[0]\n",
    "        f1 = group[group['metric'] == 'F1']['value'].iloc[0]\n",
    "        return pd.Series({'val': f\"{acc:.2f}/{f1:.2f}\", 'met': 'Acc/F1'})\n",
    "    elif task == 'STS-B':\n",
    "        corr_s = group[group['metric'] == 'Corr_s']['value'].iloc[0]\n",
    "        corr_p = group[group['metric'] == 'Corr_p']['value'].iloc[0]\n",
    "        corr_mean = (corr_s + corr_p) / 2\n",
    "        return pd.Series({'val': f\"{corr_mean:.2f}\", 'met': 'Corr'})\n",
    "    else:\n",
    "        # Standard tasks with single metrics\n",
    "        return pd.Series({'val': f\"{group['value'].iloc[0]:.2f}\", 'met': group['metric'].iloc[0]})\n",
    "\n",
    "df_transformed = df.groupby(['variant', 'rank', 'Method', 'params_formatted', 'task'], as_index=False).apply(format_values)\n",
    "\n",
    "# 1. Create a numeric version of the task scores for averaging\n",
    "def get_task_score(group):\n",
    "    # Average the 'value' column for the task (e.g., average of m and mm for MNLI)\n",
    "    return group['value'].mean()\n",
    "\n",
    "# Calculate task-level means\n",
    "task_means = df.groupby(['variant', 'rank', 'Method', 'params_formatted', 'task'])['value'].mean().reset_index()\n",
    "\n",
    "# 2. Calculate the 'All' average across all tasks for each method\n",
    "all_avg = task_means.groupby(['variant', 'rank', 'Method', 'params_formatted'])['value'].mean().reset_index()\n",
    "all_avg['task'] = 'All'\n",
    "all_avg['met'] = 'Ave.'\n",
    "all_avg['val'] = all_avg['value'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# 3. Append this to your transformed dataframe\n",
    "df_with_avg = pd.concat([df_transformed, all_avg[['variant', 'rank', 'Method', 'params_formatted', 'task', 'met', 'val']]], ignore_index=True)\n",
    "\n",
    "# 3. Pivot the table\n",
    "# Index: Method and Params\n",
    "# Columns: Task and the combined Metric name\n",
    "pivot_df = df_with_avg.pivot(\n",
    "    index=['variant', 'rank', 'Method', 'params_formatted'],\n",
    "    columns=['task', 'met'],\n",
    "    values='val'\n",
    ")\n",
    "\n",
    "# 4. Custom Sorting\n",
    "# Use variant to put 'fft' first, then rank descending (31 then 15)\n",
    "pivot_df = pivot_df.sort_index(level=['variant', 'rank'], ascending=[True, False])\n",
    "\n",
    "# Clean up index: remove the helper columns used for sorting\n",
    "pivot_df.index = pivot_df.index.droplevel(['variant', 'rank'])\n",
    "\n",
    "# 5. Column Ordering (to match the image)\n",
    "task_order = ['MNLI', 'SST-2', 'CoLA', 'QQP', 'QNLI', 'RTE', 'MRPC', 'STS-B', 'All']\n",
    "# Filter tasks to only those present in your data\n",
    "existing_tasks = [t for t in task_order if t in pivot_df.columns.get_level_values(0)]\n",
    "pivot_df = pivot_df.reindex(columns=existing_tasks, level=0)\n",
    "\n",
    "pivot_df.index.names = ['Method', r'\\# Params']\n",
    "pivot_df.columns.names = [None, None]\n",
    "pivot_df.index.names = [None, None]\n",
    "\n",
    "# Display result\n",
    "print(pivot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
