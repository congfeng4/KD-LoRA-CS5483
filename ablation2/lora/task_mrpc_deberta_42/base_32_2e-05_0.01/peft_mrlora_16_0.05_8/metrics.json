{
    "eval_loss": 0.5131276249885559,
    "eval_accuracy": 0.8799019607843137,
    "eval_f1": 0.9110707803992741,
    "eval_runtime": 0.1998,
    "eval_samples_per_second": 2041.793,
    "eval_steps_per_second": 20.018,
    "epoch": 117.24137931034483,
    "log_history": [
        {
            "loss": 0.6602,
            "grad_norm": 0.6221625804901123,
            "learning_rate": 1.3793103448275863e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.6369855403900146,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.2047,
            "eval_samples_per_second": 1993.235,
            "eval_steps_per_second": 19.542,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.6236,
            "grad_norm": 0.5657413601875305,
            "learning_rate": 2.7586206896551727e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.5727006793022156,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.2023,
            "eval_samples_per_second": 2016.547,
            "eval_steps_per_second": 19.77,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.5093,
            "grad_norm": 2.1918141841888428,
            "learning_rate": 4.1379310344827587e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.44053253531455994,
            "eval_accuracy": 0.7794117647058824,
            "eval_f1": 0.8484848484848486,
            "eval_runtime": 0.1986,
            "eval_samples_per_second": 2053.988,
            "eval_steps_per_second": 20.137,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.3904,
            "grad_norm": 0.8650699853897095,
            "learning_rate": 5.517241379310345e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.3770653307437897,
            "eval_accuracy": 0.8308823529411765,
            "eval_f1": 0.8695652173913044,
            "eval_runtime": 0.2007,
            "eval_samples_per_second": 2033.085,
            "eval_steps_per_second": 19.932,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.3282,
            "grad_norm": 1.7408723831176758,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.37862786650657654,
            "eval_accuracy": 0.8553921568627451,
            "eval_f1": 0.8888888888888888,
            "eval_runtime": 0.198,
            "eval_samples_per_second": 2060.492,
            "eval_steps_per_second": 20.201,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.2872,
            "grad_norm": 2.371819019317627,
            "learning_rate": 8.275862068965517e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.3320527970790863,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.901669758812616,
            "eval_runtime": 0.202,
            "eval_samples_per_second": 2019.484,
            "eval_steps_per_second": 19.799,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.2494,
            "grad_norm": 1.046166181564331,
            "learning_rate": 9.655172413793105e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.34594929218292236,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.8917910447761195,
            "eval_runtime": 0.199,
            "eval_samples_per_second": 2050.412,
            "eval_steps_per_second": 20.102,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.2066,
            "grad_norm": 1.8848525285720825,
            "learning_rate": 0.0001103448275862069,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.37950417399406433,
            "eval_accuracy": 0.8578431372549019,
            "eval_f1": 0.8941605839416058,
            "eval_runtime": 0.1976,
            "eval_samples_per_second": 2064.948,
            "eval_steps_per_second": 20.245,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.1717,
            "grad_norm": 3.4305946826934814,
            "learning_rate": 0.00012413793103448277,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.3581162691116333,
            "eval_accuracy": 0.8725490196078431,
            "eval_f1": 0.9054545454545455,
            "eval_runtime": 0.1482,
            "eval_samples_per_second": 2753.811,
            "eval_steps_per_second": 26.998,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.1407,
            "grad_norm": 1.9537076950073242,
            "learning_rate": 0.00013793103448275863,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.4129126965999603,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8965517241379312,
            "eval_runtime": 0.1989,
            "eval_samples_per_second": 2051.612,
            "eval_steps_per_second": 20.114,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "loss": 0.1156,
            "grad_norm": 2.928593158721924,
            "learning_rate": 0.00015172413793103449,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "eval_loss": 0.42421475052833557,
            "eval_accuracy": 0.8627450980392157,
            "eval_f1": 0.8974358974358974,
            "eval_runtime": 0.2018,
            "eval_samples_per_second": 2021.6,
            "eval_steps_per_second": 19.82,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "loss": 0.0963,
            "grad_norm": 1.2163251638412476,
            "learning_rate": 0.00016551724137931035,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "eval_loss": 0.47535809874534607,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9097345132743363,
            "eval_runtime": 0.2004,
            "eval_samples_per_second": 2035.876,
            "eval_steps_per_second": 19.96,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "loss": 0.0805,
            "grad_norm": 1.4249324798583984,
            "learning_rate": 0.0001793103448275862,
            "epoch": 89.65517241379311,
            "step": 2600
        },
        {
            "eval_loss": 0.5012169480323792,
            "eval_accuracy": 0.8651960784313726,
            "eval_f1": 0.9012567324955117,
            "eval_runtime": 0.1978,
            "eval_samples_per_second": 2063.16,
            "eval_steps_per_second": 20.227,
            "epoch": 89.65517241379311,
            "step": 2600
        },
        {
            "loss": 0.0608,
            "grad_norm": 4.5359787940979,
            "learning_rate": 0.0001931034482758621,
            "epoch": 96.55172413793103,
            "step": 2800
        },
        {
            "eval_loss": 0.5652571320533752,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9097345132743363,
            "eval_runtime": 0.1971,
            "eval_samples_per_second": 2070.387,
            "eval_steps_per_second": 20.298,
            "epoch": 96.55172413793103,
            "step": 2800
        },
        {
            "loss": 0.0531,
            "grad_norm": 1.5233439207077026,
            "learning_rate": 0.0001992337164750958,
            "epoch": 103.44827586206897,
            "step": 3000
        },
        {
            "eval_loss": 0.5721175074577332,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8987566607460036,
            "eval_runtime": 0.1983,
            "eval_samples_per_second": 2057.119,
            "eval_steps_per_second": 20.168,
            "epoch": 103.44827586206897,
            "step": 3000
        },
        {
            "loss": 0.044,
            "grad_norm": 2.5536956787109375,
            "learning_rate": 0.00019770114942528738,
            "epoch": 110.34482758620689,
            "step": 3200
        },
        {
            "eval_loss": 0.5800337195396423,
            "eval_accuracy": 0.8725490196078431,
            "eval_f1": 0.9051094890510949,
            "eval_runtime": 0.1542,
            "eval_samples_per_second": 2645.537,
            "eval_steps_per_second": 25.937,
            "epoch": 110.34482758620689,
            "step": 3200
        },
        {
            "loss": 0.0381,
            "grad_norm": 1.861673355102539,
            "learning_rate": 0.00019616858237547893,
            "epoch": 117.24137931034483,
            "step": 3400
        },
        {
            "eval_loss": 0.6303101181983948,
            "eval_accuracy": 0.8774509803921569,
            "eval_f1": 0.9090909090909091,
            "eval_runtime": 0.1987,
            "eval_samples_per_second": 2052.884,
            "eval_steps_per_second": 20.126,
            "epoch": 117.24137931034483,
            "step": 3400
        },
        {
            "train_runtime": 452.8223,
            "train_samples_per_second": 8100.308,
            "train_steps_per_second": 64.043,
            "total_flos": 2.8726127476342784e+16,
            "train_loss": 0.23857428606818704,
            "epoch": 117.24137931034483,
            "step": 3400
        },
        {
            "eval_loss": 0.5131276249885559,
            "eval_accuracy": 0.8799019607843137,
            "eval_f1": 0.9110707803992741,
            "eval_runtime": 0.1998,
            "eval_samples_per_second": 2041.793,
            "eval_steps_per_second": 20.018,
            "epoch": 117.24137931034483,
            "step": 3400
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation2",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "mrpc",
        "peft": "mrlora",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 452.8223,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344
        ],
        "memory_reserved": [
            5079.302144,
            5079.302144,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296
        ]
    },
    "variant": "lora"
}