{
    "eval_loss": 0.44303736090660095,
    "eval_pearson": 0.8985293696396646,
    "eval_spearman": 0.9004376512326221,
    "eval_runtime": 0.5751,
    "eval_samples_per_second": 2608.377,
    "eval_steps_per_second": 20.867,
    "epoch": 66.66666666666667,
    "log_history": [
        {
            "loss": 9.4743,
            "grad_norm": 25.288846969604492,
            "learning_rate": 8.88888888888889e-06,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "eval_loss": 7.4742865562438965,
            "eval_pearson": 0.05531171000337614,
            "eval_spearman": 0.039148660549166214,
            "eval_runtime": 0.5816,
            "eval_samples_per_second": 2579.07,
            "eval_steps_per_second": 20.633,
            "epoch": 4.444444444444445,
            "step": 200
        },
        {
            "loss": 7.017,
            "grad_norm": 31.85257339477539,
            "learning_rate": 1.777777777777778e-05,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "eval_loss": 2.4568278789520264,
            "eval_pearson": 0.06820840438333176,
            "eval_spearman": 0.04298943699078687,
            "eval_runtime": 0.575,
            "eval_samples_per_second": 2608.489,
            "eval_steps_per_second": 20.868,
            "epoch": 8.88888888888889,
            "step": 400
        },
        {
            "loss": 1.5919,
            "grad_norm": 8.670724868774414,
            "learning_rate": 2.6666666666666667e-05,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "eval_loss": 0.7547173500061035,
            "eval_pearson": 0.8374425254219853,
            "eval_spearman": 0.8412944669107298,
            "eval_runtime": 0.4569,
            "eval_samples_per_second": 3283.154,
            "eval_steps_per_second": 26.265,
            "epoch": 13.333333333333334,
            "step": 600
        },
        {
            "loss": 0.6621,
            "grad_norm": 2.2640483379364014,
            "learning_rate": 3.555555555555556e-05,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "eval_loss": 0.6172452569007874,
            "eval_pearson": 0.8632858680854056,
            "eval_spearman": 0.8678922791491452,
            "eval_runtime": 0.5778,
            "eval_samples_per_second": 2595.972,
            "eval_steps_per_second": 20.768,
            "epoch": 17.77777777777778,
            "step": 800
        },
        {
            "loss": 0.5258,
            "grad_norm": 3.517097234725952,
            "learning_rate": 4.4444444444444447e-05,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "eval_loss": 0.5473794937133789,
            "eval_pearson": 0.8759201901434539,
            "eval_spearman": 0.8815568208291897,
            "eval_runtime": 0.4277,
            "eval_samples_per_second": 3507.025,
            "eval_steps_per_second": 28.056,
            "epoch": 22.22222222222222,
            "step": 1000
        },
        {
            "loss": 0.438,
            "grad_norm": 3.05698823928833,
            "learning_rate": 5.333333333333333e-05,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "eval_loss": 0.5039076209068298,
            "eval_pearson": 0.8887290444081918,
            "eval_spearman": 0.8926142405315411,
            "eval_runtime": 0.4355,
            "eval_samples_per_second": 3444.576,
            "eval_steps_per_second": 27.557,
            "epoch": 26.666666666666668,
            "step": 1200
        },
        {
            "loss": 0.39,
            "grad_norm": 3.2079169750213623,
            "learning_rate": 6.222222222222222e-05,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "eval_loss": 0.478798508644104,
            "eval_pearson": 0.8923103066491861,
            "eval_spearman": 0.8967186643118691,
            "eval_runtime": 0.451,
            "eval_samples_per_second": 3326.22,
            "eval_steps_per_second": 26.61,
            "epoch": 31.11111111111111,
            "step": 1400
        },
        {
            "loss": 0.3452,
            "grad_norm": 3.220916986465454,
            "learning_rate": 7.111111111111112e-05,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "eval_loss": 0.4749990999698639,
            "eval_pearson": 0.8981716161598321,
            "eval_spearman": 0.9004759530908688,
            "eval_runtime": 0.4464,
            "eval_samples_per_second": 3360.217,
            "eval_steps_per_second": 26.882,
            "epoch": 35.55555555555556,
            "step": 1600
        },
        {
            "loss": 0.3196,
            "grad_norm": 3.517911672592163,
            "learning_rate": 8e-05,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "eval_loss": 0.4700363874435425,
            "eval_pearson": 0.8957420236221362,
            "eval_spearman": 0.900219425834561,
            "eval_runtime": 0.4393,
            "eval_samples_per_second": 3414.298,
            "eval_steps_per_second": 27.314,
            "epoch": 40.0,
            "step": 1800
        },
        {
            "loss": 0.2867,
            "grad_norm": 1.5253071784973145,
            "learning_rate": 8.888888888888889e-05,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "eval_loss": 0.4445893466472626,
            "eval_pearson": 0.8990175351298655,
            "eval_spearman": 0.9024457215125166,
            "eval_runtime": 0.4922,
            "eval_samples_per_second": 3047.756,
            "eval_steps_per_second": 24.382,
            "epoch": 44.44444444444444,
            "step": 2000
        },
        {
            "loss": 0.266,
            "grad_norm": 2.965608835220337,
            "learning_rate": 9.777777777777778e-05,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "eval_loss": 0.4391934275627136,
            "eval_pearson": 0.8989059160091809,
            "eval_spearman": 0.9018022919360497,
            "eval_runtime": 0.5752,
            "eval_samples_per_second": 2607.742,
            "eval_steps_per_second": 20.862,
            "epoch": 48.888888888888886,
            "step": 2200
        },
        {
            "loss": 0.2404,
            "grad_norm": 2.873884439468384,
            "learning_rate": 0.00010666666666666667,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "eval_loss": 0.4555997848510742,
            "eval_pearson": 0.8991011727932336,
            "eval_spearman": 0.9021505506990922,
            "eval_runtime": 0.5973,
            "eval_samples_per_second": 2511.2,
            "eval_steps_per_second": 20.09,
            "epoch": 53.333333333333336,
            "step": 2400
        },
        {
            "loss": 0.2226,
            "grad_norm": 2.428417205810547,
            "learning_rate": 0.00011555555555555555,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "eval_loss": 0.4373493790626526,
            "eval_pearson": 0.9011031384357431,
            "eval_spearman": 0.9031276711599205,
            "eval_runtime": 0.5734,
            "eval_samples_per_second": 2615.967,
            "eval_steps_per_second": 20.928,
            "epoch": 57.77777777777778,
            "step": 2600
        },
        {
            "loss": 0.2044,
            "grad_norm": 2.039963722229004,
            "learning_rate": 0.00012444444444444444,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "eval_loss": 0.4544863998889923,
            "eval_pearson": 0.9014450418359378,
            "eval_spearman": 0.90291290928698,
            "eval_runtime": 0.4311,
            "eval_samples_per_second": 3479.707,
            "eval_steps_per_second": 27.838,
            "epoch": 62.22222222222222,
            "step": 2800
        },
        {
            "loss": 0.1902,
            "grad_norm": 2.031663179397583,
            "learning_rate": 0.00013333333333333334,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.45803821086883545,
            "eval_pearson": 0.8992937255054613,
            "eval_spearman": 0.9003887862015567,
            "eval_runtime": 0.574,
            "eval_samples_per_second": 2613.303,
            "eval_steps_per_second": 20.906,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "train_runtime": 397.4218,
            "train_samples_per_second": 14465.739,
            "train_steps_per_second": 113.23,
            "total_flos": 2.534613008252928e+16,
            "train_loss": 1.4782650273640952,
            "epoch": 66.66666666666667,
            "step": 3000
        },
        {
            "eval_loss": 0.44303736090660095,
            "eval_pearson": 0.8985293696396646,
            "eval_spearman": 0.9004376512326221,
            "eval_runtime": 0.5751,
            "eval_samples_per_second": 2608.377,
            "eval_steps_per_second": 20.867,
            "epoch": 66.66666666666667,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation2",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "stsb",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 5749
    },
    "train": {
        "train_time": 397.4218,
        "trainable_params_count": 0.295681,
        "memory_allocated": [
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984,
            761.641984
        ],
        "memory_reserved": [
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144
        ]
    },
    "variant": "lora"
}