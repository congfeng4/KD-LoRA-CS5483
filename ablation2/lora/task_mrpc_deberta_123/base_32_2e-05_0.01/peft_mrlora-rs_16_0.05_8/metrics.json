{
    "eval_loss": 0.4698798358440399,
    "eval_accuracy": 0.8799019607843137,
    "eval_f1": 0.9120287253141832,
    "eval_runtime": 0.1992,
    "eval_samples_per_second": 2048.061,
    "eval_steps_per_second": 20.079,
    "epoch": 103.44827586206897,
    "log_history": [
        {
            "loss": 0.6622,
            "grad_norm": 0.2315894514322281,
            "learning_rate": 1.3793103448275863e-05,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "eval_loss": 0.6356313228607178,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.2,
            "eval_samples_per_second": 2040.043,
            "eval_steps_per_second": 20.0,
            "epoch": 6.896551724137931,
            "step": 200
        },
        {
            "loss": 0.6113,
            "grad_norm": 0.6553660035133362,
            "learning_rate": 2.7586206896551727e-05,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "eval_loss": 0.5310755968093872,
            "eval_accuracy": 0.6838235294117647,
            "eval_f1": 0.8122270742358079,
            "eval_runtime": 0.1994,
            "eval_samples_per_second": 2045.897,
            "eval_steps_per_second": 20.058,
            "epoch": 13.793103448275861,
            "step": 400
        },
        {
            "loss": 0.4812,
            "grad_norm": 1.7908859252929688,
            "learning_rate": 4.1379310344827587e-05,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "eval_loss": 0.4121790826320648,
            "eval_accuracy": 0.8161764705882353,
            "eval_f1": 0.866785079928952,
            "eval_runtime": 0.2002,
            "eval_samples_per_second": 2038.032,
            "eval_steps_per_second": 19.981,
            "epoch": 20.689655172413794,
            "step": 600
        },
        {
            "loss": 0.3735,
            "grad_norm": 3.556964635848999,
            "learning_rate": 5.517241379310345e-05,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "eval_loss": 0.3662174344062805,
            "eval_accuracy": 0.8480392156862745,
            "eval_f1": 0.8868613138686131,
            "eval_runtime": 0.2004,
            "eval_samples_per_second": 2036.041,
            "eval_steps_per_second": 19.961,
            "epoch": 27.586206896551722,
            "step": 800
        },
        {
            "loss": 0.3084,
            "grad_norm": 2.1676323413848877,
            "learning_rate": 6.896551724137931e-05,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "eval_loss": 0.32216429710388184,
            "eval_accuracy": 0.8602941176470589,
            "eval_f1": 0.8957952468007313,
            "eval_runtime": 0.1987,
            "eval_samples_per_second": 2052.951,
            "eval_steps_per_second": 20.127,
            "epoch": 34.48275862068966,
            "step": 1000
        },
        {
            "loss": 0.2605,
            "grad_norm": 2.028054714202881,
            "learning_rate": 8.275862068965517e-05,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "eval_loss": 0.3283596932888031,
            "eval_accuracy": 0.875,
            "eval_f1": 0.9084380610412927,
            "eval_runtime": 0.1483,
            "eval_samples_per_second": 2750.5,
            "eval_steps_per_second": 26.966,
            "epoch": 41.37931034482759,
            "step": 1200
        },
        {
            "loss": 0.2222,
            "grad_norm": 13.721274375915527,
            "learning_rate": 9.655172413793105e-05,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "eval_loss": 0.3110986649990082,
            "eval_accuracy": 0.8774509803921569,
            "eval_f1": 0.9067164179104479,
            "eval_runtime": 0.1501,
            "eval_samples_per_second": 2718.218,
            "eval_steps_per_second": 26.649,
            "epoch": 48.275862068965516,
            "step": 1400
        },
        {
            "loss": 0.1697,
            "grad_norm": 2.184798002243042,
            "learning_rate": 0.0001103448275862069,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "eval_loss": 0.34890538454055786,
            "eval_accuracy": 0.8872549019607843,
            "eval_f1": 0.9175627240143369,
            "eval_runtime": 0.1984,
            "eval_samples_per_second": 2056.921,
            "eval_steps_per_second": 20.166,
            "epoch": 55.172413793103445,
            "step": 1600
        },
        {
            "loss": 0.1341,
            "grad_norm": 10.826218605041504,
            "learning_rate": 0.00012413793103448277,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "eval_loss": 0.3700551688671112,
            "eval_accuracy": 0.8529411764705882,
            "eval_f1": 0.8867924528301886,
            "eval_runtime": 0.1526,
            "eval_samples_per_second": 2674.454,
            "eval_steps_per_second": 26.22,
            "epoch": 62.06896551724138,
            "step": 1800
        },
        {
            "loss": 0.11,
            "grad_norm": 2.0129435062408447,
            "learning_rate": 0.00013793103448275863,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "eval_loss": 0.411479651927948,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9197860962566845,
            "eval_runtime": 0.1983,
            "eval_samples_per_second": 2057.878,
            "eval_steps_per_second": 20.175,
            "epoch": 68.96551724137932,
            "step": 2000
        },
        {
            "loss": 0.0886,
            "grad_norm": 5.560288429260254,
            "learning_rate": 0.00015172413793103449,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "eval_loss": 0.4630144238471985,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9027522935779816,
            "eval_runtime": 0.199,
            "eval_samples_per_second": 2049.749,
            "eval_steps_per_second": 20.096,
            "epoch": 75.86206896551724,
            "step": 2200
        },
        {
            "loss": 0.072,
            "grad_norm": 6.531894683837891,
            "learning_rate": 0.00016551724137931035,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "eval_loss": 0.473111629486084,
            "eval_accuracy": 0.8700980392156863,
            "eval_f1": 0.9020332717190389,
            "eval_runtime": 0.1433,
            "eval_samples_per_second": 2847.215,
            "eval_steps_per_second": 27.914,
            "epoch": 82.75862068965517,
            "step": 2400
        },
        {
            "loss": 0.0652,
            "grad_norm": 1.8994396924972534,
            "learning_rate": 0.0001793103448275862,
            "epoch": 89.65517241379311,
            "step": 2600
        },
        {
            "eval_loss": 0.49287086725234985,
            "eval_accuracy": 0.8897058823529411,
            "eval_f1": 0.9180327868852459,
            "eval_runtime": 0.2007,
            "eval_samples_per_second": 2032.592,
            "eval_steps_per_second": 19.927,
            "epoch": 89.65517241379311,
            "step": 2600
        },
        {
            "loss": 0.0584,
            "grad_norm": 2.4186625480651855,
            "learning_rate": 0.0001931034482758621,
            "epoch": 96.55172413793103,
            "step": 2800
        },
        {
            "eval_loss": 0.46665892004966736,
            "eval_accuracy": 0.8799019607843137,
            "eval_f1": 0.9110707803992741,
            "eval_runtime": 0.1599,
            "eval_samples_per_second": 2551.729,
            "eval_steps_per_second": 25.017,
            "epoch": 96.55172413793103,
            "step": 2800
        },
        {
            "loss": 0.0439,
            "grad_norm": 4.698035717010498,
            "learning_rate": 0.0001992337164750958,
            "epoch": 103.44827586206897,
            "step": 3000
        },
        {
            "eval_loss": 0.572663426399231,
            "eval_accuracy": 0.8774509803921569,
            "eval_f1": 0.9100719424460433,
            "eval_runtime": 0.2182,
            "eval_samples_per_second": 1869.773,
            "eval_steps_per_second": 18.331,
            "epoch": 103.44827586206897,
            "step": 3000
        },
        {
            "train_runtime": 390.0205,
            "train_samples_per_second": 9404.634,
            "train_steps_per_second": 74.355,
            "total_flos": 2.534658306736128e+16,
            "train_loss": 0.24408819484710692,
            "epoch": 103.44827586206897,
            "step": 3000
        },
        {
            "eval_loss": 0.4698798358440399,
            "eval_accuracy": 0.8799019607843137,
            "eval_f1": 0.9120287253141832,
            "eval_runtime": 0.1992,
            "eval_samples_per_second": 2048.061,
            "eval_steps_per_second": 20.079,
            "epoch": 103.44827586206897,
            "step": 3000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation2",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "mrpc",
        "peft": "mrlora-rs",
        "seed": 123,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 3668
    },
    "train": {
        "train_time": 390.0205,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344
        ],
        "memory_reserved": [
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296
        ]
    },
    "variant": "lora"
}