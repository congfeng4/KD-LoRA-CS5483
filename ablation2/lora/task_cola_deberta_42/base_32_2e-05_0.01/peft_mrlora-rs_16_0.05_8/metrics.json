{
    "eval_loss": 0.4732401669025421,
    "eval_matthews_correlation": 0.6707098431032927,
    "eval_runtime": 0.436,
    "eval_samples_per_second": 2392.201,
    "eval_steps_per_second": 20.642,
    "epoch": 74.6268656716418,
    "log_history": [
        {
            "loss": 0.6595,
            "grad_norm": 1.1849244832992554,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6457575559616089,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4382,
            "eval_samples_per_second": 2380.118,
            "eval_steps_per_second": 20.538,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.624,
            "grad_norm": 0.340312659740448,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6109347939491272,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4452,
            "eval_samples_per_second": 2342.811,
            "eval_steps_per_second": 20.216,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5683,
            "grad_norm": 0.701592206954956,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5092583298683167,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4389,
            "eval_samples_per_second": 2376.312,
            "eval_steps_per_second": 20.505,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.4303,
            "grad_norm": 1.1794489622116089,
            "learning_rate": 2.3880597014925373e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.4497915804386139,
            "eval_matthews_correlation": 0.5829964770702437,
            "eval_runtime": 0.439,
            "eval_samples_per_second": 2375.821,
            "eval_steps_per_second": 20.501,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.369,
            "grad_norm": 1.1380596160888672,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.41300269961357117,
            "eval_matthews_correlation": 0.6308143863677894,
            "eval_runtime": 0.3451,
            "eval_samples_per_second": 3022.424,
            "eval_steps_per_second": 26.08,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.3391,
            "grad_norm": 1.268082618713379,
            "learning_rate": 3.582089552238806e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.39174532890319824,
            "eval_matthews_correlation": 0.62069223130672,
            "eval_runtime": 0.4424,
            "eval_samples_per_second": 2357.834,
            "eval_steps_per_second": 20.346,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3215,
            "grad_norm": 1.8865952491760254,
            "learning_rate": 4.1791044776119404e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.41124051809310913,
            "eval_matthews_correlation": 0.6160749417102861,
            "eval_runtime": 0.4425,
            "eval_samples_per_second": 2356.843,
            "eval_steps_per_second": 20.337,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3035,
            "grad_norm": 1.8469160795211792,
            "learning_rate": 4.7761194029850745e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.4030580222606659,
            "eval_matthews_correlation": 0.620774050860113,
            "eval_runtime": 0.3404,
            "eval_samples_per_second": 3064.345,
            "eval_steps_per_second": 26.442,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2844,
            "grad_norm": 1.9953210353851318,
            "learning_rate": 5.373134328358209e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.38997766375541687,
            "eval_matthews_correlation": 0.660301076782038,
            "eval_runtime": 0.4521,
            "eval_samples_per_second": 2307.142,
            "eval_steps_per_second": 19.908,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2714,
            "grad_norm": 2.5344743728637695,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.39613765478134155,
            "eval_matthews_correlation": 0.6530464576994947,
            "eval_runtime": 0.4429,
            "eval_samples_per_second": 2354.817,
            "eval_steps_per_second": 20.32,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2526,
            "grad_norm": 2.2856667041778564,
            "learning_rate": 6.567164179104478e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.39829447865486145,
            "eval_matthews_correlation": 0.6587886115933416,
            "eval_runtime": 0.4486,
            "eval_samples_per_second": 2324.891,
            "eval_steps_per_second": 20.061,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.241,
            "grad_norm": 4.3677449226379395,
            "learning_rate": 7.164179104477612e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.40731239318847656,
            "eval_matthews_correlation": 0.6591892411081671,
            "eval_runtime": 0.4448,
            "eval_samples_per_second": 2344.895,
            "eval_steps_per_second": 20.234,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.2282,
            "grad_norm": 2.1462314128875732,
            "learning_rate": 7.761194029850747e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.447214275598526,
            "eval_matthews_correlation": 0.6554406339964501,
            "eval_runtime": 0.4428,
            "eval_samples_per_second": 2355.395,
            "eval_steps_per_second": 20.325,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.2151,
            "grad_norm": 2.8460404872894287,
            "learning_rate": 8.358208955223881e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4079486131668091,
            "eval_matthews_correlation": 0.6639332131389398,
            "eval_runtime": 0.4385,
            "eval_samples_per_second": 2378.343,
            "eval_steps_per_second": 20.523,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.1992,
            "grad_norm": 2.1776676177978516,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.4614335000514984,
            "eval_matthews_correlation": 0.645568857149829,
            "eval_runtime": 0.4397,
            "eval_samples_per_second": 2372.204,
            "eval_steps_per_second": 20.47,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.188,
            "grad_norm": 2.7317092418670654,
            "learning_rate": 9.552238805970149e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.4190889894962311,
            "eval_matthews_correlation": 0.6664065124293871,
            "eval_runtime": 0.3412,
            "eval_samples_per_second": 3057.299,
            "eval_steps_per_second": 26.381,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.1837,
            "grad_norm": 2.5387117862701416,
            "learning_rate": 0.00010149253731343284,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.5111650228500366,
            "eval_matthews_correlation": 0.6431079373028232,
            "eval_runtime": 0.4423,
            "eval_samples_per_second": 2358.272,
            "eval_steps_per_second": 20.349,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1696,
            "grad_norm": 3.211240530014038,
            "learning_rate": 0.00010746268656716419,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.4841013550758362,
            "eval_matthews_correlation": 0.6504575418273714,
            "eval_runtime": 0.3357,
            "eval_samples_per_second": 3106.667,
            "eval_steps_per_second": 26.807,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.1605,
            "grad_norm": 2.608002185821533,
            "learning_rate": 0.00011343283582089552,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.4951728880405426,
            "eval_matthews_correlation": 0.6528696803276511,
            "eval_runtime": 0.4448,
            "eval_samples_per_second": 2344.635,
            "eval_steps_per_second": 20.232,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.1452,
            "grad_norm": 2.955110788345337,
            "learning_rate": 0.00011940298507462686,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.47779446840286255,
            "eval_matthews_correlation": 0.6683232889248042,
            "eval_runtime": 0.4408,
            "eval_samples_per_second": 2366.345,
            "eval_steps_per_second": 20.419,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.1382,
            "grad_norm": 2.784625768661499,
            "learning_rate": 0.00012537313432835822,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.5584771037101746,
            "eval_matthews_correlation": 0.6557119936152133,
            "eval_runtime": 0.453,
            "eval_samples_per_second": 2302.258,
            "eval_steps_per_second": 19.866,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.1287,
            "grad_norm": 4.582145690917969,
            "learning_rate": 0.00013134328358208955,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.49382683634757996,
            "eval_matthews_correlation": 0.6580702636158169,
            "eval_runtime": 0.446,
            "eval_samples_per_second": 2338.618,
            "eval_steps_per_second": 20.18,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.1259,
            "grad_norm": 3.4447031021118164,
            "learning_rate": 0.0001373134328358209,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.5670368671417236,
            "eval_matthews_correlation": 0.6504245143813093,
            "eval_runtime": 0.4536,
            "eval_samples_per_second": 2299.518,
            "eval_steps_per_second": 19.842,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.1115,
            "grad_norm": 2.3319835662841797,
            "learning_rate": 0.00014328358208955225,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.5374293923377991,
            "eval_matthews_correlation": 0.6609225600006813,
            "eval_runtime": 0.4147,
            "eval_samples_per_second": 2515.22,
            "eval_steps_per_second": 21.704,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.1052,
            "grad_norm": 3.392868757247925,
            "learning_rate": 0.0001492537313432836,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.5318779945373535,
            "eval_matthews_correlation": 0.6657363416382442,
            "eval_runtime": 0.4343,
            "eval_samples_per_second": 2401.432,
            "eval_steps_per_second": 20.722,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "train_runtime": 671.1045,
            "train_samples_per_second": 12741.682,
            "train_steps_per_second": 99.835,
            "total_flos": 4.22443051122688e+16,
            "train_loss": 0.2705441825866699,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4732401669025421,
            "eval_matthews_correlation": 0.6707098431032927,
            "eval_runtime": 0.436,
            "eval_samples_per_second": 2392.201,
            "eval_steps_per_second": 20.642,
            "epoch": 74.6268656716418,
            "step": 5000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation2",
        "lora_dropout": 0.05,
        "use_rslora": true,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "cola",
        "peft": "mrlora-rs",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 671.1045,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344
        ],
        "memory_reserved": [
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5079.302144,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296
        ]
    },
    "variant": "lora"
}