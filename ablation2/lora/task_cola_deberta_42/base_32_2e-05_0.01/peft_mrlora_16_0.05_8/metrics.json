{
    "eval_loss": 0.4271987974643707,
    "eval_matthews_correlation": 0.6438860260804725,
    "eval_runtime": 0.3996,
    "eval_samples_per_second": 2610.322,
    "eval_steps_per_second": 22.524,
    "epoch": 74.6268656716418,
    "log_history": [
        {
            "loss": 0.6598,
            "grad_norm": 1.1951693296432495,
            "learning_rate": 5.970149253731343e-06,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "eval_loss": 0.6466478705406189,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3707,
            "eval_samples_per_second": 2813.695,
            "eval_steps_per_second": 24.279,
            "epoch": 2.9850746268656714,
            "step": 200
        },
        {
            "loss": 0.6277,
            "grad_norm": 0.25721171498298645,
            "learning_rate": 1.1940298507462686e-05,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "eval_loss": 0.6154270172119141,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.3317,
            "eval_samples_per_second": 3143.939,
            "eval_steps_per_second": 27.129,
            "epoch": 5.970149253731344,
            "step": 400
        },
        {
            "loss": 0.5957,
            "grad_norm": 0.6073396801948547,
            "learning_rate": 1.791044776119403e-05,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "eval_loss": 0.5771200060844421,
            "eval_matthews_correlation": 0.0,
            "eval_runtime": 0.4408,
            "eval_samples_per_second": 2366.249,
            "eval_steps_per_second": 20.418,
            "epoch": 8.955223880597014,
            "step": 600
        },
        {
            "loss": 0.4941,
            "grad_norm": 0.6661003828048706,
            "learning_rate": 2.3880597014925373e-05,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "eval_loss": 0.46484649181365967,
            "eval_matthews_correlation": 0.5458193793796755,
            "eval_runtime": 0.4394,
            "eval_samples_per_second": 2373.8,
            "eval_steps_per_second": 20.483,
            "epoch": 11.940298507462687,
            "step": 800
        },
        {
            "loss": 0.3924,
            "grad_norm": 0.8578184843063354,
            "learning_rate": 2.9850746268656714e-05,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "eval_loss": 0.43004435300827026,
            "eval_matthews_correlation": 0.6134818519595254,
            "eval_runtime": 0.4397,
            "eval_samples_per_second": 2372.063,
            "eval_steps_per_second": 20.468,
            "epoch": 14.925373134328359,
            "step": 1000
        },
        {
            "loss": 0.3576,
            "grad_norm": 0.8167455792427063,
            "learning_rate": 3.582089552238806e-05,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "eval_loss": 0.4002971947193146,
            "eval_matthews_correlation": 0.6185029155864712,
            "eval_runtime": 0.339,
            "eval_samples_per_second": 3076.891,
            "eval_steps_per_second": 26.55,
            "epoch": 17.91044776119403,
            "step": 1200
        },
        {
            "loss": 0.3357,
            "grad_norm": 1.0981367826461792,
            "learning_rate": 4.1791044776119404e-05,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "eval_loss": 0.4071577191352844,
            "eval_matthews_correlation": 0.6132379591518842,
            "eval_runtime": 0.4382,
            "eval_samples_per_second": 2380.39,
            "eval_steps_per_second": 20.54,
            "epoch": 20.895522388059703,
            "step": 1400
        },
        {
            "loss": 0.3169,
            "grad_norm": 1.1541839838027954,
            "learning_rate": 4.7761194029850745e-05,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "eval_loss": 0.401476114988327,
            "eval_matthews_correlation": 0.6131862438295606,
            "eval_runtime": 0.4369,
            "eval_samples_per_second": 2387.112,
            "eval_steps_per_second": 20.598,
            "epoch": 23.880597014925375,
            "step": 1600
        },
        {
            "loss": 0.2997,
            "grad_norm": 1.4058605432510376,
            "learning_rate": 5.373134328358209e-05,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "eval_loss": 0.3829425275325775,
            "eval_matthews_correlation": 0.6357914877947441,
            "eval_runtime": 0.3333,
            "eval_samples_per_second": 3128.864,
            "eval_steps_per_second": 26.999,
            "epoch": 26.865671641791046,
            "step": 1800
        },
        {
            "loss": 0.2876,
            "grad_norm": 1.4957815408706665,
            "learning_rate": 5.970149253731343e-05,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "eval_loss": 0.38678714632987976,
            "eval_matthews_correlation": 0.6359929134078908,
            "eval_runtime": 0.4441,
            "eval_samples_per_second": 2348.825,
            "eval_steps_per_second": 20.268,
            "epoch": 29.850746268656717,
            "step": 2000
        },
        {
            "loss": 0.2697,
            "grad_norm": 2.0743579864501953,
            "learning_rate": 6.567164179104478e-05,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "eval_loss": 0.38703909516334534,
            "eval_matthews_correlation": 0.6517407165300878,
            "eval_runtime": 0.4402,
            "eval_samples_per_second": 2369.473,
            "eval_steps_per_second": 20.446,
            "epoch": 32.83582089552239,
            "step": 2200
        },
        {
            "loss": 0.2598,
            "grad_norm": 2.728149890899658,
            "learning_rate": 7.164179104477612e-05,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "eval_loss": 0.39963874220848083,
            "eval_matthews_correlation": 0.6559789479578697,
            "eval_runtime": 0.4477,
            "eval_samples_per_second": 2329.449,
            "eval_steps_per_second": 20.101,
            "epoch": 35.82089552238806,
            "step": 2400
        },
        {
            "loss": 0.2469,
            "grad_norm": 1.4996917247772217,
            "learning_rate": 7.761194029850747e-05,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "eval_loss": 0.41615375876426697,
            "eval_matthews_correlation": 0.6479601425074826,
            "eval_runtime": 0.4477,
            "eval_samples_per_second": 2329.731,
            "eval_steps_per_second": 20.103,
            "epoch": 38.80597014925373,
            "step": 2600
        },
        {
            "loss": 0.2365,
            "grad_norm": 2.6448421478271484,
            "learning_rate": 8.358208955223881e-05,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "eval_loss": 0.4140261113643646,
            "eval_matthews_correlation": 0.6481914570909114,
            "eval_runtime": 0.4402,
            "eval_samples_per_second": 2369.552,
            "eval_steps_per_second": 20.447,
            "epoch": 41.791044776119406,
            "step": 2800
        },
        {
            "loss": 0.2215,
            "grad_norm": 2.144432544708252,
            "learning_rate": 8.955223880597016e-05,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "eval_loss": 0.41231459379196167,
            "eval_matthews_correlation": 0.6704932351005503,
            "eval_runtime": 0.3255,
            "eval_samples_per_second": 3204.484,
            "eval_steps_per_second": 27.651,
            "epoch": 44.776119402985074,
            "step": 3000
        },
        {
            "loss": 0.2099,
            "grad_norm": 1.6752171516418457,
            "learning_rate": 9.552238805970149e-05,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "eval_loss": 0.39408355951309204,
            "eval_matthews_correlation": 0.6639332131389398,
            "eval_runtime": 0.3268,
            "eval_samples_per_second": 3191.8,
            "eval_steps_per_second": 27.542,
            "epoch": 47.76119402985075,
            "step": 3200
        },
        {
            "loss": 0.2062,
            "grad_norm": 1.455890417098999,
            "learning_rate": 0.00010149253731343284,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "eval_loss": 0.45946455001831055,
            "eval_matthews_correlation": 0.6430274487762421,
            "eval_runtime": 0.4418,
            "eval_samples_per_second": 2360.936,
            "eval_steps_per_second": 20.372,
            "epoch": 50.74626865671642,
            "step": 3400
        },
        {
            "loss": 0.1921,
            "grad_norm": 2.0513713359832764,
            "learning_rate": 0.00010746268656716419,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "eval_loss": 0.4520872235298157,
            "eval_matthews_correlation": 0.6529752188824345,
            "eval_runtime": 0.4394,
            "eval_samples_per_second": 2373.661,
            "eval_steps_per_second": 20.482,
            "epoch": 53.73134328358209,
            "step": 3600
        },
        {
            "loss": 0.1828,
            "grad_norm": 1.7919869422912598,
            "learning_rate": 0.00011343283582089552,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "eval_loss": 0.44682276248931885,
            "eval_matthews_correlation": 0.6581805893879898,
            "eval_runtime": 0.4373,
            "eval_samples_per_second": 2384.988,
            "eval_steps_per_second": 20.58,
            "epoch": 56.71641791044776,
            "step": 3800
        },
        {
            "loss": 0.17,
            "grad_norm": 1.7748016119003296,
            "learning_rate": 0.00011940298507462686,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "eval_loss": 0.4507634937763214,
            "eval_matthews_correlation": 0.6777292650485364,
            "eval_runtime": 0.4419,
            "eval_samples_per_second": 2360.131,
            "eval_steps_per_second": 20.365,
            "epoch": 59.701492537313435,
            "step": 4000
        },
        {
            "loss": 0.1627,
            "grad_norm": 1.7348190546035767,
            "learning_rate": 0.00012537313432835822,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "eval_loss": 0.48555678129196167,
            "eval_matthews_correlation": 0.6517407165300878,
            "eval_runtime": 0.4367,
            "eval_samples_per_second": 2388.536,
            "eval_steps_per_second": 20.611,
            "epoch": 62.6865671641791,
            "step": 4200
        },
        {
            "loss": 0.154,
            "grad_norm": 2.0727851390838623,
            "learning_rate": 0.00013134328358208955,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "eval_loss": 0.4706120789051056,
            "eval_matthews_correlation": 0.6565021466238845,
            "eval_runtime": 0.4459,
            "eval_samples_per_second": 2339.32,
            "eval_steps_per_second": 20.186,
            "epoch": 65.67164179104478,
            "step": 4400
        },
        {
            "loss": 0.1502,
            "grad_norm": 2.823394536972046,
            "learning_rate": 0.0001373134328358209,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "eval_loss": 0.48966819047927856,
            "eval_matthews_correlation": 0.6580702636158169,
            "eval_runtime": 0.4395,
            "eval_samples_per_second": 2373.117,
            "eval_steps_per_second": 20.478,
            "epoch": 68.65671641791045,
            "step": 4600
        },
        {
            "loss": 0.1396,
            "grad_norm": 1.2843577861785889,
            "learning_rate": 0.00014328358208955225,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "eval_loss": 0.45656225085258484,
            "eval_matthews_correlation": 0.6660250068114778,
            "eval_runtime": 0.4418,
            "eval_samples_per_second": 2360.558,
            "eval_steps_per_second": 20.369,
            "epoch": 71.64179104477611,
            "step": 4800
        },
        {
            "loss": 0.1301,
            "grad_norm": 2.116729259490967,
            "learning_rate": 0.0001492537313432836,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.46793144941329956,
            "eval_matthews_correlation": 0.6460768364869137,
            "eval_runtime": 0.442,
            "eval_samples_per_second": 2359.793,
            "eval_steps_per_second": 20.363,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "train_runtime": 679.0696,
            "train_samples_per_second": 12592.23,
            "train_steps_per_second": 98.664,
            "total_flos": 4.22443051122688e+16,
            "train_loss": 0.2919586841583252,
            "epoch": 74.6268656716418,
            "step": 5000
        },
        {
            "eval_loss": 0.4271987974643707,
            "eval_matthews_correlation": 0.6438860260804725,
            "eval_runtime": 0.3996,
            "eval_samples_per_second": 2610.322,
            "eval_steps_per_second": 22.524,
            "epoch": 74.6268656716418,
            "step": 5000
        }
    ],
    "args": {
        "dataset_path": "./dataset",
        "train_batch_size": 32,
        "eval_batch_size": 32,
        "weight_decay": 0.01,
        "dir_name": "./ablation2",
        "lora_dropout": 0.05,
        "use_rslora": false,
        "use_olora": false,
        "lora_alpha": 16,
        "teacher_learning_rate": 2e-05,
        "student_learning_rate": 0.0001,
        "lora_learning_rate": 0.0002,
        "model_family": "deberta",
        "task": "cola",
        "peft": "mrlora",
        "seed": 42,
        "rank": 8,
        "student_model_name": "./models/deberta-v3-small",
        "teacher_model_name": "./models/deberta-v3-base",
        "use_lcoef": false,
        "use_bias": false,
        "train_size": 8551
    },
    "train": {
        "train_time": 679.0696,
        "trainable_params_count": 0.29645,
        "memory_allocated": [
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344,
            761.657344
        ],
        "memory_reserved": [
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296,
            5081.399296
        ]
    },
    "variant": "lora"
}