{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9a3c8b20756563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.049094Z",
     "start_time": "2026-02-08T15:55:19.046314Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 确保所有列都能显示出来\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 确保列宽足够，不会把长字符串（比如 Method 名）截断\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# 确保表格的总宽度足够，不会换行显示\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11c3496f613a08f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.062305Z",
     "start_time": "2026-02-08T15:55:19.059091Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_METRIC = {\n",
    "    \"cola\": [\"eval_matthews_correlation\"],\n",
    "    \"mnli\": [\"matched_accuracy\", \"mismatched_accuracy\"],\n",
    "    \"mrpc\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"qnli\": [\"eval_accuracy\"],\n",
    "    \"qqp\": [\"eval_accuracy\", \"eval_f1\"],\n",
    "    \"rte\": [\"eval_accuracy\"],\n",
    "    \"sst2\": [\"eval_accuracy\"],\n",
    "    \"stsb\": [\"eval_pearson\", \"eval_spearman\"],\n",
    "    \"wnli\": [\"eval_accuracy\"],\n",
    "}\n",
    "\n",
    "METRIC_NAME_MAP = {\n",
    "    'eval_matthews_correlation': 'Mcc',\n",
    "    'matched_accuracy': 'm',\n",
    "    'mismatched_accuracy': 'mm',\n",
    "    'eval_accuracy': 'Acc',\n",
    "    'eval_f1': 'F1',\n",
    "    'eval_pearson': 'Corr_p',\n",
    "    'eval_spearman': 'Corr_s',\n",
    "}\n",
    "\n",
    "TASK_NAME_MAP = {\n",
    "    'mnli': 'MNLI',\n",
    "    'sst2': 'SST-2',\n",
    "    'cola': 'CoLA',\n",
    "    'qqp': 'QQP',\n",
    "    'qnli': 'QNLI',\n",
    "    'rte': 'RTE',\n",
    "    'mrpc': 'MRPC',\n",
    "    'stsb': 'STS-B',\n",
    "}\n",
    "\n",
    "FAMILY_NAME_MAP = {\n",
    "    'bert': 'BERT-b',\n",
    "    'roberta': 'RoB-b',\n",
    "    'deberta': 'DeB-b',\n",
    "}\n",
    "\n",
    "METHOD_NAME_MAP = {\n",
    "    'lora': 'LoRA',\n",
    "    'olora': 'OLoRA',\n",
    "    'dora': 'DoRA',\n",
    "    'mrlora': 'MR-LoRA',\n",
    "    'adalora': 'AdaLoRA',\n",
    "    'mrlora-lcoef': 'MR-LoRA',\n",
    "    'rslora': 'RS-LoRA'\n",
    "}\n",
    "VARIANT_NAME_MAP = {\n",
    "    'fft': 'FFT',\n",
    "    'lora': 'LoRA-Finetuning',\n",
    "    'kd-lora': 'KD-LoRA-Finetuning'\n",
    "}\n",
    "\n",
    "REMOVE_PEFT = ['mrlora-rs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.628324Z",
     "start_time": "2026-02-08T15:55:19.066633Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dictor import dictor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import  NA\n",
    "\n",
    "def extract_experiment_data(json_file, root_dir):\n",
    "    variant = Path(json_file).relative_to(root_dir).parts[0]\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract metadata\n",
    "    model_family = dictor(data, 'args.model_family')\n",
    "    peft_method = dictor(data, 'args.peft')\n",
    "    task = dictor(data, 'args.task')\n",
    "\n",
    "    # for mnli, need patching.\n",
    "    if 'eval_runtime' in data:\n",
    "        eval_runtime = data.get('eval_runtime')\n",
    "    else:\n",
    "        eval_runtime_history = []\n",
    "        for item in data['log_history']:\n",
    "            if 'eval_runtime' in item:\n",
    "                eval_runtime_history.append(item['eval_runtime'])\n",
    "        eval_runtime = sum(eval_runtime_history) / len(eval_runtime_history)\n",
    "\n",
    "    # Get training-specific metrics\n",
    "    trainable_params = dictor(data, 'train.trainable_params_count', NA)\n",
    "    train_runtime = dictor(data, 'train.train_time', NA)\n",
    "\n",
    "    # Calculate Average GPU Memory (Allocated)\n",
    "    memory_list = dictor(data, 'train.memory_allocated', [])\n",
    "    avg_memory = np.mean(memory_list) if memory_list else NA\n",
    "\n",
    "    rank = dictor(data, 'args.rank')\n",
    "\n",
    "    # Get metrics\n",
    "    # Some tasks use eval_accuracy, others eval_matthews_correlation\n",
    "    for key in TASK_METRIC[task]:\n",
    "        if key in data:\n",
    "            accuracy = data[key]\n",
    "            yield {\n",
    "                \"family\": model_family,\n",
    "                \"peft\": peft_method,\n",
    "                \"task\": task,\n",
    "                \"variant\": variant,\n",
    "                \"value\": round(accuracy, 4),\n",
    "                \"metric\": key,\n",
    "                \"params\": round(trainable_params, 4),\n",
    "                \"traintime\": round(train_runtime, 2),\n",
    "                \"evaltime\": round(eval_runtime, 2),\n",
    "                \"gpumem\": round(avg_memory, 2),\n",
    "                \"rank\": rank, # total rank.\n",
    "                'seed': dictor(data, 'args.seed'),\n",
    "                'path': str(json_file)\n",
    "            }\n",
    "\n",
    "\n",
    "def aggregate_experiment_results(root_dir):\n",
    "    \"\"\"\n",
    "    Finds all .json files under a directory recursively, extracts data,\n",
    "    and concatenates them into one large DataFrame.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    # Recursively find all JSON files\n",
    "    json_files = list(root_path.rglob(\"*.json\"))\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {root_dir}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_dfs = []\n",
    "    for f in json_files:\n",
    "        try:\n",
    "            rows = extract_experiment_data(f, root_dir)\n",
    "            all_dfs.extend(rows)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract data from {f}\")\n",
    "            raise e\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"No valid data extracted from found files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all individual DataFrames by row\n",
    "    final_df = pd.DataFrame.from_records(all_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "df_ba = aggregate_experiment_results('./results/')\n",
    "df_ba = df_ba[~df_ba.peft.str.contains('mrlora')]\n",
    "df_ab = aggregate_experiment_results('./ablation2/')\n",
    "df = pd.concat([df_ba, df_ab], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1788f2cb16ddc5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.649969Z",
     "start_time": "2026-02-08T15:55:19.637274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>task</th>\n",
       "      <th>variant</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>traintime</th>\n",
       "      <th>evaltime</th>\n",
       "      <th>gpumem</th>\n",
       "      <th>rank</th>\n",
       "      <th>seed</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peft</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mrlora</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrlora-rs</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           family  task  variant  value  metric  params  traintime  evaltime  gpumem  rank  seed  path\n",
       "peft                                                                                                  \n",
       "mrlora         26    26       26     26      26      26         26        26      26    26    26    26\n",
       "mrlora-rs      25    25       25     25      25      25         25        25      25    25    25    25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.peft.str.contains('mrlora')].groupby('peft').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f679736d523da375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.829171Z",
     "start_time": "2026-02-08T15:55:19.824190Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['rank'] == 8]\n",
    "df = df[df['variant'].isin(['lora', 'fft'])]\n",
    "df = df[df.peft.isin(['lora', 'rslora', 'olora', 'dora', 'mrlora-rs'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156efddf6fdf988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.927223Z",
     "start_time": "2026-02-08T15:55:19.923322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lora', 'rslora', 'olora', 'dora', 'mrlora-rs'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.peft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739c88636e3bf7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:19.982098Z",
     "start_time": "2026-02-08T15:55:19.976757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0bffdeaad77442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:20.032104Z",
     "start_time": "2026-02-08T15:55:20.028658Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. 格式化 params 的函数\n",
    "def format_params(x):\n",
    "    val = float(x)\n",
    "    # 如果是整数（如 184.0），显示为 184M\n",
    "    if val.is_integer():\n",
    "        return f\"{int(val)}M\"\n",
    "    # 如果有小数（如 0.312），保留两位显示为 0.31M\n",
    "    else:\n",
    "        return f\"{val:.2f}M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac02610bcde4d812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:20.063339Z",
     "start_time": "2026-02-08T15:55:20.053162Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in METRIC_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in TASK_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)\n",
    "for key, value in FAMILY_NAME_MAP.items():\n",
    "    df.replace(key, value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc633837b217f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T15:55:20.106166Z",
     "start_time": "2026-02-08T15:55:20.067578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             MNLI SST-2  CoLA        QQP  QNLI   RTE  MRPC STS-B   All\n",
      "                             m/mm   Acc   Mcc     Acc/F1   Acc   Acc   Acc  Corr  Ave.\n",
      "BERT-b FFT     109.48M  0.82/0.83  0.92  0.61  0.89/0.86  0.91  0.66  0.84  0.89  0.82\n",
      "       DoRA    0.30M    0.78/0.79  0.92  0.58  0.76/0.49  0.89  0.69  0.86  0.89  0.78\n",
      "       LoRA    0.30M    0.78/0.79  0.92  0.59  0.76/0.49  0.89  0.70  0.86  0.89  0.78\n",
      "       OLoRA   0.30M    0.69/0.71  0.92  0.59  0.58/0.11  0.90  0.68  0.84  0.89  0.73\n",
      "       RS-LoRA 0.30M    0.80/0.80  0.92  0.59  0.85/0.82  0.90  0.70  0.86  0.89  0.81\n",
      "DeB-b  FFT     184.42M  0.90/0.90  0.96  0.71  0.90/0.88  0.94  0.83  0.89  0.91  0.88\n",
      "       DoRA    0.30M    0.88/0.88  0.95  0.68  0.47/0.32  0.93  0.83  0.89  0.90  0.81\n",
      "       LoRA    0.30M    0.88/0.88  0.95  0.68  0.47/0.32  0.93  0.83  0.89  0.90  0.81\n",
      "       MR-LoRA 0.30M    0.32/0.32  0.51  0.67  0.37/0.54  0.51  0.81  0.88  0.90  0.63\n",
      "       OLoRA   0.30M    0.88/0.89  0.95  0.69  0.47/0.32  0.93  0.81  0.88  0.90  0.81\n",
      "       RS-LoRA 0.30M    0.89/0.89  0.96  0.69  0.63/0.56  0.93  0.84  0.89  0.91  0.84\n",
      "RoB-b  FFT     124.65M  0.86/0.86  0.94  0.63  0.89/0.86  0.93  0.78  0.89  0.91  0.85\n",
      "       DoRA    0.89M    0.84/0.84  0.94  0.63  0.86/0.82  0.91  0.75  0.88  0.90  0.84\n",
      "       LoRA    0.89M    0.84/0.84  0.94  0.61  0.76/0.76  0.91  0.75  0.88  0.90  0.83\n",
      "       OLoRA   0.89M    0.84/0.84  0.94  0.60  0.86/0.83  0.92  0.73  0.89  0.90  0.84\n",
      "       RS-LoRA 0.89M    0.84/0.85  0.94  0.62  0.86/0.82  0.92  0.75  0.88  0.91  0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/tr0t3jp906z8k_q9pbcg_jd40000gn/T/ipykernel_43997/1840368405.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).apply(format_task_entries)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Standardize Method Names\n",
    "def get_method_name(row):\n",
    "    if row['variant'] == 'fft': return 'FFT'\n",
    "    if 'mrlora' in row['peft']:\n",
    "        return 'MR-LoRA'\n",
    "    return METHOD_NAME_MAP[row['peft']]\n",
    "\n",
    "df['Method'] = df.apply(get_method_name, axis=1)\n",
    "\n",
    "df['params'] = df.groupby(['family', 'variant', 'rank'])['params'].transform('mean')\n",
    "\n",
    "# 2. SEED AVERAGING (The \"Fix\")\n",
    "# We group by the configuration identifying columns.\n",
    "# We include 'params' here NOT as a grouper, but to average it\n",
    "# (though it should be constant across seeds).\n",
    "# We exclude 'metric' from the grouper so we can aggregate different metrics later.\n",
    "df_agged = df.groupby(\n",
    "    ['family', 'variant', 'rank', 'Method', 'task', 'metric'],\n",
    "    as_index=False\n",
    ").agg({\n",
    "    'value': 'mean',  # Performance Metric\n",
    "    'params': 'mean'  # Efficiency Metric\n",
    "})\n",
    "\n",
    "# 3. Handle Multi-Metric Tasks (MNLI, QQP, STS-B)\n",
    "def format_task_entries(group):\n",
    "    task = group['task'].iloc[0]\n",
    "    # Create a map for the averaged performance metrics\n",
    "    perf_map = dict(zip(group['metric'], group['value']))\n",
    "\n",
    "    # Take the mean of params for this group (efficiency is constant for the method)\n",
    "    avg_params = group['params'].mean()\n",
    "\n",
    "    if task == 'MNLI':\n",
    "        val = f\"{perf_map.get('m', 0):.2f}/{perf_map.get('mm', 0):.2f}\"\n",
    "        met = 'm/mm'\n",
    "    elif task == 'QQP':\n",
    "        val = f\"{perf_map.get('Acc', 0):.2f}/{perf_map.get('F1', 0):.2f}\"\n",
    "        met = 'Acc/F1'\n",
    "    elif task == 'STS-B':\n",
    "        # GLUE standard: average of Pearson and Spearman\n",
    "        avg_corr = (perf_map.get('Corr_s', 0) + perf_map.get('Corr_p', 0)) / 2\n",
    "        val, met = f\"{avg_corr:.2f}\", 'Corr'\n",
    "    else:\n",
    "        val, met = f\"{group['value'].iloc[0]:.2f}\", group['metric'].iloc[0]\n",
    "\n",
    "    return pd.Series({\n",
    "        'val': val,\n",
    "        'met': met,\n",
    "        'params': avg_params,\n",
    "        'numeric_score': group['value'].mean() # Used for 'All Ave.'\n",
    "    })\n",
    "\n",
    "# Apply the formatting logic\n",
    "df_transformed = df_agged.groupby(\n",
    "    ['family', 'variant', 'rank', 'Method', 'task'],\n",
    "    as_index=False\n",
    ").apply(format_task_entries)\n",
    "\n",
    "# 4. Calculate 'All Ave.' Column\n",
    "# Grouping by the method configuration to average performance across all tasks\n",
    "all_avg = df_transformed.groupby(\n",
    "    ['family', 'variant', 'rank', 'Method']\n",
    ").agg({\n",
    "    'numeric_score': 'mean',\n",
    "    'params': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "all_avg['task'], all_avg['met'] = 'All', 'Ave.'\n",
    "all_avg['val'] = all_avg['numeric_score'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# 5. Pivot and Final Formatting\n",
    "df_final = pd.concat([df_transformed, all_avg], ignore_index=True)\n",
    "\n",
    "# Formatting the Efficiency Metric (Params) for the Index\n",
    "df_final['# Params'] = df_final['params'].apply(format_params)\n",
    "\n",
    "pivot_df = df_final.pivot(\n",
    "    index=['family', 'variant', 'rank', 'Method', '# Params'],\n",
    "    columns=['task', 'met'],\n",
    "    values='val'\n",
    ")\n",
    "\n",
    "# Sorting and Cleaning\n",
    "pivot_df = pivot_df.sort_index(level=['family', 'variant', 'rank'], ascending=[True, True, False])\n",
    "pivot_df.index = pivot_df.index.droplevel(['variant', 'rank'])\n",
    "pivot_df.index.names = [None, None, None]\n",
    "pivot_df.columns.names = [None, None]\n",
    "\n",
    "# Column Ordering\n",
    "task_order = ['MNLI', 'SST-2', 'CoLA', 'QQP', 'QNLI', 'RTE', 'MRPC', 'STS-B', 'WNLI', 'All']\n",
    "existing_tasks = [t for t in task_order if t in pivot_df.columns.get_level_values(0)]\n",
    "pivot_df = pivot_df.reindex(columns=existing_tasks, level=0)\n",
    "\n",
    "print(pivot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
